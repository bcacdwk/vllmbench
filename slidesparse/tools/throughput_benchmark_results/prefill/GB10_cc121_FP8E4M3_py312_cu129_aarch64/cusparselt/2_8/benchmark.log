
========== M=512 ==========
Time: 2026-01-25 19:20:03
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:20:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:20:07 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=341878) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) ================================================================
(EngineCore_DP0 pid=341878) Internal Triton PTX codegen error
(EngineCore_DP0 pid=341878) `ptxas` stderr:
(EngineCore_DP0 pid=341878) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpwkbi9em3.ptx -o /tmp/tmpwkbi9em3.ptx.o
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) //
(EngineCore_DP0 pid=341878) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=341878) //
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) .version 8.7
(EngineCore_DP0 pid=341878) .target sm_121a
(EngineCore_DP0 pid=341878) .address_size 64
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=341878) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=341878)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=341878) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=341878) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=341878) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=341878) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=341878) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=341878) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=341878) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=341878) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=341878) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=341878) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=341878) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=341878) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=341878) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=341878) )
(EngineCore_DP0 pid=341878) .reqntid 1024
(EngineCore_DP0 pid=341878) {
(EngineCore_DP0 pid=341878) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=341878) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=341878) 	.reg .b32 	%r<115>;
(EngineCore_DP0 pid=341878) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=341878) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=341878) $L__func_begin0:
(EngineCore_DP0 pid=341878) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) // %bb.0:
(EngineCore_DP0 pid=341878) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=341878) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=341878) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=341878) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=341878) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=341878) $L__tmp0:
(EngineCore_DP0 pid=341878) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=341878) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=341878) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=341878) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=341878) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=341878) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=341878) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=341878) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=341878) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=341878) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=341878) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=341878) 	mov.b32 	%r113, 0f2B8CBCCC;
(EngineCore_DP0 pid=341878) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=341878) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=341878) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=341878) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=341878) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=341878) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=341878) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=341878) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=341878) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=341878) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=341878) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=341878) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=341878) 	mov.b32 	%r111, 0f00000000;
(EngineCore_DP0 pid=341878) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=341878) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=341878) 	mov.b32 	%r112, %r37;
(EngineCore_DP0 pid=341878) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=341878) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=341878) 	add.s32 	%r45, %r3, %r112;
(EngineCore_DP0 pid=341878) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=341878) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=341878) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=341878) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=341878) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=341878) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=341878) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=341878) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=341878) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=341878) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=341878) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=341878) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=341878) $L__tmp1:
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	bar.sync 	0;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=341878) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=341878) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=341878) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	bar.sync 	0;
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=341878) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=341878) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	bar.sync 	0;
(EngineCore_DP0 pid=341878) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=341878) $L__tmp2:
(EngineCore_DP0 pid=341878) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=341878) 	max.f32 	%r111, %r111, %r65;
(EngineCore_DP0 pid=341878) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=341878) 	add.s32 	%r112, %r112, 4096;
(EngineCore_DP0 pid=341878) 	setp.lt.s32 	%p6, %r112, %r18;
(EngineCore_DP0 pid=341878) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=341878) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=341878) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=341878) 	max.f32 	%r113, %r111, 0f2B8CBCCC;
(EngineCore_DP0 pid=341878) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=341878) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=341878) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=341878) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=341878) 	div.full.f32 	%r68, %r113, %r67;
(EngineCore_DP0 pid=341878) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=341878) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=341878) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=341878) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=341878) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=341878) 	mul.lo.s32 	%r14, %r19, 3;
(EngineCore_DP0 pid=341878) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=341878) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=341878) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=341878) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=341878) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=341878) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=341878) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=341878) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=341878) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=341878) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=341878) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=341878) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=341878) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=341878) 	div.full.f32 	%r13, %r67, %r113;
(EngineCore_DP0 pid=341878) 	mov.b32 	%r114, 0;
(EngineCore_DP0 pid=341878) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=341878)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=341878) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=341878) 	add.s32 	%r80, %r2, %r114;
(EngineCore_DP0 pid=341878) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=341878) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=341878) 	mul.hi.s32 	%r81, %r80, 1431655766;
(EngineCore_DP0 pid=341878) 	shr.u32 	%r82, %r81, 31;
(EngineCore_DP0 pid=341878) 	add.s32 	%r83, %r81, %r82;
(EngineCore_DP0 pid=341878) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=341878) 	mul.lo.s32 	%r84, %r83, 3;
(EngineCore_DP0 pid=341878) 	sub.s32 	%r85, %r80, %r84;
(EngineCore_DP0 pid=341878) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=341878) 	shl.b32 	%r86, %r83, 3;
(EngineCore_DP0 pid=341878) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=341878) 	shl.b32 	%r87, %r85, 1;
(EngineCore_DP0 pid=341878) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=341878) 	add.s32 	%r88, %r86, %r87;
(EngineCore_DP0 pid=341878) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=341878) 	setp.lt.s32 	%p14, %r88, %r17;
(EngineCore_DP0 pid=341878) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=341878) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=341878) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=341878) 	mad.wide.s32 	%rd8, %r88, 2, %rd1;
(EngineCore_DP0 pid=341878) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=341878) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=341878) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=341878) 	cvt.f32.bf16 	%r89, %rs12;
(EngineCore_DP0 pid=341878) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=341878) 	or.b32 	%r90, %r88, 1;
(EngineCore_DP0 pid=341878) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=341878) 	setp.lt.s32 	%p15, %r90, %r17;
(EngineCore_DP0 pid=341878) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=341878) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=341878) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=341878) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=341878) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=341878) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=341878) 	cvt.f32.bf16 	%r91, %rs14;
(EngineCore_DP0 pid=341878) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=341878) 	add.s32 	%r92, %r88, 2;
(EngineCore_DP0 pid=341878) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=341878) 	setp.lt.s32 	%p16, %r92, %r17;
(EngineCore_DP0 pid=341878) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=341878) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=341878) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=341878) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=341878) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=341878) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=341878) 	cvt.f32.bf16 	%r93, %rs16;
(EngineCore_DP0 pid=341878) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=341878) 	add.s32 	%r94, %r88, 3;
(EngineCore_DP0 pid=341878) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=341878) 	setp.lt.s32 	%p17, %r94, %r17;
(EngineCore_DP0 pid=341878) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=341878) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=341878) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=341878) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=341878) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=341878) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=341878) 	cvt.f32.bf16 	%r95, %rs18;
(EngineCore_DP0 pid=341878) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=341878) 	mul.f32 	%r96, %r13, %r89;
(EngineCore_DP0 pid=341878) 	mov.b32 	%r97, 0f43E00000;
(EngineCore_DP0 pid=341878) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=341878) 	min.xorsign.abs.f32 	%r70, %r96, %r97;
(EngineCore_DP0 pid=341878) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=341878) 	mul.f32 	%r98, %r13, %r91;
(EngineCore_DP0 pid=341878) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=341878) 	min.xorsign.abs.f32 	%r72, %r98, %r97;
(EngineCore_DP0 pid=341878) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=341878) 	mul.f32 	%r99, %r13, %r93;
(EngineCore_DP0 pid=341878) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=341878) 	min.xorsign.abs.f32 	%r74, %r99, %r97;
(EngineCore_DP0 pid=341878) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=341878) 	mul.f32 	%r100, %r13, %r95;
(EngineCore_DP0 pid=341878) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=341878) 	min.xorsign.abs.f32 	%r76, %r100, %r97;
(EngineCore_DP0 pid=341878) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=341878) 	cvt.u32.u16 	%r101, %rs20;
(EngineCore_DP0 pid=341878) 	and.b32 	%r102, %r101, 255;
(EngineCore_DP0 pid=341878) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=341878) 	cvt.u32.u16 	%r103, %rs22;
(EngineCore_DP0 pid=341878) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=341878) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=341878) 	cvt.u32.u16 	%r105, %rs23;
(EngineCore_DP0 pid=341878) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=341878) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=341878) 	mul.wide.u16 	%r106, %rs24, 256;
(EngineCore_DP0 pid=341878) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=341878) 	or.b32 	%r107, %r106, %r102;
(EngineCore_DP0 pid=341878) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=341878) 	shl.b32 	%r108, %r104, 16;
(EngineCore_DP0 pid=341878) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=341878) 	or.b32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=341878) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=341878) 	shl.b32 	%r110, %r105, 24;
(EngineCore_DP0 pid=341878) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=341878) 	or.b32 	%r78, %r109, %r110;
(EngineCore_DP0 pid=341878) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=341878) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=341878) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=341878) 	// begin inline asm
(EngineCore_DP0 pid=341878) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=341878) 	// end inline asm
(EngineCore_DP0 pid=341878) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=341878) 	add.s32 	%r114, %r114, 1024;
(EngineCore_DP0 pid=341878) 	setp.lt.s32 	%p18, %r114, %r14;
(EngineCore_DP0 pid=341878) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=341878) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=341878) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=341878) 	ret;
(EngineCore_DP0 pid=341878) $L__tmp3:
(EngineCore_DP0 pid=341878) $L__func_end0:
(EngineCore_DP0 pid=341878)                                         // -- End function
(EngineCore_DP0 pid=341878) }
(EngineCore_DP0 pid=341878) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=341878) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=341878) 	.section	.debug_abbrev
(EngineCore_DP0 pid=341878) 	{
(EngineCore_DP0 pid=341878) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=341878) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=341878) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=341878) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=341878) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=341878) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=341878) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=341878) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=341878) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=341878) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=341878) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=341878) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=341878) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=341878) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=341878) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=341878) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=341878) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=341878) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=341878) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=341878) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=341878) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=341878) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=341878) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=341878) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=341878) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=341878) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=341878) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=341878) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=341878) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=341878) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=341878) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=341878) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=341878) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=341878) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=341878) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=341878) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=341878) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=341878) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=341878) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=341878) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=341878) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=341878) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=341878) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=341878) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=341878) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=341878) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=341878) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=341878) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=341878) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=341878) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=341878) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=341878) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=341878) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=341878) 	}
(EngineCore_DP0 pid=341878) 	.section	.debug_info
(EngineCore_DP0 pid=341878) 	{
(EngineCore_DP0 pid=341878) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=341878) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=341878) .b8 0
(EngineCore_DP0 pid=341878) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=341878) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=341878) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=341878) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=341878) .b8 114
(EngineCore_DP0 pid=341878) .b8 105
(EngineCore_DP0 pid=341878) .b8 116
(EngineCore_DP0 pid=341878) .b8 111
(EngineCore_DP0 pid=341878) .b8 110
(EngineCore_DP0 pid=341878) .b8 0
(EngineCore_DP0 pid=341878) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=341878) .b8 0
(EngineCore_DP0 pid=341878) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=341878) .b8 117
(EngineCore_DP0 pid=341878) .b8 97
(EngineCore_DP0 pid=341878) .b8 110
(EngineCore_DP0 pid=341878) .b8 116
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 115
(EngineCore_DP0 pid=341878) .b8 108
(EngineCore_DP0 pid=341878) .b8 105
(EngineCore_DP0 pid=341878) .b8 100
(EngineCore_DP0 pid=341878) .b8 101
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 116
(EngineCore_DP0 pid=341878) .b8 117
(EngineCore_DP0 pid=341878) .b8 110
(EngineCore_DP0 pid=341878) .b8 101
(EngineCore_DP0 pid=341878) .b8 100
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 76
(EngineCore_DP0 pid=341878) .b8 108
(EngineCore_DP0 pid=341878) .b8 97
(EngineCore_DP0 pid=341878) .b8 109
(EngineCore_DP0 pid=341878) .b8 97
(EngineCore_DP0 pid=341878) .b8 51
(EngineCore_DP0 pid=341878) .b8 46
(EngineCore_DP0 pid=341878) .b8 50
(EngineCore_DP0 pid=341878) .b8 45
(EngineCore_DP0 pid=341878) .b8 49
(EngineCore_DP0 pid=341878) .b8 66
(EngineCore_DP0 pid=341878) .b8 46
(EngineCore_DP0 pid=341878) .b8 112
(EngineCore_DP0 pid=341878) .b8 121
(EngineCore_DP0 pid=341878) .b8 0
(EngineCore_DP0 pid=341878) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=341878) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=341878) .b8 114
(EngineCore_DP0 pid=341878) .b8 111
(EngineCore_DP0 pid=341878) .b8 111
(EngineCore_DP0 pid=341878) .b8 116
(EngineCore_DP0 pid=341878) .b8 47
(EngineCore_DP0 pid=341878) .b8 118
(EngineCore_DP0 pid=341878) .b8 108
(EngineCore_DP0 pid=341878) .b8 108
(EngineCore_DP0 pid=341878) .b8 109
(EngineCore_DP0 pid=341878) .b8 98
(EngineCore_DP0 pid=341878) .b8 101
(EngineCore_DP0 pid=341878) .b8 110
(EngineCore_DP0 pid=341878) .b8 99
(EngineCore_DP0 pid=341878) .b8 104
(EngineCore_DP0 pid=341878) .b8 47
(EngineCore_DP0 pid=341878) .b8 115
(EngineCore_DP0 pid=341878) .b8 108
(EngineCore_DP0 pid=341878) .b8 105
(EngineCore_DP0 pid=341878) .b8 100
(EngineCore_DP0 pid=341878) .b8 101
(EngineCore_DP0 pid=341878) .b8 115
(EngineCore_DP0 pid=341878) .b8 112
(EngineCore_DP0 pid=341878) .b8 97
(EngineCore_DP0 pid=341878) .b8 114
(EngineCore_DP0 pid=341878) .b8 115
(EngineCore_DP0 pid=341878) .b8 101
(EngineCore_DP0 pid=341878) .b8 47
(EngineCore_DP0 pid=341878) .b8 99
(EngineCore_DP0 pid=341878) .b8 115
(EngineCore_DP0 pid=341878) .b8 114
(EngineCore_DP0 pid=341878) .b8 99
(EngineCore_DP0 pid=341878) .b8 47
(EngineCore_DP0 pid=341878) .b8 102
(EngineCore_DP0 pid=341878) .b8 117
(EngineCore_DP0 pid=341878) .b8 115
(EngineCore_DP0 pid=341878) .b8 101
(EngineCore_DP0 pid=341878) .b8 100
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 113
(EngineCore_DP0 pid=341878) .b8 117
(EngineCore_DP0 pid=341878) .b8 97
(EngineCore_DP0 pid=341878) .b8 110
(EngineCore_DP0 pid=341878) .b8 116
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 115
(EngineCore_DP0 pid=341878) .b8 108
(EngineCore_DP0 pid=341878) .b8 105
(EngineCore_DP0 pid=341878) .b8 100
(EngineCore_DP0 pid=341878) .b8 101
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 116
(EngineCore_DP0 pid=341878) .b8 114
(EngineCore_DP0 pid=341878) .b8 105
(EngineCore_DP0 pid=341878) .b8 116
(EngineCore_DP0 pid=341878) .b8 111
(EngineCore_DP0 pid=341878) .b8 110
(EngineCore_DP0 pid=341878) .b8 47
(EngineCore_DP0 pid=341878) .b8 98
(EngineCore_DP0 pid=341878) .b8 117
(EngineCore_DP0 pid=341878) .b8 105
(EngineCore_DP0 pid=341878) .b8 108
(EngineCore_DP0 pid=341878) .b8 100
(EngineCore_DP0 pid=341878) .b8 47
(EngineCore_DP0 pid=341878) .b8 71
(EngineCore_DP0 pid=341878) .b8 66
(EngineCore_DP0 pid=341878) .b8 49
(EngineCore_DP0 pid=341878) .b8 48
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 99
(EngineCore_DP0 pid=341878) .b8 99
(EngineCore_DP0 pid=341878) .b8 49
(EngineCore_DP0 pid=341878) .b8 50
(EngineCore_DP0 pid=341878) .b8 49
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 112
(EngineCore_DP0 pid=341878) .b8 121
(EngineCore_DP0 pid=341878) .b8 51
(EngineCore_DP0 pid=341878) .b8 49
(EngineCore_DP0 pid=341878) .b8 50
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 99
(EngineCore_DP0 pid=341878) .b8 117
(EngineCore_DP0 pid=341878) .b8 49
(EngineCore_DP0 pid=341878) .b8 50
(EngineCore_DP0 pid=341878) .b8 57
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 97
(EngineCore_DP0 pid=341878) .b8 97
(EngineCore_DP0 pid=341878) .b8 114
(EngineCore_DP0 pid=341878) .b8 99
(EngineCore_DP0 pid=341878) .b8 104
(EngineCore_DP0 pid=341878) .b8 54
(EngineCore_DP0 pid=341878) .b8 52
(EngineCore_DP0 pid=341878) .b8 0
(EngineCore_DP0 pid=341878) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=341878) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=341878) .b8 113
(EngineCore_DP0 pid=341878) .b8 117
(EngineCore_DP0 pid=341878) .b8 97
(EngineCore_DP0 pid=341878) .b8 110
(EngineCore_DP0 pid=341878) .b8 116
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 115
(EngineCore_DP0 pid=341878) .b8 108
(EngineCore_DP0 pid=341878) .b8 105
(EngineCore_DP0 pid=341878) .b8 100
(EngineCore_DP0 pid=341878) .b8 101
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 102
(EngineCore_DP0 pid=341878) .b8 112
(EngineCore_DP0 pid=341878) .b8 56
(EngineCore_DP0 pid=341878) .b8 95
(EngineCore_DP0 pid=341878) .b8 107
(EngineCore_DP0 pid=341878) .b8 101
(EngineCore_DP0 pid=341878) .b8 114
(EngineCore_DP0 pid=341878) .b8 110
(EngineCore_DP0 pid=341878) .b8 101
(EngineCore_DP0 pid=341878) .b8 108
(EngineCore_DP0 pid=341878) .b8 0
(EngineCore_DP0 pid=341878) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=341878) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=341878) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=341878) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=341878) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=341878) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=341878) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=341878) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=341878) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=341878) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=341878) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=341878) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=341878) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=341878) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=341878) 	}
(EngineCore_DP0 pid=341878) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) ================================================================
(EngineCore_DP0 pid=341878) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpwkbi9em3.ptx', '-o', '/tmp/tmpwkbi9em3.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] 
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] 
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] 
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpwkbi9em3.ptx -o /tmp/tmpwkbi9em3.ptx.o
(EngineCore_DP0 pid=341878) ERROR 01-25 19:20:23 [core.py:866] 

STDERR:
[2026-01-25 19:20:06] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:20:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:06] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:20:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:20:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:20:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:20:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:20:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:20:10] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:20:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:10] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:20:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:20:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:20:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:20:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:20:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:11] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:11] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:11] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:11] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:11] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=341878) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=341878) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.98s/it]
(EngineCore_DP0 pid=341878) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.98s/it]
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=341878) [2026-01-25 19:20:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=341878) Process EngineCore_DP0:
(EngineCore_DP0 pid=341878) Traceback (most recent call last):
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=341878)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=341878)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=341878)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=341878) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpwkbi9em3.ptx', '-o', '/tmp/tmpwkbi9em3.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) Traceback (most recent call last):
(EngineCore_DP0 pid=341878)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=341878)     self.run()
(EngineCore_DP0 pid=341878)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=341878)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=341878)     raise e
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=341878)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=341878)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=341878)     super().__init__(
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=341878)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=341878)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=341878)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=341878)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=341878)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=341878)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=341878)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=341878)     return func(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=341878)     return func(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=341878)     self.model_runner.profile_run()
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=341878)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=341878)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=341878)     return func(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=341878)     outputs = self.model(
(EngineCore_DP0 pid=341878)               ^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341878)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341878)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=341878)     model_output = self.model(
(EngineCore_DP0 pid=341878)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=341878)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=341878)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=341878)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341878)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341878)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=341878)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=341878)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341878)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341878)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=341878)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=341878)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=341878)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=341878)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=341878)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=341878)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=341878)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=341878)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=341878)     return self._linear_fn(
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=341878)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=341878)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=341878)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=341878)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=341878)     return fn(input, L)
(EngineCore_DP0 pid=341878)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=341878)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=341878)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=341878)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=341878)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=341878)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=341878)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=341878)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=341878)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=341878)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=341878)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=341878)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=341878)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=341878)     raise PTXASError(error)
(EngineCore_DP0 pid=341878) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=341878) `ptxas` stderr:
(EngineCore_DP0 pid=341878) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=341878) 
(EngineCore_DP0 pid=341878) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpwkbi9em3.ptx -o /tmp/tmpwkbi9em3.ptx.o
(EngineCore_DP0 pid=341878) 
[rank0]:[W125 19:20:24.183241552 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 19:20:25
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:20:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:20:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=342362) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) ================================================================
(EngineCore_DP0 pid=342362) Internal Triton PTX codegen error
(EngineCore_DP0 pid=342362) `ptxas` stderr:
(EngineCore_DP0 pid=342362) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp05vt6wm3.ptx -o /tmp/tmp05vt6wm3.ptx.o
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) //
(EngineCore_DP0 pid=342362) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=342362) //
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) .version 8.7
(EngineCore_DP0 pid=342362) .target sm_121a
(EngineCore_DP0 pid=342362) .address_size 64
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=342362) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=342362)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=342362) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=342362) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=342362) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=342362) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=342362) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=342362) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=342362) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=342362) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=342362) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=342362) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=342362) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=342362) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=342362) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=342362) )
(EngineCore_DP0 pid=342362) .reqntid 512
(EngineCore_DP0 pid=342362) {
(EngineCore_DP0 pid=342362) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=342362) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=342362) 	.reg .b32 	%r<127>;
(EngineCore_DP0 pid=342362) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=342362) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=342362) $L__func_begin0:
(EngineCore_DP0 pid=342362) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) // %bb.0:
(EngineCore_DP0 pid=342362) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=342362) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=342362) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=342362) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=342362) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=342362) $L__tmp0:
(EngineCore_DP0 pid=342362) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=342362) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=342362) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=342362) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=342362) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=342362) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=342362) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=342362) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=342362) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=342362) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=342362) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=342362) 	mov.b32 	%r125, 0f2B8CBCCC;
(EngineCore_DP0 pid=342362) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=342362) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=342362) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=342362) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=342362) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=342362) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=342362) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=342362) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=342362) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=342362) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=342362) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=342362) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=342362) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=342362) 	mov.b32 	%r123, 0f00000000;
(EngineCore_DP0 pid=342362) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=342362) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=342362) 	mov.b32 	%r124, %r40;
(EngineCore_DP0 pid=342362) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=342362) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=342362) 	add.s32 	%r58, %r4, %r124;
(EngineCore_DP0 pid=342362) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=342362) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=342362) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=342362) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=342362) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=342362) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=342362) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=342362) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=342362) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=342362) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=342362) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=342362) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=342362) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=342362) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=342362) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=342362) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=342362) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=342362) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=342362) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=342362) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=342362) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=342362) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=342362) $L__tmp1:
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	bar.sync 	0;
(EngineCore_DP0 pid=342362) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=342362) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=342362) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=342362) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=342362) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=342362) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=342362) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=342362) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	bar.sync 	0;
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=342362) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=342362) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=342362) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=342362) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=342362) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	bar.sync 	0;
(EngineCore_DP0 pid=342362) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=342362) $L__tmp2:
(EngineCore_DP0 pid=342362) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=342362) 	max.f32 	%r123, %r123, %r77;
(EngineCore_DP0 pid=342362) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=342362) 	add.s32 	%r124, %r124, 8192;
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p7, %r124, %r19;
(EngineCore_DP0 pid=342362) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=342362) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=342362) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=342362) 	max.f32 	%r125, %r123, 0f2B8CBCCC;
(EngineCore_DP0 pid=342362) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=342362) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=342362) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=342362) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=342362) 	div.full.f32 	%r80, %r125, %r79;
(EngineCore_DP0 pid=342362) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=342362) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=342362) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=342362) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=342362) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=342362) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=342362) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=342362) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=342362) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=342362) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=342362) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=342362) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=342362) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=342362) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=342362) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=342362) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=342362) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=342362) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=342362) 	div.full.f32 	%r14, %r79, %r125;
(EngineCore_DP0 pid=342362) 	mov.b32 	%r126, 0;
(EngineCore_DP0 pid=342362) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=342362)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=342362) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=342362) 	add.s32 	%r92, %r3, %r126;
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=342362) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=342362) 	mul.hi.s32 	%r93, %r92, 1431655766;
(EngineCore_DP0 pid=342362) 	shr.u32 	%r94, %r93, 31;
(EngineCore_DP0 pid=342362) 	add.s32 	%r95, %r93, %r94;
(EngineCore_DP0 pid=342362) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=342362) 	mul.lo.s32 	%r96, %r95, 3;
(EngineCore_DP0 pid=342362) 	sub.s32 	%r97, %r92, %r96;
(EngineCore_DP0 pid=342362) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=342362) 	shl.b32 	%r98, %r95, 3;
(EngineCore_DP0 pid=342362) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=342362) 	shl.b32 	%r99, %r97, 1;
(EngineCore_DP0 pid=342362) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=342362) 	add.s32 	%r100, %r98, %r99;
(EngineCore_DP0 pid=342362) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p15, %r100, %r18;
(EngineCore_DP0 pid=342362) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=342362) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=342362) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=342362) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=342362) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=342362) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=342362) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=342362) 	cvt.f32.bf16 	%r101, %rs48;
(EngineCore_DP0 pid=342362) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=342362) 	or.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=342362) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p16, %r102, %r18;
(EngineCore_DP0 pid=342362) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=342362) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=342362) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=342362) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=342362) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=342362) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=342362) 	cvt.f32.bf16 	%r103, %rs50;
(EngineCore_DP0 pid=342362) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=342362) 	add.s32 	%r104, %r100, 2;
(EngineCore_DP0 pid=342362) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p17, %r104, %r18;
(EngineCore_DP0 pid=342362) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=342362) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=342362) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=342362) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=342362) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=342362) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=342362) 	cvt.f32.bf16 	%r105, %rs52;
(EngineCore_DP0 pid=342362) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=342362) 	add.s32 	%r106, %r100, 3;
(EngineCore_DP0 pid=342362) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p18, %r106, %r18;
(EngineCore_DP0 pid=342362) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=342362) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=342362) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=342362) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=342362) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=342362) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=342362) 	cvt.f32.bf16 	%r107, %rs54;
(EngineCore_DP0 pid=342362) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=342362) 	mul.f32 	%r108, %r14, %r101;
(EngineCore_DP0 pid=342362) 	mov.b32 	%r109, 0f43E00000;
(EngineCore_DP0 pid=342362) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=342362) 	min.xorsign.abs.f32 	%r82, %r108, %r109;
(EngineCore_DP0 pid=342362) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=342362) 	mul.f32 	%r110, %r14, %r103;
(EngineCore_DP0 pid=342362) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=342362) 	min.xorsign.abs.f32 	%r84, %r110, %r109;
(EngineCore_DP0 pid=342362) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=342362) 	mul.f32 	%r111, %r14, %r105;
(EngineCore_DP0 pid=342362) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=342362) 	min.xorsign.abs.f32 	%r86, %r111, %r109;
(EngineCore_DP0 pid=342362) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=342362) 	mul.f32 	%r112, %r14, %r107;
(EngineCore_DP0 pid=342362) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=342362) 	min.xorsign.abs.f32 	%r88, %r112, %r109;
(EngineCore_DP0 pid=342362) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=342362) 	cvt.u32.u16 	%r113, %rs56;
(EngineCore_DP0 pid=342362) 	and.b32 	%r114, %r113, 255;
(EngineCore_DP0 pid=342362) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=342362) 	cvt.u32.u16 	%r115, %rs58;
(EngineCore_DP0 pid=342362) 	and.b32 	%r116, %r115, 255;
(EngineCore_DP0 pid=342362) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=342362) 	cvt.u32.u16 	%r117, %rs59;
(EngineCore_DP0 pid=342362) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=342362) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=342362) 	mul.wide.u16 	%r118, %rs60, 256;
(EngineCore_DP0 pid=342362) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=342362) 	or.b32 	%r119, %r118, %r114;
(EngineCore_DP0 pid=342362) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=342362) 	shl.b32 	%r120, %r116, 16;
(EngineCore_DP0 pid=342362) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=342362) 	or.b32 	%r121, %r119, %r120;
(EngineCore_DP0 pid=342362) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=342362) 	shl.b32 	%r122, %r117, 24;
(EngineCore_DP0 pid=342362) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=342362) 	or.b32 	%r90, %r121, %r122;
(EngineCore_DP0 pid=342362) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=342362) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=342362) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=342362) 	// begin inline asm
(EngineCore_DP0 pid=342362) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=342362) 	// end inline asm
(EngineCore_DP0 pid=342362) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=342362) 	add.s32 	%r126, %r126, 512;
(EngineCore_DP0 pid=342362) 	setp.lt.s32 	%p19, %r126, %r15;
(EngineCore_DP0 pid=342362) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=342362) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=342362) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=342362) 	ret;
(EngineCore_DP0 pid=342362) $L__tmp3:
(EngineCore_DP0 pid=342362) $L__func_end0:
(EngineCore_DP0 pid=342362)                                         // -- End function
(EngineCore_DP0 pid=342362) }
(EngineCore_DP0 pid=342362) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=342362) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=342362) 	.section	.debug_abbrev
(EngineCore_DP0 pid=342362) 	{
(EngineCore_DP0 pid=342362) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=342362) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=342362) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=342362) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=342362) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=342362) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=342362) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=342362) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=342362) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=342362) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=342362) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=342362) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=342362) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=342362) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=342362) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=342362) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=342362) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=342362) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=342362) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=342362) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=342362) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=342362) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=342362) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=342362) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=342362) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=342362) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=342362) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=342362) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=342362) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=342362) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=342362) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=342362) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=342362) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=342362) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=342362) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=342362) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=342362) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=342362) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=342362) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=342362) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=342362) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=342362) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=342362) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=342362) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=342362) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=342362) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=342362) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=342362) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=342362) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=342362) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=342362) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=342362) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=342362) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=342362) 	}
(EngineCore_DP0 pid=342362) 	.section	.debug_info
(EngineCore_DP0 pid=342362) 	{
(EngineCore_DP0 pid=342362) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=342362) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=342362) .b8 0
(EngineCore_DP0 pid=342362) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=342362) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=342362) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=342362) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=342362) .b8 114
(EngineCore_DP0 pid=342362) .b8 105
(EngineCore_DP0 pid=342362) .b8 116
(EngineCore_DP0 pid=342362) .b8 111
(EngineCore_DP0 pid=342362) .b8 110
(EngineCore_DP0 pid=342362) .b8 0
(EngineCore_DP0 pid=342362) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=342362) .b8 0
(EngineCore_DP0 pid=342362) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=342362) .b8 117
(EngineCore_DP0 pid=342362) .b8 97
(EngineCore_DP0 pid=342362) .b8 110
(EngineCore_DP0 pid=342362) .b8 116
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 115
(EngineCore_DP0 pid=342362) .b8 108
(EngineCore_DP0 pid=342362) .b8 105
(EngineCore_DP0 pid=342362) .b8 100
(EngineCore_DP0 pid=342362) .b8 101
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 116
(EngineCore_DP0 pid=342362) .b8 117
(EngineCore_DP0 pid=342362) .b8 110
(EngineCore_DP0 pid=342362) .b8 101
(EngineCore_DP0 pid=342362) .b8 100
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 76
(EngineCore_DP0 pid=342362) .b8 108
(EngineCore_DP0 pid=342362) .b8 97
(EngineCore_DP0 pid=342362) .b8 109
(EngineCore_DP0 pid=342362) .b8 97
(EngineCore_DP0 pid=342362) .b8 51
(EngineCore_DP0 pid=342362) .b8 46
(EngineCore_DP0 pid=342362) .b8 50
(EngineCore_DP0 pid=342362) .b8 45
(EngineCore_DP0 pid=342362) .b8 49
(EngineCore_DP0 pid=342362) .b8 66
(EngineCore_DP0 pid=342362) .b8 46
(EngineCore_DP0 pid=342362) .b8 112
(EngineCore_DP0 pid=342362) .b8 121
(EngineCore_DP0 pid=342362) .b8 0
(EngineCore_DP0 pid=342362) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=342362) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=342362) .b8 114
(EngineCore_DP0 pid=342362) .b8 111
(EngineCore_DP0 pid=342362) .b8 111
(EngineCore_DP0 pid=342362) .b8 116
(EngineCore_DP0 pid=342362) .b8 47
(EngineCore_DP0 pid=342362) .b8 118
(EngineCore_DP0 pid=342362) .b8 108
(EngineCore_DP0 pid=342362) .b8 108
(EngineCore_DP0 pid=342362) .b8 109
(EngineCore_DP0 pid=342362) .b8 98
(EngineCore_DP0 pid=342362) .b8 101
(EngineCore_DP0 pid=342362) .b8 110
(EngineCore_DP0 pid=342362) .b8 99
(EngineCore_DP0 pid=342362) .b8 104
(EngineCore_DP0 pid=342362) .b8 47
(EngineCore_DP0 pid=342362) .b8 115
(EngineCore_DP0 pid=342362) .b8 108
(EngineCore_DP0 pid=342362) .b8 105
(EngineCore_DP0 pid=342362) .b8 100
(EngineCore_DP0 pid=342362) .b8 101
(EngineCore_DP0 pid=342362) .b8 115
(EngineCore_DP0 pid=342362) .b8 112
(EngineCore_DP0 pid=342362) .b8 97
(EngineCore_DP0 pid=342362) .b8 114
(EngineCore_DP0 pid=342362) .b8 115
(EngineCore_DP0 pid=342362) .b8 101
(EngineCore_DP0 pid=342362) .b8 47
(EngineCore_DP0 pid=342362) .b8 99
(EngineCore_DP0 pid=342362) .b8 115
(EngineCore_DP0 pid=342362) .b8 114
(EngineCore_DP0 pid=342362) .b8 99
(EngineCore_DP0 pid=342362) .b8 47
(EngineCore_DP0 pid=342362) .b8 102
(EngineCore_DP0 pid=342362) .b8 117
(EngineCore_DP0 pid=342362) .b8 115
(EngineCore_DP0 pid=342362) .b8 101
(EngineCore_DP0 pid=342362) .b8 100
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 113
(EngineCore_DP0 pid=342362) .b8 117
(EngineCore_DP0 pid=342362) .b8 97
(EngineCore_DP0 pid=342362) .b8 110
(EngineCore_DP0 pid=342362) .b8 116
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 115
(EngineCore_DP0 pid=342362) .b8 108
(EngineCore_DP0 pid=342362) .b8 105
(EngineCore_DP0 pid=342362) .b8 100
(EngineCore_DP0 pid=342362) .b8 101
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 116
(EngineCore_DP0 pid=342362) .b8 114
(EngineCore_DP0 pid=342362) .b8 105
(EngineCore_DP0 pid=342362) .b8 116
(EngineCore_DP0 pid=342362) .b8 111
(EngineCore_DP0 pid=342362) .b8 110
(EngineCore_DP0 pid=342362) .b8 47
(EngineCore_DP0 pid=342362) .b8 98
(EngineCore_DP0 pid=342362) .b8 117
(EngineCore_DP0 pid=342362) .b8 105
(EngineCore_DP0 pid=342362) .b8 108
(EngineCore_DP0 pid=342362) .b8 100
(EngineCore_DP0 pid=342362) .b8 47
(EngineCore_DP0 pid=342362) .b8 71
(EngineCore_DP0 pid=342362) .b8 66
(EngineCore_DP0 pid=342362) .b8 49
(EngineCore_DP0 pid=342362) .b8 48
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 99
(EngineCore_DP0 pid=342362) .b8 99
(EngineCore_DP0 pid=342362) .b8 49
(EngineCore_DP0 pid=342362) .b8 50
(EngineCore_DP0 pid=342362) .b8 49
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 112
(EngineCore_DP0 pid=342362) .b8 121
(EngineCore_DP0 pid=342362) .b8 51
(EngineCore_DP0 pid=342362) .b8 49
(EngineCore_DP0 pid=342362) .b8 50
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 99
(EngineCore_DP0 pid=342362) .b8 117
(EngineCore_DP0 pid=342362) .b8 49
(EngineCore_DP0 pid=342362) .b8 50
(EngineCore_DP0 pid=342362) .b8 57
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 97
(EngineCore_DP0 pid=342362) .b8 97
(EngineCore_DP0 pid=342362) .b8 114
(EngineCore_DP0 pid=342362) .b8 99
(EngineCore_DP0 pid=342362) .b8 104
(EngineCore_DP0 pid=342362) .b8 54
(EngineCore_DP0 pid=342362) .b8 52
(EngineCore_DP0 pid=342362) .b8 0
(EngineCore_DP0 pid=342362) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=342362) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=342362) .b8 113
(EngineCore_DP0 pid=342362) .b8 117
(EngineCore_DP0 pid=342362) .b8 97
(EngineCore_DP0 pid=342362) .b8 110
(EngineCore_DP0 pid=342362) .b8 116
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 115
(EngineCore_DP0 pid=342362) .b8 108
(EngineCore_DP0 pid=342362) .b8 105
(EngineCore_DP0 pid=342362) .b8 100
(EngineCore_DP0 pid=342362) .b8 101
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 102
(EngineCore_DP0 pid=342362) .b8 112
(EngineCore_DP0 pid=342362) .b8 56
(EngineCore_DP0 pid=342362) .b8 95
(EngineCore_DP0 pid=342362) .b8 107
(EngineCore_DP0 pid=342362) .b8 101
(EngineCore_DP0 pid=342362) .b8 114
(EngineCore_DP0 pid=342362) .b8 110
(EngineCore_DP0 pid=342362) .b8 101
(EngineCore_DP0 pid=342362) .b8 108
(EngineCore_DP0 pid=342362) .b8 0
(EngineCore_DP0 pid=342362) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=342362) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=342362) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=342362) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=342362) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=342362) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=342362) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=342362) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=342362) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=342362) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=342362) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=342362) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=342362) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=342362) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=342362) 	}
(EngineCore_DP0 pid=342362) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) ================================================================
(EngineCore_DP0 pid=342362) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp05vt6wm3.ptx', '-o', '/tmp/tmp05vt6wm3.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] 
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] 
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] 
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp05vt6wm3.ptx -o /tmp/tmp05vt6wm3.ptx.o
(EngineCore_DP0 pid=342362) ERROR 01-25 19:20:46 [core.py:866] 

STDERR:
[2026-01-25 19:20:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:20:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:20:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:20:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:20:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:20:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:20:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:20:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:20:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:20:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:20:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:20:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:20:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:20:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:33] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:33] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:33] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:33] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:33] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=342362) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=342362) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.93s/it]
(EngineCore_DP0 pid=342362) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.93s/it]
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=342362) [2026-01-25 19:20:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=342362) Process EngineCore_DP0:
(EngineCore_DP0 pid=342362) Traceback (most recent call last):
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=342362)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=342362)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=342362)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=342362) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp05vt6wm3.ptx', '-o', '/tmp/tmp05vt6wm3.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) Traceback (most recent call last):
(EngineCore_DP0 pid=342362)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=342362)     self.run()
(EngineCore_DP0 pid=342362)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=342362)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=342362)     raise e
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=342362)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=342362)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=342362)     super().__init__(
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=342362)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=342362)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=342362)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=342362)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=342362)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=342362)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=342362)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=342362)     return func(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=342362)     return func(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=342362)     self.model_runner.profile_run()
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=342362)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=342362)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=342362)     return func(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=342362)     outputs = self.model(
(EngineCore_DP0 pid=342362)               ^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342362)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342362)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=342362)     model_output = self.model(
(EngineCore_DP0 pid=342362)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=342362)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=342362)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=342362)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342362)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342362)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=342362)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=342362)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342362)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342362)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=342362)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=342362)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342362)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342362)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=342362)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=342362)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=342362)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=342362)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=342362)     return self._linear_fn(
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=342362)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=342362)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=342362)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=342362)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=342362)     return fn(input, L)
(EngineCore_DP0 pid=342362)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=342362)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=342362)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=342362)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=342362)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=342362)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=342362)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=342362)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=342362)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=342362)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=342362)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=342362)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342362)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=342362)     raise PTXASError(error)
(EngineCore_DP0 pid=342362) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=342362) `ptxas` stderr:
(EngineCore_DP0 pid=342362) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=342362) 
(EngineCore_DP0 pid=342362) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp05vt6wm3.ptx -o /tmp/tmp05vt6wm3.ptx.o
(EngineCore_DP0 pid=342362) 
[rank0]:[W125 19:20:46.610998073 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 19:20:48
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:20:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:20:52 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=342882) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) ================================================================
(EngineCore_DP0 pid=342882) Internal Triton PTX codegen error
(EngineCore_DP0 pid=342882) `ptxas` stderr:
(EngineCore_DP0 pid=342882) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8cglrs1w.ptx -o /tmp/tmp8cglrs1w.ptx.o
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) //
(EngineCore_DP0 pid=342882) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=342882) //
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) .version 8.7
(EngineCore_DP0 pid=342882) .target sm_121a
(EngineCore_DP0 pid=342882) .address_size 64
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=342882) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=342882)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=342882) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=342882) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=342882) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=342882) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=342882) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=342882) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=342882) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=342882) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=342882) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=342882) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=342882) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=342882) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=342882) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=342882) )
(EngineCore_DP0 pid=342882) .reqntid 512
(EngineCore_DP0 pid=342882) {
(EngineCore_DP0 pid=342882) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=342882) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=342882) 	.reg .b32 	%r<127>;
(EngineCore_DP0 pid=342882) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=342882) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=342882) $L__func_begin0:
(EngineCore_DP0 pid=342882) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) // %bb.0:
(EngineCore_DP0 pid=342882) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=342882) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=342882) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=342882) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=342882) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=342882) $L__tmp0:
(EngineCore_DP0 pid=342882) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=342882) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=342882) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=342882) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=342882) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=342882) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=342882) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=342882) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=342882) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=342882) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=342882) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=342882) 	mov.b32 	%r125, 0f2B8CBCCC;
(EngineCore_DP0 pid=342882) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=342882) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=342882) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=342882) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=342882) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=342882) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=342882) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=342882) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=342882) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=342882) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=342882) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=342882) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=342882) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=342882) 	mov.b32 	%r123, 0f00000000;
(EngineCore_DP0 pid=342882) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=342882) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=342882) 	mov.b32 	%r124, %r40;
(EngineCore_DP0 pid=342882) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=342882) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=342882) 	add.s32 	%r58, %r4, %r124;
(EngineCore_DP0 pid=342882) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=342882) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=342882) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=342882) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=342882) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=342882) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=342882) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=342882) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=342882) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=342882) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=342882) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=342882) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=342882) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=342882) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=342882) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=342882) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=342882) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=342882) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=342882) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=342882) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=342882) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=342882) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=342882) $L__tmp1:
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	bar.sync 	0;
(EngineCore_DP0 pid=342882) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=342882) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=342882) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=342882) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=342882) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=342882) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=342882) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=342882) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	bar.sync 	0;
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=342882) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=342882) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=342882) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=342882) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=342882) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	bar.sync 	0;
(EngineCore_DP0 pid=342882) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=342882) $L__tmp2:
(EngineCore_DP0 pid=342882) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=342882) 	max.f32 	%r123, %r123, %r77;
(EngineCore_DP0 pid=342882) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=342882) 	add.s32 	%r124, %r124, 8192;
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p7, %r124, %r19;
(EngineCore_DP0 pid=342882) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=342882) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=342882) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=342882) 	max.f32 	%r125, %r123, 0f2B8CBCCC;
(EngineCore_DP0 pid=342882) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=342882) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=342882) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=342882) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=342882) 	div.full.f32 	%r80, %r125, %r79;
(EngineCore_DP0 pid=342882) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=342882) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=342882) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=342882) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=342882) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=342882) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=342882) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=342882) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=342882) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=342882) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=342882) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=342882) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=342882) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=342882) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=342882) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=342882) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=342882) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=342882) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=342882) 	div.full.f32 	%r14, %r79, %r125;
(EngineCore_DP0 pid=342882) 	mov.b32 	%r126, 0;
(EngineCore_DP0 pid=342882) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=342882)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=342882) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=342882) 	add.s32 	%r92, %r3, %r126;
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=342882) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=342882) 	mul.hi.s32 	%r93, %r92, 1431655766;
(EngineCore_DP0 pid=342882) 	shr.u32 	%r94, %r93, 31;
(EngineCore_DP0 pid=342882) 	add.s32 	%r95, %r93, %r94;
(EngineCore_DP0 pid=342882) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=342882) 	mul.lo.s32 	%r96, %r95, 3;
(EngineCore_DP0 pid=342882) 	sub.s32 	%r97, %r92, %r96;
(EngineCore_DP0 pid=342882) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=342882) 	shl.b32 	%r98, %r95, 3;
(EngineCore_DP0 pid=342882) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=342882) 	shl.b32 	%r99, %r97, 1;
(EngineCore_DP0 pid=342882) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=342882) 	add.s32 	%r100, %r98, %r99;
(EngineCore_DP0 pid=342882) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p15, %r100, %r18;
(EngineCore_DP0 pid=342882) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=342882) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=342882) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=342882) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=342882) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=342882) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=342882) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=342882) 	cvt.f32.bf16 	%r101, %rs48;
(EngineCore_DP0 pid=342882) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=342882) 	or.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=342882) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p16, %r102, %r18;
(EngineCore_DP0 pid=342882) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=342882) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=342882) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=342882) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=342882) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=342882) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=342882) 	cvt.f32.bf16 	%r103, %rs50;
(EngineCore_DP0 pid=342882) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=342882) 	add.s32 	%r104, %r100, 2;
(EngineCore_DP0 pid=342882) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p17, %r104, %r18;
(EngineCore_DP0 pid=342882) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=342882) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=342882) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=342882) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=342882) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=342882) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=342882) 	cvt.f32.bf16 	%r105, %rs52;
(EngineCore_DP0 pid=342882) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=342882) 	add.s32 	%r106, %r100, 3;
(EngineCore_DP0 pid=342882) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p18, %r106, %r18;
(EngineCore_DP0 pid=342882) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=342882) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=342882) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=342882) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=342882) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=342882) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=342882) 	cvt.f32.bf16 	%r107, %rs54;
(EngineCore_DP0 pid=342882) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=342882) 	mul.f32 	%r108, %r14, %r101;
(EngineCore_DP0 pid=342882) 	mov.b32 	%r109, 0f43E00000;
(EngineCore_DP0 pid=342882) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=342882) 	min.xorsign.abs.f32 	%r82, %r108, %r109;
(EngineCore_DP0 pid=342882) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=342882) 	mul.f32 	%r110, %r14, %r103;
(EngineCore_DP0 pid=342882) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=342882) 	min.xorsign.abs.f32 	%r84, %r110, %r109;
(EngineCore_DP0 pid=342882) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=342882) 	mul.f32 	%r111, %r14, %r105;
(EngineCore_DP0 pid=342882) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=342882) 	min.xorsign.abs.f32 	%r86, %r111, %r109;
(EngineCore_DP0 pid=342882) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=342882) 	mul.f32 	%r112, %r14, %r107;
(EngineCore_DP0 pid=342882) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=342882) 	min.xorsign.abs.f32 	%r88, %r112, %r109;
(EngineCore_DP0 pid=342882) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=342882) 	cvt.u32.u16 	%r113, %rs56;
(EngineCore_DP0 pid=342882) 	and.b32 	%r114, %r113, 255;
(EngineCore_DP0 pid=342882) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=342882) 	cvt.u32.u16 	%r115, %rs58;
(EngineCore_DP0 pid=342882) 	and.b32 	%r116, %r115, 255;
(EngineCore_DP0 pid=342882) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=342882) 	cvt.u32.u16 	%r117, %rs59;
(EngineCore_DP0 pid=342882) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=342882) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=342882) 	mul.wide.u16 	%r118, %rs60, 256;
(EngineCore_DP0 pid=342882) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=342882) 	or.b32 	%r119, %r118, %r114;
(EngineCore_DP0 pid=342882) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=342882) 	shl.b32 	%r120, %r116, 16;
(EngineCore_DP0 pid=342882) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=342882) 	or.b32 	%r121, %r119, %r120;
(EngineCore_DP0 pid=342882) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=342882) 	shl.b32 	%r122, %r117, 24;
(EngineCore_DP0 pid=342882) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=342882) 	or.b32 	%r90, %r121, %r122;
(EngineCore_DP0 pid=342882) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=342882) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=342882) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=342882) 	// begin inline asm
(EngineCore_DP0 pid=342882) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=342882) 	// end inline asm
(EngineCore_DP0 pid=342882) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=342882) 	add.s32 	%r126, %r126, 512;
(EngineCore_DP0 pid=342882) 	setp.lt.s32 	%p19, %r126, %r15;
(EngineCore_DP0 pid=342882) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=342882) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=342882) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=342882) 	ret;
(EngineCore_DP0 pid=342882) $L__tmp3:
(EngineCore_DP0 pid=342882) $L__func_end0:
(EngineCore_DP0 pid=342882)                                         // -- End function
(EngineCore_DP0 pid=342882) }
(EngineCore_DP0 pid=342882) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=342882) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=342882) 	.section	.debug_abbrev
(EngineCore_DP0 pid=342882) 	{
(EngineCore_DP0 pid=342882) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=342882) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=342882) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=342882) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=342882) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=342882) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=342882) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=342882) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=342882) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=342882) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=342882) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=342882) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=342882) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=342882) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=342882) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=342882) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=342882) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=342882) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=342882) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=342882) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=342882) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=342882) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=342882) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=342882) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=342882) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=342882) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=342882) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=342882) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=342882) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=342882) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=342882) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=342882) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=342882) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=342882) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=342882) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=342882) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=342882) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=342882) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=342882) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=342882) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=342882) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=342882) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=342882) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=342882) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=342882) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=342882) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=342882) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=342882) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=342882) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=342882) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=342882) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=342882) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=342882) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=342882) 	}
(EngineCore_DP0 pid=342882) 	.section	.debug_info
(EngineCore_DP0 pid=342882) 	{
(EngineCore_DP0 pid=342882) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=342882) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=342882) .b8 0
(EngineCore_DP0 pid=342882) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=342882) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=342882) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=342882) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=342882) .b8 114
(EngineCore_DP0 pid=342882) .b8 105
(EngineCore_DP0 pid=342882) .b8 116
(EngineCore_DP0 pid=342882) .b8 111
(EngineCore_DP0 pid=342882) .b8 110
(EngineCore_DP0 pid=342882) .b8 0
(EngineCore_DP0 pid=342882) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=342882) .b8 0
(EngineCore_DP0 pid=342882) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=342882) .b8 117
(EngineCore_DP0 pid=342882) .b8 97
(EngineCore_DP0 pid=342882) .b8 110
(EngineCore_DP0 pid=342882) .b8 116
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 115
(EngineCore_DP0 pid=342882) .b8 108
(EngineCore_DP0 pid=342882) .b8 105
(EngineCore_DP0 pid=342882) .b8 100
(EngineCore_DP0 pid=342882) .b8 101
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 116
(EngineCore_DP0 pid=342882) .b8 117
(EngineCore_DP0 pid=342882) .b8 110
(EngineCore_DP0 pid=342882) .b8 101
(EngineCore_DP0 pid=342882) .b8 100
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 76
(EngineCore_DP0 pid=342882) .b8 108
(EngineCore_DP0 pid=342882) .b8 97
(EngineCore_DP0 pid=342882) .b8 109
(EngineCore_DP0 pid=342882) .b8 97
(EngineCore_DP0 pid=342882) .b8 51
(EngineCore_DP0 pid=342882) .b8 46
(EngineCore_DP0 pid=342882) .b8 50
(EngineCore_DP0 pid=342882) .b8 45
(EngineCore_DP0 pid=342882) .b8 49
(EngineCore_DP0 pid=342882) .b8 66
(EngineCore_DP0 pid=342882) .b8 46
(EngineCore_DP0 pid=342882) .b8 112
(EngineCore_DP0 pid=342882) .b8 121
(EngineCore_DP0 pid=342882) .b8 0
(EngineCore_DP0 pid=342882) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=342882) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=342882) .b8 114
(EngineCore_DP0 pid=342882) .b8 111
(EngineCore_DP0 pid=342882) .b8 111
(EngineCore_DP0 pid=342882) .b8 116
(EngineCore_DP0 pid=342882) .b8 47
(EngineCore_DP0 pid=342882) .b8 118
(EngineCore_DP0 pid=342882) .b8 108
(EngineCore_DP0 pid=342882) .b8 108
(EngineCore_DP0 pid=342882) .b8 109
(EngineCore_DP0 pid=342882) .b8 98
(EngineCore_DP0 pid=342882) .b8 101
(EngineCore_DP0 pid=342882) .b8 110
(EngineCore_DP0 pid=342882) .b8 99
(EngineCore_DP0 pid=342882) .b8 104
(EngineCore_DP0 pid=342882) .b8 47
(EngineCore_DP0 pid=342882) .b8 115
(EngineCore_DP0 pid=342882) .b8 108
(EngineCore_DP0 pid=342882) .b8 105
(EngineCore_DP0 pid=342882) .b8 100
(EngineCore_DP0 pid=342882) .b8 101
(EngineCore_DP0 pid=342882) .b8 115
(EngineCore_DP0 pid=342882) .b8 112
(EngineCore_DP0 pid=342882) .b8 97
(EngineCore_DP0 pid=342882) .b8 114
(EngineCore_DP0 pid=342882) .b8 115
(EngineCore_DP0 pid=342882) .b8 101
(EngineCore_DP0 pid=342882) .b8 47
(EngineCore_DP0 pid=342882) .b8 99
(EngineCore_DP0 pid=342882) .b8 115
(EngineCore_DP0 pid=342882) .b8 114
(EngineCore_DP0 pid=342882) .b8 99
(EngineCore_DP0 pid=342882) .b8 47
(EngineCore_DP0 pid=342882) .b8 102
(EngineCore_DP0 pid=342882) .b8 117
(EngineCore_DP0 pid=342882) .b8 115
(EngineCore_DP0 pid=342882) .b8 101
(EngineCore_DP0 pid=342882) .b8 100
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 113
(EngineCore_DP0 pid=342882) .b8 117
(EngineCore_DP0 pid=342882) .b8 97
(EngineCore_DP0 pid=342882) .b8 110
(EngineCore_DP0 pid=342882) .b8 116
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 115
(EngineCore_DP0 pid=342882) .b8 108
(EngineCore_DP0 pid=342882) .b8 105
(EngineCore_DP0 pid=342882) .b8 100
(EngineCore_DP0 pid=342882) .b8 101
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 116
(EngineCore_DP0 pid=342882) .b8 114
(EngineCore_DP0 pid=342882) .b8 105
(EngineCore_DP0 pid=342882) .b8 116
(EngineCore_DP0 pid=342882) .b8 111
(EngineCore_DP0 pid=342882) .b8 110
(EngineCore_DP0 pid=342882) .b8 47
(EngineCore_DP0 pid=342882) .b8 98
(EngineCore_DP0 pid=342882) .b8 117
(EngineCore_DP0 pid=342882) .b8 105
(EngineCore_DP0 pid=342882) .b8 108
(EngineCore_DP0 pid=342882) .b8 100
(EngineCore_DP0 pid=342882) .b8 47
(EngineCore_DP0 pid=342882) .b8 71
(EngineCore_DP0 pid=342882) .b8 66
(EngineCore_DP0 pid=342882) .b8 49
(EngineCore_DP0 pid=342882) .b8 48
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 99
(EngineCore_DP0 pid=342882) .b8 99
(EngineCore_DP0 pid=342882) .b8 49
(EngineCore_DP0 pid=342882) .b8 50
(EngineCore_DP0 pid=342882) .b8 49
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 112
(EngineCore_DP0 pid=342882) .b8 121
(EngineCore_DP0 pid=342882) .b8 51
(EngineCore_DP0 pid=342882) .b8 49
(EngineCore_DP0 pid=342882) .b8 50
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 99
(EngineCore_DP0 pid=342882) .b8 117
(EngineCore_DP0 pid=342882) .b8 49
(EngineCore_DP0 pid=342882) .b8 50
(EngineCore_DP0 pid=342882) .b8 57
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 97
(EngineCore_DP0 pid=342882) .b8 97
(EngineCore_DP0 pid=342882) .b8 114
(EngineCore_DP0 pid=342882) .b8 99
(EngineCore_DP0 pid=342882) .b8 104
(EngineCore_DP0 pid=342882) .b8 54
(EngineCore_DP0 pid=342882) .b8 52
(EngineCore_DP0 pid=342882) .b8 0
(EngineCore_DP0 pid=342882) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=342882) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=342882) .b8 113
(EngineCore_DP0 pid=342882) .b8 117
(EngineCore_DP0 pid=342882) .b8 97
(EngineCore_DP0 pid=342882) .b8 110
(EngineCore_DP0 pid=342882) .b8 116
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 115
(EngineCore_DP0 pid=342882) .b8 108
(EngineCore_DP0 pid=342882) .b8 105
(EngineCore_DP0 pid=342882) .b8 100
(EngineCore_DP0 pid=342882) .b8 101
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 102
(EngineCore_DP0 pid=342882) .b8 112
(EngineCore_DP0 pid=342882) .b8 56
(EngineCore_DP0 pid=342882) .b8 95
(EngineCore_DP0 pid=342882) .b8 107
(EngineCore_DP0 pid=342882) .b8 101
(EngineCore_DP0 pid=342882) .b8 114
(EngineCore_DP0 pid=342882) .b8 110
(EngineCore_DP0 pid=342882) .b8 101
(EngineCore_DP0 pid=342882) .b8 108
(EngineCore_DP0 pid=342882) .b8 0
(EngineCore_DP0 pid=342882) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=342882) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=342882) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=342882) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=342882) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=342882) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=342882) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=342882) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=342882) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=342882) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=342882) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=342882) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=342882) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=342882) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=342882) 	}
(EngineCore_DP0 pid=342882) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) ================================================================
(EngineCore_DP0 pid=342882) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp8cglrs1w.ptx', '-o', '/tmp/tmp8cglrs1w.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] 
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] 
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] 
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8cglrs1w.ptx -o /tmp/tmp8cglrs1w.ptx.o
(EngineCore_DP0 pid=342882) ERROR 01-25 19:21:08 [core.py:866] 

STDERR:
[2026-01-25 19:20:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:20:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:20:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:20:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:20:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:20:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:20:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:20:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:20:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:20:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:20:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:20:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:20:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:20:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:20:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:20:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=342882) [2026-01-25 19:20:56] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=342882) [2026-01-25 19:20:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=342882) [2026-01-25 19:20:56] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=342882) [2026-01-25 19:20:56] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=342882) [2026-01-25 19:20:56] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=342882) [2026-01-25 19:20:56] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=342882) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=342882) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.83s/it]
(EngineCore_DP0 pid=342882) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.83s/it]
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) [2026-01-25 19:21:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=342882) [2026-01-25 19:21:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=342882) [2026-01-25 19:21:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=342882) [2026-01-25 19:21:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=342882) [2026-01-25 19:21:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=342882) [2026-01-25 19:21:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=342882) [2026-01-25 19:21:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=342882) [2026-01-25 19:21:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=342882) Process EngineCore_DP0:
(EngineCore_DP0 pid=342882) Traceback (most recent call last):
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=342882)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=342882)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=342882)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=342882) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp8cglrs1w.ptx', '-o', '/tmp/tmp8cglrs1w.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) Traceback (most recent call last):
(EngineCore_DP0 pid=342882)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=342882)     self.run()
(EngineCore_DP0 pid=342882)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=342882)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=342882)     raise e
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=342882)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=342882)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=342882)     super().__init__(
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=342882)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=342882)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=342882)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=342882)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=342882)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=342882)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=342882)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=342882)     return func(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=342882)     return func(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=342882)     self.model_runner.profile_run()
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=342882)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=342882)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=342882)     return func(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=342882)     outputs = self.model(
(EngineCore_DP0 pid=342882)               ^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342882)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342882)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=342882)     model_output = self.model(
(EngineCore_DP0 pid=342882)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=342882)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=342882)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=342882)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342882)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342882)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=342882)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=342882)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342882)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342882)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=342882)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=342882)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=342882)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=342882)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=342882)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=342882)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=342882)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=342882)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=342882)     return self._linear_fn(
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=342882)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=342882)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=342882)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=342882)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=342882)     return fn(input, L)
(EngineCore_DP0 pid=342882)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=342882)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=342882)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=342882)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=342882)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=342882)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=342882)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=342882)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=342882)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=342882)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=342882)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=342882)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=342882)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=342882)     raise PTXASError(error)
(EngineCore_DP0 pid=342882) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=342882) `ptxas` stderr:
(EngineCore_DP0 pid=342882) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=342882) 
(EngineCore_DP0 pid=342882) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8cglrs1w.ptx -o /tmp/tmp8cglrs1w.ptx.o
(EngineCore_DP0 pid=342882) 
[rank0]:[W125 19:21:09.354876191 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 19:21:10
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:21:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:21:15 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=343372) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) ================================================================
(EngineCore_DP0 pid=343372) Internal Triton PTX codegen error
(EngineCore_DP0 pid=343372) `ptxas` stderr:
(EngineCore_DP0 pid=343372) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyvwtueov.ptx -o /tmp/tmpyvwtueov.ptx.o
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) //
(EngineCore_DP0 pid=343372) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=343372) //
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) .version 8.7
(EngineCore_DP0 pid=343372) .target sm_121a
(EngineCore_DP0 pid=343372) .address_size 64
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=343372) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=343372)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=343372) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=343372) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=343372) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=343372) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=343372) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=343372) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=343372) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=343372) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=343372) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=343372) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=343372) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=343372) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=343372) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=343372) )
(EngineCore_DP0 pid=343372) .reqntid 512
(EngineCore_DP0 pid=343372) {
(EngineCore_DP0 pid=343372) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=343372) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=343372) 	.reg .b32 	%r<127>;
(EngineCore_DP0 pid=343372) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=343372) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=343372) $L__func_begin0:
(EngineCore_DP0 pid=343372) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) // %bb.0:
(EngineCore_DP0 pid=343372) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=343372) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=343372) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=343372) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=343372) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=343372) $L__tmp0:
(EngineCore_DP0 pid=343372) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=343372) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=343372) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=343372) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=343372) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=343372) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=343372) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=343372) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=343372) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=343372) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=343372) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=343372) 	mov.b32 	%r125, 0f2B8CBCCC;
(EngineCore_DP0 pid=343372) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=343372) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=343372) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=343372) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=343372) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=343372) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=343372) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=343372) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=343372) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=343372) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=343372) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=343372) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=343372) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=343372) 	mov.b32 	%r123, 0f00000000;
(EngineCore_DP0 pid=343372) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=343372) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=343372) 	mov.b32 	%r124, %r40;
(EngineCore_DP0 pid=343372) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=343372) 	.loc	1 188 19                        // quant_slide_tuned_Llama3.2-1B.py:188:19
(EngineCore_DP0 pid=343372) 	add.s32 	%r58, %r4, %r124;
(EngineCore_DP0 pid=343372) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=343372) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=343372) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=343372) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=343372) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=343372) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=343372) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=343372) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=343372) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=343372) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=343372) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=343372) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=343372) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=343372) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=343372) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=343372) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=343372) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=343372) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=343372) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=343372) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=343372) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=343372) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=343372) $L__tmp1:
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	bar.sync 	0;
(EngineCore_DP0 pid=343372) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=343372) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=343372) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=343372) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=343372) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=343372) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=343372) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=343372) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	bar.sync 	0;
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=343372) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=343372) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=343372) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=343372) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=343372) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	bar.sync 	0;
(EngineCore_DP0 pid=343372) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=343372) $L__tmp2:
(EngineCore_DP0 pid=343372) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=343372) 	max.f32 	%r123, %r123, %r77;
(EngineCore_DP0 pid=343372) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=343372) 	add.s32 	%r124, %r124, 8192;
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p7, %r124, %r19;
(EngineCore_DP0 pid=343372) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=343372) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=343372) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=343372) 	max.f32 	%r125, %r123, 0f2B8CBCCC;
(EngineCore_DP0 pid=343372) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=343372) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=343372) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=343372) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=343372) 	div.full.f32 	%r80, %r125, %r79;
(EngineCore_DP0 pid=343372) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=343372) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=343372) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=343372) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=343372) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=343372) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=343372) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=343372) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=343372) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=343372) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=343372) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=343372) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=343372) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=343372) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=343372) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=343372) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=343372) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=343372) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=343372) 	div.full.f32 	%r14, %r79, %r125;
(EngineCore_DP0 pid=343372) 	mov.b32 	%r126, 0;
(EngineCore_DP0 pid=343372) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=343372)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=343372) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=343372) 	add.s32 	%r92, %r3, %r126;
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=343372) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=343372) 	mul.hi.s32 	%r93, %r92, 1431655766;
(EngineCore_DP0 pid=343372) 	shr.u32 	%r94, %r93, 31;
(EngineCore_DP0 pid=343372) 	add.s32 	%r95, %r93, %r94;
(EngineCore_DP0 pid=343372) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=343372) 	mul.lo.s32 	%r96, %r95, 3;
(EngineCore_DP0 pid=343372) 	sub.s32 	%r97, %r92, %r96;
(EngineCore_DP0 pid=343372) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=343372) 	shl.b32 	%r98, %r95, 3;
(EngineCore_DP0 pid=343372) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=343372) 	shl.b32 	%r99, %r97, 1;
(EngineCore_DP0 pid=343372) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=343372) 	add.s32 	%r100, %r98, %r99;
(EngineCore_DP0 pid=343372) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p15, %r100, %r18;
(EngineCore_DP0 pid=343372) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=343372) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=343372) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=343372) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=343372) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=343372) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=343372) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=343372) 	cvt.f32.bf16 	%r101, %rs48;
(EngineCore_DP0 pid=343372) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=343372) 	or.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=343372) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p16, %r102, %r18;
(EngineCore_DP0 pid=343372) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=343372) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=343372) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=343372) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=343372) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=343372) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=343372) 	cvt.f32.bf16 	%r103, %rs50;
(EngineCore_DP0 pid=343372) 	.loc	1 215 48                        // quant_slide_tuned_Llama3.2-1B.py:215:48
(EngineCore_DP0 pid=343372) 	add.s32 	%r104, %r100, 2;
(EngineCore_DP0 pid=343372) 	.loc	1 215 53                        // quant_slide_tuned_Llama3.2-1B.py:215:53
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p17, %r104, %r18;
(EngineCore_DP0 pid=343372) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=343372) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=343372) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=343372) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=343372) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=343372) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=343372) 	cvt.f32.bf16 	%r105, %rs52;
(EngineCore_DP0 pid=343372) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=343372) 	add.s32 	%r106, %r100, 3;
(EngineCore_DP0 pid=343372) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p18, %r106, %r18;
(EngineCore_DP0 pid=343372) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=343372) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=343372) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=343372) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=343372) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=343372) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=343372) 	cvt.f32.bf16 	%r107, %rs54;
(EngineCore_DP0 pid=343372) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=343372) 	mul.f32 	%r108, %r14, %r101;
(EngineCore_DP0 pid=343372) 	mov.b32 	%r109, 0f43E00000;
(EngineCore_DP0 pid=343372) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=343372) 	min.xorsign.abs.f32 	%r82, %r108, %r109;
(EngineCore_DP0 pid=343372) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=343372) 	mul.f32 	%r110, %r14, %r103;
(EngineCore_DP0 pid=343372) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=343372) 	min.xorsign.abs.f32 	%r84, %r110, %r109;
(EngineCore_DP0 pid=343372) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=343372) 	mul.f32 	%r111, %r14, %r105;
(EngineCore_DP0 pid=343372) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=343372) 	min.xorsign.abs.f32 	%r86, %r111, %r109;
(EngineCore_DP0 pid=343372) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=343372) 	mul.f32 	%r112, %r14, %r107;
(EngineCore_DP0 pid=343372) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=343372) 	min.xorsign.abs.f32 	%r88, %r112, %r109;
(EngineCore_DP0 pid=343372) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=343372) 	cvt.u32.u16 	%r113, %rs56;
(EngineCore_DP0 pid=343372) 	and.b32 	%r114, %r113, 255;
(EngineCore_DP0 pid=343372) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=343372) 	cvt.u32.u16 	%r115, %rs58;
(EngineCore_DP0 pid=343372) 	and.b32 	%r116, %r115, 255;
(EngineCore_DP0 pid=343372) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=343372) 	cvt.u32.u16 	%r117, %rs59;
(EngineCore_DP0 pid=343372) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=343372) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=343372) 	mul.wide.u16 	%r118, %rs60, 256;
(EngineCore_DP0 pid=343372) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=343372) 	or.b32 	%r119, %r118, %r114;
(EngineCore_DP0 pid=343372) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=343372) 	shl.b32 	%r120, %r116, 16;
(EngineCore_DP0 pid=343372) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=343372) 	or.b32 	%r121, %r119, %r120;
(EngineCore_DP0 pid=343372) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=343372) 	shl.b32 	%r122, %r117, 24;
(EngineCore_DP0 pid=343372) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=343372) 	or.b32 	%r90, %r121, %r122;
(EngineCore_DP0 pid=343372) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=343372) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=343372) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=343372) 	// begin inline asm
(EngineCore_DP0 pid=343372) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=343372) 	// end inline asm
(EngineCore_DP0 pid=343372) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=343372) 	add.s32 	%r126, %r126, 512;
(EngineCore_DP0 pid=343372) 	setp.lt.s32 	%p19, %r126, %r15;
(EngineCore_DP0 pid=343372) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=343372) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=343372) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=343372) 	ret;
(EngineCore_DP0 pid=343372) $L__tmp3:
(EngineCore_DP0 pid=343372) $L__func_end0:
(EngineCore_DP0 pid=343372)                                         // -- End function
(EngineCore_DP0 pid=343372) }
(EngineCore_DP0 pid=343372) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=343372) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=343372) 	.section	.debug_abbrev
(EngineCore_DP0 pid=343372) 	{
(EngineCore_DP0 pid=343372) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=343372) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=343372) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=343372) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=343372) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=343372) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=343372) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=343372) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=343372) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=343372) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=343372) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=343372) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=343372) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=343372) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=343372) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=343372) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=343372) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=343372) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=343372) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=343372) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=343372) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=343372) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=343372) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=343372) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=343372) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=343372) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=343372) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=343372) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=343372) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=343372) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=343372) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=343372) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=343372) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=343372) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=343372) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=343372) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=343372) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=343372) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=343372) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=343372) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=343372) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=343372) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=343372) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=343372) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=343372) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=343372) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=343372) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=343372) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=343372) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=343372) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=343372) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=343372) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=343372) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=343372) 	}
(EngineCore_DP0 pid=343372) 	.section	.debug_info
(EngineCore_DP0 pid=343372) 	{
(EngineCore_DP0 pid=343372) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=343372) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=343372) .b8 0
(EngineCore_DP0 pid=343372) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=343372) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=343372) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=343372) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=343372) .b8 114
(EngineCore_DP0 pid=343372) .b8 105
(EngineCore_DP0 pid=343372) .b8 116
(EngineCore_DP0 pid=343372) .b8 111
(EngineCore_DP0 pid=343372) .b8 110
(EngineCore_DP0 pid=343372) .b8 0
(EngineCore_DP0 pid=343372) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=343372) .b8 0
(EngineCore_DP0 pid=343372) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=343372) .b8 117
(EngineCore_DP0 pid=343372) .b8 97
(EngineCore_DP0 pid=343372) .b8 110
(EngineCore_DP0 pid=343372) .b8 116
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 115
(EngineCore_DP0 pid=343372) .b8 108
(EngineCore_DP0 pid=343372) .b8 105
(EngineCore_DP0 pid=343372) .b8 100
(EngineCore_DP0 pid=343372) .b8 101
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 116
(EngineCore_DP0 pid=343372) .b8 117
(EngineCore_DP0 pid=343372) .b8 110
(EngineCore_DP0 pid=343372) .b8 101
(EngineCore_DP0 pid=343372) .b8 100
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 76
(EngineCore_DP0 pid=343372) .b8 108
(EngineCore_DP0 pid=343372) .b8 97
(EngineCore_DP0 pid=343372) .b8 109
(EngineCore_DP0 pid=343372) .b8 97
(EngineCore_DP0 pid=343372) .b8 51
(EngineCore_DP0 pid=343372) .b8 46
(EngineCore_DP0 pid=343372) .b8 50
(EngineCore_DP0 pid=343372) .b8 45
(EngineCore_DP0 pid=343372) .b8 49
(EngineCore_DP0 pid=343372) .b8 66
(EngineCore_DP0 pid=343372) .b8 46
(EngineCore_DP0 pid=343372) .b8 112
(EngineCore_DP0 pid=343372) .b8 121
(EngineCore_DP0 pid=343372) .b8 0
(EngineCore_DP0 pid=343372) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=343372) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=343372) .b8 114
(EngineCore_DP0 pid=343372) .b8 111
(EngineCore_DP0 pid=343372) .b8 111
(EngineCore_DP0 pid=343372) .b8 116
(EngineCore_DP0 pid=343372) .b8 47
(EngineCore_DP0 pid=343372) .b8 118
(EngineCore_DP0 pid=343372) .b8 108
(EngineCore_DP0 pid=343372) .b8 108
(EngineCore_DP0 pid=343372) .b8 109
(EngineCore_DP0 pid=343372) .b8 98
(EngineCore_DP0 pid=343372) .b8 101
(EngineCore_DP0 pid=343372) .b8 110
(EngineCore_DP0 pid=343372) .b8 99
(EngineCore_DP0 pid=343372) .b8 104
(EngineCore_DP0 pid=343372) .b8 47
(EngineCore_DP0 pid=343372) .b8 115
(EngineCore_DP0 pid=343372) .b8 108
(EngineCore_DP0 pid=343372) .b8 105
(EngineCore_DP0 pid=343372) .b8 100
(EngineCore_DP0 pid=343372) .b8 101
(EngineCore_DP0 pid=343372) .b8 115
(EngineCore_DP0 pid=343372) .b8 112
(EngineCore_DP0 pid=343372) .b8 97
(EngineCore_DP0 pid=343372) .b8 114
(EngineCore_DP0 pid=343372) .b8 115
(EngineCore_DP0 pid=343372) .b8 101
(EngineCore_DP0 pid=343372) .b8 47
(EngineCore_DP0 pid=343372) .b8 99
(EngineCore_DP0 pid=343372) .b8 115
(EngineCore_DP0 pid=343372) .b8 114
(EngineCore_DP0 pid=343372) .b8 99
(EngineCore_DP0 pid=343372) .b8 47
(EngineCore_DP0 pid=343372) .b8 102
(EngineCore_DP0 pid=343372) .b8 117
(EngineCore_DP0 pid=343372) .b8 115
(EngineCore_DP0 pid=343372) .b8 101
(EngineCore_DP0 pid=343372) .b8 100
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 113
(EngineCore_DP0 pid=343372) .b8 117
(EngineCore_DP0 pid=343372) .b8 97
(EngineCore_DP0 pid=343372) .b8 110
(EngineCore_DP0 pid=343372) .b8 116
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 115
(EngineCore_DP0 pid=343372) .b8 108
(EngineCore_DP0 pid=343372) .b8 105
(EngineCore_DP0 pid=343372) .b8 100
(EngineCore_DP0 pid=343372) .b8 101
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 116
(EngineCore_DP0 pid=343372) .b8 114
(EngineCore_DP0 pid=343372) .b8 105
(EngineCore_DP0 pid=343372) .b8 116
(EngineCore_DP0 pid=343372) .b8 111
(EngineCore_DP0 pid=343372) .b8 110
(EngineCore_DP0 pid=343372) .b8 47
(EngineCore_DP0 pid=343372) .b8 98
(EngineCore_DP0 pid=343372) .b8 117
(EngineCore_DP0 pid=343372) .b8 105
(EngineCore_DP0 pid=343372) .b8 108
(EngineCore_DP0 pid=343372) .b8 100
(EngineCore_DP0 pid=343372) .b8 47
(EngineCore_DP0 pid=343372) .b8 71
(EngineCore_DP0 pid=343372) .b8 66
(EngineCore_DP0 pid=343372) .b8 49
(EngineCore_DP0 pid=343372) .b8 48
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 99
(EngineCore_DP0 pid=343372) .b8 99
(EngineCore_DP0 pid=343372) .b8 49
(EngineCore_DP0 pid=343372) .b8 50
(EngineCore_DP0 pid=343372) .b8 49
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 112
(EngineCore_DP0 pid=343372) .b8 121
(EngineCore_DP0 pid=343372) .b8 51
(EngineCore_DP0 pid=343372) .b8 49
(EngineCore_DP0 pid=343372) .b8 50
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 99
(EngineCore_DP0 pid=343372) .b8 117
(EngineCore_DP0 pid=343372) .b8 49
(EngineCore_DP0 pid=343372) .b8 50
(EngineCore_DP0 pid=343372) .b8 57
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 97
(EngineCore_DP0 pid=343372) .b8 97
(EngineCore_DP0 pid=343372) .b8 114
(EngineCore_DP0 pid=343372) .b8 99
(EngineCore_DP0 pid=343372) .b8 104
(EngineCore_DP0 pid=343372) .b8 54
(EngineCore_DP0 pid=343372) .b8 52
(EngineCore_DP0 pid=343372) .b8 0
(EngineCore_DP0 pid=343372) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=343372) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=343372) .b8 113
(EngineCore_DP0 pid=343372) .b8 117
(EngineCore_DP0 pid=343372) .b8 97
(EngineCore_DP0 pid=343372) .b8 110
(EngineCore_DP0 pid=343372) .b8 116
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 115
(EngineCore_DP0 pid=343372) .b8 108
(EngineCore_DP0 pid=343372) .b8 105
(EngineCore_DP0 pid=343372) .b8 100
(EngineCore_DP0 pid=343372) .b8 101
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 102
(EngineCore_DP0 pid=343372) .b8 112
(EngineCore_DP0 pid=343372) .b8 56
(EngineCore_DP0 pid=343372) .b8 95
(EngineCore_DP0 pid=343372) .b8 107
(EngineCore_DP0 pid=343372) .b8 101
(EngineCore_DP0 pid=343372) .b8 114
(EngineCore_DP0 pid=343372) .b8 110
(EngineCore_DP0 pid=343372) .b8 101
(EngineCore_DP0 pid=343372) .b8 108
(EngineCore_DP0 pid=343372) .b8 0
(EngineCore_DP0 pid=343372) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=343372) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=343372) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=343372) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=343372) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=343372) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=343372) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=343372) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=343372) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=343372) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=343372) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=343372) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=343372) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=343372) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=343372) 	}
(EngineCore_DP0 pid=343372) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) ================================================================
(EngineCore_DP0 pid=343372) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpyvwtueov.ptx', '-o', '/tmp/tmpyvwtueov.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] 
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] 
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] 
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyvwtueov.ptx -o /tmp/tmpyvwtueov.ptx.o
(EngineCore_DP0 pid=343372) ERROR 01-25 19:21:32 [core.py:866] 

STDERR:
[2026-01-25 19:21:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:21:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:21:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:21:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:21:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:21:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:21:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:21:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:21:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:21:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:21:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:21:19] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:21:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:21:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:21:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:21:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:21:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:21:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:20] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:20] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:20] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:20] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:20] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=343372) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=343372) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.78s/it]
(EngineCore_DP0 pid=343372) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.78s/it]
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=343372) [2026-01-25 19:21:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=343372) Process EngineCore_DP0:
(EngineCore_DP0 pid=343372) Traceback (most recent call last):
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=343372)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=343372)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=343372)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=343372) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpyvwtueov.ptx', '-o', '/tmp/tmpyvwtueov.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) Traceback (most recent call last):
(EngineCore_DP0 pid=343372)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=343372)     self.run()
(EngineCore_DP0 pid=343372)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=343372)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=343372)     raise e
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=343372)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=343372)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=343372)     super().__init__(
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=343372)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=343372)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=343372)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=343372)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=343372)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=343372)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=343372)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=343372)     return func(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=343372)     return func(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=343372)     self.model_runner.profile_run()
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=343372)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=343372)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=343372)     return func(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=343372)     outputs = self.model(
(EngineCore_DP0 pid=343372)               ^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343372)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343372)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=343372)     model_output = self.model(
(EngineCore_DP0 pid=343372)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=343372)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=343372)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=343372)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343372)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343372)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=343372)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=343372)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343372)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343372)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=343372)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=343372)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343372)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343372)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=343372)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=343372)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=343372)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=343372)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=343372)     return self._linear_fn(
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=343372)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=343372)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=343372)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=343372)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=343372)     return fn(input, L)
(EngineCore_DP0 pid=343372)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=343372)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=343372)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=343372)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=343372)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=343372)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=343372)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=343372)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=343372)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=343372)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=343372)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=343372)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343372)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=343372)     raise PTXASError(error)
(EngineCore_DP0 pid=343372) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=343372) `ptxas` stderr:
(EngineCore_DP0 pid=343372) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=343372) 
(EngineCore_DP0 pid=343372) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpyvwtueov.ptx -o /tmp/tmpyvwtueov.ptx.o
(EngineCore_DP0 pid=343372) 
[rank0]:[W125 19:21:32.740180055 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 19:21:34
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:21:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:21:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=343914) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) ================================================================
(EngineCore_DP0 pid=343914) Internal Triton PTX codegen error
(EngineCore_DP0 pid=343914) `ptxas` stderr:
(EngineCore_DP0 pid=343914) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpkmvkilx2.ptx -o /tmp/tmpkmvkilx2.ptx.o
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) //
(EngineCore_DP0 pid=343914) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=343914) //
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) .version 8.7
(EngineCore_DP0 pid=343914) .target sm_121a
(EngineCore_DP0 pid=343914) .address_size 64
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=343914) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=343914)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=343914) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=343914) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=343914) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=343914) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=343914) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=343914) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=343914) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=343914) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=343914) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=343914) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=343914) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=343914) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=343914) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=343914) )
(EngineCore_DP0 pid=343914) .reqntid 512
(EngineCore_DP0 pid=343914) {
(EngineCore_DP0 pid=343914) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=343914) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=343914) 	.reg .b32 	%r<224>;
(EngineCore_DP0 pid=343914) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=343914) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=343914) $L__func_begin0:
(EngineCore_DP0 pid=343914) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) // %bb.0:
(EngineCore_DP0 pid=343914) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=343914) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=343914) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=343914) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=343914) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=343914) $L__tmp0:
(EngineCore_DP0 pid=343914) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=343914) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=343914) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=343914) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=343914) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=343914) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=343914) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=343914) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=343914) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=343914) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=343914) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=343914) 	mov.b32 	%r222, 0f2B8CBCCC;
(EngineCore_DP0 pid=343914) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=343914) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=343914) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=343914) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=343914) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=343914) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=343914) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=343914) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=343914) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=343914) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=343914) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=343914) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=343914) 	mov.b32 	%r220, 0f00000000;
(EngineCore_DP0 pid=343914) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=343914) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=343914) 	mov.b32 	%r221, %r49;
(EngineCore_DP0 pid=343914) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=343914) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=343914) 	add.s32 	%r59, %r4, %r221;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=343914) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=343914) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=343914) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=343914) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=343914) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=343914) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=343914) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=343914) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=343914) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=343914) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=343914) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=343914) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=343914) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=343914) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=343914) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=343914) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=343914) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=343914) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=343914) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=343914) $L__tmp1:
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	bar.sync 	0;
(EngineCore_DP0 pid=343914) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=343914) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=343914) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=343914) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=343914) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=343914) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=343914) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=343914) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=343914) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=343914) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=343914) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=343914) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	bar.sync 	0;
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=343914) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=343914) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=343914) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=343914) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=343914) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	bar.sync 	0;
(EngineCore_DP0 pid=343914) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=343914) $L__tmp2:
(EngineCore_DP0 pid=343914) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=343914) 	max.f32 	%r220, %r220, %r77;
(EngineCore_DP0 pid=343914) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=343914) 	add.s32 	%r221, %r221, 4096;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p6, %r221, %r28;
(EngineCore_DP0 pid=343914) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=343914) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=343914) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=343914) 	max.f32 	%r222, %r220, 0f2B8CBCCC;
(EngineCore_DP0 pid=343914) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=343914) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=343914) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=343914) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=343914) 	div.full.f32 	%r80, %r222, %r79;
(EngineCore_DP0 pid=343914) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=343914) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=343914) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=343914) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=343914) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=343914) 	mul.lo.s32 	%r15, %r29, 3;
(EngineCore_DP0 pid=343914) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=343914) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=343914) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=343914) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=343914) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=343914) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=343914) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=343914) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=343914) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=343914) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=343914) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=343914) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=343914) 	div.full.f32 	%r14, %r79, %r222;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=343914) 	mov.b32 	%r223, 0;
(EngineCore_DP0 pid=343914) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=343914)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=343914) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=343914) 	add.s32 	%r103, %r16, %r223;
(EngineCore_DP0 pid=343914) 	add.s32 	%r104, %r103, 1;
(EngineCore_DP0 pid=343914) 	add.s32 	%r105, %r103, 2;
(EngineCore_DP0 pid=343914) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=343914) 	add.s32 	%r106, %r103, 3;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p25, %r103, %r15;
(EngineCore_DP0 pid=343914) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=343914) 	mul.hi.s32 	%r107, %r106, 1431655766;
(EngineCore_DP0 pid=343914) 	shr.u32 	%r108, %r107, 31;
(EngineCore_DP0 pid=343914) 	add.s32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=343914) 	mul.hi.s32 	%r110, %r105, 1431655766;
(EngineCore_DP0 pid=343914) 	shr.u32 	%r111, %r110, 31;
(EngineCore_DP0 pid=343914) 	add.s32 	%r112, %r110, %r111;
(EngineCore_DP0 pid=343914) 	mul.hi.s32 	%r113, %r104, 1431655766;
(EngineCore_DP0 pid=343914) 	shr.u32 	%r114, %r113, 31;
(EngineCore_DP0 pid=343914) 	add.s32 	%r115, %r113, %r114;
(EngineCore_DP0 pid=343914) 	mul.hi.s32 	%r116, %r103, 1431655766;
(EngineCore_DP0 pid=343914) 	shr.u32 	%r117, %r116, 31;
(EngineCore_DP0 pid=343914) 	add.s32 	%r118, %r116, %r117;
(EngineCore_DP0 pid=343914) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=343914) 	mul.lo.s32 	%r119, %r118, 3;
(EngineCore_DP0 pid=343914) 	mul.lo.s32 	%r120, %r115, 3;
(EngineCore_DP0 pid=343914) 	mul.lo.s32 	%r121, %r112, 3;
(EngineCore_DP0 pid=343914) 	mul.lo.s32 	%r122, %r109, 3;
(EngineCore_DP0 pid=343914) 	sub.s32 	%r123, %r106, %r122;
(EngineCore_DP0 pid=343914) 	sub.s32 	%r124, %r105, %r121;
(EngineCore_DP0 pid=343914) 	sub.s32 	%r125, %r104, %r120;
(EngineCore_DP0 pid=343914) 	sub.s32 	%r126, %r103, %r119;
(EngineCore_DP0 pid=343914) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=343914) 	shl.b32 	%r127, %r118, 3;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r128, %r115, 3;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r129, %r112, 3;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r130, %r109, 3;
(EngineCore_DP0 pid=343914) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=343914) 	shl.b32 	%r131, %r126, 1;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r132, %r125, 1;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r133, %r124, 1;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r134, %r123, 1;
(EngineCore_DP0 pid=343914) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=343914) 	add.s32 	%r135, %r130, %r134;
(EngineCore_DP0 pid=343914) 	add.s32 	%r136, %r129, %r133;
(EngineCore_DP0 pid=343914) 	add.s32 	%r137, %r128, %r132;
(EngineCore_DP0 pid=343914) 	add.s32 	%r138, %r127, %r131;
(EngineCore_DP0 pid=343914) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p26, %r138, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p27, %r137, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p28, %r136, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p29, %r135, %r27;
(EngineCore_DP0 pid=343914) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=343914) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=343914) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=343914) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=343914) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=343914) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=343914) 	mad.wide.s32 	%rd8, %r138, 2, %rd1;
(EngineCore_DP0 pid=343914) 	mad.wide.s32 	%rd9, %r137, 2, %rd1;
(EngineCore_DP0 pid=343914) 	mad.wide.s32 	%rd10, %r136, 2, %rd1;
(EngineCore_DP0 pid=343914) 	mad.wide.s32 	%rd11, %r135, 2, %rd1;
(EngineCore_DP0 pid=343914) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=343914) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=343914) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=343914) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=343914) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=343914) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r139, %rs24;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r140, %rs26;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r141, %rs28;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r142, %rs30;
(EngineCore_DP0 pid=343914) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=343914) 	or.b32 	%r143, %r138, 1;
(EngineCore_DP0 pid=343914) 	or.b32 	%r144, %r137, 1;
(EngineCore_DP0 pid=343914) 	or.b32 	%r145, %r136, 1;
(EngineCore_DP0 pid=343914) 	or.b32 	%r146, %r135, 1;
(EngineCore_DP0 pid=343914) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p30, %r143, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p31, %r144, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p32, %r145, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p33, %r146, %r27;
(EngineCore_DP0 pid=343914) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=343914) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=343914) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=343914) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=343914) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=343914) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=343914) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=343914) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=343914) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=343914) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=343914) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=343914) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=343914) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=343914) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=343914) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r147, %rs32;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r148, %rs34;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r149, %rs36;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r150, %rs38;
(EngineCore_DP0 pid=343914) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=343914) 	add.s32 	%r151, %r138, 2;
(EngineCore_DP0 pid=343914) 	add.s32 	%r152, %r137, 2;
(EngineCore_DP0 pid=343914) 	add.s32 	%r153, %r136, 2;
(EngineCore_DP0 pid=343914) 	add.s32 	%r154, %r135, 2;
(EngineCore_DP0 pid=343914) 	add.s32 	%r155, %r138, 3;
(EngineCore_DP0 pid=343914) 	add.s32 	%r156, %r137, 3;
(EngineCore_DP0 pid=343914) 	add.s32 	%r157, %r136, 3;
(EngineCore_DP0 pid=343914) 	add.s32 	%r158, %r135, 3;
(EngineCore_DP0 pid=343914) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p34, %r158, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p35, %r157, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p36, %r156, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p37, %r155, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p38, %r154, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p39, %r153, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p40, %r152, %r27;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p41, %r151, %r27;
(EngineCore_DP0 pid=343914) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=343914) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=343914) 	and.pred 	%p18, %p25, %p40;
(EngineCore_DP0 pid=343914) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=343914) 	and.pred 	%p20, %p25, %p38;
(EngineCore_DP0 pid=343914) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=343914) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=343914) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=343914) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=343914) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=343914) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=343914) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=343914) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=343914) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=343914) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r159, %rs40;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r160, %rs42;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r161, %rs44;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r162, %rs46;
(EngineCore_DP0 pid=343914) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=343914) 	and.pred 	%p21, %p25, %p37;
(EngineCore_DP0 pid=343914) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=343914) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=343914) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=343914) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=343914) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=343914) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=343914) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=343914) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=343914) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=343914) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=343914) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=343914) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=343914) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r163, %rs48;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r164, %rs50;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r165, %rs52;
(EngineCore_DP0 pid=343914) 	cvt.f32.bf16 	%r166, %rs54;
(EngineCore_DP0 pid=343914) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=343914) 	mul.f32 	%r167, %r14, %r139;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r168, %r14, %r140;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r169, %r14, %r141;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r170, %r14, %r142;
(EngineCore_DP0 pid=343914) 	mov.b32 	%r171, 0f43E00000;
(EngineCore_DP0 pid=343914) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r82, %r167, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r83, %r168, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r84, %r169, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r85, %r170, %r171;
(EngineCore_DP0 pid=343914) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=343914) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=343914) 	mul.f32 	%r172, %r14, %r147;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r173, %r14, %r148;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r174, %r14, %r149;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r175, %r14, %r150;
(EngineCore_DP0 pid=343914) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r86, %r172, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r87, %r173, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r88, %r174, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r89, %r175, %r171;
(EngineCore_DP0 pid=343914) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=343914) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=343914) 	mul.f32 	%r176, %r14, %r159;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r177, %r14, %r160;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r178, %r14, %r161;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r179, %r14, %r162;
(EngineCore_DP0 pid=343914) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r90, %r176, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r91, %r177, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r92, %r178, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r93, %r179, %r171;
(EngineCore_DP0 pid=343914) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=343914) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=343914) 	mul.f32 	%r180, %r14, %r163;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r181, %r14, %r164;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r182, %r14, %r165;
(EngineCore_DP0 pid=343914) 	mul.f32 	%r183, %r14, %r166;
(EngineCore_DP0 pid=343914) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r94, %r180, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r95, %r181, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r96, %r182, %r171;
(EngineCore_DP0 pid=343914) 	min.xorsign.abs.f32 	%r97, %r183, %r171;
(EngineCore_DP0 pid=343914) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=343914) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r184, %rs56;
(EngineCore_DP0 pid=343914) 	and.b32 	%r185, %r184, 255;
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r186, %rs64;
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r187, %rs57;
(EngineCore_DP0 pid=343914) 	and.b32 	%r188, %r187, 255;
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r189, %rs65;
(EngineCore_DP0 pid=343914) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r190, %rs60;
(EngineCore_DP0 pid=343914) 	and.b32 	%r191, %r190, 255;
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r192, %rs68;
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r193, %rs61;
(EngineCore_DP0 pid=343914) 	and.b32 	%r194, %r193, 255;
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r195, %rs69;
(EngineCore_DP0 pid=343914) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r196, %rs62;
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r197, %rs70;
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r198, %rs63;
(EngineCore_DP0 pid=343914) 	cvt.u32.u16 	%r199, %rs71;
(EngineCore_DP0 pid=343914) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=343914) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=343914) 	mul.wide.u16 	%r200, %rs72, 256;
(EngineCore_DP0 pid=343914) 	mul.wide.u16 	%r201, %rs66, 256;
(EngineCore_DP0 pid=343914) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=343914) 	mul.wide.u16 	%r202, %rs73, 256;
(EngineCore_DP0 pid=343914) 	mul.wide.u16 	%r203, %rs67, 256;
(EngineCore_DP0 pid=343914) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=343914) 	or.b32 	%r204, %r200, %r185;
(EngineCore_DP0 pid=343914) 	or.b32 	%r205, %r201, %r186;
(EngineCore_DP0 pid=343914) 	or.b32 	%r206, %r202, %r188;
(EngineCore_DP0 pid=343914) 	or.b32 	%r207, %r203, %r189;
(EngineCore_DP0 pid=343914) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=343914) 	shl.b32 	%r208, %r191, 16;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r209, %r192, 16;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r210, %r194, 16;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r211, %r195, 16;
(EngineCore_DP0 pid=343914) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=343914) 	or.b32 	%r212, %r208, %r204;
(EngineCore_DP0 pid=343914) 	or.b32 	%r213, %r209, %r205;
(EngineCore_DP0 pid=343914) 	or.b32 	%r214, %r210, %r206;
(EngineCore_DP0 pid=343914) 	or.b32 	%r215, %r211, %r207;
(EngineCore_DP0 pid=343914) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=343914) 	shl.b32 	%r216, %r196, 24;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r217, %r197, 24;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r218, %r198, 24;
(EngineCore_DP0 pid=343914) 	shl.b32 	%r219, %r199, 24;
(EngineCore_DP0 pid=343914) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=343914) 	or.b32 	%r98, %r216, %r212;
(EngineCore_DP0 pid=343914) 	or.b32 	%r99, %r217, %r213;
(EngineCore_DP0 pid=343914) 	or.b32 	%r100, %r218, %r214;
(EngineCore_DP0 pid=343914) 	or.b32 	%r101, %r219, %r215;
(EngineCore_DP0 pid=343914) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=343914) 	mad.wide.s32 	%rd24, %r103, 4, %rd2;
(EngineCore_DP0 pid=343914) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=343914) 	// begin inline asm
(EngineCore_DP0 pid=343914) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=343914) 	// end inline asm
(EngineCore_DP0 pid=343914) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=343914) 	add.s32 	%r223, %r223, 2048;
(EngineCore_DP0 pid=343914) 	setp.lt.s32 	%p42, %r223, %r15;
(EngineCore_DP0 pid=343914) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=343914) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=343914) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=343914) 	ret;
(EngineCore_DP0 pid=343914) $L__tmp3:
(EngineCore_DP0 pid=343914) $L__func_end0:
(EngineCore_DP0 pid=343914)                                         // -- End function
(EngineCore_DP0 pid=343914) }
(EngineCore_DP0 pid=343914) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=343914) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=343914) 	.section	.debug_abbrev
(EngineCore_DP0 pid=343914) 	{
(EngineCore_DP0 pid=343914) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=343914) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=343914) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=343914) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=343914) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=343914) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=343914) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=343914) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=343914) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=343914) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=343914) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=343914) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=343914) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=343914) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=343914) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=343914) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=343914) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=343914) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=343914) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=343914) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=343914) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=343914) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=343914) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=343914) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=343914) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=343914) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=343914) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=343914) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=343914) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=343914) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=343914) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=343914) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=343914) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=343914) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=343914) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=343914) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=343914) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=343914) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=343914) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=343914) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=343914) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=343914) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=343914) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=343914) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=343914) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=343914) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=343914) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=343914) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=343914) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=343914) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=343914) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=343914) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=343914) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=343914) 	}
(EngineCore_DP0 pid=343914) 	.section	.debug_info
(EngineCore_DP0 pid=343914) 	{
(EngineCore_DP0 pid=343914) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=343914) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=343914) .b8 0
(EngineCore_DP0 pid=343914) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=343914) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=343914) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=343914) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=343914) .b8 114
(EngineCore_DP0 pid=343914) .b8 105
(EngineCore_DP0 pid=343914) .b8 116
(EngineCore_DP0 pid=343914) .b8 111
(EngineCore_DP0 pid=343914) .b8 110
(EngineCore_DP0 pid=343914) .b8 0
(EngineCore_DP0 pid=343914) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=343914) .b8 0
(EngineCore_DP0 pid=343914) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=343914) .b8 117
(EngineCore_DP0 pid=343914) .b8 97
(EngineCore_DP0 pid=343914) .b8 110
(EngineCore_DP0 pid=343914) .b8 116
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 115
(EngineCore_DP0 pid=343914) .b8 108
(EngineCore_DP0 pid=343914) .b8 105
(EngineCore_DP0 pid=343914) .b8 100
(EngineCore_DP0 pid=343914) .b8 101
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 116
(EngineCore_DP0 pid=343914) .b8 117
(EngineCore_DP0 pid=343914) .b8 110
(EngineCore_DP0 pid=343914) .b8 101
(EngineCore_DP0 pid=343914) .b8 100
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 76
(EngineCore_DP0 pid=343914) .b8 108
(EngineCore_DP0 pid=343914) .b8 97
(EngineCore_DP0 pid=343914) .b8 109
(EngineCore_DP0 pid=343914) .b8 97
(EngineCore_DP0 pid=343914) .b8 51
(EngineCore_DP0 pid=343914) .b8 46
(EngineCore_DP0 pid=343914) .b8 50
(EngineCore_DP0 pid=343914) .b8 45
(EngineCore_DP0 pid=343914) .b8 49
(EngineCore_DP0 pid=343914) .b8 66
(EngineCore_DP0 pid=343914) .b8 46
(EngineCore_DP0 pid=343914) .b8 112
(EngineCore_DP0 pid=343914) .b8 121
(EngineCore_DP0 pid=343914) .b8 0
(EngineCore_DP0 pid=343914) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=343914) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=343914) .b8 114
(EngineCore_DP0 pid=343914) .b8 111
(EngineCore_DP0 pid=343914) .b8 111
(EngineCore_DP0 pid=343914) .b8 116
(EngineCore_DP0 pid=343914) .b8 47
(EngineCore_DP0 pid=343914) .b8 118
(EngineCore_DP0 pid=343914) .b8 108
(EngineCore_DP0 pid=343914) .b8 108
(EngineCore_DP0 pid=343914) .b8 109
(EngineCore_DP0 pid=343914) .b8 98
(EngineCore_DP0 pid=343914) .b8 101
(EngineCore_DP0 pid=343914) .b8 110
(EngineCore_DP0 pid=343914) .b8 99
(EngineCore_DP0 pid=343914) .b8 104
(EngineCore_DP0 pid=343914) .b8 47
(EngineCore_DP0 pid=343914) .b8 115
(EngineCore_DP0 pid=343914) .b8 108
(EngineCore_DP0 pid=343914) .b8 105
(EngineCore_DP0 pid=343914) .b8 100
(EngineCore_DP0 pid=343914) .b8 101
(EngineCore_DP0 pid=343914) .b8 115
(EngineCore_DP0 pid=343914) .b8 112
(EngineCore_DP0 pid=343914) .b8 97
(EngineCore_DP0 pid=343914) .b8 114
(EngineCore_DP0 pid=343914) .b8 115
(EngineCore_DP0 pid=343914) .b8 101
(EngineCore_DP0 pid=343914) .b8 47
(EngineCore_DP0 pid=343914) .b8 99
(EngineCore_DP0 pid=343914) .b8 115
(EngineCore_DP0 pid=343914) .b8 114
(EngineCore_DP0 pid=343914) .b8 99
(EngineCore_DP0 pid=343914) .b8 47
(EngineCore_DP0 pid=343914) .b8 102
(EngineCore_DP0 pid=343914) .b8 117
(EngineCore_DP0 pid=343914) .b8 115
(EngineCore_DP0 pid=343914) .b8 101
(EngineCore_DP0 pid=343914) .b8 100
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 113
(EngineCore_DP0 pid=343914) .b8 117
(EngineCore_DP0 pid=343914) .b8 97
(EngineCore_DP0 pid=343914) .b8 110
(EngineCore_DP0 pid=343914) .b8 116
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 115
(EngineCore_DP0 pid=343914) .b8 108
(EngineCore_DP0 pid=343914) .b8 105
(EngineCore_DP0 pid=343914) .b8 100
(EngineCore_DP0 pid=343914) .b8 101
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 116
(EngineCore_DP0 pid=343914) .b8 114
(EngineCore_DP0 pid=343914) .b8 105
(EngineCore_DP0 pid=343914) .b8 116
(EngineCore_DP0 pid=343914) .b8 111
(EngineCore_DP0 pid=343914) .b8 110
(EngineCore_DP0 pid=343914) .b8 47
(EngineCore_DP0 pid=343914) .b8 98
(EngineCore_DP0 pid=343914) .b8 117
(EngineCore_DP0 pid=343914) .b8 105
(EngineCore_DP0 pid=343914) .b8 108
(EngineCore_DP0 pid=343914) .b8 100
(EngineCore_DP0 pid=343914) .b8 47
(EngineCore_DP0 pid=343914) .b8 71
(EngineCore_DP0 pid=343914) .b8 66
(EngineCore_DP0 pid=343914) .b8 49
(EngineCore_DP0 pid=343914) .b8 48
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 99
(EngineCore_DP0 pid=343914) .b8 99
(EngineCore_DP0 pid=343914) .b8 49
(EngineCore_DP0 pid=343914) .b8 50
(EngineCore_DP0 pid=343914) .b8 49
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 112
(EngineCore_DP0 pid=343914) .b8 121
(EngineCore_DP0 pid=343914) .b8 51
(EngineCore_DP0 pid=343914) .b8 49
(EngineCore_DP0 pid=343914) .b8 50
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 99
(EngineCore_DP0 pid=343914) .b8 117
(EngineCore_DP0 pid=343914) .b8 49
(EngineCore_DP0 pid=343914) .b8 50
(EngineCore_DP0 pid=343914) .b8 57
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 97
(EngineCore_DP0 pid=343914) .b8 97
(EngineCore_DP0 pid=343914) .b8 114
(EngineCore_DP0 pid=343914) .b8 99
(EngineCore_DP0 pid=343914) .b8 104
(EngineCore_DP0 pid=343914) .b8 54
(EngineCore_DP0 pid=343914) .b8 52
(EngineCore_DP0 pid=343914) .b8 0
(EngineCore_DP0 pid=343914) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=343914) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=343914) .b8 113
(EngineCore_DP0 pid=343914) .b8 117
(EngineCore_DP0 pid=343914) .b8 97
(EngineCore_DP0 pid=343914) .b8 110
(EngineCore_DP0 pid=343914) .b8 116
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 115
(EngineCore_DP0 pid=343914) .b8 108
(EngineCore_DP0 pid=343914) .b8 105
(EngineCore_DP0 pid=343914) .b8 100
(EngineCore_DP0 pid=343914) .b8 101
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 102
(EngineCore_DP0 pid=343914) .b8 112
(EngineCore_DP0 pid=343914) .b8 56
(EngineCore_DP0 pid=343914) .b8 95
(EngineCore_DP0 pid=343914) .b8 107
(EngineCore_DP0 pid=343914) .b8 101
(EngineCore_DP0 pid=343914) .b8 114
(EngineCore_DP0 pid=343914) .b8 110
(EngineCore_DP0 pid=343914) .b8 101
(EngineCore_DP0 pid=343914) .b8 108
(EngineCore_DP0 pid=343914) .b8 0
(EngineCore_DP0 pid=343914) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=343914) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=343914) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=343914) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=343914) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=343914) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=343914) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=343914) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=343914) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=343914) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=343914) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=343914) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=343914) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=343914) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=343914) 	}
(EngineCore_DP0 pid=343914) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) ================================================================
(EngineCore_DP0 pid=343914) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpkmvkilx2.ptx', '-o', '/tmp/tmpkmvkilx2.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] 
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] 
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] 
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpkmvkilx2.ptx -o /tmp/tmpkmvkilx2.ptx.o
(EngineCore_DP0 pid=343914) ERROR 01-25 19:21:57 [core.py:866] 

STDERR:
[2026-01-25 19:21:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:21:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:21:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:21:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:21:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:21:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:21:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:21:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:21:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:21:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:21:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:21:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:21:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:21:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:21:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:21:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:21:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:21:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:21:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=343914) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=343914) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.95s/it]
(EngineCore_DP0 pid=343914) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.95s/it]
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=343914) [2026-01-25 19:21:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=343914) Process EngineCore_DP0:
(EngineCore_DP0 pid=343914) Traceback (most recent call last):
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=343914)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=343914)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=343914)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=343914) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpkmvkilx2.ptx', '-o', '/tmp/tmpkmvkilx2.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) Traceback (most recent call last):
(EngineCore_DP0 pid=343914)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=343914)     self.run()
(EngineCore_DP0 pid=343914)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=343914)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=343914)     raise e
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=343914)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=343914)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=343914)     super().__init__(
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=343914)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=343914)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=343914)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=343914)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=343914)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=343914)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=343914)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=343914)     return func(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=343914)     return func(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=343914)     self.model_runner.profile_run()
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=343914)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=343914)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=343914)     return func(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=343914)     outputs = self.model(
(EngineCore_DP0 pid=343914)               ^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343914)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343914)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=343914)     model_output = self.model(
(EngineCore_DP0 pid=343914)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=343914)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=343914)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=343914)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343914)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343914)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=343914)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=343914)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343914)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343914)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=343914)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=343914)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=343914)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=343914)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=343914)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=343914)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=343914)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=343914)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=343914)     return self._linear_fn(
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=343914)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=343914)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=343914)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=343914)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=343914)     return fn(input, L)
(EngineCore_DP0 pid=343914)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=343914)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=343914)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=343914)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=343914)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=343914)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=343914)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=343914)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=343914)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=343914)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=343914)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=343914)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=343914)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=343914)     raise PTXASError(error)
(EngineCore_DP0 pid=343914) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=343914) `ptxas` stderr:
(EngineCore_DP0 pid=343914) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=343914) 
(EngineCore_DP0 pid=343914) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpkmvkilx2.ptx -o /tmp/tmpkmvkilx2.ptx.o
(EngineCore_DP0 pid=343914) 
[rank0]:[W125 19:21:57.848417444 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 19:21:59
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:22:08 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:22:08 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=344507) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) ================================================================
(EngineCore_DP0 pid=344507) Internal Triton PTX codegen error
(EngineCore_DP0 pid=344507) `ptxas` stderr:
(EngineCore_DP0 pid=344507) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpi3r0sygm.ptx -o /tmp/tmpi3r0sygm.ptx.o
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) //
(EngineCore_DP0 pid=344507) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=344507) //
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) .version 8.7
(EngineCore_DP0 pid=344507) .target sm_121a
(EngineCore_DP0 pid=344507) .address_size 64
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=344507) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=344507)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=344507) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=344507) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=344507) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=344507) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=344507) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=344507) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=344507) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=344507) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=344507) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=344507) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=344507) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=344507) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=344507) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=344507) )
(EngineCore_DP0 pid=344507) .reqntid 512
(EngineCore_DP0 pid=344507) {
(EngineCore_DP0 pid=344507) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=344507) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=344507) 	.reg .b32 	%r<224>;
(EngineCore_DP0 pid=344507) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=344507) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=344507) $L__func_begin0:
(EngineCore_DP0 pid=344507) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) // %bb.0:
(EngineCore_DP0 pid=344507) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=344507) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=344507) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=344507) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=344507) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=344507) $L__tmp0:
(EngineCore_DP0 pid=344507) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=344507) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=344507) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=344507) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=344507) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=344507) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=344507) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=344507) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=344507) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=344507) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=344507) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=344507) 	mov.b32 	%r222, 0f2B8CBCCC;
(EngineCore_DP0 pid=344507) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=344507) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=344507) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=344507) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=344507) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=344507) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=344507) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=344507) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=344507) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=344507) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=344507) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=344507) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=344507) 	mov.b32 	%r220, 0f00000000;
(EngineCore_DP0 pid=344507) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=344507) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=344507) 	mov.b32 	%r221, %r49;
(EngineCore_DP0 pid=344507) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=344507) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=344507) 	add.s32 	%r59, %r4, %r221;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=344507) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=344507) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=344507) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=344507) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=344507) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=344507) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=344507) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=344507) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=344507) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=344507) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=344507) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=344507) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=344507) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=344507) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=344507) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=344507) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=344507) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=344507) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=344507) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=344507) $L__tmp1:
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	bar.sync 	0;
(EngineCore_DP0 pid=344507) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=344507) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=344507) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=344507) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=344507) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=344507) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=344507) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=344507) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=344507) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=344507) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=344507) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=344507) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	bar.sync 	0;
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=344507) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=344507) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=344507) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=344507) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=344507) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	bar.sync 	0;
(EngineCore_DP0 pid=344507) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=344507) $L__tmp2:
(EngineCore_DP0 pid=344507) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=344507) 	max.f32 	%r220, %r220, %r77;
(EngineCore_DP0 pid=344507) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=344507) 	add.s32 	%r221, %r221, 4096;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p6, %r221, %r28;
(EngineCore_DP0 pid=344507) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=344507) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=344507) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=344507) 	max.f32 	%r222, %r220, 0f2B8CBCCC;
(EngineCore_DP0 pid=344507) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=344507) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=344507) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=344507) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=344507) 	div.full.f32 	%r80, %r222, %r79;
(EngineCore_DP0 pid=344507) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=344507) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=344507) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=344507) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=344507) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=344507) 	mul.lo.s32 	%r15, %r29, 3;
(EngineCore_DP0 pid=344507) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=344507) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=344507) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=344507) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=344507) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=344507) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=344507) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=344507) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=344507) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=344507) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=344507) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=344507) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=344507) 	div.full.f32 	%r14, %r79, %r222;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=344507) 	mov.b32 	%r223, 0;
(EngineCore_DP0 pid=344507) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=344507)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=344507) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=344507) 	add.s32 	%r103, %r16, %r223;
(EngineCore_DP0 pid=344507) 	add.s32 	%r104, %r103, 1;
(EngineCore_DP0 pid=344507) 	add.s32 	%r105, %r103, 2;
(EngineCore_DP0 pid=344507) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=344507) 	add.s32 	%r106, %r103, 3;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p25, %r103, %r15;
(EngineCore_DP0 pid=344507) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=344507) 	mul.hi.s32 	%r107, %r106, 1431655766;
(EngineCore_DP0 pid=344507) 	shr.u32 	%r108, %r107, 31;
(EngineCore_DP0 pid=344507) 	add.s32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=344507) 	mul.hi.s32 	%r110, %r105, 1431655766;
(EngineCore_DP0 pid=344507) 	shr.u32 	%r111, %r110, 31;
(EngineCore_DP0 pid=344507) 	add.s32 	%r112, %r110, %r111;
(EngineCore_DP0 pid=344507) 	mul.hi.s32 	%r113, %r104, 1431655766;
(EngineCore_DP0 pid=344507) 	shr.u32 	%r114, %r113, 31;
(EngineCore_DP0 pid=344507) 	add.s32 	%r115, %r113, %r114;
(EngineCore_DP0 pid=344507) 	mul.hi.s32 	%r116, %r103, 1431655766;
(EngineCore_DP0 pid=344507) 	shr.u32 	%r117, %r116, 31;
(EngineCore_DP0 pid=344507) 	add.s32 	%r118, %r116, %r117;
(EngineCore_DP0 pid=344507) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=344507) 	mul.lo.s32 	%r119, %r118, 3;
(EngineCore_DP0 pid=344507) 	mul.lo.s32 	%r120, %r115, 3;
(EngineCore_DP0 pid=344507) 	mul.lo.s32 	%r121, %r112, 3;
(EngineCore_DP0 pid=344507) 	mul.lo.s32 	%r122, %r109, 3;
(EngineCore_DP0 pid=344507) 	sub.s32 	%r123, %r106, %r122;
(EngineCore_DP0 pid=344507) 	sub.s32 	%r124, %r105, %r121;
(EngineCore_DP0 pid=344507) 	sub.s32 	%r125, %r104, %r120;
(EngineCore_DP0 pid=344507) 	sub.s32 	%r126, %r103, %r119;
(EngineCore_DP0 pid=344507) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=344507) 	shl.b32 	%r127, %r118, 3;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r128, %r115, 3;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r129, %r112, 3;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r130, %r109, 3;
(EngineCore_DP0 pid=344507) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=344507) 	shl.b32 	%r131, %r126, 1;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r132, %r125, 1;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r133, %r124, 1;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r134, %r123, 1;
(EngineCore_DP0 pid=344507) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=344507) 	add.s32 	%r135, %r130, %r134;
(EngineCore_DP0 pid=344507) 	add.s32 	%r136, %r129, %r133;
(EngineCore_DP0 pid=344507) 	add.s32 	%r137, %r128, %r132;
(EngineCore_DP0 pid=344507) 	add.s32 	%r138, %r127, %r131;
(EngineCore_DP0 pid=344507) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p26, %r138, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p27, %r137, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p28, %r136, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p29, %r135, %r27;
(EngineCore_DP0 pid=344507) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=344507) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=344507) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=344507) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=344507) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=344507) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=344507) 	mad.wide.s32 	%rd8, %r138, 2, %rd1;
(EngineCore_DP0 pid=344507) 	mad.wide.s32 	%rd9, %r137, 2, %rd1;
(EngineCore_DP0 pid=344507) 	mad.wide.s32 	%rd10, %r136, 2, %rd1;
(EngineCore_DP0 pid=344507) 	mad.wide.s32 	%rd11, %r135, 2, %rd1;
(EngineCore_DP0 pid=344507) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=344507) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=344507) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=344507) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=344507) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=344507) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r139, %rs24;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r140, %rs26;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r141, %rs28;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r142, %rs30;
(EngineCore_DP0 pid=344507) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=344507) 	or.b32 	%r143, %r138, 1;
(EngineCore_DP0 pid=344507) 	or.b32 	%r144, %r137, 1;
(EngineCore_DP0 pid=344507) 	or.b32 	%r145, %r136, 1;
(EngineCore_DP0 pid=344507) 	or.b32 	%r146, %r135, 1;
(EngineCore_DP0 pid=344507) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p30, %r143, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p31, %r144, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p32, %r145, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p33, %r146, %r27;
(EngineCore_DP0 pid=344507) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=344507) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=344507) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=344507) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=344507) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=344507) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=344507) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=344507) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=344507) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=344507) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=344507) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=344507) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=344507) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=344507) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=344507) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r147, %rs32;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r148, %rs34;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r149, %rs36;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r150, %rs38;
(EngineCore_DP0 pid=344507) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=344507) 	add.s32 	%r151, %r138, 2;
(EngineCore_DP0 pid=344507) 	add.s32 	%r152, %r137, 2;
(EngineCore_DP0 pid=344507) 	add.s32 	%r153, %r136, 2;
(EngineCore_DP0 pid=344507) 	add.s32 	%r154, %r135, 2;
(EngineCore_DP0 pid=344507) 	add.s32 	%r155, %r138, 3;
(EngineCore_DP0 pid=344507) 	add.s32 	%r156, %r137, 3;
(EngineCore_DP0 pid=344507) 	add.s32 	%r157, %r136, 3;
(EngineCore_DP0 pid=344507) 	add.s32 	%r158, %r135, 3;
(EngineCore_DP0 pid=344507) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p34, %r158, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p35, %r157, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p36, %r156, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p37, %r155, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p38, %r154, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p39, %r153, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p40, %r152, %r27;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p41, %r151, %r27;
(EngineCore_DP0 pid=344507) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=344507) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=344507) 	and.pred 	%p18, %p25, %p40;
(EngineCore_DP0 pid=344507) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=344507) 	and.pred 	%p20, %p25, %p38;
(EngineCore_DP0 pid=344507) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=344507) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=344507) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=344507) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=344507) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=344507) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=344507) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=344507) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=344507) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=344507) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r159, %rs40;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r160, %rs42;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r161, %rs44;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r162, %rs46;
(EngineCore_DP0 pid=344507) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=344507) 	and.pred 	%p21, %p25, %p37;
(EngineCore_DP0 pid=344507) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=344507) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=344507) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=344507) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=344507) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=344507) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=344507) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=344507) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=344507) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=344507) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=344507) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=344507) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=344507) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r163, %rs48;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r164, %rs50;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r165, %rs52;
(EngineCore_DP0 pid=344507) 	cvt.f32.bf16 	%r166, %rs54;
(EngineCore_DP0 pid=344507) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=344507) 	mul.f32 	%r167, %r14, %r139;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r168, %r14, %r140;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r169, %r14, %r141;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r170, %r14, %r142;
(EngineCore_DP0 pid=344507) 	mov.b32 	%r171, 0f43E00000;
(EngineCore_DP0 pid=344507) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r82, %r167, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r83, %r168, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r84, %r169, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r85, %r170, %r171;
(EngineCore_DP0 pid=344507) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=344507) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=344507) 	mul.f32 	%r172, %r14, %r147;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r173, %r14, %r148;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r174, %r14, %r149;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r175, %r14, %r150;
(EngineCore_DP0 pid=344507) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r86, %r172, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r87, %r173, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r88, %r174, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r89, %r175, %r171;
(EngineCore_DP0 pid=344507) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=344507) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=344507) 	mul.f32 	%r176, %r14, %r159;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r177, %r14, %r160;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r178, %r14, %r161;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r179, %r14, %r162;
(EngineCore_DP0 pid=344507) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r90, %r176, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r91, %r177, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r92, %r178, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r93, %r179, %r171;
(EngineCore_DP0 pid=344507) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=344507) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=344507) 	mul.f32 	%r180, %r14, %r163;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r181, %r14, %r164;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r182, %r14, %r165;
(EngineCore_DP0 pid=344507) 	mul.f32 	%r183, %r14, %r166;
(EngineCore_DP0 pid=344507) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r94, %r180, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r95, %r181, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r96, %r182, %r171;
(EngineCore_DP0 pid=344507) 	min.xorsign.abs.f32 	%r97, %r183, %r171;
(EngineCore_DP0 pid=344507) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=344507) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r184, %rs56;
(EngineCore_DP0 pid=344507) 	and.b32 	%r185, %r184, 255;
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r186, %rs64;
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r187, %rs57;
(EngineCore_DP0 pid=344507) 	and.b32 	%r188, %r187, 255;
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r189, %rs65;
(EngineCore_DP0 pid=344507) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r190, %rs60;
(EngineCore_DP0 pid=344507) 	and.b32 	%r191, %r190, 255;
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r192, %rs68;
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r193, %rs61;
(EngineCore_DP0 pid=344507) 	and.b32 	%r194, %r193, 255;
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r195, %rs69;
(EngineCore_DP0 pid=344507) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r196, %rs62;
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r197, %rs70;
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r198, %rs63;
(EngineCore_DP0 pid=344507) 	cvt.u32.u16 	%r199, %rs71;
(EngineCore_DP0 pid=344507) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=344507) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=344507) 	mul.wide.u16 	%r200, %rs72, 256;
(EngineCore_DP0 pid=344507) 	mul.wide.u16 	%r201, %rs66, 256;
(EngineCore_DP0 pid=344507) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=344507) 	mul.wide.u16 	%r202, %rs73, 256;
(EngineCore_DP0 pid=344507) 	mul.wide.u16 	%r203, %rs67, 256;
(EngineCore_DP0 pid=344507) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=344507) 	or.b32 	%r204, %r200, %r185;
(EngineCore_DP0 pid=344507) 	or.b32 	%r205, %r201, %r186;
(EngineCore_DP0 pid=344507) 	or.b32 	%r206, %r202, %r188;
(EngineCore_DP0 pid=344507) 	or.b32 	%r207, %r203, %r189;
(EngineCore_DP0 pid=344507) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=344507) 	shl.b32 	%r208, %r191, 16;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r209, %r192, 16;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r210, %r194, 16;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r211, %r195, 16;
(EngineCore_DP0 pid=344507) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=344507) 	or.b32 	%r212, %r208, %r204;
(EngineCore_DP0 pid=344507) 	or.b32 	%r213, %r209, %r205;
(EngineCore_DP0 pid=344507) 	or.b32 	%r214, %r210, %r206;
(EngineCore_DP0 pid=344507) 	or.b32 	%r215, %r211, %r207;
(EngineCore_DP0 pid=344507) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=344507) 	shl.b32 	%r216, %r196, 24;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r217, %r197, 24;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r218, %r198, 24;
(EngineCore_DP0 pid=344507) 	shl.b32 	%r219, %r199, 24;
(EngineCore_DP0 pid=344507) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=344507) 	or.b32 	%r98, %r216, %r212;
(EngineCore_DP0 pid=344507) 	or.b32 	%r99, %r217, %r213;
(EngineCore_DP0 pid=344507) 	or.b32 	%r100, %r218, %r214;
(EngineCore_DP0 pid=344507) 	or.b32 	%r101, %r219, %r215;
(EngineCore_DP0 pid=344507) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=344507) 	mad.wide.s32 	%rd24, %r103, 4, %rd2;
(EngineCore_DP0 pid=344507) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=344507) 	// begin inline asm
(EngineCore_DP0 pid=344507) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=344507) 	// end inline asm
(EngineCore_DP0 pid=344507) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=344507) 	add.s32 	%r223, %r223, 2048;
(EngineCore_DP0 pid=344507) 	setp.lt.s32 	%p42, %r223, %r15;
(EngineCore_DP0 pid=344507) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=344507) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=344507) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=344507) 	ret;
(EngineCore_DP0 pid=344507) $L__tmp3:
(EngineCore_DP0 pid=344507) $L__func_end0:
(EngineCore_DP0 pid=344507)                                         // -- End function
(EngineCore_DP0 pid=344507) }
(EngineCore_DP0 pid=344507) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=344507) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=344507) 	.section	.debug_abbrev
(EngineCore_DP0 pid=344507) 	{
(EngineCore_DP0 pid=344507) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=344507) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=344507) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=344507) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=344507) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=344507) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=344507) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=344507) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=344507) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=344507) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=344507) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=344507) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=344507) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=344507) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=344507) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=344507) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=344507) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=344507) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=344507) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=344507) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=344507) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=344507) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=344507) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=344507) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=344507) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=344507) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=344507) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=344507) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=344507) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=344507) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=344507) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=344507) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=344507) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=344507) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=344507) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=344507) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=344507) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=344507) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=344507) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=344507) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=344507) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=344507) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=344507) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=344507) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=344507) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=344507) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=344507) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=344507) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=344507) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=344507) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=344507) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=344507) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=344507) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=344507) 	}
(EngineCore_DP0 pid=344507) 	.section	.debug_info
(EngineCore_DP0 pid=344507) 	{
(EngineCore_DP0 pid=344507) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=344507) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=344507) .b8 0
(EngineCore_DP0 pid=344507) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=344507) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=344507) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=344507) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=344507) .b8 114
(EngineCore_DP0 pid=344507) .b8 105
(EngineCore_DP0 pid=344507) .b8 116
(EngineCore_DP0 pid=344507) .b8 111
(EngineCore_DP0 pid=344507) .b8 110
(EngineCore_DP0 pid=344507) .b8 0
(EngineCore_DP0 pid=344507) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=344507) .b8 0
(EngineCore_DP0 pid=344507) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=344507) .b8 117
(EngineCore_DP0 pid=344507) .b8 97
(EngineCore_DP0 pid=344507) .b8 110
(EngineCore_DP0 pid=344507) .b8 116
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 115
(EngineCore_DP0 pid=344507) .b8 108
(EngineCore_DP0 pid=344507) .b8 105
(EngineCore_DP0 pid=344507) .b8 100
(EngineCore_DP0 pid=344507) .b8 101
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 116
(EngineCore_DP0 pid=344507) .b8 117
(EngineCore_DP0 pid=344507) .b8 110
(EngineCore_DP0 pid=344507) .b8 101
(EngineCore_DP0 pid=344507) .b8 100
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 76
(EngineCore_DP0 pid=344507) .b8 108
(EngineCore_DP0 pid=344507) .b8 97
(EngineCore_DP0 pid=344507) .b8 109
(EngineCore_DP0 pid=344507) .b8 97
(EngineCore_DP0 pid=344507) .b8 51
(EngineCore_DP0 pid=344507) .b8 46
(EngineCore_DP0 pid=344507) .b8 50
(EngineCore_DP0 pid=344507) .b8 45
(EngineCore_DP0 pid=344507) .b8 49
(EngineCore_DP0 pid=344507) .b8 66
(EngineCore_DP0 pid=344507) .b8 46
(EngineCore_DP0 pid=344507) .b8 112
(EngineCore_DP0 pid=344507) .b8 121
(EngineCore_DP0 pid=344507) .b8 0
(EngineCore_DP0 pid=344507) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=344507) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=344507) .b8 114
(EngineCore_DP0 pid=344507) .b8 111
(EngineCore_DP0 pid=344507) .b8 111
(EngineCore_DP0 pid=344507) .b8 116
(EngineCore_DP0 pid=344507) .b8 47
(EngineCore_DP0 pid=344507) .b8 118
(EngineCore_DP0 pid=344507) .b8 108
(EngineCore_DP0 pid=344507) .b8 108
(EngineCore_DP0 pid=344507) .b8 109
(EngineCore_DP0 pid=344507) .b8 98
(EngineCore_DP0 pid=344507) .b8 101
(EngineCore_DP0 pid=344507) .b8 110
(EngineCore_DP0 pid=344507) .b8 99
(EngineCore_DP0 pid=344507) .b8 104
(EngineCore_DP0 pid=344507) .b8 47
(EngineCore_DP0 pid=344507) .b8 115
(EngineCore_DP0 pid=344507) .b8 108
(EngineCore_DP0 pid=344507) .b8 105
(EngineCore_DP0 pid=344507) .b8 100
(EngineCore_DP0 pid=344507) .b8 101
(EngineCore_DP0 pid=344507) .b8 115
(EngineCore_DP0 pid=344507) .b8 112
(EngineCore_DP0 pid=344507) .b8 97
(EngineCore_DP0 pid=344507) .b8 114
(EngineCore_DP0 pid=344507) .b8 115
(EngineCore_DP0 pid=344507) .b8 101
(EngineCore_DP0 pid=344507) .b8 47
(EngineCore_DP0 pid=344507) .b8 99
(EngineCore_DP0 pid=344507) .b8 115
(EngineCore_DP0 pid=344507) .b8 114
(EngineCore_DP0 pid=344507) .b8 99
(EngineCore_DP0 pid=344507) .b8 47
(EngineCore_DP0 pid=344507) .b8 102
(EngineCore_DP0 pid=344507) .b8 117
(EngineCore_DP0 pid=344507) .b8 115
(EngineCore_DP0 pid=344507) .b8 101
(EngineCore_DP0 pid=344507) .b8 100
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 113
(EngineCore_DP0 pid=344507) .b8 117
(EngineCore_DP0 pid=344507) .b8 97
(EngineCore_DP0 pid=344507) .b8 110
(EngineCore_DP0 pid=344507) .b8 116
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 115
(EngineCore_DP0 pid=344507) .b8 108
(EngineCore_DP0 pid=344507) .b8 105
(EngineCore_DP0 pid=344507) .b8 100
(EngineCore_DP0 pid=344507) .b8 101
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 116
(EngineCore_DP0 pid=344507) .b8 114
(EngineCore_DP0 pid=344507) .b8 105
(EngineCore_DP0 pid=344507) .b8 116
(EngineCore_DP0 pid=344507) .b8 111
(EngineCore_DP0 pid=344507) .b8 110
(EngineCore_DP0 pid=344507) .b8 47
(EngineCore_DP0 pid=344507) .b8 98
(EngineCore_DP0 pid=344507) .b8 117
(EngineCore_DP0 pid=344507) .b8 105
(EngineCore_DP0 pid=344507) .b8 108
(EngineCore_DP0 pid=344507) .b8 100
(EngineCore_DP0 pid=344507) .b8 47
(EngineCore_DP0 pid=344507) .b8 71
(EngineCore_DP0 pid=344507) .b8 66
(EngineCore_DP0 pid=344507) .b8 49
(EngineCore_DP0 pid=344507) .b8 48
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 99
(EngineCore_DP0 pid=344507) .b8 99
(EngineCore_DP0 pid=344507) .b8 49
(EngineCore_DP0 pid=344507) .b8 50
(EngineCore_DP0 pid=344507) .b8 49
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 112
(EngineCore_DP0 pid=344507) .b8 121
(EngineCore_DP0 pid=344507) .b8 51
(EngineCore_DP0 pid=344507) .b8 49
(EngineCore_DP0 pid=344507) .b8 50
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 99
(EngineCore_DP0 pid=344507) .b8 117
(EngineCore_DP0 pid=344507) .b8 49
(EngineCore_DP0 pid=344507) .b8 50
(EngineCore_DP0 pid=344507) .b8 57
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 97
(EngineCore_DP0 pid=344507) .b8 97
(EngineCore_DP0 pid=344507) .b8 114
(EngineCore_DP0 pid=344507) .b8 99
(EngineCore_DP0 pid=344507) .b8 104
(EngineCore_DP0 pid=344507) .b8 54
(EngineCore_DP0 pid=344507) .b8 52
(EngineCore_DP0 pid=344507) .b8 0
(EngineCore_DP0 pid=344507) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=344507) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=344507) .b8 113
(EngineCore_DP0 pid=344507) .b8 117
(EngineCore_DP0 pid=344507) .b8 97
(EngineCore_DP0 pid=344507) .b8 110
(EngineCore_DP0 pid=344507) .b8 116
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 115
(EngineCore_DP0 pid=344507) .b8 108
(EngineCore_DP0 pid=344507) .b8 105
(EngineCore_DP0 pid=344507) .b8 100
(EngineCore_DP0 pid=344507) .b8 101
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 102
(EngineCore_DP0 pid=344507) .b8 112
(EngineCore_DP0 pid=344507) .b8 56
(EngineCore_DP0 pid=344507) .b8 95
(EngineCore_DP0 pid=344507) .b8 107
(EngineCore_DP0 pid=344507) .b8 101
(EngineCore_DP0 pid=344507) .b8 114
(EngineCore_DP0 pid=344507) .b8 110
(EngineCore_DP0 pid=344507) .b8 101
(EngineCore_DP0 pid=344507) .b8 108
(EngineCore_DP0 pid=344507) .b8 0
(EngineCore_DP0 pid=344507) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=344507) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=344507) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=344507) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=344507) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=344507) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=344507) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=344507) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=344507) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=344507) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=344507) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=344507) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=344507) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=344507) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=344507) 	}
(EngineCore_DP0 pid=344507) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) ================================================================
(EngineCore_DP0 pid=344507) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpi3r0sygm.ptx', '-o', '/tmp/tmpi3r0sygm.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] 
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] 
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] 
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpi3r0sygm.ptx -o /tmp/tmpi3r0sygm.ptx.o
(EngineCore_DP0 pid=344507) ERROR 01-25 19:22:25 [core.py:866] 

STDERR:
[2026-01-25 19:22:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:22:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:22:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:22:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:22:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:22:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:22:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:22:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:22:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:22:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:22:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:22:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:22:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:22:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:22:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:22:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:22:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:22:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:12] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:12] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:12] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:12] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:12] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=344507) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=344507) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.95s/it]
(EngineCore_DP0 pid=344507) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.95s/it]
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=344507) [2026-01-25 19:22:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=344507) Process EngineCore_DP0:
(EngineCore_DP0 pid=344507) Traceback (most recent call last):
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=344507)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=344507)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=344507)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=344507) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpi3r0sygm.ptx', '-o', '/tmp/tmpi3r0sygm.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) Traceback (most recent call last):
(EngineCore_DP0 pid=344507)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=344507)     self.run()
(EngineCore_DP0 pid=344507)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=344507)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=344507)     raise e
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=344507)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=344507)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=344507)     super().__init__(
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=344507)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=344507)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=344507)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=344507)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=344507)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=344507)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=344507)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=344507)     return func(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=344507)     return func(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=344507)     self.model_runner.profile_run()
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=344507)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=344507)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=344507)     return func(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=344507)     outputs = self.model(
(EngineCore_DP0 pid=344507)               ^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=344507)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=344507)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=344507)     model_output = self.model(
(EngineCore_DP0 pid=344507)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=344507)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=344507)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=344507)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=344507)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=344507)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=344507)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=344507)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=344507)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=344507)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=344507)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=344507)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=344507)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=344507)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=344507)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=344507)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=344507)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=344507)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=344507)     return self._linear_fn(
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=344507)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=344507)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=344507)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=344507)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=344507)     return fn(input, L)
(EngineCore_DP0 pid=344507)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=344507)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=344507)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=344507)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=344507)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=344507)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=344507)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=344507)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=344507)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=344507)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=344507)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=344507)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=344507)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=344507)     raise PTXASError(error)
(EngineCore_DP0 pid=344507) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=344507) `ptxas` stderr:
(EngineCore_DP0 pid=344507) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=344507) 
(EngineCore_DP0 pid=344507) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpi3r0sygm.ptx -o /tmp/tmpi3r0sygm.ptx.o
(EngineCore_DP0 pid=344507) 
[rank0]:[W125 19:22:25.797732628 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 19:22:27
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:22:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:22:42 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=345178) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) ================================================================
(EngineCore_DP0 pid=345178) Internal Triton PTX codegen error
(EngineCore_DP0 pid=345178) `ptxas` stderr:
(EngineCore_DP0 pid=345178) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4ter7x9n.ptx -o /tmp/tmp4ter7x9n.ptx.o
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) //
(EngineCore_DP0 pid=345178) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=345178) //
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) .version 8.7
(EngineCore_DP0 pid=345178) .target sm_121a
(EngineCore_DP0 pid=345178) .address_size 64
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=345178) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=345178)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=345178) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=345178) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=345178) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=345178) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=345178) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=345178) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=345178) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=345178) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=345178) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=345178) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=345178) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=345178) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=345178) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=345178) )
(EngineCore_DP0 pid=345178) .reqntid 512
(EngineCore_DP0 pid=345178) {
(EngineCore_DP0 pid=345178) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=345178) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=345178) 	.reg .b32 	%r<224>;
(EngineCore_DP0 pid=345178) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=345178) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=345178) $L__func_begin0:
(EngineCore_DP0 pid=345178) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) // %bb.0:
(EngineCore_DP0 pid=345178) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=345178) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=345178) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=345178) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=345178) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=345178) $L__tmp0:
(EngineCore_DP0 pid=345178) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=345178) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=345178) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=345178) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=345178) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=345178) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=345178) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=345178) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=345178) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=345178) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=345178) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=345178) 	mov.b32 	%r222, 0f2B8CBCCC;
(EngineCore_DP0 pid=345178) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=345178) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=345178) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=345178) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=345178) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=345178) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=345178) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=345178) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=345178) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=345178) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=345178) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=345178) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=345178) 	mov.b32 	%r220, 0f00000000;
(EngineCore_DP0 pid=345178) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=345178) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=345178) 	mov.b32 	%r221, %r49;
(EngineCore_DP0 pid=345178) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=345178) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=345178) 	add.s32 	%r59, %r4, %r221;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=345178) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=345178) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=345178) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=345178) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=345178) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=345178) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=345178) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=345178) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=345178) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=345178) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=345178) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=345178) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=345178) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=345178) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=345178) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=345178) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=345178) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=345178) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=345178) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=345178) $L__tmp1:
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	bar.sync 	0;
(EngineCore_DP0 pid=345178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=345178) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=345178) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=345178) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=345178) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=345178) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=345178) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=345178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=345178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=345178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=345178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=345178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	bar.sync 	0;
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=345178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=345178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=345178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=345178) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=345178) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	bar.sync 	0;
(EngineCore_DP0 pid=345178) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=345178) $L__tmp2:
(EngineCore_DP0 pid=345178) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=345178) 	max.f32 	%r220, %r220, %r77;
(EngineCore_DP0 pid=345178) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=345178) 	add.s32 	%r221, %r221, 4096;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p6, %r221, %r28;
(EngineCore_DP0 pid=345178) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=345178) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=345178) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=345178) 	max.f32 	%r222, %r220, 0f2B8CBCCC;
(EngineCore_DP0 pid=345178) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=345178) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=345178) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=345178) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=345178) 	div.full.f32 	%r80, %r222, %r79;
(EngineCore_DP0 pid=345178) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=345178) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=345178) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=345178) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=345178) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=345178) 	mul.lo.s32 	%r15, %r29, 3;
(EngineCore_DP0 pid=345178) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=345178) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=345178) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=345178) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=345178) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=345178) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=345178) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=345178) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=345178) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=345178) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=345178) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=345178) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=345178) 	div.full.f32 	%r14, %r79, %r222;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=345178) 	mov.b32 	%r223, 0;
(EngineCore_DP0 pid=345178) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=345178)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=345178) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=345178) 	add.s32 	%r103, %r16, %r223;
(EngineCore_DP0 pid=345178) 	add.s32 	%r104, %r103, 1;
(EngineCore_DP0 pid=345178) 	add.s32 	%r105, %r103, 2;
(EngineCore_DP0 pid=345178) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=345178) 	add.s32 	%r106, %r103, 3;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p25, %r103, %r15;
(EngineCore_DP0 pid=345178) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=345178) 	mul.hi.s32 	%r107, %r106, 1431655766;
(EngineCore_DP0 pid=345178) 	shr.u32 	%r108, %r107, 31;
(EngineCore_DP0 pid=345178) 	add.s32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=345178) 	mul.hi.s32 	%r110, %r105, 1431655766;
(EngineCore_DP0 pid=345178) 	shr.u32 	%r111, %r110, 31;
(EngineCore_DP0 pid=345178) 	add.s32 	%r112, %r110, %r111;
(EngineCore_DP0 pid=345178) 	mul.hi.s32 	%r113, %r104, 1431655766;
(EngineCore_DP0 pid=345178) 	shr.u32 	%r114, %r113, 31;
(EngineCore_DP0 pid=345178) 	add.s32 	%r115, %r113, %r114;
(EngineCore_DP0 pid=345178) 	mul.hi.s32 	%r116, %r103, 1431655766;
(EngineCore_DP0 pid=345178) 	shr.u32 	%r117, %r116, 31;
(EngineCore_DP0 pid=345178) 	add.s32 	%r118, %r116, %r117;
(EngineCore_DP0 pid=345178) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=345178) 	mul.lo.s32 	%r119, %r118, 3;
(EngineCore_DP0 pid=345178) 	mul.lo.s32 	%r120, %r115, 3;
(EngineCore_DP0 pid=345178) 	mul.lo.s32 	%r121, %r112, 3;
(EngineCore_DP0 pid=345178) 	mul.lo.s32 	%r122, %r109, 3;
(EngineCore_DP0 pid=345178) 	sub.s32 	%r123, %r106, %r122;
(EngineCore_DP0 pid=345178) 	sub.s32 	%r124, %r105, %r121;
(EngineCore_DP0 pid=345178) 	sub.s32 	%r125, %r104, %r120;
(EngineCore_DP0 pid=345178) 	sub.s32 	%r126, %r103, %r119;
(EngineCore_DP0 pid=345178) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=345178) 	shl.b32 	%r127, %r118, 3;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r128, %r115, 3;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r129, %r112, 3;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r130, %r109, 3;
(EngineCore_DP0 pid=345178) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=345178) 	shl.b32 	%r131, %r126, 1;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r132, %r125, 1;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r133, %r124, 1;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r134, %r123, 1;
(EngineCore_DP0 pid=345178) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=345178) 	add.s32 	%r135, %r130, %r134;
(EngineCore_DP0 pid=345178) 	add.s32 	%r136, %r129, %r133;
(EngineCore_DP0 pid=345178) 	add.s32 	%r137, %r128, %r132;
(EngineCore_DP0 pid=345178) 	add.s32 	%r138, %r127, %r131;
(EngineCore_DP0 pid=345178) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p26, %r138, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p27, %r137, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p28, %r136, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p29, %r135, %r27;
(EngineCore_DP0 pid=345178) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=345178) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=345178) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=345178) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=345178) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=345178) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=345178) 	mad.wide.s32 	%rd8, %r138, 2, %rd1;
(EngineCore_DP0 pid=345178) 	mad.wide.s32 	%rd9, %r137, 2, %rd1;
(EngineCore_DP0 pid=345178) 	mad.wide.s32 	%rd10, %r136, 2, %rd1;
(EngineCore_DP0 pid=345178) 	mad.wide.s32 	%rd11, %r135, 2, %rd1;
(EngineCore_DP0 pid=345178) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=345178) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=345178) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=345178) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=345178) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=345178) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r139, %rs24;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r140, %rs26;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r141, %rs28;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r142, %rs30;
(EngineCore_DP0 pid=345178) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=345178) 	or.b32 	%r143, %r138, 1;
(EngineCore_DP0 pid=345178) 	or.b32 	%r144, %r137, 1;
(EngineCore_DP0 pid=345178) 	or.b32 	%r145, %r136, 1;
(EngineCore_DP0 pid=345178) 	or.b32 	%r146, %r135, 1;
(EngineCore_DP0 pid=345178) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p30, %r143, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p31, %r144, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p32, %r145, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p33, %r146, %r27;
(EngineCore_DP0 pid=345178) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=345178) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=345178) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=345178) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=345178) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=345178) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=345178) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=345178) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=345178) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=345178) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=345178) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=345178) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=345178) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=345178) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=345178) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r147, %rs32;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r148, %rs34;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r149, %rs36;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r150, %rs38;
(EngineCore_DP0 pid=345178) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=345178) 	add.s32 	%r151, %r138, 2;
(EngineCore_DP0 pid=345178) 	add.s32 	%r152, %r137, 2;
(EngineCore_DP0 pid=345178) 	add.s32 	%r153, %r136, 2;
(EngineCore_DP0 pid=345178) 	add.s32 	%r154, %r135, 2;
(EngineCore_DP0 pid=345178) 	add.s32 	%r155, %r138, 3;
(EngineCore_DP0 pid=345178) 	add.s32 	%r156, %r137, 3;
(EngineCore_DP0 pid=345178) 	add.s32 	%r157, %r136, 3;
(EngineCore_DP0 pid=345178) 	add.s32 	%r158, %r135, 3;
(EngineCore_DP0 pid=345178) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p34, %r158, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p35, %r157, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p36, %r156, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p37, %r155, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p38, %r154, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p39, %r153, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p40, %r152, %r27;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p41, %r151, %r27;
(EngineCore_DP0 pid=345178) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=345178) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=345178) 	and.pred 	%p18, %p25, %p40;
(EngineCore_DP0 pid=345178) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=345178) 	and.pred 	%p20, %p25, %p38;
(EngineCore_DP0 pid=345178) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=345178) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=345178) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=345178) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=345178) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=345178) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=345178) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=345178) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=345178) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=345178) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r159, %rs40;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r160, %rs42;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r161, %rs44;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r162, %rs46;
(EngineCore_DP0 pid=345178) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=345178) 	and.pred 	%p21, %p25, %p37;
(EngineCore_DP0 pid=345178) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=345178) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=345178) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=345178) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=345178) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=345178) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=345178) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=345178) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=345178) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=345178) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=345178) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=345178) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=345178) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r163, %rs48;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r164, %rs50;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r165, %rs52;
(EngineCore_DP0 pid=345178) 	cvt.f32.bf16 	%r166, %rs54;
(EngineCore_DP0 pid=345178) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=345178) 	mul.f32 	%r167, %r14, %r139;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r168, %r14, %r140;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r169, %r14, %r141;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r170, %r14, %r142;
(EngineCore_DP0 pid=345178) 	mov.b32 	%r171, 0f43E00000;
(EngineCore_DP0 pid=345178) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r82, %r167, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r83, %r168, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r84, %r169, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r85, %r170, %r171;
(EngineCore_DP0 pid=345178) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=345178) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=345178) 	mul.f32 	%r172, %r14, %r147;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r173, %r14, %r148;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r174, %r14, %r149;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r175, %r14, %r150;
(EngineCore_DP0 pid=345178) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r86, %r172, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r87, %r173, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r88, %r174, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r89, %r175, %r171;
(EngineCore_DP0 pid=345178) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=345178) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=345178) 	mul.f32 	%r176, %r14, %r159;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r177, %r14, %r160;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r178, %r14, %r161;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r179, %r14, %r162;
(EngineCore_DP0 pid=345178) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r90, %r176, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r91, %r177, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r92, %r178, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r93, %r179, %r171;
(EngineCore_DP0 pid=345178) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=345178) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=345178) 	mul.f32 	%r180, %r14, %r163;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r181, %r14, %r164;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r182, %r14, %r165;
(EngineCore_DP0 pid=345178) 	mul.f32 	%r183, %r14, %r166;
(EngineCore_DP0 pid=345178) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r94, %r180, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r95, %r181, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r96, %r182, %r171;
(EngineCore_DP0 pid=345178) 	min.xorsign.abs.f32 	%r97, %r183, %r171;
(EngineCore_DP0 pid=345178) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=345178) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r184, %rs56;
(EngineCore_DP0 pid=345178) 	and.b32 	%r185, %r184, 255;
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r186, %rs64;
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r187, %rs57;
(EngineCore_DP0 pid=345178) 	and.b32 	%r188, %r187, 255;
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r189, %rs65;
(EngineCore_DP0 pid=345178) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r190, %rs60;
(EngineCore_DP0 pid=345178) 	and.b32 	%r191, %r190, 255;
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r192, %rs68;
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r193, %rs61;
(EngineCore_DP0 pid=345178) 	and.b32 	%r194, %r193, 255;
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r195, %rs69;
(EngineCore_DP0 pid=345178) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r196, %rs62;
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r197, %rs70;
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r198, %rs63;
(EngineCore_DP0 pid=345178) 	cvt.u32.u16 	%r199, %rs71;
(EngineCore_DP0 pid=345178) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=345178) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=345178) 	mul.wide.u16 	%r200, %rs72, 256;
(EngineCore_DP0 pid=345178) 	mul.wide.u16 	%r201, %rs66, 256;
(EngineCore_DP0 pid=345178) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=345178) 	mul.wide.u16 	%r202, %rs73, 256;
(EngineCore_DP0 pid=345178) 	mul.wide.u16 	%r203, %rs67, 256;
(EngineCore_DP0 pid=345178) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=345178) 	or.b32 	%r204, %r200, %r185;
(EngineCore_DP0 pid=345178) 	or.b32 	%r205, %r201, %r186;
(EngineCore_DP0 pid=345178) 	or.b32 	%r206, %r202, %r188;
(EngineCore_DP0 pid=345178) 	or.b32 	%r207, %r203, %r189;
(EngineCore_DP0 pid=345178) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=345178) 	shl.b32 	%r208, %r191, 16;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r209, %r192, 16;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r210, %r194, 16;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r211, %r195, 16;
(EngineCore_DP0 pid=345178) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=345178) 	or.b32 	%r212, %r208, %r204;
(EngineCore_DP0 pid=345178) 	or.b32 	%r213, %r209, %r205;
(EngineCore_DP0 pid=345178) 	or.b32 	%r214, %r210, %r206;
(EngineCore_DP0 pid=345178) 	or.b32 	%r215, %r211, %r207;
(EngineCore_DP0 pid=345178) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=345178) 	shl.b32 	%r216, %r196, 24;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r217, %r197, 24;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r218, %r198, 24;
(EngineCore_DP0 pid=345178) 	shl.b32 	%r219, %r199, 24;
(EngineCore_DP0 pid=345178) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=345178) 	or.b32 	%r98, %r216, %r212;
(EngineCore_DP0 pid=345178) 	or.b32 	%r99, %r217, %r213;
(EngineCore_DP0 pid=345178) 	or.b32 	%r100, %r218, %r214;
(EngineCore_DP0 pid=345178) 	or.b32 	%r101, %r219, %r215;
(EngineCore_DP0 pid=345178) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=345178) 	mad.wide.s32 	%rd24, %r103, 4, %rd2;
(EngineCore_DP0 pid=345178) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=345178) 	// begin inline asm
(EngineCore_DP0 pid=345178) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=345178) 	// end inline asm
(EngineCore_DP0 pid=345178) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=345178) 	add.s32 	%r223, %r223, 2048;
(EngineCore_DP0 pid=345178) 	setp.lt.s32 	%p42, %r223, %r15;
(EngineCore_DP0 pid=345178) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=345178) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=345178) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=345178) 	ret;
(EngineCore_DP0 pid=345178) $L__tmp3:
(EngineCore_DP0 pid=345178) $L__func_end0:
(EngineCore_DP0 pid=345178)                                         // -- End function
(EngineCore_DP0 pid=345178) }
(EngineCore_DP0 pid=345178) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=345178) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=345178) 	.section	.debug_abbrev
(EngineCore_DP0 pid=345178) 	{
(EngineCore_DP0 pid=345178) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=345178) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=345178) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=345178) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=345178) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=345178) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=345178) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=345178) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=345178) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=345178) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=345178) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=345178) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=345178) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=345178) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=345178) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=345178) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=345178) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=345178) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=345178) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=345178) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=345178) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=345178) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=345178) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=345178) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=345178) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=345178) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=345178) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=345178) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=345178) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=345178) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=345178) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=345178) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=345178) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=345178) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=345178) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=345178) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=345178) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=345178) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=345178) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=345178) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=345178) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=345178) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=345178) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=345178) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=345178) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=345178) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=345178) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=345178) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=345178) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=345178) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=345178) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=345178) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=345178) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=345178) 	}
(EngineCore_DP0 pid=345178) 	.section	.debug_info
(EngineCore_DP0 pid=345178) 	{
(EngineCore_DP0 pid=345178) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=345178) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=345178) .b8 0
(EngineCore_DP0 pid=345178) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=345178) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=345178) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=345178) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=345178) .b8 114
(EngineCore_DP0 pid=345178) .b8 105
(EngineCore_DP0 pid=345178) .b8 116
(EngineCore_DP0 pid=345178) .b8 111
(EngineCore_DP0 pid=345178) .b8 110
(EngineCore_DP0 pid=345178) .b8 0
(EngineCore_DP0 pid=345178) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=345178) .b8 0
(EngineCore_DP0 pid=345178) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=345178) .b8 117
(EngineCore_DP0 pid=345178) .b8 97
(EngineCore_DP0 pid=345178) .b8 110
(EngineCore_DP0 pid=345178) .b8 116
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 115
(EngineCore_DP0 pid=345178) .b8 108
(EngineCore_DP0 pid=345178) .b8 105
(EngineCore_DP0 pid=345178) .b8 100
(EngineCore_DP0 pid=345178) .b8 101
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 116
(EngineCore_DP0 pid=345178) .b8 117
(EngineCore_DP0 pid=345178) .b8 110
(EngineCore_DP0 pid=345178) .b8 101
(EngineCore_DP0 pid=345178) .b8 100
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 76
(EngineCore_DP0 pid=345178) .b8 108
(EngineCore_DP0 pid=345178) .b8 97
(EngineCore_DP0 pid=345178) .b8 109
(EngineCore_DP0 pid=345178) .b8 97
(EngineCore_DP0 pid=345178) .b8 51
(EngineCore_DP0 pid=345178) .b8 46
(EngineCore_DP0 pid=345178) .b8 50
(EngineCore_DP0 pid=345178) .b8 45
(EngineCore_DP0 pid=345178) .b8 49
(EngineCore_DP0 pid=345178) .b8 66
(EngineCore_DP0 pid=345178) .b8 46
(EngineCore_DP0 pid=345178) .b8 112
(EngineCore_DP0 pid=345178) .b8 121
(EngineCore_DP0 pid=345178) .b8 0
(EngineCore_DP0 pid=345178) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=345178) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=345178) .b8 114
(EngineCore_DP0 pid=345178) .b8 111
(EngineCore_DP0 pid=345178) .b8 111
(EngineCore_DP0 pid=345178) .b8 116
(EngineCore_DP0 pid=345178) .b8 47
(EngineCore_DP0 pid=345178) .b8 118
(EngineCore_DP0 pid=345178) .b8 108
(EngineCore_DP0 pid=345178) .b8 108
(EngineCore_DP0 pid=345178) .b8 109
(EngineCore_DP0 pid=345178) .b8 98
(EngineCore_DP0 pid=345178) .b8 101
(EngineCore_DP0 pid=345178) .b8 110
(EngineCore_DP0 pid=345178) .b8 99
(EngineCore_DP0 pid=345178) .b8 104
(EngineCore_DP0 pid=345178) .b8 47
(EngineCore_DP0 pid=345178) .b8 115
(EngineCore_DP0 pid=345178) .b8 108
(EngineCore_DP0 pid=345178) .b8 105
(EngineCore_DP0 pid=345178) .b8 100
(EngineCore_DP0 pid=345178) .b8 101
(EngineCore_DP0 pid=345178) .b8 115
(EngineCore_DP0 pid=345178) .b8 112
(EngineCore_DP0 pid=345178) .b8 97
(EngineCore_DP0 pid=345178) .b8 114
(EngineCore_DP0 pid=345178) .b8 115
(EngineCore_DP0 pid=345178) .b8 101
(EngineCore_DP0 pid=345178) .b8 47
(EngineCore_DP0 pid=345178) .b8 99
(EngineCore_DP0 pid=345178) .b8 115
(EngineCore_DP0 pid=345178) .b8 114
(EngineCore_DP0 pid=345178) .b8 99
(EngineCore_DP0 pid=345178) .b8 47
(EngineCore_DP0 pid=345178) .b8 102
(EngineCore_DP0 pid=345178) .b8 117
(EngineCore_DP0 pid=345178) .b8 115
(EngineCore_DP0 pid=345178) .b8 101
(EngineCore_DP0 pid=345178) .b8 100
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 113
(EngineCore_DP0 pid=345178) .b8 117
(EngineCore_DP0 pid=345178) .b8 97
(EngineCore_DP0 pid=345178) .b8 110
(EngineCore_DP0 pid=345178) .b8 116
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 115
(EngineCore_DP0 pid=345178) .b8 108
(EngineCore_DP0 pid=345178) .b8 105
(EngineCore_DP0 pid=345178) .b8 100
(EngineCore_DP0 pid=345178) .b8 101
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 116
(EngineCore_DP0 pid=345178) .b8 114
(EngineCore_DP0 pid=345178) .b8 105
(EngineCore_DP0 pid=345178) .b8 116
(EngineCore_DP0 pid=345178) .b8 111
(EngineCore_DP0 pid=345178) .b8 110
(EngineCore_DP0 pid=345178) .b8 47
(EngineCore_DP0 pid=345178) .b8 98
(EngineCore_DP0 pid=345178) .b8 117
(EngineCore_DP0 pid=345178) .b8 105
(EngineCore_DP0 pid=345178) .b8 108
(EngineCore_DP0 pid=345178) .b8 100
(EngineCore_DP0 pid=345178) .b8 47
(EngineCore_DP0 pid=345178) .b8 71
(EngineCore_DP0 pid=345178) .b8 66
(EngineCore_DP0 pid=345178) .b8 49
(EngineCore_DP0 pid=345178) .b8 48
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 99
(EngineCore_DP0 pid=345178) .b8 99
(EngineCore_DP0 pid=345178) .b8 49
(EngineCore_DP0 pid=345178) .b8 50
(EngineCore_DP0 pid=345178) .b8 49
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 112
(EngineCore_DP0 pid=345178) .b8 121
(EngineCore_DP0 pid=345178) .b8 51
(EngineCore_DP0 pid=345178) .b8 49
(EngineCore_DP0 pid=345178) .b8 50
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 99
(EngineCore_DP0 pid=345178) .b8 117
(EngineCore_DP0 pid=345178) .b8 49
(EngineCore_DP0 pid=345178) .b8 50
(EngineCore_DP0 pid=345178) .b8 57
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 97
(EngineCore_DP0 pid=345178) .b8 97
(EngineCore_DP0 pid=345178) .b8 114
(EngineCore_DP0 pid=345178) .b8 99
(EngineCore_DP0 pid=345178) .b8 104
(EngineCore_DP0 pid=345178) .b8 54
(EngineCore_DP0 pid=345178) .b8 52
(EngineCore_DP0 pid=345178) .b8 0
(EngineCore_DP0 pid=345178) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=345178) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=345178) .b8 113
(EngineCore_DP0 pid=345178) .b8 117
(EngineCore_DP0 pid=345178) .b8 97
(EngineCore_DP0 pid=345178) .b8 110
(EngineCore_DP0 pid=345178) .b8 116
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 115
(EngineCore_DP0 pid=345178) .b8 108
(EngineCore_DP0 pid=345178) .b8 105
(EngineCore_DP0 pid=345178) .b8 100
(EngineCore_DP0 pid=345178) .b8 101
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 102
(EngineCore_DP0 pid=345178) .b8 112
(EngineCore_DP0 pid=345178) .b8 56
(EngineCore_DP0 pid=345178) .b8 95
(EngineCore_DP0 pid=345178) .b8 107
(EngineCore_DP0 pid=345178) .b8 101
(EngineCore_DP0 pid=345178) .b8 114
(EngineCore_DP0 pid=345178) .b8 110
(EngineCore_DP0 pid=345178) .b8 101
(EngineCore_DP0 pid=345178) .b8 108
(EngineCore_DP0 pid=345178) .b8 0
(EngineCore_DP0 pid=345178) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=345178) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=345178) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=345178) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=345178) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=345178) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=345178) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=345178) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=345178) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=345178) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=345178) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=345178) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=345178) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=345178) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=345178) 	}
(EngineCore_DP0 pid=345178) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) ================================================================
(EngineCore_DP0 pid=345178) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp4ter7x9n.ptx', '-o', '/tmp/tmp4ter7x9n.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] 
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] 
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] 
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4ter7x9n.ptx -o /tmp/tmp4ter7x9n.ptx.o
(EngineCore_DP0 pid=345178) ERROR 01-25 19:22:59 [core.py:866] 

STDERR:
[2026-01-25 19:22:42] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:22:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:22:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:22:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:22:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:22:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:22:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:22:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:22:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:22:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:22:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:22:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:22:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:22:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:22:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:22:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:22:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:22:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:22:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=345178) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=345178) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.98s/it]
(EngineCore_DP0 pid=345178) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.98s/it]
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=345178) [2026-01-25 19:22:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=345178) Process EngineCore_DP0:
(EngineCore_DP0 pid=345178) Traceback (most recent call last):
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=345178)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=345178)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=345178)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=345178) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp4ter7x9n.ptx', '-o', '/tmp/tmp4ter7x9n.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) Traceback (most recent call last):
(EngineCore_DP0 pid=345178)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=345178)     self.run()
(EngineCore_DP0 pid=345178)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=345178)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=345178)     raise e
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=345178)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=345178)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=345178)     super().__init__(
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=345178)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=345178)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=345178)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=345178)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=345178)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=345178)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=345178)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=345178)     return func(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=345178)     return func(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=345178)     self.model_runner.profile_run()
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=345178)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=345178)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=345178)     return func(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=345178)     outputs = self.model(
(EngineCore_DP0 pid=345178)               ^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345178)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345178)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=345178)     model_output = self.model(
(EngineCore_DP0 pid=345178)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=345178)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=345178)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=345178)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345178)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345178)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=345178)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=345178)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345178)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345178)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=345178)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=345178)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345178)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345178)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=345178)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=345178)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=345178)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=345178)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=345178)     return self._linear_fn(
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=345178)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=345178)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=345178)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=345178)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=345178)     return fn(input, L)
(EngineCore_DP0 pid=345178)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=345178)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=345178)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=345178)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=345178)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=345178)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=345178)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=345178)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=345178)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=345178)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=345178)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=345178)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345178)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=345178)     raise PTXASError(error)
(EngineCore_DP0 pid=345178) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=345178) `ptxas` stderr:
(EngineCore_DP0 pid=345178) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=345178) 
(EngineCore_DP0 pid=345178) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4ter7x9n.ptx -o /tmp/tmp4ter7x9n.ptx.o
(EngineCore_DP0 pid=345178) 
[rank0]:[W125 19:22:59.776952136 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 19:23:01
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:23:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:23:28 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=345999) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) ================================================================
(EngineCore_DP0 pid=345999) Internal Triton PTX codegen error
(EngineCore_DP0 pid=345999) `ptxas` stderr:
(EngineCore_DP0 pid=345999) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpc0f7qe0r.ptx -o /tmp/tmpc0f7qe0r.ptx.o
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) //
(EngineCore_DP0 pid=345999) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=345999) //
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) .version 8.7
(EngineCore_DP0 pid=345999) .target sm_121a
(EngineCore_DP0 pid=345999) .address_size 64
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=345999) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=345999)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=345999) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=345999) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=345999) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=345999) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=345999) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=345999) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=345999) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=345999) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=345999) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=345999) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=345999) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=345999) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=345999) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=345999) )
(EngineCore_DP0 pid=345999) .reqntid 512
(EngineCore_DP0 pid=345999) {
(EngineCore_DP0 pid=345999) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=345999) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=345999) 	.reg .b32 	%r<224>;
(EngineCore_DP0 pid=345999) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=345999) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=345999) $L__func_begin0:
(EngineCore_DP0 pid=345999) 	.loc	1 167 0                         // quant_slide_tuned_Llama3.2-1B.py:167:0
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) // %bb.0:
(EngineCore_DP0 pid=345999) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=345999) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=345999) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=345999) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=345999) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=345999) $L__tmp0:
(EngineCore_DP0 pid=345999) 	.loc	1 177 24                        // quant_slide_tuned_Llama3.2-1B.py:177:24
(EngineCore_DP0 pid=345999) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=345999) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=345999) 	.loc	1 182 26                        // quant_slide_tuned_Llama3.2-1B.py:182:26
(EngineCore_DP0 pid=345999) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=345999) 	.loc	1 182 20                        // quant_slide_tuned_Llama3.2-1B.py:182:20
(EngineCore_DP0 pid=345999) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=345999) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=345999) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=345999) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=345999) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=345999) 	mov.b32 	%r222, 0f2B8CBCCC;
(EngineCore_DP0 pid=345999) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=345999) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=345999) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=345999) 	.loc	1 188 32                        // quant_slide_tuned_Llama3.2-1B.py:188:32
(EngineCore_DP0 pid=345999) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=345999) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=345999) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=345999) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=345999) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=345999) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=345999) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=345999) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=345999) 	mov.b32 	%r220, 0f00000000;
(EngineCore_DP0 pid=345999) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=345999) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=345999) 	mov.b32 	%r221, %r49;
(EngineCore_DP0 pid=345999) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=345999) 	.loc	1 189 22                        // quant_slide_tuned_Llama3.2-1B.py:189:22
(EngineCore_DP0 pid=345999) 	add.s32 	%r59, %r4, %r221;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=345999) 	.loc	1 190 29                        // quant_slide_tuned_Llama3.2-1B.py:190:29
(EngineCore_DP0 pid=345999) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=345999) 	.loc	1 190 21                        // quant_slide_tuned_Llama3.2-1B.py:190:21
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=345999) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=345999) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=345999) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=345999) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=345999) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=345999) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=345999) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=345999) 	.loc	1 191 50                        // quant_slide_tuned_Llama3.2-1B.py:191:50
(EngineCore_DP0 pid=345999) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=345999) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=345999) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=345999) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=345999) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=345999) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=345999) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=345999) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=345999) $L__tmp1:
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	bar.sync 	0;
(EngineCore_DP0 pid=345999) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=345999) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=345999) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=345999) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=345999) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=345999) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=345999) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=345999) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=345999) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=345999) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=345999) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=345999) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	bar.sync 	0;
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=345999) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=345999) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=345999) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=345999) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=345999) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-1B.py:191:43 ]
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	bar.sync 	0;
(EngineCore_DP0 pid=345999) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=345999) $L__tmp2:
(EngineCore_DP0 pid=345999) 	.loc	1 191 36                        // quant_slide_tuned_Llama3.2-1B.py:191:36
(EngineCore_DP0 pid=345999) 	max.f32 	%r220, %r220, %r77;
(EngineCore_DP0 pid=345999) 	.loc	1 187 35                        // quant_slide_tuned_Llama3.2-1B.py:187:35
(EngineCore_DP0 pid=345999) 	add.s32 	%r221, %r221, 4096;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p6, %r221, %r28;
(EngineCore_DP0 pid=345999) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=345999) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=345999) 	.loc	1 193 32                        // quant_slide_tuned_Llama3.2-1B.py:193:32
(EngineCore_DP0 pid=345999) 	max.f32 	%r222, %r220, 0f2B8CBCCC;
(EngineCore_DP0 pid=345999) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=345999) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-1B.py:0:32
(EngineCore_DP0 pid=345999) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=345999) 	.loc	1 194 32                        // quant_slide_tuned_Llama3.2-1B.py:194:32
(EngineCore_DP0 pid=345999) 	div.full.f32 	%r80, %r222, %r79;
(EngineCore_DP0 pid=345999) 	.loc	1 194 41                        // quant_slide_tuned_Llama3.2-1B.py:194:41
(EngineCore_DP0 pid=345999) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=345999) 	.loc	1 196 25                        // quant_slide_tuned_Llama3.2-1B.py:196:25
(EngineCore_DP0 pid=345999) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=345999) 	.loc	1 196 30                        // quant_slide_tuned_Llama3.2-1B.py:196:30
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	.loc	1 199 29                        // quant_slide_tuned_Llama3.2-1B.py:199:29
(EngineCore_DP0 pid=345999) 	mul.lo.s32 	%r15, %r29, 3;
(EngineCore_DP0 pid=345999) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=345999) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=345999) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=345999) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-1B.py:0:41
(EngineCore_DP0 pid=345999) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=345999) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=345999) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=345999) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=345999) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=345999) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=345999) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=345999) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=345999) 	div.full.f32 	%r14, %r79, %r222;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=345999) 	mov.b32 	%r223, 0;
(EngineCore_DP0 pid=345999) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=345999)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=345999) 	.loc	1 202 31                        // quant_slide_tuned_Llama3.2-1B.py:202:31
(EngineCore_DP0 pid=345999) 	add.s32 	%r103, %r16, %r223;
(EngineCore_DP0 pid=345999) 	add.s32 	%r104, %r103, 1;
(EngineCore_DP0 pid=345999) 	add.s32 	%r105, %r103, 2;
(EngineCore_DP0 pid=345999) 	.loc	1 203 30                        // quant_slide_tuned_Llama3.2-1B.py:203:30
(EngineCore_DP0 pid=345999) 	add.s32 	%r106, %r103, 3;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p25, %r103, %r15;
(EngineCore_DP0 pid=345999) 	.loc	1 206 24                        // quant_slide_tuned_Llama3.2-1B.py:206:24
(EngineCore_DP0 pid=345999) 	mul.hi.s32 	%r107, %r106, 1431655766;
(EngineCore_DP0 pid=345999) 	shr.u32 	%r108, %r107, 31;
(EngineCore_DP0 pid=345999) 	add.s32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=345999) 	mul.hi.s32 	%r110, %r105, 1431655766;
(EngineCore_DP0 pid=345999) 	shr.u32 	%r111, %r110, 31;
(EngineCore_DP0 pid=345999) 	add.s32 	%r112, %r110, %r111;
(EngineCore_DP0 pid=345999) 	mul.hi.s32 	%r113, %r104, 1431655766;
(EngineCore_DP0 pid=345999) 	shr.u32 	%r114, %r113, 31;
(EngineCore_DP0 pid=345999) 	add.s32 	%r115, %r113, %r114;
(EngineCore_DP0 pid=345999) 	mul.hi.s32 	%r116, %r103, 1431655766;
(EngineCore_DP0 pid=345999) 	shr.u32 	%r117, %r116, 31;
(EngineCore_DP0 pid=345999) 	add.s32 	%r118, %r116, %r117;
(EngineCore_DP0 pid=345999) 	.loc	1 207 23                        // quant_slide_tuned_Llama3.2-1B.py:207:23
(EngineCore_DP0 pid=345999) 	mul.lo.s32 	%r119, %r118, 3;
(EngineCore_DP0 pid=345999) 	mul.lo.s32 	%r120, %r115, 3;
(EngineCore_DP0 pid=345999) 	mul.lo.s32 	%r121, %r112, 3;
(EngineCore_DP0 pid=345999) 	mul.lo.s32 	%r122, %r109, 3;
(EngineCore_DP0 pid=345999) 	sub.s32 	%r123, %r106, %r122;
(EngineCore_DP0 pid=345999) 	sub.s32 	%r124, %r105, %r121;
(EngineCore_DP0 pid=345999) 	sub.s32 	%r125, %r104, %r120;
(EngineCore_DP0 pid=345999) 	sub.s32 	%r126, %r103, %r119;
(EngineCore_DP0 pid=345999) 	.loc	1 208 22                        // quant_slide_tuned_Llama3.2-1B.py:208:22
(EngineCore_DP0 pid=345999) 	shl.b32 	%r127, %r118, 3;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r128, %r115, 3;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r129, %r112, 3;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r130, %r109, 3;
(EngineCore_DP0 pid=345999) 	.loc	1 208 30                        // quant_slide_tuned_Llama3.2-1B.py:208:30
(EngineCore_DP0 pid=345999) 	shl.b32 	%r131, %r126, 1;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r132, %r125, 1;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r133, %r124, 1;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r134, %r123, 1;
(EngineCore_DP0 pid=345999) 	.loc	1 208 26                        // quant_slide_tuned_Llama3.2-1B.py:208:26
(EngineCore_DP0 pid=345999) 	add.s32 	%r135, %r130, %r134;
(EngineCore_DP0 pid=345999) 	add.s32 	%r136, %r129, %r133;
(EngineCore_DP0 pid=345999) 	add.s32 	%r137, %r128, %r132;
(EngineCore_DP0 pid=345999) 	add.s32 	%r138, %r127, %r131;
(EngineCore_DP0 pid=345999) 	.loc	1 211 53                        // quant_slide_tuned_Llama3.2-1B.py:211:53
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p26, %r138, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p27, %r137, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p28, %r136, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p29, %r135, %r27;
(EngineCore_DP0 pid=345999) 	.loc	1 211 37                        // quant_slide_tuned_Llama3.2-1B.py:211:37
(EngineCore_DP0 pid=345999) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=345999) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=345999) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=345999) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=345999) 	.loc	1 210 29                        // quant_slide_tuned_Llama3.2-1B.py:210:29
(EngineCore_DP0 pid=345999) 	mad.wide.s32 	%rd8, %r138, 2, %rd1;
(EngineCore_DP0 pid=345999) 	mad.wide.s32 	%rd9, %r137, 2, %rd1;
(EngineCore_DP0 pid=345999) 	mad.wide.s32 	%rd10, %r136, 2, %rd1;
(EngineCore_DP0 pid=345999) 	mad.wide.s32 	%rd11, %r135, 2, %rd1;
(EngineCore_DP0 pid=345999) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=345999) 	.loc	1 210 21                        // quant_slide_tuned_Llama3.2-1B.py:210:21
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=345999) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=345999) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=345999) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=345999) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	.loc	1 211 79                        // quant_slide_tuned_Llama3.2-1B.py:211:79
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r139, %rs24;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r140, %rs26;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r141, %rs28;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r142, %rs30;
(EngineCore_DP0 pid=345999) 	.loc	1 213 48                        // quant_slide_tuned_Llama3.2-1B.py:213:48
(EngineCore_DP0 pid=345999) 	or.b32 	%r143, %r138, 1;
(EngineCore_DP0 pid=345999) 	or.b32 	%r144, %r137, 1;
(EngineCore_DP0 pid=345999) 	or.b32 	%r145, %r136, 1;
(EngineCore_DP0 pid=345999) 	or.b32 	%r146, %r135, 1;
(EngineCore_DP0 pid=345999) 	.loc	1 213 53                        // quant_slide_tuned_Llama3.2-1B.py:213:53
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p30, %r143, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p31, %r144, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p32, %r145, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p33, %r146, %r27;
(EngineCore_DP0 pid=345999) 	.loc	1 213 37                        // quant_slide_tuned_Llama3.2-1B.py:213:37
(EngineCore_DP0 pid=345999) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=345999) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=345999) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=345999) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=345999) 	.loc	1 212 39                        // quant_slide_tuned_Llama3.2-1B.py:212:39
(EngineCore_DP0 pid=345999) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=345999) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=345999) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=345999) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=345999) 	.loc	1 212 21                        // quant_slide_tuned_Llama3.2-1B.py:212:21
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=345999) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=345999) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=345999) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=345999) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	.loc	1 213 79                        // quant_slide_tuned_Llama3.2-1B.py:213:79
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r147, %rs32;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r148, %rs34;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r149, %rs36;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r150, %rs38;
(EngineCore_DP0 pid=345999) 	.loc	1 217 48                        // quant_slide_tuned_Llama3.2-1B.py:217:48
(EngineCore_DP0 pid=345999) 	add.s32 	%r151, %r138, 2;
(EngineCore_DP0 pid=345999) 	add.s32 	%r152, %r137, 2;
(EngineCore_DP0 pid=345999) 	add.s32 	%r153, %r136, 2;
(EngineCore_DP0 pid=345999) 	add.s32 	%r154, %r135, 2;
(EngineCore_DP0 pid=345999) 	add.s32 	%r155, %r138, 3;
(EngineCore_DP0 pid=345999) 	add.s32 	%r156, %r137, 3;
(EngineCore_DP0 pid=345999) 	add.s32 	%r157, %r136, 3;
(EngineCore_DP0 pid=345999) 	add.s32 	%r158, %r135, 3;
(EngineCore_DP0 pid=345999) 	.loc	1 217 53                        // quant_slide_tuned_Llama3.2-1B.py:217:53
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p34, %r158, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p35, %r157, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p36, %r156, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p37, %r155, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p38, %r154, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p39, %r153, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p40, %r152, %r27;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p41, %r151, %r27;
(EngineCore_DP0 pid=345999) 	.loc	1 215 37                        // quant_slide_tuned_Llama3.2-1B.py:215:37
(EngineCore_DP0 pid=345999) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=345999) 	and.pred 	%p18, %p25, %p40;
(EngineCore_DP0 pid=345999) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=345999) 	and.pred 	%p20, %p25, %p38;
(EngineCore_DP0 pid=345999) 	.loc	1 214 39                        // quant_slide_tuned_Llama3.2-1B.py:214:39
(EngineCore_DP0 pid=345999) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=345999) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=345999) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=345999) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=345999) 	.loc	1 214 21                        // quant_slide_tuned_Llama3.2-1B.py:214:21
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=345999) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=345999) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=345999) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=345999) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	.loc	1 215 79                        // quant_slide_tuned_Llama3.2-1B.py:215:79
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r159, %rs40;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r160, %rs42;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r161, %rs44;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r162, %rs46;
(EngineCore_DP0 pid=345999) 	.loc	1 217 37                        // quant_slide_tuned_Llama3.2-1B.py:217:37
(EngineCore_DP0 pid=345999) 	and.pred 	%p21, %p25, %p37;
(EngineCore_DP0 pid=345999) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=345999) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=345999) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=345999) 	.loc	1 216 39                        // quant_slide_tuned_Llama3.2-1B.py:216:39
(EngineCore_DP0 pid=345999) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=345999) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=345999) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=345999) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=345999) 	.loc	1 216 21                        // quant_slide_tuned_Llama3.2-1B.py:216:21
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=345999) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=345999) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=345999) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=345999) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	.loc	1 217 79                        // quant_slide_tuned_Llama3.2-1B.py:217:79
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r163, %rs48;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r164, %rs50;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r165, %rs52;
(EngineCore_DP0 pid=345999) 	cvt.f32.bf16 	%r166, %rs54;
(EngineCore_DP0 pid=345999) 	.loc	1 219 27                        // quant_slide_tuned_Llama3.2-1B.py:219:27
(EngineCore_DP0 pid=345999) 	mul.f32 	%r167, %r14, %r139;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r168, %r14, %r140;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r169, %r14, %r141;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r170, %r14, %r142;
(EngineCore_DP0 pid=345999) 	mov.b32 	%r171, 0f43E00000;
(EngineCore_DP0 pid=345999) 	.loc	1 219 48                        // quant_slide_tuned_Llama3.2-1B.py:219:48
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r82, %r167, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r83, %r168, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r84, %r169, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r85, %r170, %r171;
(EngineCore_DP0 pid=345999) 	.loc	1 219 60                        // quant_slide_tuned_Llama3.2-1B.py:219:60
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=345999) 	.loc	1 220 27                        // quant_slide_tuned_Llama3.2-1B.py:220:27
(EngineCore_DP0 pid=345999) 	mul.f32 	%r172, %r14, %r147;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r173, %r14, %r148;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r174, %r14, %r149;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r175, %r14, %r150;
(EngineCore_DP0 pid=345999) 	.loc	1 220 48                        // quant_slide_tuned_Llama3.2-1B.py:220:48
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r86, %r172, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r87, %r173, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r88, %r174, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r89, %r175, %r171;
(EngineCore_DP0 pid=345999) 	.loc	1 220 60                        // quant_slide_tuned_Llama3.2-1B.py:220:60
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=345999) 	.loc	1 221 27                        // quant_slide_tuned_Llama3.2-1B.py:221:27
(EngineCore_DP0 pid=345999) 	mul.f32 	%r176, %r14, %r159;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r177, %r14, %r160;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r178, %r14, %r161;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r179, %r14, %r162;
(EngineCore_DP0 pid=345999) 	.loc	1 221 48                        // quant_slide_tuned_Llama3.2-1B.py:221:48
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r90, %r176, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r91, %r177, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r92, %r178, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r93, %r179, %r171;
(EngineCore_DP0 pid=345999) 	.loc	1 221 60                        // quant_slide_tuned_Llama3.2-1B.py:221:60
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=345999) 	.loc	1 222 27                        // quant_slide_tuned_Llama3.2-1B.py:222:27
(EngineCore_DP0 pid=345999) 	mul.f32 	%r180, %r14, %r163;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r181, %r14, %r164;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r182, %r14, %r165;
(EngineCore_DP0 pid=345999) 	mul.f32 	%r183, %r14, %r166;
(EngineCore_DP0 pid=345999) 	.loc	1 222 48                        // quant_slide_tuned_Llama3.2-1B.py:222:48
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r94, %r180, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r95, %r181, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r96, %r182, %r171;
(EngineCore_DP0 pid=345999) 	min.xorsign.abs.f32 	%r97, %r183, %r171;
(EngineCore_DP0 pid=345999) 	.loc	1 222 60                        // quant_slide_tuned_Llama3.2-1B.py:222:60
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=345999) 	.loc	1 224 45                        // quant_slide_tuned_Llama3.2-1B.py:224:45
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r184, %rs56;
(EngineCore_DP0 pid=345999) 	and.b32 	%r185, %r184, 255;
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r186, %rs64;
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r187, %rs57;
(EngineCore_DP0 pid=345999) 	and.b32 	%r188, %r187, 255;
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r189, %rs65;
(EngineCore_DP0 pid=345999) 	.loc	1 226 45                        // quant_slide_tuned_Llama3.2-1B.py:226:45
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r190, %rs60;
(EngineCore_DP0 pid=345999) 	and.b32 	%r191, %r190, 255;
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r192, %rs68;
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r193, %rs61;
(EngineCore_DP0 pid=345999) 	and.b32 	%r194, %r193, 255;
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r195, %rs69;
(EngineCore_DP0 pid=345999) 	.loc	1 227 45                        // quant_slide_tuned_Llama3.2-1B.py:227:45
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r196, %rs62;
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r197, %rs70;
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r198, %rs63;
(EngineCore_DP0 pid=345999) 	cvt.u32.u16 	%r199, %rs71;
(EngineCore_DP0 pid=345999) 	.loc	1 229 30                        // quant_slide_tuned_Llama3.2-1B.py:229:30
(EngineCore_DP0 pid=345999) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=345999) 	mul.wide.u16 	%r200, %rs72, 256;
(EngineCore_DP0 pid=345999) 	mul.wide.u16 	%r201, %rs66, 256;
(EngineCore_DP0 pid=345999) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=345999) 	mul.wide.u16 	%r202, %rs73, 256;
(EngineCore_DP0 pid=345999) 	mul.wide.u16 	%r203, %rs67, 256;
(EngineCore_DP0 pid=345999) 	.loc	1 229 24                        // quant_slide_tuned_Llama3.2-1B.py:229:24
(EngineCore_DP0 pid=345999) 	or.b32 	%r204, %r200, %r185;
(EngineCore_DP0 pid=345999) 	or.b32 	%r205, %r201, %r186;
(EngineCore_DP0 pid=345999) 	or.b32 	%r206, %r202, %r188;
(EngineCore_DP0 pid=345999) 	or.b32 	%r207, %r203, %r189;
(EngineCore_DP0 pid=345999) 	.loc	1 229 42                        // quant_slide_tuned_Llama3.2-1B.py:229:42
(EngineCore_DP0 pid=345999) 	shl.b32 	%r208, %r191, 16;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r209, %r192, 16;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r210, %r194, 16;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r211, %r195, 16;
(EngineCore_DP0 pid=345999) 	.loc	1 229 36                        // quant_slide_tuned_Llama3.2-1B.py:229:36
(EngineCore_DP0 pid=345999) 	or.b32 	%r212, %r208, %r204;
(EngineCore_DP0 pid=345999) 	or.b32 	%r213, %r209, %r205;
(EngineCore_DP0 pid=345999) 	or.b32 	%r214, %r210, %r206;
(EngineCore_DP0 pid=345999) 	or.b32 	%r215, %r211, %r207;
(EngineCore_DP0 pid=345999) 	.loc	1 229 55                        // quant_slide_tuned_Llama3.2-1B.py:229:55
(EngineCore_DP0 pid=345999) 	shl.b32 	%r216, %r196, 24;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r217, %r197, 24;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r218, %r198, 24;
(EngineCore_DP0 pid=345999) 	shl.b32 	%r219, %r199, 24;
(EngineCore_DP0 pid=345999) 	.loc	1 229 49                        // quant_slide_tuned_Llama3.2-1B.py:229:49
(EngineCore_DP0 pid=345999) 	or.b32 	%r98, %r216, %r212;
(EngineCore_DP0 pid=345999) 	or.b32 	%r99, %r217, %r213;
(EngineCore_DP0 pid=345999) 	or.b32 	%r100, %r218, %r214;
(EngineCore_DP0 pid=345999) 	or.b32 	%r101, %r219, %r215;
(EngineCore_DP0 pid=345999) 	.loc	1 230 29                        // quant_slide_tuned_Llama3.2-1B.py:230:29
(EngineCore_DP0 pid=345999) 	mad.wide.s32 	%rd24, %r103, 4, %rd2;
(EngineCore_DP0 pid=345999) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-1B.py:230:39
(EngineCore_DP0 pid=345999) 	// begin inline asm
(EngineCore_DP0 pid=345999) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=345999) 	// end inline asm
(EngineCore_DP0 pid=345999) 	.loc	1 201 41                        // quant_slide_tuned_Llama3.2-1B.py:201:41
(EngineCore_DP0 pid=345999) 	add.s32 	%r223, %r223, 2048;
(EngineCore_DP0 pid=345999) 	setp.lt.s32 	%p42, %r223, %r15;
(EngineCore_DP0 pid=345999) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=345999) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=345999) 	.loc	1 201 4                         // quant_slide_tuned_Llama3.2-1B.py:201:4
(EngineCore_DP0 pid=345999) 	ret;
(EngineCore_DP0 pid=345999) $L__tmp3:
(EngineCore_DP0 pid=345999) $L__func_end0:
(EngineCore_DP0 pid=345999)                                         // -- End function
(EngineCore_DP0 pid=345999) }
(EngineCore_DP0 pid=345999) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py"
(EngineCore_DP0 pid=345999) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=345999) 	.section	.debug_abbrev
(EngineCore_DP0 pid=345999) 	{
(EngineCore_DP0 pid=345999) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=345999) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=345999) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=345999) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=345999) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=345999) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=345999) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=345999) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=345999) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=345999) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=345999) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=345999) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=345999) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=345999) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=345999) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=345999) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=345999) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=345999) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=345999) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=345999) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=345999) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=345999) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=345999) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=345999) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=345999) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=345999) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=345999) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=345999) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=345999) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=345999) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=345999) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=345999) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=345999) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=345999) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=345999) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=345999) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=345999) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=345999) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=345999) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=345999) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=345999) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=345999) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=345999) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=345999) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=345999) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=345999) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=345999) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=345999) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=345999) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=345999) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=345999) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=345999) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=345999) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=345999) 	}
(EngineCore_DP0 pid=345999) 	.section	.debug_info
(EngineCore_DP0 pid=345999) 	{
(EngineCore_DP0 pid=345999) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=345999) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=345999) .b8 0
(EngineCore_DP0 pid=345999) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=345999) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=345999) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=345999) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=345999) .b8 114
(EngineCore_DP0 pid=345999) .b8 105
(EngineCore_DP0 pid=345999) .b8 116
(EngineCore_DP0 pid=345999) .b8 111
(EngineCore_DP0 pid=345999) .b8 110
(EngineCore_DP0 pid=345999) .b8 0
(EngineCore_DP0 pid=345999) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=345999) .b8 0
(EngineCore_DP0 pid=345999) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=345999) .b8 117
(EngineCore_DP0 pid=345999) .b8 97
(EngineCore_DP0 pid=345999) .b8 110
(EngineCore_DP0 pid=345999) .b8 116
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 115
(EngineCore_DP0 pid=345999) .b8 108
(EngineCore_DP0 pid=345999) .b8 105
(EngineCore_DP0 pid=345999) .b8 100
(EngineCore_DP0 pid=345999) .b8 101
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 116
(EngineCore_DP0 pid=345999) .b8 117
(EngineCore_DP0 pid=345999) .b8 110
(EngineCore_DP0 pid=345999) .b8 101
(EngineCore_DP0 pid=345999) .b8 100
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 76
(EngineCore_DP0 pid=345999) .b8 108
(EngineCore_DP0 pid=345999) .b8 97
(EngineCore_DP0 pid=345999) .b8 109
(EngineCore_DP0 pid=345999) .b8 97
(EngineCore_DP0 pid=345999) .b8 51
(EngineCore_DP0 pid=345999) .b8 46
(EngineCore_DP0 pid=345999) .b8 50
(EngineCore_DP0 pid=345999) .b8 45
(EngineCore_DP0 pid=345999) .b8 49
(EngineCore_DP0 pid=345999) .b8 66
(EngineCore_DP0 pid=345999) .b8 46
(EngineCore_DP0 pid=345999) .b8 112
(EngineCore_DP0 pid=345999) .b8 121
(EngineCore_DP0 pid=345999) .b8 0
(EngineCore_DP0 pid=345999) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=345999) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=345999) .b8 114
(EngineCore_DP0 pid=345999) .b8 111
(EngineCore_DP0 pid=345999) .b8 111
(EngineCore_DP0 pid=345999) .b8 116
(EngineCore_DP0 pid=345999) .b8 47
(EngineCore_DP0 pid=345999) .b8 118
(EngineCore_DP0 pid=345999) .b8 108
(EngineCore_DP0 pid=345999) .b8 108
(EngineCore_DP0 pid=345999) .b8 109
(EngineCore_DP0 pid=345999) .b8 98
(EngineCore_DP0 pid=345999) .b8 101
(EngineCore_DP0 pid=345999) .b8 110
(EngineCore_DP0 pid=345999) .b8 99
(EngineCore_DP0 pid=345999) .b8 104
(EngineCore_DP0 pid=345999) .b8 47
(EngineCore_DP0 pid=345999) .b8 115
(EngineCore_DP0 pid=345999) .b8 108
(EngineCore_DP0 pid=345999) .b8 105
(EngineCore_DP0 pid=345999) .b8 100
(EngineCore_DP0 pid=345999) .b8 101
(EngineCore_DP0 pid=345999) .b8 115
(EngineCore_DP0 pid=345999) .b8 112
(EngineCore_DP0 pid=345999) .b8 97
(EngineCore_DP0 pid=345999) .b8 114
(EngineCore_DP0 pid=345999) .b8 115
(EngineCore_DP0 pid=345999) .b8 101
(EngineCore_DP0 pid=345999) .b8 47
(EngineCore_DP0 pid=345999) .b8 99
(EngineCore_DP0 pid=345999) .b8 115
(EngineCore_DP0 pid=345999) .b8 114
(EngineCore_DP0 pid=345999) .b8 99
(EngineCore_DP0 pid=345999) .b8 47
(EngineCore_DP0 pid=345999) .b8 102
(EngineCore_DP0 pid=345999) .b8 117
(EngineCore_DP0 pid=345999) .b8 115
(EngineCore_DP0 pid=345999) .b8 101
(EngineCore_DP0 pid=345999) .b8 100
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 113
(EngineCore_DP0 pid=345999) .b8 117
(EngineCore_DP0 pid=345999) .b8 97
(EngineCore_DP0 pid=345999) .b8 110
(EngineCore_DP0 pid=345999) .b8 116
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 115
(EngineCore_DP0 pid=345999) .b8 108
(EngineCore_DP0 pid=345999) .b8 105
(EngineCore_DP0 pid=345999) .b8 100
(EngineCore_DP0 pid=345999) .b8 101
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 116
(EngineCore_DP0 pid=345999) .b8 114
(EngineCore_DP0 pid=345999) .b8 105
(EngineCore_DP0 pid=345999) .b8 116
(EngineCore_DP0 pid=345999) .b8 111
(EngineCore_DP0 pid=345999) .b8 110
(EngineCore_DP0 pid=345999) .b8 47
(EngineCore_DP0 pid=345999) .b8 98
(EngineCore_DP0 pid=345999) .b8 117
(EngineCore_DP0 pid=345999) .b8 105
(EngineCore_DP0 pid=345999) .b8 108
(EngineCore_DP0 pid=345999) .b8 100
(EngineCore_DP0 pid=345999) .b8 47
(EngineCore_DP0 pid=345999) .b8 71
(EngineCore_DP0 pid=345999) .b8 66
(EngineCore_DP0 pid=345999) .b8 49
(EngineCore_DP0 pid=345999) .b8 48
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 99
(EngineCore_DP0 pid=345999) .b8 99
(EngineCore_DP0 pid=345999) .b8 49
(EngineCore_DP0 pid=345999) .b8 50
(EngineCore_DP0 pid=345999) .b8 49
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 112
(EngineCore_DP0 pid=345999) .b8 121
(EngineCore_DP0 pid=345999) .b8 51
(EngineCore_DP0 pid=345999) .b8 49
(EngineCore_DP0 pid=345999) .b8 50
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 99
(EngineCore_DP0 pid=345999) .b8 117
(EngineCore_DP0 pid=345999) .b8 49
(EngineCore_DP0 pid=345999) .b8 50
(EngineCore_DP0 pid=345999) .b8 57
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 97
(EngineCore_DP0 pid=345999) .b8 97
(EngineCore_DP0 pid=345999) .b8 114
(EngineCore_DP0 pid=345999) .b8 99
(EngineCore_DP0 pid=345999) .b8 104
(EngineCore_DP0 pid=345999) .b8 54
(EngineCore_DP0 pid=345999) .b8 52
(EngineCore_DP0 pid=345999) .b8 0
(EngineCore_DP0 pid=345999) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=345999) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=345999) .b8 113
(EngineCore_DP0 pid=345999) .b8 117
(EngineCore_DP0 pid=345999) .b8 97
(EngineCore_DP0 pid=345999) .b8 110
(EngineCore_DP0 pid=345999) .b8 116
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 115
(EngineCore_DP0 pid=345999) .b8 108
(EngineCore_DP0 pid=345999) .b8 105
(EngineCore_DP0 pid=345999) .b8 100
(EngineCore_DP0 pid=345999) .b8 101
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 102
(EngineCore_DP0 pid=345999) .b8 112
(EngineCore_DP0 pid=345999) .b8 56
(EngineCore_DP0 pid=345999) .b8 95
(EngineCore_DP0 pid=345999) .b8 107
(EngineCore_DP0 pid=345999) .b8 101
(EngineCore_DP0 pid=345999) .b8 114
(EngineCore_DP0 pid=345999) .b8 110
(EngineCore_DP0 pid=345999) .b8 101
(EngineCore_DP0 pid=345999) .b8 108
(EngineCore_DP0 pid=345999) .b8 0
(EngineCore_DP0 pid=345999) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=345999) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=345999) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=345999) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=345999) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=345999) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=345999) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=345999) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=345999) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=345999) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=345999) .b8 191                                 // DW_AT_call_line
(EngineCore_DP0 pid=345999) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=345999) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=345999) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=345999) 	}
(EngineCore_DP0 pid=345999) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) ================================================================
(EngineCore_DP0 pid=345999) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpc0f7qe0r.ptx', '-o', '/tmp/tmpc0f7qe0r.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] 
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] 
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] 
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpc0f7qe0r.ptx -o /tmp/tmpc0f7qe0r.ptx.o
(EngineCore_DP0 pid=345999) ERROR 01-25 19:23:44 [core.py:866] 

STDERR:
[2026-01-25 19:23:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:23:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:23:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:23:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:23:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:23:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:23:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:23:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:23:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:23:31] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 19:23:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:23:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:23:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:23:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:23:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:23:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:23:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:23:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:23:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:32] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:32] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:32] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:32] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:32] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=345999) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=345999) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.83s/it]
(EngineCore_DP0 pid=345999) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.83s/it]
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=345999) [2026-01-25 19:23:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=345999) Process EngineCore_DP0:
(EngineCore_DP0 pid=345999) Traceback (most recent call last):
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=345999)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=345999)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=345999)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=345999) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpc0f7qe0r.ptx', '-o', '/tmp/tmpc0f7qe0r.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) Traceback (most recent call last):
(EngineCore_DP0 pid=345999)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=345999)     self.run()
(EngineCore_DP0 pid=345999)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=345999)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=345999)     raise e
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=345999)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=345999)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=345999)     super().__init__(
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=345999)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=345999)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=345999)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=345999)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=345999)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=345999)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=345999)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=345999)     return func(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=345999)     return func(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=345999)     self.model_runner.profile_run()
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=345999)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=345999)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=345999)     return func(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=345999)     outputs = self.model(
(EngineCore_DP0 pid=345999)               ^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345999)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345999)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=345999)     model_output = self.model(
(EngineCore_DP0 pid=345999)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=345999)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=345999)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=345999)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345999)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345999)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=345999)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=345999)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345999)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345999)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=345999)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=345999)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=345999)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=345999)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=345999)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=345999)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=345999)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=345999)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=345999)     return self._linear_fn(
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=345999)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=345999)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=345999)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=345999)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=345999)     return fn(input, L)
(EngineCore_DP0 pid=345999)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-1B.py", line 259, in quant_slide_fp8_triton
(EngineCore_DP0 pid=345999)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=345999)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=345999)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=345999)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=345999)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=345999)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=345999)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=345999)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=345999)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=345999)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=345999)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=345999)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=345999)     raise PTXASError(error)
(EngineCore_DP0 pid=345999) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=345999) `ptxas` stderr:
(EngineCore_DP0 pid=345999) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=345999) 
(EngineCore_DP0 pid=345999) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpc0f7qe0r.ptx -o /tmp/tmpc0f7qe0r.ptx.o
(EngineCore_DP0 pid=345999) 
[rank0]:[W125 19:23:44.156994198 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 20:09:25
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:09:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:09:29 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=398175) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) ================================================================
(EngineCore_DP0 pid=398175) Internal Triton PTX codegen error
(EngineCore_DP0 pid=398175) `ptxas` stderr:
(EngineCore_DP0 pid=398175) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4i1vunue.ptx -o /tmp/tmp4i1vunue.ptx.o
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) //
(EngineCore_DP0 pid=398175) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=398175) //
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) .version 8.7
(EngineCore_DP0 pid=398175) .target sm_121a
(EngineCore_DP0 pid=398175) .address_size 64
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=398175) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=398175)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=398175) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=398175) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=398175) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=398175) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=398175) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=398175) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=398175) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=398175) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=398175) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=398175) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=398175) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=398175) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=398175) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=398175) )
(EngineCore_DP0 pid=398175) .reqntid 1024
(EngineCore_DP0 pid=398175) {
(EngineCore_DP0 pid=398175) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=398175) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=398175) 	.reg .b32 	%r<115>;
(EngineCore_DP0 pid=398175) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=398175) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=398175) $L__func_begin0:
(EngineCore_DP0 pid=398175) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) // %bb.0:
(EngineCore_DP0 pid=398175) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=398175) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=398175) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=398175) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=398175) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=398175) $L__tmp0:
(EngineCore_DP0 pid=398175) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=398175) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=398175) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=398175) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=398175) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=398175) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=398175) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=398175) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=398175) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=398175) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=398175) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=398175) 	mov.b32 	%r113, 0f2B8CBCCC;
(EngineCore_DP0 pid=398175) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=398175) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=398175) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=398175) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=398175) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=398175) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=398175) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=398175) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=398175) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=398175) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=398175) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=398175) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=398175) 	mov.b32 	%r111, 0f00000000;
(EngineCore_DP0 pid=398175) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=398175) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=398175) 	mov.b32 	%r112, %r37;
(EngineCore_DP0 pid=398175) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=398175) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=398175) 	add.s32 	%r45, %r3, %r112;
(EngineCore_DP0 pid=398175) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=398175) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=398175) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=398175) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=398175) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=398175) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=398175) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=398175) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=398175) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=398175) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=398175) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=398175) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=398175) $L__tmp1:
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	bar.sync 	0;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=398175) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=398175) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=398175) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	bar.sync 	0;
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=398175) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=398175) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	bar.sync 	0;
(EngineCore_DP0 pid=398175) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=398175) $L__tmp2:
(EngineCore_DP0 pid=398175) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=398175) 	max.f32 	%r111, %r111, %r65;
(EngineCore_DP0 pid=398175) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=398175) 	add.s32 	%r112, %r112, 4096;
(EngineCore_DP0 pid=398175) 	setp.lt.s32 	%p6, %r112, %r18;
(EngineCore_DP0 pid=398175) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=398175) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=398175) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=398175) 	max.f32 	%r113, %r111, 0f2B8CBCCC;
(EngineCore_DP0 pid=398175) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=398175) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=398175) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=398175) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=398175) 	div.full.f32 	%r68, %r113, %r67;
(EngineCore_DP0 pid=398175) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=398175) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=398175) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=398175) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=398175) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=398175) 	mul.lo.s32 	%r14, %r19, 3;
(EngineCore_DP0 pid=398175) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=398175) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=398175) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=398175) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=398175) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=398175) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=398175) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=398175) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=398175) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=398175) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=398175) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=398175) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=398175) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=398175) 	div.full.f32 	%r13, %r67, %r113;
(EngineCore_DP0 pid=398175) 	mov.b32 	%r114, 0;
(EngineCore_DP0 pid=398175) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=398175)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=398175) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=398175) 	add.s32 	%r80, %r2, %r114;
(EngineCore_DP0 pid=398175) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=398175) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=398175) 	mul.hi.s32 	%r81, %r80, 1431655766;
(EngineCore_DP0 pid=398175) 	shr.u32 	%r82, %r81, 31;
(EngineCore_DP0 pid=398175) 	add.s32 	%r83, %r81, %r82;
(EngineCore_DP0 pid=398175) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=398175) 	mul.lo.s32 	%r84, %r83, 3;
(EngineCore_DP0 pid=398175) 	sub.s32 	%r85, %r80, %r84;
(EngineCore_DP0 pid=398175) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=398175) 	shl.b32 	%r86, %r83, 3;
(EngineCore_DP0 pid=398175) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=398175) 	shl.b32 	%r87, %r85, 1;
(EngineCore_DP0 pid=398175) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=398175) 	add.s32 	%r88, %r86, %r87;
(EngineCore_DP0 pid=398175) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=398175) 	setp.lt.s32 	%p14, %r88, %r17;
(EngineCore_DP0 pid=398175) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=398175) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=398175) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=398175) 	mad.wide.s32 	%rd8, %r88, 2, %rd1;
(EngineCore_DP0 pid=398175) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=398175) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=398175) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=398175) 	cvt.f32.bf16 	%r89, %rs12;
(EngineCore_DP0 pid=398175) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=398175) 	or.b32 	%r90, %r88, 1;
(EngineCore_DP0 pid=398175) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=398175) 	setp.lt.s32 	%p15, %r90, %r17;
(EngineCore_DP0 pid=398175) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=398175) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=398175) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=398175) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=398175) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=398175) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=398175) 	cvt.f32.bf16 	%r91, %rs14;
(EngineCore_DP0 pid=398175) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=398175) 	add.s32 	%r92, %r88, 2;
(EngineCore_DP0 pid=398175) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=398175) 	setp.lt.s32 	%p16, %r92, %r17;
(EngineCore_DP0 pid=398175) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=398175) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=398175) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=398175) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=398175) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=398175) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=398175) 	cvt.f32.bf16 	%r93, %rs16;
(EngineCore_DP0 pid=398175) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=398175) 	add.s32 	%r94, %r88, 3;
(EngineCore_DP0 pid=398175) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=398175) 	setp.lt.s32 	%p17, %r94, %r17;
(EngineCore_DP0 pid=398175) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=398175) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=398175) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=398175) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=398175) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=398175) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=398175) 	cvt.f32.bf16 	%r95, %rs18;
(EngineCore_DP0 pid=398175) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=398175) 	mul.f32 	%r96, %r13, %r89;
(EngineCore_DP0 pid=398175) 	mov.b32 	%r97, 0f43E00000;
(EngineCore_DP0 pid=398175) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=398175) 	min.xorsign.abs.f32 	%r70, %r96, %r97;
(EngineCore_DP0 pid=398175) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=398175) 	mul.f32 	%r98, %r13, %r91;
(EngineCore_DP0 pid=398175) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=398175) 	min.xorsign.abs.f32 	%r72, %r98, %r97;
(EngineCore_DP0 pid=398175) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=398175) 	mul.f32 	%r99, %r13, %r93;
(EngineCore_DP0 pid=398175) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=398175) 	min.xorsign.abs.f32 	%r74, %r99, %r97;
(EngineCore_DP0 pid=398175) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=398175) 	mul.f32 	%r100, %r13, %r95;
(EngineCore_DP0 pid=398175) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=398175) 	min.xorsign.abs.f32 	%r76, %r100, %r97;
(EngineCore_DP0 pid=398175) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=398175) 	cvt.u32.u16 	%r101, %rs20;
(EngineCore_DP0 pid=398175) 	and.b32 	%r102, %r101, 255;
(EngineCore_DP0 pid=398175) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=398175) 	cvt.u32.u16 	%r103, %rs22;
(EngineCore_DP0 pid=398175) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=398175) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=398175) 	cvt.u32.u16 	%r105, %rs23;
(EngineCore_DP0 pid=398175) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=398175) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=398175) 	mul.wide.u16 	%r106, %rs24, 256;
(EngineCore_DP0 pid=398175) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=398175) 	or.b32 	%r107, %r106, %r102;
(EngineCore_DP0 pid=398175) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=398175) 	shl.b32 	%r108, %r104, 16;
(EngineCore_DP0 pid=398175) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=398175) 	or.b32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=398175) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=398175) 	shl.b32 	%r110, %r105, 24;
(EngineCore_DP0 pid=398175) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=398175) 	or.b32 	%r78, %r109, %r110;
(EngineCore_DP0 pid=398175) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=398175) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=398175) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=398175) 	// begin inline asm
(EngineCore_DP0 pid=398175) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=398175) 	// end inline asm
(EngineCore_DP0 pid=398175) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=398175) 	add.s32 	%r114, %r114, 1024;
(EngineCore_DP0 pid=398175) 	setp.lt.s32 	%p18, %r114, %r14;
(EngineCore_DP0 pid=398175) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=398175) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=398175) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=398175) 	ret;
(EngineCore_DP0 pid=398175) $L__tmp3:
(EngineCore_DP0 pid=398175) $L__func_end0:
(EngineCore_DP0 pid=398175)                                         // -- End function
(EngineCore_DP0 pid=398175) }
(EngineCore_DP0 pid=398175) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=398175) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=398175) 	.section	.debug_abbrev
(EngineCore_DP0 pid=398175) 	{
(EngineCore_DP0 pid=398175) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=398175) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=398175) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=398175) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=398175) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=398175) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=398175) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=398175) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=398175) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=398175) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=398175) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=398175) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=398175) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=398175) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=398175) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=398175) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=398175) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=398175) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=398175) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=398175) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=398175) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=398175) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=398175) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=398175) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=398175) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=398175) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=398175) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=398175) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=398175) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=398175) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=398175) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=398175) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=398175) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=398175) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=398175) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=398175) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=398175) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=398175) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=398175) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=398175) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=398175) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=398175) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=398175) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=398175) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=398175) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=398175) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=398175) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=398175) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=398175) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=398175) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=398175) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=398175) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=398175) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=398175) 	}
(EngineCore_DP0 pid=398175) 	.section	.debug_info
(EngineCore_DP0 pid=398175) 	{
(EngineCore_DP0 pid=398175) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=398175) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=398175) .b8 0
(EngineCore_DP0 pid=398175) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=398175) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=398175) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=398175) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=398175) .b8 114
(EngineCore_DP0 pid=398175) .b8 105
(EngineCore_DP0 pid=398175) .b8 116
(EngineCore_DP0 pid=398175) .b8 111
(EngineCore_DP0 pid=398175) .b8 110
(EngineCore_DP0 pid=398175) .b8 0
(EngineCore_DP0 pid=398175) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=398175) .b8 0
(EngineCore_DP0 pid=398175) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=398175) .b8 117
(EngineCore_DP0 pid=398175) .b8 97
(EngineCore_DP0 pid=398175) .b8 110
(EngineCore_DP0 pid=398175) .b8 116
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 115
(EngineCore_DP0 pid=398175) .b8 108
(EngineCore_DP0 pid=398175) .b8 105
(EngineCore_DP0 pid=398175) .b8 100
(EngineCore_DP0 pid=398175) .b8 101
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 116
(EngineCore_DP0 pid=398175) .b8 117
(EngineCore_DP0 pid=398175) .b8 110
(EngineCore_DP0 pid=398175) .b8 101
(EngineCore_DP0 pid=398175) .b8 100
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 76
(EngineCore_DP0 pid=398175) .b8 108
(EngineCore_DP0 pid=398175) .b8 97
(EngineCore_DP0 pid=398175) .b8 109
(EngineCore_DP0 pid=398175) .b8 97
(EngineCore_DP0 pid=398175) .b8 51
(EngineCore_DP0 pid=398175) .b8 46
(EngineCore_DP0 pid=398175) .b8 50
(EngineCore_DP0 pid=398175) .b8 45
(EngineCore_DP0 pid=398175) .b8 51
(EngineCore_DP0 pid=398175) .b8 66
(EngineCore_DP0 pid=398175) .b8 46
(EngineCore_DP0 pid=398175) .b8 112
(EngineCore_DP0 pid=398175) .b8 121
(EngineCore_DP0 pid=398175) .b8 0
(EngineCore_DP0 pid=398175) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=398175) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=398175) .b8 114
(EngineCore_DP0 pid=398175) .b8 111
(EngineCore_DP0 pid=398175) .b8 111
(EngineCore_DP0 pid=398175) .b8 116
(EngineCore_DP0 pid=398175) .b8 47
(EngineCore_DP0 pid=398175) .b8 118
(EngineCore_DP0 pid=398175) .b8 108
(EngineCore_DP0 pid=398175) .b8 108
(EngineCore_DP0 pid=398175) .b8 109
(EngineCore_DP0 pid=398175) .b8 98
(EngineCore_DP0 pid=398175) .b8 101
(EngineCore_DP0 pid=398175) .b8 110
(EngineCore_DP0 pid=398175) .b8 99
(EngineCore_DP0 pid=398175) .b8 104
(EngineCore_DP0 pid=398175) .b8 47
(EngineCore_DP0 pid=398175) .b8 115
(EngineCore_DP0 pid=398175) .b8 108
(EngineCore_DP0 pid=398175) .b8 105
(EngineCore_DP0 pid=398175) .b8 100
(EngineCore_DP0 pid=398175) .b8 101
(EngineCore_DP0 pid=398175) .b8 115
(EngineCore_DP0 pid=398175) .b8 112
(EngineCore_DP0 pid=398175) .b8 97
(EngineCore_DP0 pid=398175) .b8 114
(EngineCore_DP0 pid=398175) .b8 115
(EngineCore_DP0 pid=398175) .b8 101
(EngineCore_DP0 pid=398175) .b8 47
(EngineCore_DP0 pid=398175) .b8 99
(EngineCore_DP0 pid=398175) .b8 115
(EngineCore_DP0 pid=398175) .b8 114
(EngineCore_DP0 pid=398175) .b8 99
(EngineCore_DP0 pid=398175) .b8 47
(EngineCore_DP0 pid=398175) .b8 102
(EngineCore_DP0 pid=398175) .b8 117
(EngineCore_DP0 pid=398175) .b8 115
(EngineCore_DP0 pid=398175) .b8 101
(EngineCore_DP0 pid=398175) .b8 100
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 113
(EngineCore_DP0 pid=398175) .b8 117
(EngineCore_DP0 pid=398175) .b8 97
(EngineCore_DP0 pid=398175) .b8 110
(EngineCore_DP0 pid=398175) .b8 116
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 115
(EngineCore_DP0 pid=398175) .b8 108
(EngineCore_DP0 pid=398175) .b8 105
(EngineCore_DP0 pid=398175) .b8 100
(EngineCore_DP0 pid=398175) .b8 101
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 116
(EngineCore_DP0 pid=398175) .b8 114
(EngineCore_DP0 pid=398175) .b8 105
(EngineCore_DP0 pid=398175) .b8 116
(EngineCore_DP0 pid=398175) .b8 111
(EngineCore_DP0 pid=398175) .b8 110
(EngineCore_DP0 pid=398175) .b8 47
(EngineCore_DP0 pid=398175) .b8 98
(EngineCore_DP0 pid=398175) .b8 117
(EngineCore_DP0 pid=398175) .b8 105
(EngineCore_DP0 pid=398175) .b8 108
(EngineCore_DP0 pid=398175) .b8 100
(EngineCore_DP0 pid=398175) .b8 47
(EngineCore_DP0 pid=398175) .b8 71
(EngineCore_DP0 pid=398175) .b8 66
(EngineCore_DP0 pid=398175) .b8 49
(EngineCore_DP0 pid=398175) .b8 48
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 99
(EngineCore_DP0 pid=398175) .b8 99
(EngineCore_DP0 pid=398175) .b8 49
(EngineCore_DP0 pid=398175) .b8 50
(EngineCore_DP0 pid=398175) .b8 49
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 112
(EngineCore_DP0 pid=398175) .b8 121
(EngineCore_DP0 pid=398175) .b8 51
(EngineCore_DP0 pid=398175) .b8 49
(EngineCore_DP0 pid=398175) .b8 50
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 99
(EngineCore_DP0 pid=398175) .b8 117
(EngineCore_DP0 pid=398175) .b8 49
(EngineCore_DP0 pid=398175) .b8 50
(EngineCore_DP0 pid=398175) .b8 57
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 97
(EngineCore_DP0 pid=398175) .b8 97
(EngineCore_DP0 pid=398175) .b8 114
(EngineCore_DP0 pid=398175) .b8 99
(EngineCore_DP0 pid=398175) .b8 104
(EngineCore_DP0 pid=398175) .b8 54
(EngineCore_DP0 pid=398175) .b8 52
(EngineCore_DP0 pid=398175) .b8 0
(EngineCore_DP0 pid=398175) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=398175) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=398175) .b8 113
(EngineCore_DP0 pid=398175) .b8 117
(EngineCore_DP0 pid=398175) .b8 97
(EngineCore_DP0 pid=398175) .b8 110
(EngineCore_DP0 pid=398175) .b8 116
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 115
(EngineCore_DP0 pid=398175) .b8 108
(EngineCore_DP0 pid=398175) .b8 105
(EngineCore_DP0 pid=398175) .b8 100
(EngineCore_DP0 pid=398175) .b8 101
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 102
(EngineCore_DP0 pid=398175) .b8 112
(EngineCore_DP0 pid=398175) .b8 56
(EngineCore_DP0 pid=398175) .b8 95
(EngineCore_DP0 pid=398175) .b8 107
(EngineCore_DP0 pid=398175) .b8 101
(EngineCore_DP0 pid=398175) .b8 114
(EngineCore_DP0 pid=398175) .b8 110
(EngineCore_DP0 pid=398175) .b8 101
(EngineCore_DP0 pid=398175) .b8 108
(EngineCore_DP0 pid=398175) .b8 0
(EngineCore_DP0 pid=398175) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=398175) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=398175) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=398175) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=398175) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=398175) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=398175) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=398175) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=398175) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=398175) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=398175) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=398175) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=398175) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=398175) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=398175) 	}
(EngineCore_DP0 pid=398175) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) ================================================================
(EngineCore_DP0 pid=398175) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp4i1vunue.ptx', '-o', '/tmp/tmp4i1vunue.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] 
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] 
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] 
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4i1vunue.ptx -o /tmp/tmp4i1vunue.ptx.o
(EngineCore_DP0 pid=398175) ERROR 01-25 20:09:58 [core.py:866] 

STDERR:
[2026-01-25 20:09:28] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:09:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:09:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:09:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:09:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:09:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:09:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:09:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:09:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:09:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:09:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:09:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:09:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:09:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:09:32] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:09:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:09:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:09:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:09:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:09:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:09:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:09:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:09:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:09:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:09:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:09:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:09:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:09:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:33] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:33] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:33] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:33] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:33] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=398175) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=398175) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.69s/it]
(EngineCore_DP0 pid=398175) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.69s/it]
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=398175) [2026-01-25 20:09:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=398175) Process EngineCore_DP0:
(EngineCore_DP0 pid=398175) Traceback (most recent call last):
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=398175)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=398175)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=398175)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=398175) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp4i1vunue.ptx', '-o', '/tmp/tmp4i1vunue.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) Traceback (most recent call last):
(EngineCore_DP0 pid=398175)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=398175)     self.run()
(EngineCore_DP0 pid=398175)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=398175)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=398175)     raise e
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=398175)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=398175)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=398175)     super().__init__(
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=398175)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=398175)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=398175)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=398175)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=398175)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=398175)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=398175)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=398175)     return func(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=398175)     return func(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=398175)     self.model_runner.profile_run()
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=398175)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=398175)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=398175)     return func(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=398175)     outputs = self.model(
(EngineCore_DP0 pid=398175)               ^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398175)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398175)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=398175)     model_output = self.model(
(EngineCore_DP0 pid=398175)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=398175)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=398175)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=398175)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398175)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398175)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=398175)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=398175)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398175)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398175)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=398175)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=398175)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398175)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398175)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=398175)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=398175)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=398175)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=398175)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=398175)     return self._linear_fn(
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=398175)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=398175)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=398175)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=398175)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=398175)     return fn(input, L)
(EngineCore_DP0 pid=398175)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=398175)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=398175)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=398175)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=398175)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=398175)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=398175)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=398175)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=398175)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=398175)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=398175)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=398175)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398175)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=398175)     raise PTXASError(error)
(EngineCore_DP0 pid=398175) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=398175) `ptxas` stderr:
(EngineCore_DP0 pid=398175) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=398175) 
(EngineCore_DP0 pid=398175) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp4i1vunue.ptx -o /tmp/tmp4i1vunue.ptx.o
(EngineCore_DP0 pid=398175) 
[rank0]:[W125 20:09:59.405218331 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 20:10:00
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:10:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:10:04 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=398852) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) ================================================================
(EngineCore_DP0 pid=398852) Internal Triton PTX codegen error
(EngineCore_DP0 pid=398852) `ptxas` stderr:
(EngineCore_DP0 pid=398852) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp6ehga0mv.ptx -o /tmp/tmp6ehga0mv.ptx.o
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) //
(EngineCore_DP0 pid=398852) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=398852) //
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) .version 8.7
(EngineCore_DP0 pid=398852) .target sm_121a
(EngineCore_DP0 pid=398852) .address_size 64
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=398852) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=398852)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=398852) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=398852) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=398852) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=398852) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=398852) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=398852) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=398852) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=398852) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=398852) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=398852) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=398852) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=398852) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=398852) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=398852) )
(EngineCore_DP0 pid=398852) .reqntid 512
(EngineCore_DP0 pid=398852) {
(EngineCore_DP0 pid=398852) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=398852) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=398852) 	.reg .b32 	%r<118>;
(EngineCore_DP0 pid=398852) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=398852) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=398852) $L__func_begin0:
(EngineCore_DP0 pid=398852) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) // %bb.0:
(EngineCore_DP0 pid=398852) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=398852) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=398852) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=398852) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=398852) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=398852) $L__tmp0:
(EngineCore_DP0 pid=398852) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=398852) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=398852) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=398852) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=398852) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=398852) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=398852) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=398852) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=398852) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=398852) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=398852) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=398852) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=398852) 	mov.b32 	%r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=398852) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=398852) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=398852) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=398852) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=398852) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=398852) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=398852) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=398852) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=398852) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=398852) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=398852) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=398852) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=398852) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=398852) 	mov.b32 	%r114, 0f00000000;
(EngineCore_DP0 pid=398852) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=398852) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=398852) 	mov.b32 	%r115, %r40;
(EngineCore_DP0 pid=398852) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=398852) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=398852) 	add.s32 	%r50, %r4, %r115;
(EngineCore_DP0 pid=398852) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=398852) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=398852) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=398852) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=398852) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=398852) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=398852) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=398852) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=398852) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=398852) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=398852) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=398852) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=398852) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=398852) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=398852) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=398852) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=398852) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=398852) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=398852) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=398852) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=398852) $L__tmp1:
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	bar.sync 	0;
(EngineCore_DP0 pid=398852) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=398852) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=398852) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=398852) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=398852) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=398852) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=398852) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=398852) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=398852) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=398852) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=398852) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=398852) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=398852) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	bar.sync 	0;
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=398852) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=398852) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=398852) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=398852) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=398852) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	bar.sync 	0;
(EngineCore_DP0 pid=398852) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=398852) $L__tmp2:
(EngineCore_DP0 pid=398852) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=398852) 	max.f32 	%r114, %r114, %r68;
(EngineCore_DP0 pid=398852) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=398852) 	add.s32 	%r115, %r115, 4096;
(EngineCore_DP0 pid=398852) 	setp.lt.s32 	%p6, %r115, %r19;
(EngineCore_DP0 pid=398852) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=398852) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=398852) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=398852) 	max.f32 	%r116, %r114, 0f2B8CBCCC;
(EngineCore_DP0 pid=398852) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=398852) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=398852) 	mov.b32 	%r70, 0f43E00000;
(EngineCore_DP0 pid=398852) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=398852) 	div.full.f32 	%r71, %r116, %r70;
(EngineCore_DP0 pid=398852) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=398852) 	max.f32 	%r69, %r71, 0f36924925;
(EngineCore_DP0 pid=398852) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=398852) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=398852) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=398852) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=398852) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=398852) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=398852) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=398852) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=398852) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=398852) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=398852) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=398852) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=398852) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=398852) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=398852) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=398852) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=398852) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=398852) 	div.full.f32 	%r14, %r70, %r116;
(EngineCore_DP0 pid=398852) 	mov.b32 	%r117, 0;
(EngineCore_DP0 pid=398852) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=398852)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=398852) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=398852) 	add.s32 	%r83, %r3, %r117;
(EngineCore_DP0 pid=398852) 	setp.lt.s32 	%p13, %r83, %r15;
(EngineCore_DP0 pid=398852) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=398852) 	mul.hi.s32 	%r84, %r83, 1431655766;
(EngineCore_DP0 pid=398852) 	shr.u32 	%r85, %r84, 31;
(EngineCore_DP0 pid=398852) 	add.s32 	%r86, %r84, %r85;
(EngineCore_DP0 pid=398852) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=398852) 	mul.lo.s32 	%r87, %r86, 3;
(EngineCore_DP0 pid=398852) 	sub.s32 	%r88, %r83, %r87;
(EngineCore_DP0 pid=398852) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=398852) 	shl.b32 	%r89, %r86, 3;
(EngineCore_DP0 pid=398852) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=398852) 	shl.b32 	%r90, %r88, 1;
(EngineCore_DP0 pid=398852) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=398852) 	add.s32 	%r91, %r89, %r90;
(EngineCore_DP0 pid=398852) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=398852) 	setp.lt.s32 	%p14, %r91, %r18;
(EngineCore_DP0 pid=398852) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=398852) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=398852) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=398852) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=398852) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=398852) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=398852) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=398852) 	cvt.f32.bf16 	%r92, %rs24;
(EngineCore_DP0 pid=398852) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=398852) 	or.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=398852) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=398852) 	setp.lt.s32 	%p15, %r93, %r18;
(EngineCore_DP0 pid=398852) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=398852) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=398852) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=398852) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=398852) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=398852) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=398852) 	cvt.f32.bf16 	%r94, %rs26;
(EngineCore_DP0 pid=398852) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=398852) 	add.s32 	%r95, %r91, 2;
(EngineCore_DP0 pid=398852) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=398852) 	setp.lt.s32 	%p16, %r95, %r18;
(EngineCore_DP0 pid=398852) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=398852) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=398852) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=398852) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=398852) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=398852) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=398852) 	cvt.f32.bf16 	%r96, %rs28;
(EngineCore_DP0 pid=398852) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=398852) 	add.s32 	%r97, %r91, 3;
(EngineCore_DP0 pid=398852) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=398852) 	setp.lt.s32 	%p17, %r97, %r18;
(EngineCore_DP0 pid=398852) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=398852) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=398852) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=398852) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=398852) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=398852) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=398852) 	cvt.f32.bf16 	%r98, %rs30;
(EngineCore_DP0 pid=398852) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=398852) 	mul.f32 	%r99, %r14, %r92;
(EngineCore_DP0 pid=398852) 	mov.b32 	%r100, 0f43E00000;
(EngineCore_DP0 pid=398852) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=398852) 	min.xorsign.abs.f32 	%r73, %r99, %r100;
(EngineCore_DP0 pid=398852) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r74, %r73; 
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=398852) 	mul.f32 	%r101, %r14, %r94;
(EngineCore_DP0 pid=398852) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=398852) 	min.xorsign.abs.f32 	%r75, %r101, %r100;
(EngineCore_DP0 pid=398852) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r76, %r75; 
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=398852) 	mul.f32 	%r102, %r14, %r96;
(EngineCore_DP0 pid=398852) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=398852) 	min.xorsign.abs.f32 	%r77, %r102, %r100;
(EngineCore_DP0 pid=398852) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r78, %r77; 
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=398852) 	mul.f32 	%r103, %r14, %r98;
(EngineCore_DP0 pid=398852) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=398852) 	min.xorsign.abs.f32 	%r79, %r103, %r100;
(EngineCore_DP0 pid=398852) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r80, %r79; 
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=398852) 	cvt.u32.u16 	%r104, %rs32;
(EngineCore_DP0 pid=398852) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=398852) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=398852) 	cvt.u32.u16 	%r106, %rs34;
(EngineCore_DP0 pid=398852) 	and.b32 	%r107, %r106, 255;
(EngineCore_DP0 pid=398852) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=398852) 	cvt.u32.u16 	%r108, %rs35;
(EngineCore_DP0 pid=398852) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=398852) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=398852) 	mul.wide.u16 	%r109, %rs36, 256;
(EngineCore_DP0 pid=398852) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=398852) 	or.b32 	%r110, %r109, %r105;
(EngineCore_DP0 pid=398852) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=398852) 	shl.b32 	%r111, %r107, 16;
(EngineCore_DP0 pid=398852) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=398852) 	or.b32 	%r112, %r110, %r111;
(EngineCore_DP0 pid=398852) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=398852) 	shl.b32 	%r113, %r108, 24;
(EngineCore_DP0 pid=398852) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=398852) 	or.b32 	%r81, %r112, %r113;
(EngineCore_DP0 pid=398852) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=398852) 	mad.wide.s32 	%rd12, %r83, 4, %rd2;
(EngineCore_DP0 pid=398852) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=398852) 	// begin inline asm
(EngineCore_DP0 pid=398852) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r81 };
(EngineCore_DP0 pid=398852) 	// end inline asm
(EngineCore_DP0 pid=398852) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=398852) 	add.s32 	%r117, %r117, 512;
(EngineCore_DP0 pid=398852) 	setp.lt.s32 	%p18, %r117, %r15;
(EngineCore_DP0 pid=398852) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=398852) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=398852) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=398852) 	ret;
(EngineCore_DP0 pid=398852) $L__tmp3:
(EngineCore_DP0 pid=398852) $L__func_end0:
(EngineCore_DP0 pid=398852)                                         // -- End function
(EngineCore_DP0 pid=398852) }
(EngineCore_DP0 pid=398852) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=398852) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=398852) 	.section	.debug_abbrev
(EngineCore_DP0 pid=398852) 	{
(EngineCore_DP0 pid=398852) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=398852) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=398852) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=398852) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=398852) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=398852) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=398852) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=398852) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=398852) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=398852) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=398852) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=398852) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=398852) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=398852) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=398852) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=398852) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=398852) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=398852) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=398852) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=398852) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=398852) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=398852) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=398852) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=398852) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=398852) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=398852) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=398852) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=398852) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=398852) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=398852) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=398852) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=398852) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=398852) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=398852) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=398852) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=398852) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=398852) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=398852) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=398852) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=398852) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=398852) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=398852) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=398852) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=398852) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=398852) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=398852) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=398852) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=398852) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=398852) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=398852) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=398852) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=398852) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=398852) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=398852) 	}
(EngineCore_DP0 pid=398852) 	.section	.debug_info
(EngineCore_DP0 pid=398852) 	{
(EngineCore_DP0 pid=398852) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=398852) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=398852) .b8 0
(EngineCore_DP0 pid=398852) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=398852) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=398852) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=398852) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=398852) .b8 114
(EngineCore_DP0 pid=398852) .b8 105
(EngineCore_DP0 pid=398852) .b8 116
(EngineCore_DP0 pid=398852) .b8 111
(EngineCore_DP0 pid=398852) .b8 110
(EngineCore_DP0 pid=398852) .b8 0
(EngineCore_DP0 pid=398852) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=398852) .b8 0
(EngineCore_DP0 pid=398852) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=398852) .b8 117
(EngineCore_DP0 pid=398852) .b8 97
(EngineCore_DP0 pid=398852) .b8 110
(EngineCore_DP0 pid=398852) .b8 116
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 115
(EngineCore_DP0 pid=398852) .b8 108
(EngineCore_DP0 pid=398852) .b8 105
(EngineCore_DP0 pid=398852) .b8 100
(EngineCore_DP0 pid=398852) .b8 101
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 116
(EngineCore_DP0 pid=398852) .b8 117
(EngineCore_DP0 pid=398852) .b8 110
(EngineCore_DP0 pid=398852) .b8 101
(EngineCore_DP0 pid=398852) .b8 100
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 76
(EngineCore_DP0 pid=398852) .b8 108
(EngineCore_DP0 pid=398852) .b8 97
(EngineCore_DP0 pid=398852) .b8 109
(EngineCore_DP0 pid=398852) .b8 97
(EngineCore_DP0 pid=398852) .b8 51
(EngineCore_DP0 pid=398852) .b8 46
(EngineCore_DP0 pid=398852) .b8 50
(EngineCore_DP0 pid=398852) .b8 45
(EngineCore_DP0 pid=398852) .b8 51
(EngineCore_DP0 pid=398852) .b8 66
(EngineCore_DP0 pid=398852) .b8 46
(EngineCore_DP0 pid=398852) .b8 112
(EngineCore_DP0 pid=398852) .b8 121
(EngineCore_DP0 pid=398852) .b8 0
(EngineCore_DP0 pid=398852) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=398852) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=398852) .b8 114
(EngineCore_DP0 pid=398852) .b8 111
(EngineCore_DP0 pid=398852) .b8 111
(EngineCore_DP0 pid=398852) .b8 116
(EngineCore_DP0 pid=398852) .b8 47
(EngineCore_DP0 pid=398852) .b8 118
(EngineCore_DP0 pid=398852) .b8 108
(EngineCore_DP0 pid=398852) .b8 108
(EngineCore_DP0 pid=398852) .b8 109
(EngineCore_DP0 pid=398852) .b8 98
(EngineCore_DP0 pid=398852) .b8 101
(EngineCore_DP0 pid=398852) .b8 110
(EngineCore_DP0 pid=398852) .b8 99
(EngineCore_DP0 pid=398852) .b8 104
(EngineCore_DP0 pid=398852) .b8 47
(EngineCore_DP0 pid=398852) .b8 115
(EngineCore_DP0 pid=398852) .b8 108
(EngineCore_DP0 pid=398852) .b8 105
(EngineCore_DP0 pid=398852) .b8 100
(EngineCore_DP0 pid=398852) .b8 101
(EngineCore_DP0 pid=398852) .b8 115
(EngineCore_DP0 pid=398852) .b8 112
(EngineCore_DP0 pid=398852) .b8 97
(EngineCore_DP0 pid=398852) .b8 114
(EngineCore_DP0 pid=398852) .b8 115
(EngineCore_DP0 pid=398852) .b8 101
(EngineCore_DP0 pid=398852) .b8 47
(EngineCore_DP0 pid=398852) .b8 99
(EngineCore_DP0 pid=398852) .b8 115
(EngineCore_DP0 pid=398852) .b8 114
(EngineCore_DP0 pid=398852) .b8 99
(EngineCore_DP0 pid=398852) .b8 47
(EngineCore_DP0 pid=398852) .b8 102
(EngineCore_DP0 pid=398852) .b8 117
(EngineCore_DP0 pid=398852) .b8 115
(EngineCore_DP0 pid=398852) .b8 101
(EngineCore_DP0 pid=398852) .b8 100
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 113
(EngineCore_DP0 pid=398852) .b8 117
(EngineCore_DP0 pid=398852) .b8 97
(EngineCore_DP0 pid=398852) .b8 110
(EngineCore_DP0 pid=398852) .b8 116
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 115
(EngineCore_DP0 pid=398852) .b8 108
(EngineCore_DP0 pid=398852) .b8 105
(EngineCore_DP0 pid=398852) .b8 100
(EngineCore_DP0 pid=398852) .b8 101
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 116
(EngineCore_DP0 pid=398852) .b8 114
(EngineCore_DP0 pid=398852) .b8 105
(EngineCore_DP0 pid=398852) .b8 116
(EngineCore_DP0 pid=398852) .b8 111
(EngineCore_DP0 pid=398852) .b8 110
(EngineCore_DP0 pid=398852) .b8 47
(EngineCore_DP0 pid=398852) .b8 98
(EngineCore_DP0 pid=398852) .b8 117
(EngineCore_DP0 pid=398852) .b8 105
(EngineCore_DP0 pid=398852) .b8 108
(EngineCore_DP0 pid=398852) .b8 100
(EngineCore_DP0 pid=398852) .b8 47
(EngineCore_DP0 pid=398852) .b8 71
(EngineCore_DP0 pid=398852) .b8 66
(EngineCore_DP0 pid=398852) .b8 49
(EngineCore_DP0 pid=398852) .b8 48
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 99
(EngineCore_DP0 pid=398852) .b8 99
(EngineCore_DP0 pid=398852) .b8 49
(EngineCore_DP0 pid=398852) .b8 50
(EngineCore_DP0 pid=398852) .b8 49
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 112
(EngineCore_DP0 pid=398852) .b8 121
(EngineCore_DP0 pid=398852) .b8 51
(EngineCore_DP0 pid=398852) .b8 49
(EngineCore_DP0 pid=398852) .b8 50
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 99
(EngineCore_DP0 pid=398852) .b8 117
(EngineCore_DP0 pid=398852) .b8 49
(EngineCore_DP0 pid=398852) .b8 50
(EngineCore_DP0 pid=398852) .b8 57
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 97
(EngineCore_DP0 pid=398852) .b8 97
(EngineCore_DP0 pid=398852) .b8 114
(EngineCore_DP0 pid=398852) .b8 99
(EngineCore_DP0 pid=398852) .b8 104
(EngineCore_DP0 pid=398852) .b8 54
(EngineCore_DP0 pid=398852) .b8 52
(EngineCore_DP0 pid=398852) .b8 0
(EngineCore_DP0 pid=398852) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=398852) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=398852) .b8 113
(EngineCore_DP0 pid=398852) .b8 117
(EngineCore_DP0 pid=398852) .b8 97
(EngineCore_DP0 pid=398852) .b8 110
(EngineCore_DP0 pid=398852) .b8 116
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 115
(EngineCore_DP0 pid=398852) .b8 108
(EngineCore_DP0 pid=398852) .b8 105
(EngineCore_DP0 pid=398852) .b8 100
(EngineCore_DP0 pid=398852) .b8 101
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 102
(EngineCore_DP0 pid=398852) .b8 112
(EngineCore_DP0 pid=398852) .b8 56
(EngineCore_DP0 pid=398852) .b8 95
(EngineCore_DP0 pid=398852) .b8 107
(EngineCore_DP0 pid=398852) .b8 101
(EngineCore_DP0 pid=398852) .b8 114
(EngineCore_DP0 pid=398852) .b8 110
(EngineCore_DP0 pid=398852) .b8 101
(EngineCore_DP0 pid=398852) .b8 108
(EngineCore_DP0 pid=398852) .b8 0
(EngineCore_DP0 pid=398852) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=398852) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=398852) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=398852) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=398852) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=398852) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=398852) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=398852) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=398852) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=398852) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=398852) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=398852) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=398852) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=398852) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=398852) 	}
(EngineCore_DP0 pid=398852) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) ================================================================
(EngineCore_DP0 pid=398852) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp6ehga0mv.ptx', '-o', '/tmp/tmp6ehga0mv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] 
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] 
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] 
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp6ehga0mv.ptx -o /tmp/tmp6ehga0mv.ptx.o
(EngineCore_DP0 pid=398852) ERROR 01-25 20:10:34 [core.py:866] 

STDERR:
[2026-01-25 20:10:04] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:10:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:10:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:10:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:10:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:10:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:10:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:10:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:10:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:10:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:10:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:10:08] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:10:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:10:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:10:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:10:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:10:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:10:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=398852) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=398852) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.29s/it]
(EngineCore_DP0 pid=398852) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.29s/it]
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=398852) [2026-01-25 20:10:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=398852) Process EngineCore_DP0:
(EngineCore_DP0 pid=398852) Traceback (most recent call last):
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=398852)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=398852)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=398852)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=398852) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp6ehga0mv.ptx', '-o', '/tmp/tmp6ehga0mv.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) Traceback (most recent call last):
(EngineCore_DP0 pid=398852)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=398852)     self.run()
(EngineCore_DP0 pid=398852)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=398852)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=398852)     raise e
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=398852)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=398852)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=398852)     super().__init__(
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=398852)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=398852)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=398852)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=398852)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=398852)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=398852)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=398852)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=398852)     return func(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=398852)     return func(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=398852)     self.model_runner.profile_run()
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=398852)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=398852)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=398852)     return func(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=398852)     outputs = self.model(
(EngineCore_DP0 pid=398852)               ^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398852)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398852)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=398852)     model_output = self.model(
(EngineCore_DP0 pid=398852)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=398852)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=398852)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=398852)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398852)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398852)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=398852)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=398852)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398852)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398852)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=398852)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=398852)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=398852)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=398852)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=398852)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=398852)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=398852)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=398852)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=398852)     return self._linear_fn(
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=398852)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=398852)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=398852)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=398852)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=398852)     return fn(input, L)
(EngineCore_DP0 pid=398852)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=398852)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=398852)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=398852)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=398852)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=398852)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=398852)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=398852)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=398852)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=398852)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=398852)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=398852)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=398852)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=398852)     raise PTXASError(error)
(EngineCore_DP0 pid=398852) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=398852) `ptxas` stderr:
(EngineCore_DP0 pid=398852) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=398852) 
(EngineCore_DP0 pid=398852) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp6ehga0mv.ptx -o /tmp/tmp6ehga0mv.ptx.o
(EngineCore_DP0 pid=398852) 
[rank0]:[W125 20:10:34.875251749 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 20:10:36
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:10:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:10:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=399533) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) ================================================================
(EngineCore_DP0 pid=399533) Internal Triton PTX codegen error
(EngineCore_DP0 pid=399533) `ptxas` stderr:
(EngineCore_DP0 pid=399533) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpgkjz8mii.ptx -o /tmp/tmpgkjz8mii.ptx.o
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) //
(EngineCore_DP0 pid=399533) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=399533) //
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) .version 8.7
(EngineCore_DP0 pid=399533) .target sm_121a
(EngineCore_DP0 pid=399533) .address_size 64
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=399533) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=399533)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=399533) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=399533) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=399533) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=399533) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=399533) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=399533) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=399533) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=399533) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=399533) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=399533) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=399533) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=399533) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=399533) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=399533) )
(EngineCore_DP0 pid=399533) .reqntid 512
(EngineCore_DP0 pid=399533) {
(EngineCore_DP0 pid=399533) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=399533) 	.reg .b16 	%rs<37>;
(EngineCore_DP0 pid=399533) 	.reg .b32 	%r<118>;
(EngineCore_DP0 pid=399533) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=399533) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=399533) $L__func_begin0:
(EngineCore_DP0 pid=399533) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) // %bb.0:
(EngineCore_DP0 pid=399533) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=399533) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=399533) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=399533) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=399533) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=399533) $L__tmp0:
(EngineCore_DP0 pid=399533) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=399533) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=399533) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=399533) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=399533) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=399533) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=399533) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=399533) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=399533) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=399533) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=399533) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=399533) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=399533) 	mov.b32 	%r116, 0f2B8CBCCC;
(EngineCore_DP0 pid=399533) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=399533) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=399533) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=399533) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=399533) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=399533) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=399533) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=399533) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=399533) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=399533) 	add.s32 	%r44, %r34, %r33;
(EngineCore_DP0 pid=399533) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=399533) 	add.s32 	%r47, %r34, %r35;
(EngineCore_DP0 pid=399533) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=399533) 	mov.b32 	%r114, 0f00000000;
(EngineCore_DP0 pid=399533) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=399533) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=399533) 	mov.b32 	%r115, %r40;
(EngineCore_DP0 pid=399533) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=399533) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=399533) 	add.s32 	%r50, %r4, %r115;
(EngineCore_DP0 pid=399533) 	setp.lt.s32 	%p2, %r50, %r18;
(EngineCore_DP0 pid=399533) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=399533) 	mad.wide.s32 	%rd6, %r50, 2, %rd1;
(EngineCore_DP0 pid=399533) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=399533) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=399533) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=399533) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=399533) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=399533) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=399533) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=399533) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=399533) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=399533) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=399533) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=399533) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=399533) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=399533) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=399533) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=399533) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=399533) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=399533) $L__tmp1:
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	bar.sync 	0;
(EngineCore_DP0 pid=399533) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=399533) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=399533) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=399533) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=399533) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=399533) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=399533) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=399533) 	cvt.f32.bf16 	%r51, %rs23;
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	shfl.sync.bfly.b32 	%r52, %r51, 16, 31, -1;
(EngineCore_DP0 pid=399533) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	max.f32 	%r53, %r51, %r52;
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	shfl.sync.bfly.b32 	%r54, %r53, 8, 31, -1;
(EngineCore_DP0 pid=399533) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	max.f32 	%r55, %r53, %r54;
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	shfl.sync.bfly.b32 	%r56, %r55, 4, 31, -1;
(EngineCore_DP0 pid=399533) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	max.f32 	%r57, %r55, %r56;
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	shfl.sync.bfly.b32 	%r58, %r57, 2, 31, -1;
(EngineCore_DP0 pid=399533) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	shfl.sync.bfly.b32 	%r60, %r59, 1, 31, -1;
(EngineCore_DP0 pid=399533) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	max.f32 	%r45, %r59, %r60;
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	@%p3 st.shared.b32 [ %r44 + 0 ], %r45;
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	bar.sync 	0;
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	@%p4 ld.shared.b32 %r46, [ %r47 + 0 ];
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	shfl.sync.bfly.b32 	%r61, %r46, 8, 31, -1;
(EngineCore_DP0 pid=399533) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	max.f32 	%r62, %r46, %r61;
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	shfl.sync.bfly.b32 	%r63, %r62, 4, 31, -1;
(EngineCore_DP0 pid=399533) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	shfl.sync.bfly.b32 	%r65, %r64, 2, 31, -1;
(EngineCore_DP0 pid=399533) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	shfl.sync.bfly.b32 	%r67, %r66, 1, 31, -1;
(EngineCore_DP0 pid=399533) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	max.f32 	%r49, %r66, %r67;
(EngineCore_DP0 pid=399533) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	@%p19 st.shared.b32 [ %r47 + 0 ], %r49;
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	bar.sync 	0;
(EngineCore_DP0 pid=399533) 	ld.shared.b32 	%r68, [global_smem];
(EngineCore_DP0 pid=399533) $L__tmp2:
(EngineCore_DP0 pid=399533) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=399533) 	max.f32 	%r114, %r114, %r68;
(EngineCore_DP0 pid=399533) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=399533) 	add.s32 	%r115, %r115, 4096;
(EngineCore_DP0 pid=399533) 	setp.lt.s32 	%p6, %r115, %r19;
(EngineCore_DP0 pid=399533) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=399533) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=399533) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=399533) 	max.f32 	%r116, %r114, 0f2B8CBCCC;
(EngineCore_DP0 pid=399533) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=399533) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=399533) 	mov.b32 	%r70, 0f43E00000;
(EngineCore_DP0 pid=399533) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=399533) 	div.full.f32 	%r71, %r116, %r70;
(EngineCore_DP0 pid=399533) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=399533) 	max.f32 	%r69, %r71, 0f36924925;
(EngineCore_DP0 pid=399533) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=399533) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=399533) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r69 };
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=399533) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=399533) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=399533) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=399533) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=399533) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=399533) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=399533) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=399533) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=399533) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=399533) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=399533) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=399533) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=399533) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=399533) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=399533) 	div.full.f32 	%r14, %r70, %r116;
(EngineCore_DP0 pid=399533) 	mov.b32 	%r117, 0;
(EngineCore_DP0 pid=399533) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=399533)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=399533) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=399533) 	add.s32 	%r83, %r3, %r117;
(EngineCore_DP0 pid=399533) 	setp.lt.s32 	%p13, %r83, %r15;
(EngineCore_DP0 pid=399533) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=399533) 	mul.hi.s32 	%r84, %r83, 1431655766;
(EngineCore_DP0 pid=399533) 	shr.u32 	%r85, %r84, 31;
(EngineCore_DP0 pid=399533) 	add.s32 	%r86, %r84, %r85;
(EngineCore_DP0 pid=399533) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=399533) 	mul.lo.s32 	%r87, %r86, 3;
(EngineCore_DP0 pid=399533) 	sub.s32 	%r88, %r83, %r87;
(EngineCore_DP0 pid=399533) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=399533) 	shl.b32 	%r89, %r86, 3;
(EngineCore_DP0 pid=399533) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=399533) 	shl.b32 	%r90, %r88, 1;
(EngineCore_DP0 pid=399533) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=399533) 	add.s32 	%r91, %r89, %r90;
(EngineCore_DP0 pid=399533) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=399533) 	setp.lt.s32 	%p14, %r91, %r18;
(EngineCore_DP0 pid=399533) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=399533) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=399533) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=399533) 	mad.wide.s32 	%rd8, %r91, 2, %rd1;
(EngineCore_DP0 pid=399533) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=399533) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=399533) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=399533) 	cvt.f32.bf16 	%r92, %rs24;
(EngineCore_DP0 pid=399533) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=399533) 	or.b32 	%r93, %r91, 1;
(EngineCore_DP0 pid=399533) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=399533) 	setp.lt.s32 	%p15, %r93, %r18;
(EngineCore_DP0 pid=399533) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=399533) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=399533) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=399533) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=399533) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=399533) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=399533) 	cvt.f32.bf16 	%r94, %rs26;
(EngineCore_DP0 pid=399533) 	.loc	1 229 48                        // quant_slide_tuned_Llama3.2-3B.py:229:48
(EngineCore_DP0 pid=399533) 	add.s32 	%r95, %r91, 2;
(EngineCore_DP0 pid=399533) 	.loc	1 229 53                        // quant_slide_tuned_Llama3.2-3B.py:229:53
(EngineCore_DP0 pid=399533) 	setp.lt.s32 	%p16, %r95, %r18;
(EngineCore_DP0 pid=399533) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=399533) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=399533) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=399533) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=399533) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=399533) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=399533) 	cvt.f32.bf16 	%r96, %rs28;
(EngineCore_DP0 pid=399533) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=399533) 	add.s32 	%r97, %r91, 3;
(EngineCore_DP0 pid=399533) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=399533) 	setp.lt.s32 	%p17, %r97, %r18;
(EngineCore_DP0 pid=399533) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=399533) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=399533) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=399533) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=399533) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=399533) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=399533) 	cvt.f32.bf16 	%r98, %rs30;
(EngineCore_DP0 pid=399533) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=399533) 	mul.f32 	%r99, %r14, %r92;
(EngineCore_DP0 pid=399533) 	mov.b32 	%r100, 0f43E00000;
(EngineCore_DP0 pid=399533) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=399533) 	min.xorsign.abs.f32 	%r73, %r99, %r100;
(EngineCore_DP0 pid=399533) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	cvt.rn.satfinite.e4m3x2.f32  %rs32, %r74, %r73; 
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=399533) 	mul.f32 	%r101, %r14, %r94;
(EngineCore_DP0 pid=399533) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=399533) 	min.xorsign.abs.f32 	%r75, %r101, %r100;
(EngineCore_DP0 pid=399533) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	cvt.rn.satfinite.e4m3x2.f32  %rs33, %r76, %r75; 
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=399533) 	mul.f32 	%r102, %r14, %r96;
(EngineCore_DP0 pid=399533) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=399533) 	min.xorsign.abs.f32 	%r77, %r102, %r100;
(EngineCore_DP0 pid=399533) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	cvt.rn.satfinite.e4m3x2.f32  %rs34, %r78, %r77; 
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=399533) 	mul.f32 	%r103, %r14, %r98;
(EngineCore_DP0 pid=399533) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=399533) 	min.xorsign.abs.f32 	%r79, %r103, %r100;
(EngineCore_DP0 pid=399533) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	cvt.rn.satfinite.e4m3x2.f32  %rs35, %r80, %r79; 
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=399533) 	cvt.u32.u16 	%r104, %rs32;
(EngineCore_DP0 pid=399533) 	and.b32 	%r105, %r104, 255;
(EngineCore_DP0 pid=399533) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=399533) 	cvt.u32.u16 	%r106, %rs34;
(EngineCore_DP0 pid=399533) 	and.b32 	%r107, %r106, 255;
(EngineCore_DP0 pid=399533) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=399533) 	cvt.u32.u16 	%r108, %rs35;
(EngineCore_DP0 pid=399533) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=399533) 	and.b16 	%rs36, %rs33, 255;
(EngineCore_DP0 pid=399533) 	mul.wide.u16 	%r109, %rs36, 256;
(EngineCore_DP0 pid=399533) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=399533) 	or.b32 	%r110, %r109, %r105;
(EngineCore_DP0 pid=399533) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=399533) 	shl.b32 	%r111, %r107, 16;
(EngineCore_DP0 pid=399533) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=399533) 	or.b32 	%r112, %r110, %r111;
(EngineCore_DP0 pid=399533) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=399533) 	shl.b32 	%r113, %r108, 24;
(EngineCore_DP0 pid=399533) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=399533) 	or.b32 	%r81, %r112, %r113;
(EngineCore_DP0 pid=399533) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=399533) 	mad.wide.s32 	%rd12, %r83, 4, %rd2;
(EngineCore_DP0 pid=399533) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=399533) 	// begin inline asm
(EngineCore_DP0 pid=399533) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r81 };
(EngineCore_DP0 pid=399533) 	// end inline asm
(EngineCore_DP0 pid=399533) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=399533) 	add.s32 	%r117, %r117, 512;
(EngineCore_DP0 pid=399533) 	setp.lt.s32 	%p18, %r117, %r15;
(EngineCore_DP0 pid=399533) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=399533) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=399533) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=399533) 	ret;
(EngineCore_DP0 pid=399533) $L__tmp3:
(EngineCore_DP0 pid=399533) $L__func_end0:
(EngineCore_DP0 pid=399533)                                         // -- End function
(EngineCore_DP0 pid=399533) }
(EngineCore_DP0 pid=399533) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=399533) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=399533) 	.section	.debug_abbrev
(EngineCore_DP0 pid=399533) 	{
(EngineCore_DP0 pid=399533) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=399533) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=399533) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=399533) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=399533) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=399533) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=399533) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=399533) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=399533) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=399533) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=399533) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=399533) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=399533) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=399533) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=399533) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=399533) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=399533) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=399533) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=399533) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=399533) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=399533) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=399533) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=399533) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=399533) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=399533) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=399533) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=399533) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=399533) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=399533) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=399533) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=399533) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=399533) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=399533) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=399533) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=399533) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=399533) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=399533) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=399533) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=399533) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=399533) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=399533) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=399533) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=399533) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=399533) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=399533) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=399533) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=399533) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=399533) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=399533) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=399533) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=399533) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=399533) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=399533) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=399533) 	}
(EngineCore_DP0 pid=399533) 	.section	.debug_info
(EngineCore_DP0 pid=399533) 	{
(EngineCore_DP0 pid=399533) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=399533) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=399533) .b8 0
(EngineCore_DP0 pid=399533) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=399533) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=399533) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=399533) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=399533) .b8 114
(EngineCore_DP0 pid=399533) .b8 105
(EngineCore_DP0 pid=399533) .b8 116
(EngineCore_DP0 pid=399533) .b8 111
(EngineCore_DP0 pid=399533) .b8 110
(EngineCore_DP0 pid=399533) .b8 0
(EngineCore_DP0 pid=399533) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=399533) .b8 0
(EngineCore_DP0 pid=399533) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=399533) .b8 117
(EngineCore_DP0 pid=399533) .b8 97
(EngineCore_DP0 pid=399533) .b8 110
(EngineCore_DP0 pid=399533) .b8 116
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 115
(EngineCore_DP0 pid=399533) .b8 108
(EngineCore_DP0 pid=399533) .b8 105
(EngineCore_DP0 pid=399533) .b8 100
(EngineCore_DP0 pid=399533) .b8 101
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 116
(EngineCore_DP0 pid=399533) .b8 117
(EngineCore_DP0 pid=399533) .b8 110
(EngineCore_DP0 pid=399533) .b8 101
(EngineCore_DP0 pid=399533) .b8 100
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 76
(EngineCore_DP0 pid=399533) .b8 108
(EngineCore_DP0 pid=399533) .b8 97
(EngineCore_DP0 pid=399533) .b8 109
(EngineCore_DP0 pid=399533) .b8 97
(EngineCore_DP0 pid=399533) .b8 51
(EngineCore_DP0 pid=399533) .b8 46
(EngineCore_DP0 pid=399533) .b8 50
(EngineCore_DP0 pid=399533) .b8 45
(EngineCore_DP0 pid=399533) .b8 51
(EngineCore_DP0 pid=399533) .b8 66
(EngineCore_DP0 pid=399533) .b8 46
(EngineCore_DP0 pid=399533) .b8 112
(EngineCore_DP0 pid=399533) .b8 121
(EngineCore_DP0 pid=399533) .b8 0
(EngineCore_DP0 pid=399533) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=399533) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=399533) .b8 114
(EngineCore_DP0 pid=399533) .b8 111
(EngineCore_DP0 pid=399533) .b8 111
(EngineCore_DP0 pid=399533) .b8 116
(EngineCore_DP0 pid=399533) .b8 47
(EngineCore_DP0 pid=399533) .b8 118
(EngineCore_DP0 pid=399533) .b8 108
(EngineCore_DP0 pid=399533) .b8 108
(EngineCore_DP0 pid=399533) .b8 109
(EngineCore_DP0 pid=399533) .b8 98
(EngineCore_DP0 pid=399533) .b8 101
(EngineCore_DP0 pid=399533) .b8 110
(EngineCore_DP0 pid=399533) .b8 99
(EngineCore_DP0 pid=399533) .b8 104
(EngineCore_DP0 pid=399533) .b8 47
(EngineCore_DP0 pid=399533) .b8 115
(EngineCore_DP0 pid=399533) .b8 108
(EngineCore_DP0 pid=399533) .b8 105
(EngineCore_DP0 pid=399533) .b8 100
(EngineCore_DP0 pid=399533) .b8 101
(EngineCore_DP0 pid=399533) .b8 115
(EngineCore_DP0 pid=399533) .b8 112
(EngineCore_DP0 pid=399533) .b8 97
(EngineCore_DP0 pid=399533) .b8 114
(EngineCore_DP0 pid=399533) .b8 115
(EngineCore_DP0 pid=399533) .b8 101
(EngineCore_DP0 pid=399533) .b8 47
(EngineCore_DP0 pid=399533) .b8 99
(EngineCore_DP0 pid=399533) .b8 115
(EngineCore_DP0 pid=399533) .b8 114
(EngineCore_DP0 pid=399533) .b8 99
(EngineCore_DP0 pid=399533) .b8 47
(EngineCore_DP0 pid=399533) .b8 102
(EngineCore_DP0 pid=399533) .b8 117
(EngineCore_DP0 pid=399533) .b8 115
(EngineCore_DP0 pid=399533) .b8 101
(EngineCore_DP0 pid=399533) .b8 100
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 113
(EngineCore_DP0 pid=399533) .b8 117
(EngineCore_DP0 pid=399533) .b8 97
(EngineCore_DP0 pid=399533) .b8 110
(EngineCore_DP0 pid=399533) .b8 116
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 115
(EngineCore_DP0 pid=399533) .b8 108
(EngineCore_DP0 pid=399533) .b8 105
(EngineCore_DP0 pid=399533) .b8 100
(EngineCore_DP0 pid=399533) .b8 101
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 116
(EngineCore_DP0 pid=399533) .b8 114
(EngineCore_DP0 pid=399533) .b8 105
(EngineCore_DP0 pid=399533) .b8 116
(EngineCore_DP0 pid=399533) .b8 111
(EngineCore_DP0 pid=399533) .b8 110
(EngineCore_DP0 pid=399533) .b8 47
(EngineCore_DP0 pid=399533) .b8 98
(EngineCore_DP0 pid=399533) .b8 117
(EngineCore_DP0 pid=399533) .b8 105
(EngineCore_DP0 pid=399533) .b8 108
(EngineCore_DP0 pid=399533) .b8 100
(EngineCore_DP0 pid=399533) .b8 47
(EngineCore_DP0 pid=399533) .b8 71
(EngineCore_DP0 pid=399533) .b8 66
(EngineCore_DP0 pid=399533) .b8 49
(EngineCore_DP0 pid=399533) .b8 48
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 99
(EngineCore_DP0 pid=399533) .b8 99
(EngineCore_DP0 pid=399533) .b8 49
(EngineCore_DP0 pid=399533) .b8 50
(EngineCore_DP0 pid=399533) .b8 49
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 112
(EngineCore_DP0 pid=399533) .b8 121
(EngineCore_DP0 pid=399533) .b8 51
(EngineCore_DP0 pid=399533) .b8 49
(EngineCore_DP0 pid=399533) .b8 50
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 99
(EngineCore_DP0 pid=399533) .b8 117
(EngineCore_DP0 pid=399533) .b8 49
(EngineCore_DP0 pid=399533) .b8 50
(EngineCore_DP0 pid=399533) .b8 57
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 97
(EngineCore_DP0 pid=399533) .b8 97
(EngineCore_DP0 pid=399533) .b8 114
(EngineCore_DP0 pid=399533) .b8 99
(EngineCore_DP0 pid=399533) .b8 104
(EngineCore_DP0 pid=399533) .b8 54
(EngineCore_DP0 pid=399533) .b8 52
(EngineCore_DP0 pid=399533) .b8 0
(EngineCore_DP0 pid=399533) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=399533) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=399533) .b8 113
(EngineCore_DP0 pid=399533) .b8 117
(EngineCore_DP0 pid=399533) .b8 97
(EngineCore_DP0 pid=399533) .b8 110
(EngineCore_DP0 pid=399533) .b8 116
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 115
(EngineCore_DP0 pid=399533) .b8 108
(EngineCore_DP0 pid=399533) .b8 105
(EngineCore_DP0 pid=399533) .b8 100
(EngineCore_DP0 pid=399533) .b8 101
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 102
(EngineCore_DP0 pid=399533) .b8 112
(EngineCore_DP0 pid=399533) .b8 56
(EngineCore_DP0 pid=399533) .b8 95
(EngineCore_DP0 pid=399533) .b8 107
(EngineCore_DP0 pid=399533) .b8 101
(EngineCore_DP0 pid=399533) .b8 114
(EngineCore_DP0 pid=399533) .b8 110
(EngineCore_DP0 pid=399533) .b8 101
(EngineCore_DP0 pid=399533) .b8 108
(EngineCore_DP0 pid=399533) .b8 0
(EngineCore_DP0 pid=399533) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=399533) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=399533) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=399533) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=399533) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=399533) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=399533) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=399533) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=399533) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=399533) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=399533) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=399533) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=399533) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=399533) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=399533) 	}
(EngineCore_DP0 pid=399533) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) ================================================================
(EngineCore_DP0 pid=399533) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpgkjz8mii.ptx', '-o', '/tmp/tmpgkjz8mii.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] 
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] 
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] 
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpgkjz8mii.ptx -o /tmp/tmpgkjz8mii.ptx.o
(EngineCore_DP0 pid=399533) ERROR 01-25 20:11:10 [core.py:866] 

STDERR:
[2026-01-25 20:10:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:10:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:10:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:10:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:10:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:10:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:10:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:10:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:10:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:10:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:10:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:10:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:10:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:10:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:10:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:10:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:10:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:10:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:10:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=399533) [2026-01-25 20:10:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=399533) [2026-01-25 20:10:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=399533) [2026-01-25 20:10:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=399533) [2026-01-25 20:10:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=399533) [2026-01-25 20:10:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=399533) [2026-01-25 20:10:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=399533) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=399533) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.67s/it]
(EngineCore_DP0 pid=399533) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.67s/it]
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) [2026-01-25 20:11:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=399533) [2026-01-25 20:11:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=399533) [2026-01-25 20:11:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=399533) [2026-01-25 20:11:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=399533) [2026-01-25 20:11:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=399533) [2026-01-25 20:11:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=399533) [2026-01-25 20:11:09] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=399533) [2026-01-25 20:11:09] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=399533) Process EngineCore_DP0:
(EngineCore_DP0 pid=399533) Traceback (most recent call last):
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=399533)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=399533)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=399533)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=399533) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpgkjz8mii.ptx', '-o', '/tmp/tmpgkjz8mii.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) Traceback (most recent call last):
(EngineCore_DP0 pid=399533)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=399533)     self.run()
(EngineCore_DP0 pid=399533)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=399533)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=399533)     raise e
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=399533)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=399533)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=399533)     super().__init__(
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=399533)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=399533)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=399533)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=399533)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=399533)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=399533)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=399533)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=399533)     return func(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=399533)     return func(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=399533)     self.model_runner.profile_run()
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=399533)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=399533)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=399533)     return func(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=399533)     outputs = self.model(
(EngineCore_DP0 pid=399533)               ^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=399533)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=399533)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=399533)     model_output = self.model(
(EngineCore_DP0 pid=399533)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=399533)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=399533)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=399533)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=399533)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=399533)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=399533)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=399533)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=399533)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=399533)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=399533)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=399533)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=399533)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=399533)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=399533)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=399533)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=399533)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=399533)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=399533)     return self._linear_fn(
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=399533)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=399533)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=399533)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=399533)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=399533)     return fn(input, L)
(EngineCore_DP0 pid=399533)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=399533)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=399533)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=399533)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=399533)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=399533)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=399533)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=399533)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=399533)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=399533)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=399533)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=399533)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=399533)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=399533)     raise PTXASError(error)
(EngineCore_DP0 pid=399533) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=399533) `ptxas` stderr:
(EngineCore_DP0 pid=399533) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=399533) 
(EngineCore_DP0 pid=399533) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpgkjz8mii.ptx -o /tmp/tmpgkjz8mii.ptx.o
(EngineCore_DP0 pid=399533) 
[rank0]:[W125 20:11:10.106332982 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 20:11:12
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:11:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:11:17 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=400250) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) ================================================================
(EngineCore_DP0 pid=400250) Internal Triton PTX codegen error
(EngineCore_DP0 pid=400250) `ptxas` stderr:
(EngineCore_DP0 pid=400250) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpn0wd7rq0.ptx -o /tmp/tmpn0wd7rq0.ptx.o
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) //
(EngineCore_DP0 pid=400250) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=400250) //
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) .version 8.7
(EngineCore_DP0 pid=400250) .target sm_121a
(EngineCore_DP0 pid=400250) .address_size 64
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=400250) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=400250)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=400250) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=400250) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=400250) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=400250) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=400250) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=400250) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=400250) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=400250) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=400250) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=400250) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=400250) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=400250) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=400250) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=400250) )
(EngineCore_DP0 pid=400250) .reqntid 512
(EngineCore_DP0 pid=400250) {
(EngineCore_DP0 pid=400250) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=400250) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=400250) 	.reg .b32 	%r<152>;
(EngineCore_DP0 pid=400250) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=400250) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=400250) $L__func_begin0:
(EngineCore_DP0 pid=400250) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) // %bb.0:
(EngineCore_DP0 pid=400250) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=400250) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=400250) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=400250) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=400250) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=400250) $L__tmp0:
(EngineCore_DP0 pid=400250) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=400250) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=400250) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=400250) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=400250) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=400250) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=400250) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=400250) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=400250) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=400250) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=400250) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=400250) 	mov.b32 	%r150, 0f2B8CBCCC;
(EngineCore_DP0 pid=400250) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=400250) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=400250) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=400250) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=400250) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=400250) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=400250) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=400250) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=400250) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=400250) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=400250) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=400250) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=400250) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=400250) 	mov.b32 	%r148, 0f00000000;
(EngineCore_DP0 pid=400250) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=400250) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=400250) 	mov.b32 	%r149, %r45;
(EngineCore_DP0 pid=400250) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=400250) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=400250) 	add.s32 	%r55, %r4, %r149;
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=400250) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=400250) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=400250) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=400250) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=400250) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=400250) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=400250) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=400250) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=400250) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=400250) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=400250) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=400250) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=400250) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=400250) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=400250) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=400250) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=400250) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=400250) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=400250) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=400250) $L__tmp1:
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	bar.sync 	0;
(EngineCore_DP0 pid=400250) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=400250) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=400250) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=400250) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=400250) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=400250) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=400250) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=400250) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=400250) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=400250) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=400250) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=400250) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=400250) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	bar.sync 	0;
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=400250) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=400250) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=400250) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=400250) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=400250) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	bar.sync 	0;
(EngineCore_DP0 pid=400250) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=400250) $L__tmp2:
(EngineCore_DP0 pid=400250) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=400250) 	max.f32 	%r148, %r148, %r73;
(EngineCore_DP0 pid=400250) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=400250) 	add.s32 	%r149, %r149, 4096;
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p6, %r149, %r24;
(EngineCore_DP0 pid=400250) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=400250) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=400250) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=400250) 	max.f32 	%r150, %r148, 0f2B8CBCCC;
(EngineCore_DP0 pid=400250) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=400250) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=400250) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=400250) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=400250) 	div.full.f32 	%r76, %r150, %r75;
(EngineCore_DP0 pid=400250) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=400250) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=400250) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=400250) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=400250) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=400250) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=400250) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=400250) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=400250) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=400250) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=400250) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=400250) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=400250) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=400250) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=400250) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=400250) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=400250) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=400250) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=400250) 	div.full.f32 	%r14, %r75, %r150;
(EngineCore_DP0 pid=400250) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=400250) 	mov.b32 	%r151, 0;
(EngineCore_DP0 pid=400250) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=400250)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=400250) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=400250) 	add.s32 	%r89, %r16, %r151;
(EngineCore_DP0 pid=400250) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=400250) 	add.s32 	%r90, %r89, 1;
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p17, %r89, %r15;
(EngineCore_DP0 pid=400250) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=400250) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=400250) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=400250) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=400250) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=400250) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=400250) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=400250) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=400250) 	mul.lo.s32 	%r97, %r96, 3;
(EngineCore_DP0 pid=400250) 	mul.lo.s32 	%r98, %r93, 3;
(EngineCore_DP0 pid=400250) 	sub.s32 	%r99, %r90, %r98;
(EngineCore_DP0 pid=400250) 	sub.s32 	%r100, %r89, %r97;
(EngineCore_DP0 pid=400250) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=400250) 	shl.b32 	%r101, %r96, 3;
(EngineCore_DP0 pid=400250) 	shl.b32 	%r102, %r93, 3;
(EngineCore_DP0 pid=400250) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=400250) 	shl.b32 	%r103, %r100, 1;
(EngineCore_DP0 pid=400250) 	shl.b32 	%r104, %r99, 1;
(EngineCore_DP0 pid=400250) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=400250) 	add.s32 	%r105, %r102, %r104;
(EngineCore_DP0 pid=400250) 	add.s32 	%r106, %r101, %r103;
(EngineCore_DP0 pid=400250) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p18, %r106, %r23;
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p19, %r105, %r23;
(EngineCore_DP0 pid=400250) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=400250) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=400250) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=400250) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=400250) 	mad.wide.s32 	%rd8, %r106, 2, %rd1;
(EngineCore_DP0 pid=400250) 	mad.wide.s32 	%rd9, %r105, 2, %rd1;
(EngineCore_DP0 pid=400250) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=400250) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=400250) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=400250) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=400250) 	cvt.f32.bf16 	%r107, %rs24;
(EngineCore_DP0 pid=400250) 	cvt.f32.bf16 	%r108, %rs26;
(EngineCore_DP0 pid=400250) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=400250) 	or.b32 	%r109, %r106, 1;
(EngineCore_DP0 pid=400250) 	or.b32 	%r110, %r105, 1;
(EngineCore_DP0 pid=400250) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p20, %r109, %r23;
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p21, %r110, %r23;
(EngineCore_DP0 pid=400250) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=400250) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=400250) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=400250) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=400250) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=400250) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=400250) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=400250) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=400250) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=400250) 	cvt.f32.bf16 	%r111, %rs28;
(EngineCore_DP0 pid=400250) 	cvt.f32.bf16 	%r112, %rs30;
(EngineCore_DP0 pid=400250) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=400250) 	add.s32 	%r113, %r106, 2;
(EngineCore_DP0 pid=400250) 	add.s32 	%r114, %r105, 2;
(EngineCore_DP0 pid=400250) 	add.s32 	%r115, %r106, 3;
(EngineCore_DP0 pid=400250) 	add.s32 	%r116, %r105, 3;
(EngineCore_DP0 pid=400250) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p22, %r116, %r23;
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p23, %r115, %r23;
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p24, %r114, %r23;
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p25, %r113, %r23;
(EngineCore_DP0 pid=400250) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=400250) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=400250) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=400250) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=400250) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=400250) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=400250) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=400250) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=400250) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=400250) 	cvt.f32.bf16 	%r117, %rs32;
(EngineCore_DP0 pid=400250) 	cvt.f32.bf16 	%r118, %rs34;
(EngineCore_DP0 pid=400250) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=400250) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=400250) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=400250) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=400250) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=400250) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=400250) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=400250) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=400250) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=400250) 	cvt.f32.bf16 	%r119, %rs36;
(EngineCore_DP0 pid=400250) 	cvt.f32.bf16 	%r120, %rs38;
(EngineCore_DP0 pid=400250) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=400250) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=400250) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=400250) 	mov.b32 	%r123, 0f43E00000;
(EngineCore_DP0 pid=400250) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=400250) 	min.xorsign.abs.f32 	%r78, %r121, %r123;
(EngineCore_DP0 pid=400250) 	min.xorsign.abs.f32 	%r79, %r122, %r123;
(EngineCore_DP0 pid=400250) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=400250) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=400250) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=400250) 	mul.f32 	%r125, %r14, %r112;
(EngineCore_DP0 pid=400250) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=400250) 	min.xorsign.abs.f32 	%r80, %r124, %r123;
(EngineCore_DP0 pid=400250) 	min.xorsign.abs.f32 	%r81, %r125, %r123;
(EngineCore_DP0 pid=400250) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=400250) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=400250) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=400250) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=400250) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=400250) 	min.xorsign.abs.f32 	%r82, %r126, %r123;
(EngineCore_DP0 pid=400250) 	min.xorsign.abs.f32 	%r83, %r127, %r123;
(EngineCore_DP0 pid=400250) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=400250) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=400250) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=400250) 	mul.f32 	%r129, %r14, %r120;
(EngineCore_DP0 pid=400250) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=400250) 	min.xorsign.abs.f32 	%r84, %r128, %r123;
(EngineCore_DP0 pid=400250) 	min.xorsign.abs.f32 	%r85, %r129, %r123;
(EngineCore_DP0 pid=400250) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=400250) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=400250) 	cvt.u32.u16 	%r130, %rs40;
(EngineCore_DP0 pid=400250) 	and.b32 	%r131, %r130, 255;
(EngineCore_DP0 pid=400250) 	cvt.u32.u16 	%r132, %rs44;
(EngineCore_DP0 pid=400250) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=400250) 	cvt.u32.u16 	%r133, %rs42;
(EngineCore_DP0 pid=400250) 	and.b32 	%r134, %r133, 255;
(EngineCore_DP0 pid=400250) 	cvt.u32.u16 	%r135, %rs46;
(EngineCore_DP0 pid=400250) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=400250) 	cvt.u32.u16 	%r136, %rs43;
(EngineCore_DP0 pid=400250) 	cvt.u32.u16 	%r137, %rs47;
(EngineCore_DP0 pid=400250) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=400250) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=400250) 	mul.wide.u16 	%r138, %rs48, 256;
(EngineCore_DP0 pid=400250) 	mul.wide.u16 	%r139, %rs45, 256;
(EngineCore_DP0 pid=400250) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=400250) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=400250) 	or.b32 	%r141, %r139, %r132;
(EngineCore_DP0 pid=400250) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=400250) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=400250) 	shl.b32 	%r143, %r135, 16;
(EngineCore_DP0 pid=400250) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=400250) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=400250) 	or.b32 	%r145, %r141, %r143;
(EngineCore_DP0 pid=400250) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=400250) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=400250) 	shl.b32 	%r147, %r137, 24;
(EngineCore_DP0 pid=400250) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=400250) 	or.b32 	%r86, %r144, %r146;
(EngineCore_DP0 pid=400250) 	or.b32 	%r87, %r145, %r147;
(EngineCore_DP0 pid=400250) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=400250) 	mad.wide.s32 	%rd16, %r89, 4, %rd2;
(EngineCore_DP0 pid=400250) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=400250) 	// begin inline asm
(EngineCore_DP0 pid=400250) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=400250) 	// end inline asm
(EngineCore_DP0 pid=400250) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=400250) 	add.s32 	%r151, %r151, 1024;
(EngineCore_DP0 pid=400250) 	setp.lt.s32 	%p26, %r151, %r15;
(EngineCore_DP0 pid=400250) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=400250) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=400250) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=400250) 	ret;
(EngineCore_DP0 pid=400250) $L__tmp3:
(EngineCore_DP0 pid=400250) $L__func_end0:
(EngineCore_DP0 pid=400250)                                         // -- End function
(EngineCore_DP0 pid=400250) }
(EngineCore_DP0 pid=400250) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=400250) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=400250) 	.section	.debug_abbrev
(EngineCore_DP0 pid=400250) 	{
(EngineCore_DP0 pid=400250) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=400250) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=400250) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=400250) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=400250) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=400250) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=400250) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=400250) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=400250) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=400250) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=400250) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=400250) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=400250) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=400250) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=400250) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=400250) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=400250) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=400250) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=400250) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=400250) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=400250) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=400250) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=400250) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=400250) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=400250) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=400250) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=400250) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=400250) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=400250) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=400250) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=400250) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=400250) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=400250) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=400250) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=400250) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=400250) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=400250) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=400250) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=400250) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=400250) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=400250) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=400250) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=400250) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=400250) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=400250) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=400250) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=400250) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=400250) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=400250) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=400250) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=400250) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=400250) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=400250) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=400250) 	}
(EngineCore_DP0 pid=400250) 	.section	.debug_info
(EngineCore_DP0 pid=400250) 	{
(EngineCore_DP0 pid=400250) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=400250) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=400250) .b8 0
(EngineCore_DP0 pid=400250) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=400250) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=400250) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=400250) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=400250) .b8 114
(EngineCore_DP0 pid=400250) .b8 105
(EngineCore_DP0 pid=400250) .b8 116
(EngineCore_DP0 pid=400250) .b8 111
(EngineCore_DP0 pid=400250) .b8 110
(EngineCore_DP0 pid=400250) .b8 0
(EngineCore_DP0 pid=400250) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=400250) .b8 0
(EngineCore_DP0 pid=400250) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=400250) .b8 117
(EngineCore_DP0 pid=400250) .b8 97
(EngineCore_DP0 pid=400250) .b8 110
(EngineCore_DP0 pid=400250) .b8 116
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 115
(EngineCore_DP0 pid=400250) .b8 108
(EngineCore_DP0 pid=400250) .b8 105
(EngineCore_DP0 pid=400250) .b8 100
(EngineCore_DP0 pid=400250) .b8 101
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 116
(EngineCore_DP0 pid=400250) .b8 117
(EngineCore_DP0 pid=400250) .b8 110
(EngineCore_DP0 pid=400250) .b8 101
(EngineCore_DP0 pid=400250) .b8 100
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 76
(EngineCore_DP0 pid=400250) .b8 108
(EngineCore_DP0 pid=400250) .b8 97
(EngineCore_DP0 pid=400250) .b8 109
(EngineCore_DP0 pid=400250) .b8 97
(EngineCore_DP0 pid=400250) .b8 51
(EngineCore_DP0 pid=400250) .b8 46
(EngineCore_DP0 pid=400250) .b8 50
(EngineCore_DP0 pid=400250) .b8 45
(EngineCore_DP0 pid=400250) .b8 51
(EngineCore_DP0 pid=400250) .b8 66
(EngineCore_DP0 pid=400250) .b8 46
(EngineCore_DP0 pid=400250) .b8 112
(EngineCore_DP0 pid=400250) .b8 121
(EngineCore_DP0 pid=400250) .b8 0
(EngineCore_DP0 pid=400250) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=400250) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=400250) .b8 114
(EngineCore_DP0 pid=400250) .b8 111
(EngineCore_DP0 pid=400250) .b8 111
(EngineCore_DP0 pid=400250) .b8 116
(EngineCore_DP0 pid=400250) .b8 47
(EngineCore_DP0 pid=400250) .b8 118
(EngineCore_DP0 pid=400250) .b8 108
(EngineCore_DP0 pid=400250) .b8 108
(EngineCore_DP0 pid=400250) .b8 109
(EngineCore_DP0 pid=400250) .b8 98
(EngineCore_DP0 pid=400250) .b8 101
(EngineCore_DP0 pid=400250) .b8 110
(EngineCore_DP0 pid=400250) .b8 99
(EngineCore_DP0 pid=400250) .b8 104
(EngineCore_DP0 pid=400250) .b8 47
(EngineCore_DP0 pid=400250) .b8 115
(EngineCore_DP0 pid=400250) .b8 108
(EngineCore_DP0 pid=400250) .b8 105
(EngineCore_DP0 pid=400250) .b8 100
(EngineCore_DP0 pid=400250) .b8 101
(EngineCore_DP0 pid=400250) .b8 115
(EngineCore_DP0 pid=400250) .b8 112
(EngineCore_DP0 pid=400250) .b8 97
(EngineCore_DP0 pid=400250) .b8 114
(EngineCore_DP0 pid=400250) .b8 115
(EngineCore_DP0 pid=400250) .b8 101
(EngineCore_DP0 pid=400250) .b8 47
(EngineCore_DP0 pid=400250) .b8 99
(EngineCore_DP0 pid=400250) .b8 115
(EngineCore_DP0 pid=400250) .b8 114
(EngineCore_DP0 pid=400250) .b8 99
(EngineCore_DP0 pid=400250) .b8 47
(EngineCore_DP0 pid=400250) .b8 102
(EngineCore_DP0 pid=400250) .b8 117
(EngineCore_DP0 pid=400250) .b8 115
(EngineCore_DP0 pid=400250) .b8 101
(EngineCore_DP0 pid=400250) .b8 100
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 113
(EngineCore_DP0 pid=400250) .b8 117
(EngineCore_DP0 pid=400250) .b8 97
(EngineCore_DP0 pid=400250) .b8 110
(EngineCore_DP0 pid=400250) .b8 116
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 115
(EngineCore_DP0 pid=400250) .b8 108
(EngineCore_DP0 pid=400250) .b8 105
(EngineCore_DP0 pid=400250) .b8 100
(EngineCore_DP0 pid=400250) .b8 101
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 116
(EngineCore_DP0 pid=400250) .b8 114
(EngineCore_DP0 pid=400250) .b8 105
(EngineCore_DP0 pid=400250) .b8 116
(EngineCore_DP0 pid=400250) .b8 111
(EngineCore_DP0 pid=400250) .b8 110
(EngineCore_DP0 pid=400250) .b8 47
(EngineCore_DP0 pid=400250) .b8 98
(EngineCore_DP0 pid=400250) .b8 117
(EngineCore_DP0 pid=400250) .b8 105
(EngineCore_DP0 pid=400250) .b8 108
(EngineCore_DP0 pid=400250) .b8 100
(EngineCore_DP0 pid=400250) .b8 47
(EngineCore_DP0 pid=400250) .b8 71
(EngineCore_DP0 pid=400250) .b8 66
(EngineCore_DP0 pid=400250) .b8 49
(EngineCore_DP0 pid=400250) .b8 48
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 99
(EngineCore_DP0 pid=400250) .b8 99
(EngineCore_DP0 pid=400250) .b8 49
(EngineCore_DP0 pid=400250) .b8 50
(EngineCore_DP0 pid=400250) .b8 49
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 112
(EngineCore_DP0 pid=400250) .b8 121
(EngineCore_DP0 pid=400250) .b8 51
(EngineCore_DP0 pid=400250) .b8 49
(EngineCore_DP0 pid=400250) .b8 50
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 99
(EngineCore_DP0 pid=400250) .b8 117
(EngineCore_DP0 pid=400250) .b8 49
(EngineCore_DP0 pid=400250) .b8 50
(EngineCore_DP0 pid=400250) .b8 57
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 97
(EngineCore_DP0 pid=400250) .b8 97
(EngineCore_DP0 pid=400250) .b8 114
(EngineCore_DP0 pid=400250) .b8 99
(EngineCore_DP0 pid=400250) .b8 104
(EngineCore_DP0 pid=400250) .b8 54
(EngineCore_DP0 pid=400250) .b8 52
(EngineCore_DP0 pid=400250) .b8 0
(EngineCore_DP0 pid=400250) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=400250) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=400250) .b8 113
(EngineCore_DP0 pid=400250) .b8 117
(EngineCore_DP0 pid=400250) .b8 97
(EngineCore_DP0 pid=400250) .b8 110
(EngineCore_DP0 pid=400250) .b8 116
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 115
(EngineCore_DP0 pid=400250) .b8 108
(EngineCore_DP0 pid=400250) .b8 105
(EngineCore_DP0 pid=400250) .b8 100
(EngineCore_DP0 pid=400250) .b8 101
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 102
(EngineCore_DP0 pid=400250) .b8 112
(EngineCore_DP0 pid=400250) .b8 56
(EngineCore_DP0 pid=400250) .b8 95
(EngineCore_DP0 pid=400250) .b8 107
(EngineCore_DP0 pid=400250) .b8 101
(EngineCore_DP0 pid=400250) .b8 114
(EngineCore_DP0 pid=400250) .b8 110
(EngineCore_DP0 pid=400250) .b8 101
(EngineCore_DP0 pid=400250) .b8 108
(EngineCore_DP0 pid=400250) .b8 0
(EngineCore_DP0 pid=400250) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=400250) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=400250) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=400250) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=400250) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=400250) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=400250) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=400250) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=400250) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=400250) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=400250) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=400250) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=400250) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=400250) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=400250) 	}
(EngineCore_DP0 pid=400250) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) ================================================================
(EngineCore_DP0 pid=400250) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpn0wd7rq0.ptx', '-o', '/tmp/tmpn0wd7rq0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] 
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] 
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] 
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpn0wd7rq0.ptx -o /tmp/tmpn0wd7rq0.ptx.o
(EngineCore_DP0 pid=400250) ERROR 01-25 20:11:47 [core.py:866] 

STDERR:
[2026-01-25 20:11:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:11:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:11:17] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:11:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:11:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:11:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:11:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:11:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:11:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:11:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:11:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:11:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:11:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:11:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:11:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:11:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:11:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:11:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:21] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:21] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:21] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:21] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:21] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=400250) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=400250) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.35s/it]
(EngineCore_DP0 pid=400250) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.35s/it]
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=400250) [2026-01-25 20:11:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=400250) Process EngineCore_DP0:
(EngineCore_DP0 pid=400250) Traceback (most recent call last):
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=400250)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=400250)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=400250)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=400250) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpn0wd7rq0.ptx', '-o', '/tmp/tmpn0wd7rq0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) Traceback (most recent call last):
(EngineCore_DP0 pid=400250)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=400250)     self.run()
(EngineCore_DP0 pid=400250)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=400250)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=400250)     raise e
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=400250)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=400250)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=400250)     super().__init__(
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=400250)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=400250)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=400250)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=400250)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=400250)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=400250)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=400250)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=400250)     return func(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=400250)     return func(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=400250)     self.model_runner.profile_run()
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=400250)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=400250)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=400250)     return func(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=400250)     outputs = self.model(
(EngineCore_DP0 pid=400250)               ^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400250)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400250)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=400250)     model_output = self.model(
(EngineCore_DP0 pid=400250)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=400250)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=400250)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=400250)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400250)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400250)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=400250)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=400250)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400250)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400250)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=400250)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=400250)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400250)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400250)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=400250)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=400250)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=400250)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=400250)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=400250)     return self._linear_fn(
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=400250)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=400250)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=400250)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=400250)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=400250)     return fn(input, L)
(EngineCore_DP0 pid=400250)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=400250)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=400250)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=400250)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=400250)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=400250)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=400250)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=400250)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=400250)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=400250)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=400250)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=400250)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400250)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=400250)     raise PTXASError(error)
(EngineCore_DP0 pid=400250) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=400250) `ptxas` stderr:
(EngineCore_DP0 pid=400250) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=400250) 
(EngineCore_DP0 pid=400250) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpn0wd7rq0.ptx -o /tmp/tmpn0wd7rq0.ptx.o
(EngineCore_DP0 pid=400250) 
[rank0]:[W125 20:11:47.529541220 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 20:11:49
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:11:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:11:55 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=400947) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) ================================================================
(EngineCore_DP0 pid=400947) Internal Triton PTX codegen error
(EngineCore_DP0 pid=400947) `ptxas` stderr:
(EngineCore_DP0 pid=400947) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpzq757_ww.ptx -o /tmp/tmpzq757_ww.ptx.o
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) //
(EngineCore_DP0 pid=400947) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=400947) //
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) .version 8.7
(EngineCore_DP0 pid=400947) .target sm_121a
(EngineCore_DP0 pid=400947) .address_size 64
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=400947) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=400947)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=400947) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=400947) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=400947) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=400947) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=400947) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=400947) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=400947) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=400947) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=400947) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=400947) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=400947) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=400947) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=400947) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=400947) )
(EngineCore_DP0 pid=400947) .reqntid 512
(EngineCore_DP0 pid=400947) {
(EngineCore_DP0 pid=400947) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=400947) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=400947) 	.reg .b32 	%r<161>;
(EngineCore_DP0 pid=400947) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=400947) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=400947) $L__func_begin0:
(EngineCore_DP0 pid=400947) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) // %bb.0:
(EngineCore_DP0 pid=400947) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=400947) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=400947) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=400947) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=400947) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=400947) $L__tmp0:
(EngineCore_DP0 pid=400947) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=400947) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=400947) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=400947) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=400947) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=400947) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=400947) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=400947) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=400947) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=400947) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=400947) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=400947) 	mov.b32 	%r159, 0f2B8CBCCC;
(EngineCore_DP0 pid=400947) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=400947) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=400947) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=400947) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=400947) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=400947) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=400947) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=400947) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=400947) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=400947) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=400947) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=400947) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=400947) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=400947) 	mov.b32 	%r157, 0f00000000;
(EngineCore_DP0 pid=400947) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=400947) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=400947) 	mov.b32 	%r158, %r45;
(EngineCore_DP0 pid=400947) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=400947) 	.loc	1 202 19                        // quant_slide_tuned_Llama3.2-3B.py:202:19
(EngineCore_DP0 pid=400947) 	add.s32 	%r63, %r4, %r158;
(EngineCore_DP0 pid=400947) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=400947) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=400947) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=400947) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=400947) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=400947) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=400947) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=400947) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=400947) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=400947) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=400947) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=400947) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=400947) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=400947) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=400947) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=400947) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=400947) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=400947) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=400947) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=400947) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=400947) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=400947) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=400947) $L__tmp1:
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	bar.sync 	0;
(EngineCore_DP0 pid=400947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=400947) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=400947) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=400947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=400947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=400947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=400947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=400947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	bar.sync 	0;
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=400947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=400947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=400947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=400947) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=400947) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	bar.sync 	0;
(EngineCore_DP0 pid=400947) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=400947) $L__tmp2:
(EngineCore_DP0 pid=400947) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=400947) 	max.f32 	%r157, %r157, %r82;
(EngineCore_DP0 pid=400947) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=400947) 	add.s32 	%r158, %r158, 8192;
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p7, %r158, %r24;
(EngineCore_DP0 pid=400947) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=400947) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=400947) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=400947) 	max.f32 	%r159, %r157, 0f2B8CBCCC;
(EngineCore_DP0 pid=400947) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=400947) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=400947) 	mov.b32 	%r84, 0f43E00000;
(EngineCore_DP0 pid=400947) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=400947) 	div.full.f32 	%r85, %r159, %r84;
(EngineCore_DP0 pid=400947) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=400947) 	max.f32 	%r83, %r85, 0f36924925;
(EngineCore_DP0 pid=400947) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=400947) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=400947) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=400947) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=400947) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=400947) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=400947) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=400947) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=400947) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=400947) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=400947) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=400947) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=400947) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=400947) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=400947) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=400947) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=400947) 	div.full.f32 	%r14, %r84, %r159;
(EngineCore_DP0 pid=400947) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=400947) 	mov.b32 	%r160, 0;
(EngineCore_DP0 pid=400947) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=400947)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=400947) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=400947) 	add.s32 	%r98, %r16, %r160;
(EngineCore_DP0 pid=400947) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=400947) 	add.s32 	%r99, %r98, 1;
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p18, %r98, %r15;
(EngineCore_DP0 pid=400947) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=400947) 	mul.hi.s32 	%r100, %r99, 1431655766;
(EngineCore_DP0 pid=400947) 	shr.u32 	%r101, %r100, 31;
(EngineCore_DP0 pid=400947) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=400947) 	mul.hi.s32 	%r103, %r98, 1431655766;
(EngineCore_DP0 pid=400947) 	shr.u32 	%r104, %r103, 31;
(EngineCore_DP0 pid=400947) 	add.s32 	%r105, %r103, %r104;
(EngineCore_DP0 pid=400947) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=400947) 	mul.lo.s32 	%r106, %r105, 3;
(EngineCore_DP0 pid=400947) 	mul.lo.s32 	%r107, %r102, 3;
(EngineCore_DP0 pid=400947) 	sub.s32 	%r108, %r99, %r107;
(EngineCore_DP0 pid=400947) 	sub.s32 	%r109, %r98, %r106;
(EngineCore_DP0 pid=400947) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=400947) 	shl.b32 	%r110, %r105, 3;
(EngineCore_DP0 pid=400947) 	shl.b32 	%r111, %r102, 3;
(EngineCore_DP0 pid=400947) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=400947) 	shl.b32 	%r112, %r109, 1;
(EngineCore_DP0 pid=400947) 	shl.b32 	%r113, %r108, 1;
(EngineCore_DP0 pid=400947) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=400947) 	add.s32 	%r114, %r111, %r113;
(EngineCore_DP0 pid=400947) 	add.s32 	%r115, %r110, %r112;
(EngineCore_DP0 pid=400947) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p19, %r115, %r23;
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p20, %r114, %r23;
(EngineCore_DP0 pid=400947) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=400947) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=400947) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=400947) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=400947) 	mad.wide.s32 	%rd9, %r115, 2, %rd1;
(EngineCore_DP0 pid=400947) 	mad.wide.s32 	%rd10, %r114, 2, %rd1;
(EngineCore_DP0 pid=400947) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=400947) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=400947) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=400947) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=400947) 	cvt.f32.bf16 	%r116, %rs48;
(EngineCore_DP0 pid=400947) 	cvt.f32.bf16 	%r117, %rs50;
(EngineCore_DP0 pid=400947) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=400947) 	or.b32 	%r118, %r115, 1;
(EngineCore_DP0 pid=400947) 	or.b32 	%r119, %r114, 1;
(EngineCore_DP0 pid=400947) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p21, %r118, %r23;
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p22, %r119, %r23;
(EngineCore_DP0 pid=400947) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=400947) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=400947) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=400947) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=400947) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=400947) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=400947) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=400947) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=400947) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=400947) 	cvt.f32.bf16 	%r120, %rs52;
(EngineCore_DP0 pid=400947) 	cvt.f32.bf16 	%r121, %rs54;
(EngineCore_DP0 pid=400947) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=400947) 	add.s32 	%r122, %r115, 2;
(EngineCore_DP0 pid=400947) 	add.s32 	%r123, %r114, 2;
(EngineCore_DP0 pid=400947) 	add.s32 	%r124, %r115, 3;
(EngineCore_DP0 pid=400947) 	add.s32 	%r125, %r114, 3;
(EngineCore_DP0 pid=400947) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p23, %r125, %r23;
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p24, %r124, %r23;
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p25, %r123, %r23;
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p26, %r122, %r23;
(EngineCore_DP0 pid=400947) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=400947) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=400947) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=400947) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=400947) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=400947) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=400947) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=400947) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=400947) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=400947) 	cvt.f32.bf16 	%r126, %rs56;
(EngineCore_DP0 pid=400947) 	cvt.f32.bf16 	%r127, %rs58;
(EngineCore_DP0 pid=400947) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=400947) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=400947) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=400947) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=400947) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=400947) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=400947) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=400947) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=400947) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=400947) 	cvt.f32.bf16 	%r128, %rs60;
(EngineCore_DP0 pid=400947) 	cvt.f32.bf16 	%r129, %rs62;
(EngineCore_DP0 pid=400947) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=400947) 	mul.f32 	%r130, %r14, %r116;
(EngineCore_DP0 pid=400947) 	mul.f32 	%r131, %r14, %r117;
(EngineCore_DP0 pid=400947) 	mov.b32 	%r132, 0f43E00000;
(EngineCore_DP0 pid=400947) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=400947) 	min.xorsign.abs.f32 	%r87, %r130, %r132;
(EngineCore_DP0 pid=400947) 	min.xorsign.abs.f32 	%r88, %r131, %r132;
(EngineCore_DP0 pid=400947) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r88, %r87; 
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=400947) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=400947) 	mul.f32 	%r133, %r14, %r120;
(EngineCore_DP0 pid=400947) 	mul.f32 	%r134, %r14, %r121;
(EngineCore_DP0 pid=400947) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=400947) 	min.xorsign.abs.f32 	%r89, %r133, %r132;
(EngineCore_DP0 pid=400947) 	min.xorsign.abs.f32 	%r90, %r134, %r132;
(EngineCore_DP0 pid=400947) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r90, %r89; 
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=400947) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=400947) 	mul.f32 	%r135, %r14, %r126;
(EngineCore_DP0 pid=400947) 	mul.f32 	%r136, %r14, %r127;
(EngineCore_DP0 pid=400947) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=400947) 	min.xorsign.abs.f32 	%r91, %r135, %r132;
(EngineCore_DP0 pid=400947) 	min.xorsign.abs.f32 	%r92, %r136, %r132;
(EngineCore_DP0 pid=400947) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r92, %r91; 
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=400947) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=400947) 	mul.f32 	%r137, %r14, %r128;
(EngineCore_DP0 pid=400947) 	mul.f32 	%r138, %r14, %r129;
(EngineCore_DP0 pid=400947) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=400947) 	min.xorsign.abs.f32 	%r93, %r137, %r132;
(EngineCore_DP0 pid=400947) 	min.xorsign.abs.f32 	%r94, %r138, %r132;
(EngineCore_DP0 pid=400947) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r94, %r93; 
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=400947) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=400947) 	cvt.u32.u16 	%r139, %rs64;
(EngineCore_DP0 pid=400947) 	and.b32 	%r140, %r139, 255;
(EngineCore_DP0 pid=400947) 	cvt.u32.u16 	%r141, %rs68;
(EngineCore_DP0 pid=400947) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=400947) 	cvt.u32.u16 	%r142, %rs66;
(EngineCore_DP0 pid=400947) 	and.b32 	%r143, %r142, 255;
(EngineCore_DP0 pid=400947) 	cvt.u32.u16 	%r144, %rs70;
(EngineCore_DP0 pid=400947) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=400947) 	cvt.u32.u16 	%r145, %rs67;
(EngineCore_DP0 pid=400947) 	cvt.u32.u16 	%r146, %rs71;
(EngineCore_DP0 pid=400947) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=400947) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=400947) 	mul.wide.u16 	%r147, %rs72, 256;
(EngineCore_DP0 pid=400947) 	mul.wide.u16 	%r148, %rs69, 256;
(EngineCore_DP0 pid=400947) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=400947) 	or.b32 	%r149, %r147, %r140;
(EngineCore_DP0 pid=400947) 	or.b32 	%r150, %r148, %r141;
(EngineCore_DP0 pid=400947) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=400947) 	shl.b32 	%r151, %r143, 16;
(EngineCore_DP0 pid=400947) 	shl.b32 	%r152, %r144, 16;
(EngineCore_DP0 pid=400947) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=400947) 	or.b32 	%r153, %r149, %r151;
(EngineCore_DP0 pid=400947) 	or.b32 	%r154, %r150, %r152;
(EngineCore_DP0 pid=400947) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=400947) 	shl.b32 	%r155, %r145, 24;
(EngineCore_DP0 pid=400947) 	shl.b32 	%r156, %r146, 24;
(EngineCore_DP0 pid=400947) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=400947) 	or.b32 	%r95, %r153, %r155;
(EngineCore_DP0 pid=400947) 	or.b32 	%r96, %r154, %r156;
(EngineCore_DP0 pid=400947) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=400947) 	mad.wide.s32 	%rd17, %r98, 4, %rd2;
(EngineCore_DP0 pid=400947) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=400947) 	// begin inline asm
(EngineCore_DP0 pid=400947) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r95, %r96 };
(EngineCore_DP0 pid=400947) 	// end inline asm
(EngineCore_DP0 pid=400947) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=400947) 	add.s32 	%r160, %r160, 1024;
(EngineCore_DP0 pid=400947) 	setp.lt.s32 	%p27, %r160, %r15;
(EngineCore_DP0 pid=400947) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=400947) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=400947) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=400947) 	ret;
(EngineCore_DP0 pid=400947) $L__tmp3:
(EngineCore_DP0 pid=400947) $L__func_end0:
(EngineCore_DP0 pid=400947)                                         // -- End function
(EngineCore_DP0 pid=400947) }
(EngineCore_DP0 pid=400947) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=400947) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=400947) 	.section	.debug_abbrev
(EngineCore_DP0 pid=400947) 	{
(EngineCore_DP0 pid=400947) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=400947) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=400947) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=400947) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=400947) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=400947) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=400947) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=400947) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=400947) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=400947) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=400947) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=400947) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=400947) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=400947) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=400947) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=400947) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=400947) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=400947) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=400947) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=400947) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=400947) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=400947) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=400947) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=400947) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=400947) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=400947) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=400947) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=400947) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=400947) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=400947) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=400947) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=400947) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=400947) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=400947) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=400947) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=400947) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=400947) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=400947) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=400947) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=400947) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=400947) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=400947) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=400947) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=400947) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=400947) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=400947) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=400947) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=400947) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=400947) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=400947) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=400947) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=400947) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=400947) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=400947) 	}
(EngineCore_DP0 pid=400947) 	.section	.debug_info
(EngineCore_DP0 pid=400947) 	{
(EngineCore_DP0 pid=400947) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=400947) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=400947) .b8 0
(EngineCore_DP0 pid=400947) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=400947) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=400947) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=400947) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=400947) .b8 114
(EngineCore_DP0 pid=400947) .b8 105
(EngineCore_DP0 pid=400947) .b8 116
(EngineCore_DP0 pid=400947) .b8 111
(EngineCore_DP0 pid=400947) .b8 110
(EngineCore_DP0 pid=400947) .b8 0
(EngineCore_DP0 pid=400947) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=400947) .b8 0
(EngineCore_DP0 pid=400947) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=400947) .b8 117
(EngineCore_DP0 pid=400947) .b8 97
(EngineCore_DP0 pid=400947) .b8 110
(EngineCore_DP0 pid=400947) .b8 116
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 115
(EngineCore_DP0 pid=400947) .b8 108
(EngineCore_DP0 pid=400947) .b8 105
(EngineCore_DP0 pid=400947) .b8 100
(EngineCore_DP0 pid=400947) .b8 101
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 116
(EngineCore_DP0 pid=400947) .b8 117
(EngineCore_DP0 pid=400947) .b8 110
(EngineCore_DP0 pid=400947) .b8 101
(EngineCore_DP0 pid=400947) .b8 100
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 76
(EngineCore_DP0 pid=400947) .b8 108
(EngineCore_DP0 pid=400947) .b8 97
(EngineCore_DP0 pid=400947) .b8 109
(EngineCore_DP0 pid=400947) .b8 97
(EngineCore_DP0 pid=400947) .b8 51
(EngineCore_DP0 pid=400947) .b8 46
(EngineCore_DP0 pid=400947) .b8 50
(EngineCore_DP0 pid=400947) .b8 45
(EngineCore_DP0 pid=400947) .b8 51
(EngineCore_DP0 pid=400947) .b8 66
(EngineCore_DP0 pid=400947) .b8 46
(EngineCore_DP0 pid=400947) .b8 112
(EngineCore_DP0 pid=400947) .b8 121
(EngineCore_DP0 pid=400947) .b8 0
(EngineCore_DP0 pid=400947) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=400947) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=400947) .b8 114
(EngineCore_DP0 pid=400947) .b8 111
(EngineCore_DP0 pid=400947) .b8 111
(EngineCore_DP0 pid=400947) .b8 116
(EngineCore_DP0 pid=400947) .b8 47
(EngineCore_DP0 pid=400947) .b8 118
(EngineCore_DP0 pid=400947) .b8 108
(EngineCore_DP0 pid=400947) .b8 108
(EngineCore_DP0 pid=400947) .b8 109
(EngineCore_DP0 pid=400947) .b8 98
(EngineCore_DP0 pid=400947) .b8 101
(EngineCore_DP0 pid=400947) .b8 110
(EngineCore_DP0 pid=400947) .b8 99
(EngineCore_DP0 pid=400947) .b8 104
(EngineCore_DP0 pid=400947) .b8 47
(EngineCore_DP0 pid=400947) .b8 115
(EngineCore_DP0 pid=400947) .b8 108
(EngineCore_DP0 pid=400947) .b8 105
(EngineCore_DP0 pid=400947) .b8 100
(EngineCore_DP0 pid=400947) .b8 101
(EngineCore_DP0 pid=400947) .b8 115
(EngineCore_DP0 pid=400947) .b8 112
(EngineCore_DP0 pid=400947) .b8 97
(EngineCore_DP0 pid=400947) .b8 114
(EngineCore_DP0 pid=400947) .b8 115
(EngineCore_DP0 pid=400947) .b8 101
(EngineCore_DP0 pid=400947) .b8 47
(EngineCore_DP0 pid=400947) .b8 99
(EngineCore_DP0 pid=400947) .b8 115
(EngineCore_DP0 pid=400947) .b8 114
(EngineCore_DP0 pid=400947) .b8 99
(EngineCore_DP0 pid=400947) .b8 47
(EngineCore_DP0 pid=400947) .b8 102
(EngineCore_DP0 pid=400947) .b8 117
(EngineCore_DP0 pid=400947) .b8 115
(EngineCore_DP0 pid=400947) .b8 101
(EngineCore_DP0 pid=400947) .b8 100
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 113
(EngineCore_DP0 pid=400947) .b8 117
(EngineCore_DP0 pid=400947) .b8 97
(EngineCore_DP0 pid=400947) .b8 110
(EngineCore_DP0 pid=400947) .b8 116
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 115
(EngineCore_DP0 pid=400947) .b8 108
(EngineCore_DP0 pid=400947) .b8 105
(EngineCore_DP0 pid=400947) .b8 100
(EngineCore_DP0 pid=400947) .b8 101
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 116
(EngineCore_DP0 pid=400947) .b8 114
(EngineCore_DP0 pid=400947) .b8 105
(EngineCore_DP0 pid=400947) .b8 116
(EngineCore_DP0 pid=400947) .b8 111
(EngineCore_DP0 pid=400947) .b8 110
(EngineCore_DP0 pid=400947) .b8 47
(EngineCore_DP0 pid=400947) .b8 98
(EngineCore_DP0 pid=400947) .b8 117
(EngineCore_DP0 pid=400947) .b8 105
(EngineCore_DP0 pid=400947) .b8 108
(EngineCore_DP0 pid=400947) .b8 100
(EngineCore_DP0 pid=400947) .b8 47
(EngineCore_DP0 pid=400947) .b8 71
(EngineCore_DP0 pid=400947) .b8 66
(EngineCore_DP0 pid=400947) .b8 49
(EngineCore_DP0 pid=400947) .b8 48
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 99
(EngineCore_DP0 pid=400947) .b8 99
(EngineCore_DP0 pid=400947) .b8 49
(EngineCore_DP0 pid=400947) .b8 50
(EngineCore_DP0 pid=400947) .b8 49
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 112
(EngineCore_DP0 pid=400947) .b8 121
(EngineCore_DP0 pid=400947) .b8 51
(EngineCore_DP0 pid=400947) .b8 49
(EngineCore_DP0 pid=400947) .b8 50
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 99
(EngineCore_DP0 pid=400947) .b8 117
(EngineCore_DP0 pid=400947) .b8 49
(EngineCore_DP0 pid=400947) .b8 50
(EngineCore_DP0 pid=400947) .b8 57
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 97
(EngineCore_DP0 pid=400947) .b8 97
(EngineCore_DP0 pid=400947) .b8 114
(EngineCore_DP0 pid=400947) .b8 99
(EngineCore_DP0 pid=400947) .b8 104
(EngineCore_DP0 pid=400947) .b8 54
(EngineCore_DP0 pid=400947) .b8 52
(EngineCore_DP0 pid=400947) .b8 0
(EngineCore_DP0 pid=400947) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=400947) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=400947) .b8 113
(EngineCore_DP0 pid=400947) .b8 117
(EngineCore_DP0 pid=400947) .b8 97
(EngineCore_DP0 pid=400947) .b8 110
(EngineCore_DP0 pid=400947) .b8 116
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 115
(EngineCore_DP0 pid=400947) .b8 108
(EngineCore_DP0 pid=400947) .b8 105
(EngineCore_DP0 pid=400947) .b8 100
(EngineCore_DP0 pid=400947) .b8 101
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 102
(EngineCore_DP0 pid=400947) .b8 112
(EngineCore_DP0 pid=400947) .b8 56
(EngineCore_DP0 pid=400947) .b8 95
(EngineCore_DP0 pid=400947) .b8 107
(EngineCore_DP0 pid=400947) .b8 101
(EngineCore_DP0 pid=400947) .b8 114
(EngineCore_DP0 pid=400947) .b8 110
(EngineCore_DP0 pid=400947) .b8 101
(EngineCore_DP0 pid=400947) .b8 108
(EngineCore_DP0 pid=400947) .b8 0
(EngineCore_DP0 pid=400947) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=400947) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=400947) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=400947) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=400947) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=400947) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=400947) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=400947) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=400947) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=400947) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=400947) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=400947) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=400947) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=400947) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=400947) 	}
(EngineCore_DP0 pid=400947) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) ================================================================
(EngineCore_DP0 pid=400947) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpzq757_ww.ptx', '-o', '/tmp/tmpzq757_ww.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] 
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] 
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] 
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpzq757_ww.ptx -o /tmp/tmpzq757_ww.ptx.o
(EngineCore_DP0 pid=400947) ERROR 01-25 20:12:24 [core.py:866] 

STDERR:
[2026-01-25 20:11:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:11:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:11:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:11:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:11:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:11:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:11:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:11:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:11:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:11:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:11:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:11:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:11:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:11:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:11:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:11:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:11:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:11:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:11:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=400947) [2026-01-25 20:11:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=400947) [2026-01-25 20:11:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=400947) [2026-01-25 20:11:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=400947) [2026-01-25 20:11:59] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=400947) [2026-01-25 20:11:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=400947) [2026-01-25 20:11:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=400947) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=400947) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.45s/it]
(EngineCore_DP0 pid=400947) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.45s/it]
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) [2026-01-25 20:12:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=400947) [2026-01-25 20:12:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=400947) [2026-01-25 20:12:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=400947) [2026-01-25 20:12:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=400947) [2026-01-25 20:12:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=400947) [2026-01-25 20:12:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=400947) [2026-01-25 20:12:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=400947) [2026-01-25 20:12:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=400947) Process EngineCore_DP0:
(EngineCore_DP0 pid=400947) Traceback (most recent call last):
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=400947)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=400947)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=400947)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=400947) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpzq757_ww.ptx', '-o', '/tmp/tmpzq757_ww.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) Traceback (most recent call last):
(EngineCore_DP0 pid=400947)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=400947)     self.run()
(EngineCore_DP0 pid=400947)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=400947)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=400947)     raise e
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=400947)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=400947)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=400947)     super().__init__(
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=400947)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=400947)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=400947)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=400947)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=400947)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=400947)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=400947)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=400947)     return func(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=400947)     return func(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=400947)     self.model_runner.profile_run()
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=400947)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=400947)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=400947)     return func(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=400947)     outputs = self.model(
(EngineCore_DP0 pid=400947)               ^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400947)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400947)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=400947)     model_output = self.model(
(EngineCore_DP0 pid=400947)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=400947)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=400947)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=400947)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400947)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400947)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=400947)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=400947)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400947)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400947)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=400947)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=400947)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=400947)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=400947)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=400947)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=400947)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=400947)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=400947)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=400947)     return self._linear_fn(
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=400947)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=400947)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=400947)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=400947)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=400947)     return fn(input, L)
(EngineCore_DP0 pid=400947)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=400947)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=400947)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=400947)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=400947)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=400947)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=400947)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=400947)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=400947)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=400947)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=400947)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=400947)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=400947)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=400947)     raise PTXASError(error)
(EngineCore_DP0 pid=400947) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=400947) `ptxas` stderr:
(EngineCore_DP0 pid=400947) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=400947) 
(EngineCore_DP0 pid=400947) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpzq757_ww.ptx -o /tmp/tmpzq757_ww.ptx.o
(EngineCore_DP0 pid=400947) 
[rank0]:[W125 20:12:25.496159897 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 20:12:26
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:12:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:12:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=401717) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) ================================================================
(EngineCore_DP0 pid=401717) Internal Triton PTX codegen error
(EngineCore_DP0 pid=401717) `ptxas` stderr:
(EngineCore_DP0 pid=401717) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpzz99ljph.ptx -o /tmp/tmpzz99ljph.ptx.o
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) //
(EngineCore_DP0 pid=401717) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=401717) //
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) .version 8.7
(EngineCore_DP0 pid=401717) .target sm_121a
(EngineCore_DP0 pid=401717) .address_size 64
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=401717) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=401717)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=401717) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=401717) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=401717) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=401717) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=401717) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=401717) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=401717) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=401717) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=401717) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=401717) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=401717) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=401717) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=401717) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=401717) )
(EngineCore_DP0 pid=401717) .reqntid 512
(EngineCore_DP0 pid=401717) {
(EngineCore_DP0 pid=401717) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=401717) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=401717) 	.reg .b32 	%r<161>;
(EngineCore_DP0 pid=401717) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=401717) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=401717) $L__func_begin0:
(EngineCore_DP0 pid=401717) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) // %bb.0:
(EngineCore_DP0 pid=401717) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=401717) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=401717) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=401717) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=401717) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=401717) $L__tmp0:
(EngineCore_DP0 pid=401717) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=401717) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=401717) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=401717) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=401717) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=401717) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=401717) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=401717) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=401717) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=401717) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=401717) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=401717) 	mov.b32 	%r159, 0f2B8CBCCC;
(EngineCore_DP0 pid=401717) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=401717) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=401717) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=401717) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=401717) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=401717) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=401717) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=401717) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=401717) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=401717) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=401717) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=401717) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=401717) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=401717) 	mov.b32 	%r157, 0f00000000;
(EngineCore_DP0 pid=401717) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=401717) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=401717) 	mov.b32 	%r158, %r45;
(EngineCore_DP0 pid=401717) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=401717) 	.loc	1 202 19                        // quant_slide_tuned_Llama3.2-3B.py:202:19
(EngineCore_DP0 pid=401717) 	add.s32 	%r63, %r4, %r158;
(EngineCore_DP0 pid=401717) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=401717) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=401717) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=401717) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=401717) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=401717) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=401717) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=401717) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=401717) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=401717) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=401717) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=401717) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=401717) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=401717) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=401717) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=401717) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=401717) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=401717) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=401717) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=401717) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=401717) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=401717) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=401717) $L__tmp1:
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	bar.sync 	0;
(EngineCore_DP0 pid=401717) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=401717) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=401717) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=401717) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=401717) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=401717) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=401717) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=401717) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	bar.sync 	0;
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=401717) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=401717) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=401717) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=401717) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=401717) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	bar.sync 	0;
(EngineCore_DP0 pid=401717) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=401717) $L__tmp2:
(EngineCore_DP0 pid=401717) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=401717) 	max.f32 	%r157, %r157, %r82;
(EngineCore_DP0 pid=401717) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=401717) 	add.s32 	%r158, %r158, 8192;
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p7, %r158, %r24;
(EngineCore_DP0 pid=401717) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=401717) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=401717) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=401717) 	max.f32 	%r159, %r157, 0f2B8CBCCC;
(EngineCore_DP0 pid=401717) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=401717) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=401717) 	mov.b32 	%r84, 0f43E00000;
(EngineCore_DP0 pid=401717) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=401717) 	div.full.f32 	%r85, %r159, %r84;
(EngineCore_DP0 pid=401717) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=401717) 	max.f32 	%r83, %r85, 0f36924925;
(EngineCore_DP0 pid=401717) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=401717) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=401717) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=401717) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=401717) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=401717) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=401717) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=401717) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=401717) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=401717) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=401717) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=401717) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=401717) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=401717) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=401717) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=401717) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=401717) 	div.full.f32 	%r14, %r84, %r159;
(EngineCore_DP0 pid=401717) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=401717) 	mov.b32 	%r160, 0;
(EngineCore_DP0 pid=401717) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=401717)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=401717) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=401717) 	add.s32 	%r98, %r16, %r160;
(EngineCore_DP0 pid=401717) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=401717) 	add.s32 	%r99, %r98, 1;
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p18, %r98, %r15;
(EngineCore_DP0 pid=401717) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=401717) 	mul.hi.s32 	%r100, %r99, 1431655766;
(EngineCore_DP0 pid=401717) 	shr.u32 	%r101, %r100, 31;
(EngineCore_DP0 pid=401717) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=401717) 	mul.hi.s32 	%r103, %r98, 1431655766;
(EngineCore_DP0 pid=401717) 	shr.u32 	%r104, %r103, 31;
(EngineCore_DP0 pid=401717) 	add.s32 	%r105, %r103, %r104;
(EngineCore_DP0 pid=401717) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=401717) 	mul.lo.s32 	%r106, %r105, 3;
(EngineCore_DP0 pid=401717) 	mul.lo.s32 	%r107, %r102, 3;
(EngineCore_DP0 pid=401717) 	sub.s32 	%r108, %r99, %r107;
(EngineCore_DP0 pid=401717) 	sub.s32 	%r109, %r98, %r106;
(EngineCore_DP0 pid=401717) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=401717) 	shl.b32 	%r110, %r105, 3;
(EngineCore_DP0 pid=401717) 	shl.b32 	%r111, %r102, 3;
(EngineCore_DP0 pid=401717) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=401717) 	shl.b32 	%r112, %r109, 1;
(EngineCore_DP0 pid=401717) 	shl.b32 	%r113, %r108, 1;
(EngineCore_DP0 pid=401717) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=401717) 	add.s32 	%r114, %r111, %r113;
(EngineCore_DP0 pid=401717) 	add.s32 	%r115, %r110, %r112;
(EngineCore_DP0 pid=401717) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p19, %r115, %r23;
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p20, %r114, %r23;
(EngineCore_DP0 pid=401717) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=401717) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=401717) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=401717) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=401717) 	mad.wide.s32 	%rd9, %r115, 2, %rd1;
(EngineCore_DP0 pid=401717) 	mad.wide.s32 	%rd10, %r114, 2, %rd1;
(EngineCore_DP0 pid=401717) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=401717) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=401717) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=401717) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=401717) 	cvt.f32.bf16 	%r116, %rs48;
(EngineCore_DP0 pid=401717) 	cvt.f32.bf16 	%r117, %rs50;
(EngineCore_DP0 pid=401717) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=401717) 	or.b32 	%r118, %r115, 1;
(EngineCore_DP0 pid=401717) 	or.b32 	%r119, %r114, 1;
(EngineCore_DP0 pid=401717) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p21, %r118, %r23;
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p22, %r119, %r23;
(EngineCore_DP0 pid=401717) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=401717) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=401717) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=401717) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=401717) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=401717) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=401717) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=401717) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=401717) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=401717) 	cvt.f32.bf16 	%r120, %rs52;
(EngineCore_DP0 pid=401717) 	cvt.f32.bf16 	%r121, %rs54;
(EngineCore_DP0 pid=401717) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=401717) 	add.s32 	%r122, %r115, 2;
(EngineCore_DP0 pid=401717) 	add.s32 	%r123, %r114, 2;
(EngineCore_DP0 pid=401717) 	add.s32 	%r124, %r115, 3;
(EngineCore_DP0 pid=401717) 	add.s32 	%r125, %r114, 3;
(EngineCore_DP0 pid=401717) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p23, %r125, %r23;
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p24, %r124, %r23;
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p25, %r123, %r23;
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p26, %r122, %r23;
(EngineCore_DP0 pid=401717) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=401717) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=401717) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=401717) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=401717) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=401717) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=401717) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=401717) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=401717) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=401717) 	cvt.f32.bf16 	%r126, %rs56;
(EngineCore_DP0 pid=401717) 	cvt.f32.bf16 	%r127, %rs58;
(EngineCore_DP0 pid=401717) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=401717) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=401717) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=401717) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=401717) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=401717) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=401717) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=401717) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=401717) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=401717) 	cvt.f32.bf16 	%r128, %rs60;
(EngineCore_DP0 pid=401717) 	cvt.f32.bf16 	%r129, %rs62;
(EngineCore_DP0 pid=401717) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=401717) 	mul.f32 	%r130, %r14, %r116;
(EngineCore_DP0 pid=401717) 	mul.f32 	%r131, %r14, %r117;
(EngineCore_DP0 pid=401717) 	mov.b32 	%r132, 0f43E00000;
(EngineCore_DP0 pid=401717) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=401717) 	min.xorsign.abs.f32 	%r87, %r130, %r132;
(EngineCore_DP0 pid=401717) 	min.xorsign.abs.f32 	%r88, %r131, %r132;
(EngineCore_DP0 pid=401717) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r88, %r87; 
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=401717) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=401717) 	mul.f32 	%r133, %r14, %r120;
(EngineCore_DP0 pid=401717) 	mul.f32 	%r134, %r14, %r121;
(EngineCore_DP0 pid=401717) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=401717) 	min.xorsign.abs.f32 	%r89, %r133, %r132;
(EngineCore_DP0 pid=401717) 	min.xorsign.abs.f32 	%r90, %r134, %r132;
(EngineCore_DP0 pid=401717) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r90, %r89; 
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=401717) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=401717) 	mul.f32 	%r135, %r14, %r126;
(EngineCore_DP0 pid=401717) 	mul.f32 	%r136, %r14, %r127;
(EngineCore_DP0 pid=401717) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=401717) 	min.xorsign.abs.f32 	%r91, %r135, %r132;
(EngineCore_DP0 pid=401717) 	min.xorsign.abs.f32 	%r92, %r136, %r132;
(EngineCore_DP0 pid=401717) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r92, %r91; 
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=401717) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=401717) 	mul.f32 	%r137, %r14, %r128;
(EngineCore_DP0 pid=401717) 	mul.f32 	%r138, %r14, %r129;
(EngineCore_DP0 pid=401717) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=401717) 	min.xorsign.abs.f32 	%r93, %r137, %r132;
(EngineCore_DP0 pid=401717) 	min.xorsign.abs.f32 	%r94, %r138, %r132;
(EngineCore_DP0 pid=401717) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r94, %r93; 
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=401717) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=401717) 	cvt.u32.u16 	%r139, %rs64;
(EngineCore_DP0 pid=401717) 	and.b32 	%r140, %r139, 255;
(EngineCore_DP0 pid=401717) 	cvt.u32.u16 	%r141, %rs68;
(EngineCore_DP0 pid=401717) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=401717) 	cvt.u32.u16 	%r142, %rs66;
(EngineCore_DP0 pid=401717) 	and.b32 	%r143, %r142, 255;
(EngineCore_DP0 pid=401717) 	cvt.u32.u16 	%r144, %rs70;
(EngineCore_DP0 pid=401717) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=401717) 	cvt.u32.u16 	%r145, %rs67;
(EngineCore_DP0 pid=401717) 	cvt.u32.u16 	%r146, %rs71;
(EngineCore_DP0 pid=401717) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=401717) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=401717) 	mul.wide.u16 	%r147, %rs72, 256;
(EngineCore_DP0 pid=401717) 	mul.wide.u16 	%r148, %rs69, 256;
(EngineCore_DP0 pid=401717) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=401717) 	or.b32 	%r149, %r147, %r140;
(EngineCore_DP0 pid=401717) 	or.b32 	%r150, %r148, %r141;
(EngineCore_DP0 pid=401717) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=401717) 	shl.b32 	%r151, %r143, 16;
(EngineCore_DP0 pid=401717) 	shl.b32 	%r152, %r144, 16;
(EngineCore_DP0 pid=401717) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=401717) 	or.b32 	%r153, %r149, %r151;
(EngineCore_DP0 pid=401717) 	or.b32 	%r154, %r150, %r152;
(EngineCore_DP0 pid=401717) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=401717) 	shl.b32 	%r155, %r145, 24;
(EngineCore_DP0 pid=401717) 	shl.b32 	%r156, %r146, 24;
(EngineCore_DP0 pid=401717) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=401717) 	or.b32 	%r95, %r153, %r155;
(EngineCore_DP0 pid=401717) 	or.b32 	%r96, %r154, %r156;
(EngineCore_DP0 pid=401717) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=401717) 	mad.wide.s32 	%rd17, %r98, 4, %rd2;
(EngineCore_DP0 pid=401717) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=401717) 	// begin inline asm
(EngineCore_DP0 pid=401717) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r95, %r96 };
(EngineCore_DP0 pid=401717) 	// end inline asm
(EngineCore_DP0 pid=401717) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=401717) 	add.s32 	%r160, %r160, 1024;
(EngineCore_DP0 pid=401717) 	setp.lt.s32 	%p27, %r160, %r15;
(EngineCore_DP0 pid=401717) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=401717) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=401717) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=401717) 	ret;
(EngineCore_DP0 pid=401717) $L__tmp3:
(EngineCore_DP0 pid=401717) $L__func_end0:
(EngineCore_DP0 pid=401717)                                         // -- End function
(EngineCore_DP0 pid=401717) }
(EngineCore_DP0 pid=401717) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=401717) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=401717) 	.section	.debug_abbrev
(EngineCore_DP0 pid=401717) 	{
(EngineCore_DP0 pid=401717) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=401717) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=401717) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=401717) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=401717) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=401717) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=401717) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=401717) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=401717) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=401717) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=401717) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=401717) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=401717) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=401717) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=401717) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=401717) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=401717) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=401717) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=401717) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=401717) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=401717) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=401717) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=401717) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=401717) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=401717) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=401717) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=401717) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=401717) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=401717) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=401717) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=401717) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=401717) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=401717) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=401717) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=401717) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=401717) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=401717) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=401717) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=401717) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=401717) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=401717) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=401717) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=401717) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=401717) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=401717) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=401717) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=401717) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=401717) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=401717) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=401717) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=401717) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=401717) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=401717) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=401717) 	}
(EngineCore_DP0 pid=401717) 	.section	.debug_info
(EngineCore_DP0 pid=401717) 	{
(EngineCore_DP0 pid=401717) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=401717) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=401717) .b8 0
(EngineCore_DP0 pid=401717) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=401717) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=401717) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=401717) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=401717) .b8 114
(EngineCore_DP0 pid=401717) .b8 105
(EngineCore_DP0 pid=401717) .b8 116
(EngineCore_DP0 pid=401717) .b8 111
(EngineCore_DP0 pid=401717) .b8 110
(EngineCore_DP0 pid=401717) .b8 0
(EngineCore_DP0 pid=401717) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=401717) .b8 0
(EngineCore_DP0 pid=401717) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=401717) .b8 117
(EngineCore_DP0 pid=401717) .b8 97
(EngineCore_DP0 pid=401717) .b8 110
(EngineCore_DP0 pid=401717) .b8 116
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 115
(EngineCore_DP0 pid=401717) .b8 108
(EngineCore_DP0 pid=401717) .b8 105
(EngineCore_DP0 pid=401717) .b8 100
(EngineCore_DP0 pid=401717) .b8 101
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 116
(EngineCore_DP0 pid=401717) .b8 117
(EngineCore_DP0 pid=401717) .b8 110
(EngineCore_DP0 pid=401717) .b8 101
(EngineCore_DP0 pid=401717) .b8 100
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 76
(EngineCore_DP0 pid=401717) .b8 108
(EngineCore_DP0 pid=401717) .b8 97
(EngineCore_DP0 pid=401717) .b8 109
(EngineCore_DP0 pid=401717) .b8 97
(EngineCore_DP0 pid=401717) .b8 51
(EngineCore_DP0 pid=401717) .b8 46
(EngineCore_DP0 pid=401717) .b8 50
(EngineCore_DP0 pid=401717) .b8 45
(EngineCore_DP0 pid=401717) .b8 51
(EngineCore_DP0 pid=401717) .b8 66
(EngineCore_DP0 pid=401717) .b8 46
(EngineCore_DP0 pid=401717) .b8 112
(EngineCore_DP0 pid=401717) .b8 121
(EngineCore_DP0 pid=401717) .b8 0
(EngineCore_DP0 pid=401717) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=401717) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=401717) .b8 114
(EngineCore_DP0 pid=401717) .b8 111
(EngineCore_DP0 pid=401717) .b8 111
(EngineCore_DP0 pid=401717) .b8 116
(EngineCore_DP0 pid=401717) .b8 47
(EngineCore_DP0 pid=401717) .b8 118
(EngineCore_DP0 pid=401717) .b8 108
(EngineCore_DP0 pid=401717) .b8 108
(EngineCore_DP0 pid=401717) .b8 109
(EngineCore_DP0 pid=401717) .b8 98
(EngineCore_DP0 pid=401717) .b8 101
(EngineCore_DP0 pid=401717) .b8 110
(EngineCore_DP0 pid=401717) .b8 99
(EngineCore_DP0 pid=401717) .b8 104
(EngineCore_DP0 pid=401717) .b8 47
(EngineCore_DP0 pid=401717) .b8 115
(EngineCore_DP0 pid=401717) .b8 108
(EngineCore_DP0 pid=401717) .b8 105
(EngineCore_DP0 pid=401717) .b8 100
(EngineCore_DP0 pid=401717) .b8 101
(EngineCore_DP0 pid=401717) .b8 115
(EngineCore_DP0 pid=401717) .b8 112
(EngineCore_DP0 pid=401717) .b8 97
(EngineCore_DP0 pid=401717) .b8 114
(EngineCore_DP0 pid=401717) .b8 115
(EngineCore_DP0 pid=401717) .b8 101
(EngineCore_DP0 pid=401717) .b8 47
(EngineCore_DP0 pid=401717) .b8 99
(EngineCore_DP0 pid=401717) .b8 115
(EngineCore_DP0 pid=401717) .b8 114
(EngineCore_DP0 pid=401717) .b8 99
(EngineCore_DP0 pid=401717) .b8 47
(EngineCore_DP0 pid=401717) .b8 102
(EngineCore_DP0 pid=401717) .b8 117
(EngineCore_DP0 pid=401717) .b8 115
(EngineCore_DP0 pid=401717) .b8 101
(EngineCore_DP0 pid=401717) .b8 100
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 113
(EngineCore_DP0 pid=401717) .b8 117
(EngineCore_DP0 pid=401717) .b8 97
(EngineCore_DP0 pid=401717) .b8 110
(EngineCore_DP0 pid=401717) .b8 116
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 115
(EngineCore_DP0 pid=401717) .b8 108
(EngineCore_DP0 pid=401717) .b8 105
(EngineCore_DP0 pid=401717) .b8 100
(EngineCore_DP0 pid=401717) .b8 101
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 116
(EngineCore_DP0 pid=401717) .b8 114
(EngineCore_DP0 pid=401717) .b8 105
(EngineCore_DP0 pid=401717) .b8 116
(EngineCore_DP0 pid=401717) .b8 111
(EngineCore_DP0 pid=401717) .b8 110
(EngineCore_DP0 pid=401717) .b8 47
(EngineCore_DP0 pid=401717) .b8 98
(EngineCore_DP0 pid=401717) .b8 117
(EngineCore_DP0 pid=401717) .b8 105
(EngineCore_DP0 pid=401717) .b8 108
(EngineCore_DP0 pid=401717) .b8 100
(EngineCore_DP0 pid=401717) .b8 47
(EngineCore_DP0 pid=401717) .b8 71
(EngineCore_DP0 pid=401717) .b8 66
(EngineCore_DP0 pid=401717) .b8 49
(EngineCore_DP0 pid=401717) .b8 48
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 99
(EngineCore_DP0 pid=401717) .b8 99
(EngineCore_DP0 pid=401717) .b8 49
(EngineCore_DP0 pid=401717) .b8 50
(EngineCore_DP0 pid=401717) .b8 49
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 112
(EngineCore_DP0 pid=401717) .b8 121
(EngineCore_DP0 pid=401717) .b8 51
(EngineCore_DP0 pid=401717) .b8 49
(EngineCore_DP0 pid=401717) .b8 50
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 99
(EngineCore_DP0 pid=401717) .b8 117
(EngineCore_DP0 pid=401717) .b8 49
(EngineCore_DP0 pid=401717) .b8 50
(EngineCore_DP0 pid=401717) .b8 57
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 97
(EngineCore_DP0 pid=401717) .b8 97
(EngineCore_DP0 pid=401717) .b8 114
(EngineCore_DP0 pid=401717) .b8 99
(EngineCore_DP0 pid=401717) .b8 104
(EngineCore_DP0 pid=401717) .b8 54
(EngineCore_DP0 pid=401717) .b8 52
(EngineCore_DP0 pid=401717) .b8 0
(EngineCore_DP0 pid=401717) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=401717) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=401717) .b8 113
(EngineCore_DP0 pid=401717) .b8 117
(EngineCore_DP0 pid=401717) .b8 97
(EngineCore_DP0 pid=401717) .b8 110
(EngineCore_DP0 pid=401717) .b8 116
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 115
(EngineCore_DP0 pid=401717) .b8 108
(EngineCore_DP0 pid=401717) .b8 105
(EngineCore_DP0 pid=401717) .b8 100
(EngineCore_DP0 pid=401717) .b8 101
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 102
(EngineCore_DP0 pid=401717) .b8 112
(EngineCore_DP0 pid=401717) .b8 56
(EngineCore_DP0 pid=401717) .b8 95
(EngineCore_DP0 pid=401717) .b8 107
(EngineCore_DP0 pid=401717) .b8 101
(EngineCore_DP0 pid=401717) .b8 114
(EngineCore_DP0 pid=401717) .b8 110
(EngineCore_DP0 pid=401717) .b8 101
(EngineCore_DP0 pid=401717) .b8 108
(EngineCore_DP0 pid=401717) .b8 0
(EngineCore_DP0 pid=401717) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=401717) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=401717) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=401717) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=401717) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=401717) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=401717) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=401717) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=401717) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=401717) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=401717) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=401717) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=401717) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=401717) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=401717) 	}
(EngineCore_DP0 pid=401717) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) ================================================================
(EngineCore_DP0 pid=401717) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpzz99ljph.ptx', '-o', '/tmp/tmpzz99ljph.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] 
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] 
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] 
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpzz99ljph.ptx -o /tmp/tmpzz99ljph.ptx.o
(EngineCore_DP0 pid=401717) ERROR 01-25 20:13:05 [core.py:866] 

STDERR:
[2026-01-25 20:12:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:12:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:12:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:12:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:12:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:12:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:12:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:12:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:12:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:12:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:12:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:12:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:12:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:12:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:12:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:12:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:12:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:12:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:12:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:12:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:12:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:12:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:12:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:12:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:12:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:12:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:12:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:12:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=401717) [2026-01-25 20:12:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=401717) [2026-01-25 20:12:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=401717) [2026-01-25 20:12:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=401717) [2026-01-25 20:12:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=401717) [2026-01-25 20:12:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=401717) [2026-01-25 20:12:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=401717) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=401717) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.18s/it]
(EngineCore_DP0 pid=401717) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.18s/it]
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) [2026-01-25 20:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=401717) [2026-01-25 20:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=401717) [2026-01-25 20:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=401717) [2026-01-25 20:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=401717) [2026-01-25 20:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=401717) [2026-01-25 20:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=401717) [2026-01-25 20:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=401717) [2026-01-25 20:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=401717) Process EngineCore_DP0:
(EngineCore_DP0 pid=401717) Traceback (most recent call last):
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=401717)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=401717)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=401717)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=401717) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpzz99ljph.ptx', '-o', '/tmp/tmpzz99ljph.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) Traceback (most recent call last):
(EngineCore_DP0 pid=401717)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=401717)     self.run()
(EngineCore_DP0 pid=401717)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=401717)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=401717)     raise e
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=401717)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=401717)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=401717)     super().__init__(
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=401717)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=401717)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=401717)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=401717)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=401717)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=401717)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=401717)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=401717)     return func(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=401717)     return func(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=401717)     self.model_runner.profile_run()
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=401717)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=401717)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=401717)     return func(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=401717)     outputs = self.model(
(EngineCore_DP0 pid=401717)               ^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=401717)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=401717)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=401717)     model_output = self.model(
(EngineCore_DP0 pid=401717)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=401717)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=401717)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=401717)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=401717)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=401717)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=401717)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=401717)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=401717)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=401717)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=401717)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=401717)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=401717)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=401717)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=401717)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=401717)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=401717)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=401717)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=401717)     return self._linear_fn(
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=401717)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=401717)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=401717)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=401717)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=401717)     return fn(input, L)
(EngineCore_DP0 pid=401717)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=401717)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=401717)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=401717)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=401717)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=401717)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=401717)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=401717)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=401717)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=401717)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=401717)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=401717)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=401717)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=401717)     raise PTXASError(error)
(EngineCore_DP0 pid=401717) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=401717) `ptxas` stderr:
(EngineCore_DP0 pid=401717) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=401717) 
(EngineCore_DP0 pid=401717) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpzz99ljph.ptx -o /tmp/tmpzz99ljph.ptx.o
(EngineCore_DP0 pid=401717) 
[rank0]:[W125 20:13:06.293020224 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 20:13:07
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:13:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:13:22 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=402555) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) ================================================================
(EngineCore_DP0 pid=402555) Internal Triton PTX codegen error
(EngineCore_DP0 pid=402555) `ptxas` stderr:
(EngineCore_DP0 pid=402555) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnuw5ptz4.ptx -o /tmp/tmpnuw5ptz4.ptx.o
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) //
(EngineCore_DP0 pid=402555) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=402555) //
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) .version 8.7
(EngineCore_DP0 pid=402555) .target sm_121a
(EngineCore_DP0 pid=402555) .address_size 64
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=402555) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=402555)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=402555) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=402555) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=402555) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=402555) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=402555) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=402555) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=402555) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=402555) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=402555) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=402555) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=402555) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=402555) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=402555) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=402555) )
(EngineCore_DP0 pid=402555) .reqntid 512
(EngineCore_DP0 pid=402555) {
(EngineCore_DP0 pid=402555) 	.reg .pred 	%p<44>;
(EngineCore_DP0 pid=402555) 	.reg .b16 	%rs<74>;
(EngineCore_DP0 pid=402555) 	.reg .b32 	%r<224>;
(EngineCore_DP0 pid=402555) 	.reg .b64 	%rd<25>;
(EngineCore_DP0 pid=402555) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=402555) $L__func_begin0:
(EngineCore_DP0 pid=402555) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) // %bb.0:
(EngineCore_DP0 pid=402555) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=402555) 	ld.param.b32 	%r28, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=402555) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=402555) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=402555) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=402555) $L__tmp0:
(EngineCore_DP0 pid=402555) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=402555) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=402555) 	ld.param.b32 	%r31, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=402555) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=402555) 	mul.lo.s32 	%r32, %r31, %r1;
(EngineCore_DP0 pid=402555) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=402555) 	mad.wide.s32 	%rd1, %r32, 2, %rd4;
(EngineCore_DP0 pid=402555) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=402555) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=402555) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=402555) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p1, %r28, 1;
(EngineCore_DP0 pid=402555) 	mov.b32 	%r222, 0f2B8CBCCC;
(EngineCore_DP0 pid=402555) 	setp.eq.b32 	%p43, %r2, 0;
(EngineCore_DP0 pid=402555) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=402555) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=402555) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=402555) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=402555) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=402555) 	shr.u32 	%r41, %r2, 3;
(EngineCore_DP0 pid=402555) 	and.b32 	%r42, %r41, 60;
(EngineCore_DP0 pid=402555) 	mov.b32 	%r43, global_smem;
(EngineCore_DP0 pid=402555) 	add.s32 	%r53, %r43, %r42;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r44, %r2, 2;
(EngineCore_DP0 pid=402555) 	add.s32 	%r56, %r43, %r44;
(EngineCore_DP0 pid=402555) 	mov.b32 	%r49, 0;
(EngineCore_DP0 pid=402555) 	mov.b32 	%r220, 0f00000000;
(EngineCore_DP0 pid=402555) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=402555) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=402555) 	mov.b32 	%r221, %r49;
(EngineCore_DP0 pid=402555) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=402555) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=402555) 	add.s32 	%r59, %r4, %r221;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p2, %r59, %r27;
(EngineCore_DP0 pid=402555) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=402555) 	mad.wide.s32 	%rd6, %r59, 2, %rd1;
(EngineCore_DP0 pid=402555) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u32 %r45, %r49;
(EngineCore_DP0 pid=402555) 	mov.u32 %r46, %r49;
(EngineCore_DP0 pid=402555) 	mov.u32 %r47, %r49;
(EngineCore_DP0 pid=402555) 	mov.u32 %r48, %r49;
(EngineCore_DP0 pid=402555) 	@%p2 ld.global.v4.b32 { %r45, %r46, %r47, %r48 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	mov.b32 	{%rs1, %rs2}, %r45;
(EngineCore_DP0 pid=402555) 	mov.b32 	{%rs3, %rs4}, %r46;
(EngineCore_DP0 pid=402555) 	mov.b32 	{%rs5, %rs6}, %r47;
(EngineCore_DP0 pid=402555) 	mov.b32 	{%rs7, %rs8}, %r48;
(EngineCore_DP0 pid=402555) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=402555) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=402555) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=402555) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=402555) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=402555) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=402555) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=402555) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=402555) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=402555) $L__tmp1:
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	bar.sync 	0;
(EngineCore_DP0 pid=402555) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=402555) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=402555) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=402555) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=402555) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=402555) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=402555) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r60, %rs23;
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=402555) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=402555) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=402555) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=402555) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=402555) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	max.f32 	%r54, %r68, %r69;
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	@%p3 st.shared.b32 [ %r53 + 0 ], %r54;
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	bar.sync 	0;
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	@%p4 ld.shared.b32 %r55, [ %r56 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	shfl.sync.bfly.b32 	%r70, %r55, 8, 31, -1;
(EngineCore_DP0 pid=402555) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	max.f32 	%r71, %r55, %r70;
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=402555) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=402555) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=402555) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	max.f32 	%r58, %r75, %r76;
(EngineCore_DP0 pid=402555) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	@%p43 st.shared.b32 [ %r56 + 0 ], %r58;
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	bar.sync 	0;
(EngineCore_DP0 pid=402555) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=402555) $L__tmp2:
(EngineCore_DP0 pid=402555) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=402555) 	max.f32 	%r220, %r220, %r77;
(EngineCore_DP0 pid=402555) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=402555) 	add.s32 	%r221, %r221, 4096;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p6, %r221, %r28;
(EngineCore_DP0 pid=402555) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=402555) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=402555) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=402555) 	max.f32 	%r222, %r220, 0f2B8CBCCC;
(EngineCore_DP0 pid=402555) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=402555) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=402555) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=402555) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=402555) 	div.full.f32 	%r80, %r222, %r79;
(EngineCore_DP0 pid=402555) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=402555) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=402555) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=402555) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=402555) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	@%p43 st.global.b32 [ %rd7 + 0 ], { %r78 };
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=402555) 	mul.lo.s32 	%r15, %r29, 3;
(EngineCore_DP0 pid=402555) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=402555) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=402555) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=402555) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=402555) 	ld.param.b32 	%r33, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=402555) 	shr.s32 	%r34, %r33, 31;
(EngineCore_DP0 pid=402555) 	shr.u32 	%r35, %r34, 30;
(EngineCore_DP0 pid=402555) 	add.s32 	%r36, %r33, %r35;
(EngineCore_DP0 pid=402555) 	shr.s32 	%r37, %r36, 2;
(EngineCore_DP0 pid=402555) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=402555) 	mul.lo.s32 	%r38, %r37, %r1;
(EngineCore_DP0 pid=402555) 	mad.wide.s32 	%rd2, %r38, 4, %rd5;
(EngineCore_DP0 pid=402555) 	div.full.f32 	%r14, %r79, %r222;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r16, %r3, 2;
(EngineCore_DP0 pid=402555) 	mov.b32 	%r223, 0;
(EngineCore_DP0 pid=402555) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=402555)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=402555) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=402555) 	add.s32 	%r103, %r16, %r223;
(EngineCore_DP0 pid=402555) 	add.s32 	%r104, %r103, 1;
(EngineCore_DP0 pid=402555) 	add.s32 	%r105, %r103, 2;
(EngineCore_DP0 pid=402555) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=402555) 	add.s32 	%r106, %r103, 3;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p25, %r103, %r15;
(EngineCore_DP0 pid=402555) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=402555) 	mul.hi.s32 	%r107, %r106, 1431655766;
(EngineCore_DP0 pid=402555) 	shr.u32 	%r108, %r107, 31;
(EngineCore_DP0 pid=402555) 	add.s32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=402555) 	mul.hi.s32 	%r110, %r105, 1431655766;
(EngineCore_DP0 pid=402555) 	shr.u32 	%r111, %r110, 31;
(EngineCore_DP0 pid=402555) 	add.s32 	%r112, %r110, %r111;
(EngineCore_DP0 pid=402555) 	mul.hi.s32 	%r113, %r104, 1431655766;
(EngineCore_DP0 pid=402555) 	shr.u32 	%r114, %r113, 31;
(EngineCore_DP0 pid=402555) 	add.s32 	%r115, %r113, %r114;
(EngineCore_DP0 pid=402555) 	mul.hi.s32 	%r116, %r103, 1431655766;
(EngineCore_DP0 pid=402555) 	shr.u32 	%r117, %r116, 31;
(EngineCore_DP0 pid=402555) 	add.s32 	%r118, %r116, %r117;
(EngineCore_DP0 pid=402555) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=402555) 	mul.lo.s32 	%r119, %r118, 3;
(EngineCore_DP0 pid=402555) 	mul.lo.s32 	%r120, %r115, 3;
(EngineCore_DP0 pid=402555) 	mul.lo.s32 	%r121, %r112, 3;
(EngineCore_DP0 pid=402555) 	mul.lo.s32 	%r122, %r109, 3;
(EngineCore_DP0 pid=402555) 	sub.s32 	%r123, %r106, %r122;
(EngineCore_DP0 pid=402555) 	sub.s32 	%r124, %r105, %r121;
(EngineCore_DP0 pid=402555) 	sub.s32 	%r125, %r104, %r120;
(EngineCore_DP0 pid=402555) 	sub.s32 	%r126, %r103, %r119;
(EngineCore_DP0 pid=402555) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=402555) 	shl.b32 	%r127, %r118, 3;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r128, %r115, 3;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r129, %r112, 3;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r130, %r109, 3;
(EngineCore_DP0 pid=402555) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=402555) 	shl.b32 	%r131, %r126, 1;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r132, %r125, 1;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r133, %r124, 1;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r134, %r123, 1;
(EngineCore_DP0 pid=402555) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=402555) 	add.s32 	%r135, %r130, %r134;
(EngineCore_DP0 pid=402555) 	add.s32 	%r136, %r129, %r133;
(EngineCore_DP0 pid=402555) 	add.s32 	%r137, %r128, %r132;
(EngineCore_DP0 pid=402555) 	add.s32 	%r138, %r127, %r131;
(EngineCore_DP0 pid=402555) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p26, %r138, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p27, %r137, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p28, %r136, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p29, %r135, %r27;
(EngineCore_DP0 pid=402555) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=402555) 	and.pred 	%p9, %p25, %p26;
(EngineCore_DP0 pid=402555) 	and.pred 	%p10, %p25, %p27;
(EngineCore_DP0 pid=402555) 	and.pred 	%p11, %p25, %p28;
(EngineCore_DP0 pid=402555) 	and.pred 	%p12, %p25, %p29;
(EngineCore_DP0 pid=402555) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=402555) 	mad.wide.s32 	%rd8, %r138, 2, %rd1;
(EngineCore_DP0 pid=402555) 	mad.wide.s32 	%rd9, %r137, 2, %rd1;
(EngineCore_DP0 pid=402555) 	mad.wide.s32 	%rd10, %r136, 2, %rd1;
(EngineCore_DP0 pid=402555) 	mad.wide.s32 	%rd11, %r135, 2, %rd1;
(EngineCore_DP0 pid=402555) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=402555) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=402555) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=402555) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=402555) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=402555) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r139, %rs24;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r140, %rs26;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r141, %rs28;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r142, %rs30;
(EngineCore_DP0 pid=402555) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=402555) 	or.b32 	%r143, %r138, 1;
(EngineCore_DP0 pid=402555) 	or.b32 	%r144, %r137, 1;
(EngineCore_DP0 pid=402555) 	or.b32 	%r145, %r136, 1;
(EngineCore_DP0 pid=402555) 	or.b32 	%r146, %r135, 1;
(EngineCore_DP0 pid=402555) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p30, %r143, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p31, %r144, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p32, %r145, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p33, %r146, %r27;
(EngineCore_DP0 pid=402555) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=402555) 	and.pred 	%p13, %p25, %p30;
(EngineCore_DP0 pid=402555) 	and.pred 	%p14, %p25, %p31;
(EngineCore_DP0 pid=402555) 	and.pred 	%p15, %p25, %p32;
(EngineCore_DP0 pid=402555) 	and.pred 	%p16, %p25, %p33;
(EngineCore_DP0 pid=402555) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=402555) 	add.s64 	%rd12, %rd8, 2;
(EngineCore_DP0 pid=402555) 	add.s64 	%rd13, %rd9, 2;
(EngineCore_DP0 pid=402555) 	add.s64 	%rd14, %rd10, 2;
(EngineCore_DP0 pid=402555) 	add.s64 	%rd15, %rd11, 2;
(EngineCore_DP0 pid=402555) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=402555) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=402555) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=402555) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=402555) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r147, %rs32;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r148, %rs34;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r149, %rs36;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r150, %rs38;
(EngineCore_DP0 pid=402555) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=402555) 	add.s32 	%r151, %r138, 2;
(EngineCore_DP0 pid=402555) 	add.s32 	%r152, %r137, 2;
(EngineCore_DP0 pid=402555) 	add.s32 	%r153, %r136, 2;
(EngineCore_DP0 pid=402555) 	add.s32 	%r154, %r135, 2;
(EngineCore_DP0 pid=402555) 	add.s32 	%r155, %r138, 3;
(EngineCore_DP0 pid=402555) 	add.s32 	%r156, %r137, 3;
(EngineCore_DP0 pid=402555) 	add.s32 	%r157, %r136, 3;
(EngineCore_DP0 pid=402555) 	add.s32 	%r158, %r135, 3;
(EngineCore_DP0 pid=402555) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p34, %r158, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p35, %r157, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p36, %r156, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p37, %r155, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p38, %r154, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p39, %r153, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p40, %r152, %r27;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p41, %r151, %r27;
(EngineCore_DP0 pid=402555) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=402555) 	and.pred 	%p17, %p25, %p41;
(EngineCore_DP0 pid=402555) 	and.pred 	%p18, %p25, %p40;
(EngineCore_DP0 pid=402555) 	and.pred 	%p19, %p25, %p39;
(EngineCore_DP0 pid=402555) 	and.pred 	%p20, %p25, %p38;
(EngineCore_DP0 pid=402555) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=402555) 	add.s64 	%rd16, %rd8, 4;
(EngineCore_DP0 pid=402555) 	add.s64 	%rd17, %rd9, 4;
(EngineCore_DP0 pid=402555) 	add.s64 	%rd18, %rd10, 4;
(EngineCore_DP0 pid=402555) 	add.s64 	%rd19, %rd11, 4;
(EngineCore_DP0 pid=402555) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs40, %rs25;
(EngineCore_DP0 pid=402555) 	@%p17 ld.global.b16 { %rs40 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs42, %rs25;
(EngineCore_DP0 pid=402555) 	@%p18 ld.global.b16 { %rs42 }, [ %rd17 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs44, %rs25;
(EngineCore_DP0 pid=402555) 	@%p19 ld.global.b16 { %rs44 }, [ %rd18 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs46, %rs25;
(EngineCore_DP0 pid=402555) 	@%p20 ld.global.b16 { %rs46 }, [ %rd19 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r159, %rs40;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r160, %rs42;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r161, %rs44;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r162, %rs46;
(EngineCore_DP0 pid=402555) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=402555) 	and.pred 	%p21, %p25, %p37;
(EngineCore_DP0 pid=402555) 	and.pred 	%p22, %p25, %p36;
(EngineCore_DP0 pid=402555) 	and.pred 	%p23, %p25, %p35;
(EngineCore_DP0 pid=402555) 	and.pred 	%p24, %p25, %p34;
(EngineCore_DP0 pid=402555) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=402555) 	add.s64 	%rd20, %rd8, 6;
(EngineCore_DP0 pid=402555) 	add.s64 	%rd21, %rd9, 6;
(EngineCore_DP0 pid=402555) 	add.s64 	%rd22, %rd10, 6;
(EngineCore_DP0 pid=402555) 	add.s64 	%rd23, %rd11, 6;
(EngineCore_DP0 pid=402555) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs48, %rs25;
(EngineCore_DP0 pid=402555) 	@%p21 ld.global.b16 { %rs48 }, [ %rd20 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs50, %rs25;
(EngineCore_DP0 pid=402555) 	@%p22 ld.global.b16 { %rs50 }, [ %rd21 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs52, %rs25;
(EngineCore_DP0 pid=402555) 	@%p23 ld.global.b16 { %rs52 }, [ %rd22 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	mov.u16 %rs54, %rs25;
(EngineCore_DP0 pid=402555) 	@%p24 ld.global.b16 { %rs54 }, [ %rd23 + 0 ];
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r163, %rs48;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r164, %rs50;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r165, %rs52;
(EngineCore_DP0 pid=402555) 	cvt.f32.bf16 	%r166, %rs54;
(EngineCore_DP0 pid=402555) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=402555) 	mul.f32 	%r167, %r14, %r139;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r168, %r14, %r140;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r169, %r14, %r141;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r170, %r14, %r142;
(EngineCore_DP0 pid=402555) 	mov.b32 	%r171, 0f43E00000;
(EngineCore_DP0 pid=402555) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r82, %r167, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r83, %r168, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r84, %r169, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r85, %r170, %r171;
(EngineCore_DP0 pid=402555) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	shr.u16 	%rs64, %rs56, 8;
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	shr.u16 	%rs65, %rs57, 8;
(EngineCore_DP0 pid=402555) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=402555) 	mul.f32 	%r172, %r14, %r147;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r173, %r14, %r148;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r174, %r14, %r149;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r175, %r14, %r150;
(EngineCore_DP0 pid=402555) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r86, %r172, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r87, %r173, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r88, %r174, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r89, %r175, %r171;
(EngineCore_DP0 pid=402555) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	shr.u16 	%rs66, %rs58, 8;
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	shr.u16 	%rs67, %rs59, 8;
(EngineCore_DP0 pid=402555) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=402555) 	mul.f32 	%r176, %r14, %r159;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r177, %r14, %r160;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r178, %r14, %r161;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r179, %r14, %r162;
(EngineCore_DP0 pid=402555) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r90, %r176, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r91, %r177, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r92, %r178, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r93, %r179, %r171;
(EngineCore_DP0 pid=402555) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	cvt.rn.satfinite.e4m3x2.f32  %rs60, %r91, %r90; 
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	shr.u16 	%rs68, %rs60, 8;
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	cvt.rn.satfinite.e4m3x2.f32  %rs61, %r93, %r92; 
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	shr.u16 	%rs69, %rs61, 8;
(EngineCore_DP0 pid=402555) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=402555) 	mul.f32 	%r180, %r14, %r163;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r181, %r14, %r164;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r182, %r14, %r165;
(EngineCore_DP0 pid=402555) 	mul.f32 	%r183, %r14, %r166;
(EngineCore_DP0 pid=402555) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r94, %r180, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r95, %r181, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r96, %r182, %r171;
(EngineCore_DP0 pid=402555) 	min.xorsign.abs.f32 	%r97, %r183, %r171;
(EngineCore_DP0 pid=402555) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	cvt.rn.satfinite.e4m3x2.f32  %rs62, %r95, %r94; 
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	shr.u16 	%rs70, %rs62, 8;
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	cvt.rn.satfinite.e4m3x2.f32  %rs63, %r97, %r96; 
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	shr.u16 	%rs71, %rs63, 8;
(EngineCore_DP0 pid=402555) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r184, %rs56;
(EngineCore_DP0 pid=402555) 	and.b32 	%r185, %r184, 255;
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r186, %rs64;
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r187, %rs57;
(EngineCore_DP0 pid=402555) 	and.b32 	%r188, %r187, 255;
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r189, %rs65;
(EngineCore_DP0 pid=402555) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r190, %rs60;
(EngineCore_DP0 pid=402555) 	and.b32 	%r191, %r190, 255;
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r192, %rs68;
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r193, %rs61;
(EngineCore_DP0 pid=402555) 	and.b32 	%r194, %r193, 255;
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r195, %rs69;
(EngineCore_DP0 pid=402555) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r196, %rs62;
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r197, %rs70;
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r198, %rs63;
(EngineCore_DP0 pid=402555) 	cvt.u32.u16 	%r199, %rs71;
(EngineCore_DP0 pid=402555) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=402555) 	and.b16 	%rs72, %rs58, 255;
(EngineCore_DP0 pid=402555) 	mul.wide.u16 	%r200, %rs72, 256;
(EngineCore_DP0 pid=402555) 	mul.wide.u16 	%r201, %rs66, 256;
(EngineCore_DP0 pid=402555) 	and.b16 	%rs73, %rs59, 255;
(EngineCore_DP0 pid=402555) 	mul.wide.u16 	%r202, %rs73, 256;
(EngineCore_DP0 pid=402555) 	mul.wide.u16 	%r203, %rs67, 256;
(EngineCore_DP0 pid=402555) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=402555) 	or.b32 	%r204, %r200, %r185;
(EngineCore_DP0 pid=402555) 	or.b32 	%r205, %r201, %r186;
(EngineCore_DP0 pid=402555) 	or.b32 	%r206, %r202, %r188;
(EngineCore_DP0 pid=402555) 	or.b32 	%r207, %r203, %r189;
(EngineCore_DP0 pid=402555) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=402555) 	shl.b32 	%r208, %r191, 16;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r209, %r192, 16;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r210, %r194, 16;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r211, %r195, 16;
(EngineCore_DP0 pid=402555) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=402555) 	or.b32 	%r212, %r208, %r204;
(EngineCore_DP0 pid=402555) 	or.b32 	%r213, %r209, %r205;
(EngineCore_DP0 pid=402555) 	or.b32 	%r214, %r210, %r206;
(EngineCore_DP0 pid=402555) 	or.b32 	%r215, %r211, %r207;
(EngineCore_DP0 pid=402555) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=402555) 	shl.b32 	%r216, %r196, 24;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r217, %r197, 24;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r218, %r198, 24;
(EngineCore_DP0 pid=402555) 	shl.b32 	%r219, %r199, 24;
(EngineCore_DP0 pid=402555) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=402555) 	or.b32 	%r98, %r216, %r212;
(EngineCore_DP0 pid=402555) 	or.b32 	%r99, %r217, %r213;
(EngineCore_DP0 pid=402555) 	or.b32 	%r100, %r218, %r214;
(EngineCore_DP0 pid=402555) 	or.b32 	%r101, %r219, %r215;
(EngineCore_DP0 pid=402555) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=402555) 	mad.wide.s32 	%rd24, %r103, 4, %rd2;
(EngineCore_DP0 pid=402555) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=402555) 	// begin inline asm
(EngineCore_DP0 pid=402555) 	@%p25 st.global.v4.b32 [ %rd24 + 0 ], { %r98, %r99, %r100, %r101 };
(EngineCore_DP0 pid=402555) 	// end inline asm
(EngineCore_DP0 pid=402555) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=402555) 	add.s32 	%r223, %r223, 2048;
(EngineCore_DP0 pid=402555) 	setp.lt.s32 	%p42, %r223, %r15;
(EngineCore_DP0 pid=402555) 	@%p42 bra 	$L__BB0_6;
(EngineCore_DP0 pid=402555) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=402555) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=402555) 	ret;
(EngineCore_DP0 pid=402555) $L__tmp3:
(EngineCore_DP0 pid=402555) $L__func_end0:
(EngineCore_DP0 pid=402555)                                         // -- End function
(EngineCore_DP0 pid=402555) }
(EngineCore_DP0 pid=402555) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=402555) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=402555) 	.section	.debug_abbrev
(EngineCore_DP0 pid=402555) 	{
(EngineCore_DP0 pid=402555) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=402555) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=402555) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=402555) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=402555) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=402555) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=402555) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=402555) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=402555) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=402555) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=402555) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=402555) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=402555) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=402555) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=402555) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=402555) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=402555) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=402555) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=402555) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=402555) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=402555) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=402555) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=402555) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=402555) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=402555) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=402555) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=402555) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=402555) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=402555) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=402555) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=402555) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=402555) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=402555) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=402555) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=402555) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=402555) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=402555) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=402555) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=402555) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=402555) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=402555) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=402555) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=402555) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=402555) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=402555) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=402555) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=402555) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=402555) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=402555) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=402555) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=402555) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=402555) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=402555) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=402555) 	}
(EngineCore_DP0 pid=402555) 	.section	.debug_info
(EngineCore_DP0 pid=402555) 	{
(EngineCore_DP0 pid=402555) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=402555) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=402555) .b8 0
(EngineCore_DP0 pid=402555) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=402555) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=402555) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=402555) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=402555) .b8 114
(EngineCore_DP0 pid=402555) .b8 105
(EngineCore_DP0 pid=402555) .b8 116
(EngineCore_DP0 pid=402555) .b8 111
(EngineCore_DP0 pid=402555) .b8 110
(EngineCore_DP0 pid=402555) .b8 0
(EngineCore_DP0 pid=402555) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=402555) .b8 0
(EngineCore_DP0 pid=402555) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=402555) .b8 117
(EngineCore_DP0 pid=402555) .b8 97
(EngineCore_DP0 pid=402555) .b8 110
(EngineCore_DP0 pid=402555) .b8 116
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 115
(EngineCore_DP0 pid=402555) .b8 108
(EngineCore_DP0 pid=402555) .b8 105
(EngineCore_DP0 pid=402555) .b8 100
(EngineCore_DP0 pid=402555) .b8 101
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 116
(EngineCore_DP0 pid=402555) .b8 117
(EngineCore_DP0 pid=402555) .b8 110
(EngineCore_DP0 pid=402555) .b8 101
(EngineCore_DP0 pid=402555) .b8 100
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 76
(EngineCore_DP0 pid=402555) .b8 108
(EngineCore_DP0 pid=402555) .b8 97
(EngineCore_DP0 pid=402555) .b8 109
(EngineCore_DP0 pid=402555) .b8 97
(EngineCore_DP0 pid=402555) .b8 51
(EngineCore_DP0 pid=402555) .b8 46
(EngineCore_DP0 pid=402555) .b8 50
(EngineCore_DP0 pid=402555) .b8 45
(EngineCore_DP0 pid=402555) .b8 51
(EngineCore_DP0 pid=402555) .b8 66
(EngineCore_DP0 pid=402555) .b8 46
(EngineCore_DP0 pid=402555) .b8 112
(EngineCore_DP0 pid=402555) .b8 121
(EngineCore_DP0 pid=402555) .b8 0
(EngineCore_DP0 pid=402555) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=402555) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=402555) .b8 114
(EngineCore_DP0 pid=402555) .b8 111
(EngineCore_DP0 pid=402555) .b8 111
(EngineCore_DP0 pid=402555) .b8 116
(EngineCore_DP0 pid=402555) .b8 47
(EngineCore_DP0 pid=402555) .b8 118
(EngineCore_DP0 pid=402555) .b8 108
(EngineCore_DP0 pid=402555) .b8 108
(EngineCore_DP0 pid=402555) .b8 109
(EngineCore_DP0 pid=402555) .b8 98
(EngineCore_DP0 pid=402555) .b8 101
(EngineCore_DP0 pid=402555) .b8 110
(EngineCore_DP0 pid=402555) .b8 99
(EngineCore_DP0 pid=402555) .b8 104
(EngineCore_DP0 pid=402555) .b8 47
(EngineCore_DP0 pid=402555) .b8 115
(EngineCore_DP0 pid=402555) .b8 108
(EngineCore_DP0 pid=402555) .b8 105
(EngineCore_DP0 pid=402555) .b8 100
(EngineCore_DP0 pid=402555) .b8 101
(EngineCore_DP0 pid=402555) .b8 115
(EngineCore_DP0 pid=402555) .b8 112
(EngineCore_DP0 pid=402555) .b8 97
(EngineCore_DP0 pid=402555) .b8 114
(EngineCore_DP0 pid=402555) .b8 115
(EngineCore_DP0 pid=402555) .b8 101
(EngineCore_DP0 pid=402555) .b8 47
(EngineCore_DP0 pid=402555) .b8 99
(EngineCore_DP0 pid=402555) .b8 115
(EngineCore_DP0 pid=402555) .b8 114
(EngineCore_DP0 pid=402555) .b8 99
(EngineCore_DP0 pid=402555) .b8 47
(EngineCore_DP0 pid=402555) .b8 102
(EngineCore_DP0 pid=402555) .b8 117
(EngineCore_DP0 pid=402555) .b8 115
(EngineCore_DP0 pid=402555) .b8 101
(EngineCore_DP0 pid=402555) .b8 100
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 113
(EngineCore_DP0 pid=402555) .b8 117
(EngineCore_DP0 pid=402555) .b8 97
(EngineCore_DP0 pid=402555) .b8 110
(EngineCore_DP0 pid=402555) .b8 116
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 115
(EngineCore_DP0 pid=402555) .b8 108
(EngineCore_DP0 pid=402555) .b8 105
(EngineCore_DP0 pid=402555) .b8 100
(EngineCore_DP0 pid=402555) .b8 101
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 116
(EngineCore_DP0 pid=402555) .b8 114
(EngineCore_DP0 pid=402555) .b8 105
(EngineCore_DP0 pid=402555) .b8 116
(EngineCore_DP0 pid=402555) .b8 111
(EngineCore_DP0 pid=402555) .b8 110
(EngineCore_DP0 pid=402555) .b8 47
(EngineCore_DP0 pid=402555) .b8 98
(EngineCore_DP0 pid=402555) .b8 117
(EngineCore_DP0 pid=402555) .b8 105
(EngineCore_DP0 pid=402555) .b8 108
(EngineCore_DP0 pid=402555) .b8 100
(EngineCore_DP0 pid=402555) .b8 47
(EngineCore_DP0 pid=402555) .b8 71
(EngineCore_DP0 pid=402555) .b8 66
(EngineCore_DP0 pid=402555) .b8 49
(EngineCore_DP0 pid=402555) .b8 48
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 99
(EngineCore_DP0 pid=402555) .b8 99
(EngineCore_DP0 pid=402555) .b8 49
(EngineCore_DP0 pid=402555) .b8 50
(EngineCore_DP0 pid=402555) .b8 49
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 112
(EngineCore_DP0 pid=402555) .b8 121
(EngineCore_DP0 pid=402555) .b8 51
(EngineCore_DP0 pid=402555) .b8 49
(EngineCore_DP0 pid=402555) .b8 50
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 99
(EngineCore_DP0 pid=402555) .b8 117
(EngineCore_DP0 pid=402555) .b8 49
(EngineCore_DP0 pid=402555) .b8 50
(EngineCore_DP0 pid=402555) .b8 57
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 97
(EngineCore_DP0 pid=402555) .b8 97
(EngineCore_DP0 pid=402555) .b8 114
(EngineCore_DP0 pid=402555) .b8 99
(EngineCore_DP0 pid=402555) .b8 104
(EngineCore_DP0 pid=402555) .b8 54
(EngineCore_DP0 pid=402555) .b8 52
(EngineCore_DP0 pid=402555) .b8 0
(EngineCore_DP0 pid=402555) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=402555) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=402555) .b8 113
(EngineCore_DP0 pid=402555) .b8 117
(EngineCore_DP0 pid=402555) .b8 97
(EngineCore_DP0 pid=402555) .b8 110
(EngineCore_DP0 pid=402555) .b8 116
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 115
(EngineCore_DP0 pid=402555) .b8 108
(EngineCore_DP0 pid=402555) .b8 105
(EngineCore_DP0 pid=402555) .b8 100
(EngineCore_DP0 pid=402555) .b8 101
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 102
(EngineCore_DP0 pid=402555) .b8 112
(EngineCore_DP0 pid=402555) .b8 56
(EngineCore_DP0 pid=402555) .b8 95
(EngineCore_DP0 pid=402555) .b8 107
(EngineCore_DP0 pid=402555) .b8 101
(EngineCore_DP0 pid=402555) .b8 114
(EngineCore_DP0 pid=402555) .b8 110
(EngineCore_DP0 pid=402555) .b8 101
(EngineCore_DP0 pid=402555) .b8 108
(EngineCore_DP0 pid=402555) .b8 0
(EngineCore_DP0 pid=402555) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=402555) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=402555) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=402555) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=402555) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=402555) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=402555) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=402555) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=402555) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=402555) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=402555) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=402555) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=402555) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=402555) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=402555) 	}
(EngineCore_DP0 pid=402555) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) ================================================================
(EngineCore_DP0 pid=402555) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpnuw5ptz4.ptx', '-o', '/tmp/tmpnuw5ptz4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] 
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] 
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] 
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnuw5ptz4.ptx -o /tmp/tmpnuw5ptz4.ptx.o
(EngineCore_DP0 pid=402555) ERROR 01-25 20:13:52 [core.py:866] 

STDERR:
[2026-01-25 20:13:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:13:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:13:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:13:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:13:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:13:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:13:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:13:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:13:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:13:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:13:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:13:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:13:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:13:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:13:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:13:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:13:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:13:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:13:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:13:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:13:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:13:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:13:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:13:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:13:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:13:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:13:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:13:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:27] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:27] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:27] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:27] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:27] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=402555) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=402555) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.66s/it]
(EngineCore_DP0 pid=402555) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.66s/it]
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=402555) [2026-01-25 20:13:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=402555) Process EngineCore_DP0:
(EngineCore_DP0 pid=402555) Traceback (most recent call last):
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=402555)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=402555)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=402555)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=402555) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpnuw5ptz4.ptx', '-o', '/tmp/tmpnuw5ptz4.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) Traceback (most recent call last):
(EngineCore_DP0 pid=402555)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=402555)     self.run()
(EngineCore_DP0 pid=402555)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=402555)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=402555)     raise e
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=402555)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=402555)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=402555)     super().__init__(
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=402555)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=402555)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=402555)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=402555)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=402555)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=402555)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=402555)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=402555)     return func(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=402555)     return func(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=402555)     self.model_runner.profile_run()
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=402555)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=402555)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=402555)     return func(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=402555)     outputs = self.model(
(EngineCore_DP0 pid=402555)               ^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=402555)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=402555)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=402555)     model_output = self.model(
(EngineCore_DP0 pid=402555)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=402555)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=402555)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=402555)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=402555)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=402555)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=402555)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=402555)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=402555)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=402555)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=402555)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=402555)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=402555)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=402555)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=402555)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=402555)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=402555)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=402555)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=402555)     return self._linear_fn(
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=402555)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=402555)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=402555)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=402555)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=402555)     return fn(input, L)
(EngineCore_DP0 pid=402555)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=402555)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=402555)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=402555)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=402555)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=402555)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=402555)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=402555)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=402555)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=402555)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=402555)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=402555)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=402555)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=402555)     raise PTXASError(error)
(EngineCore_DP0 pid=402555) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=402555) `ptxas` stderr:
(EngineCore_DP0 pid=402555) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=402555) 
(EngineCore_DP0 pid=402555) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnuw5ptz4.ptx -o /tmp/tmpnuw5ptz4.ptx.o
(EngineCore_DP0 pid=402555) 
[rank0]:[W125 20:13:53.281673815 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 20:13:54
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 20:14:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 20:14:20 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=403548) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) ================================================================
(EngineCore_DP0 pid=403548) Internal Triton PTX codegen error
(EngineCore_DP0 pid=403548) `ptxas` stderr:
(EngineCore_DP0 pid=403548) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptim53djk.ptx -o /tmp/tmptim53djk.ptx.o
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) //
(EngineCore_DP0 pid=403548) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=403548) //
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) .version 8.7
(EngineCore_DP0 pid=403548) .target sm_121a
(EngineCore_DP0 pid=403548) .address_size 64
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=403548) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=403548)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=403548) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=403548) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=403548) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=403548) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=403548) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=403548) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=403548) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=403548) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=403548) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=403548) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=403548) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=403548) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=403548) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=403548) )
(EngineCore_DP0 pid=403548) .reqntid 512
(EngineCore_DP0 pid=403548) {
(EngineCore_DP0 pid=403548) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=403548) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=403548) 	.reg .b32 	%r<152>;
(EngineCore_DP0 pid=403548) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=403548) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=403548) $L__func_begin0:
(EngineCore_DP0 pid=403548) 	.loc	1 181 0                         // quant_slide_tuned_Llama3.2-3B.py:181:0
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) // %bb.0:
(EngineCore_DP0 pid=403548) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=403548) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=403548) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=403548) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=403548) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=403548) $L__tmp0:
(EngineCore_DP0 pid=403548) 	.loc	1 191 24                        // quant_slide_tuned_Llama3.2-3B.py:191:24
(EngineCore_DP0 pid=403548) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=403548) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=403548) 	.loc	1 196 26                        // quant_slide_tuned_Llama3.2-3B.py:196:26
(EngineCore_DP0 pid=403548) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=403548) 	.loc	1 196 20                        // quant_slide_tuned_Llama3.2-3B.py:196:20
(EngineCore_DP0 pid=403548) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=403548) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=403548) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=403548) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=403548) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=403548) 	mov.b32 	%r150, 0f2B8CBCCC;
(EngineCore_DP0 pid=403548) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=403548) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=403548) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=403548) 	.loc	1 202 32                        // quant_slide_tuned_Llama3.2-3B.py:202:32
(EngineCore_DP0 pid=403548) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=403548) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=403548) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=403548) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=403548) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=403548) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=403548) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=403548) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=403548) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=403548) 	mov.b32 	%r148, 0f00000000;
(EngineCore_DP0 pid=403548) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=403548) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=403548) 	mov.b32 	%r149, %r45;
(EngineCore_DP0 pid=403548) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=403548) 	.loc	1 203 22                        // quant_slide_tuned_Llama3.2-3B.py:203:22
(EngineCore_DP0 pid=403548) 	add.s32 	%r55, %r4, %r149;
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=403548) 	.loc	1 204 29                        // quant_slide_tuned_Llama3.2-3B.py:204:29
(EngineCore_DP0 pid=403548) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=403548) 	.loc	1 204 21                        // quant_slide_tuned_Llama3.2-3B.py:204:21
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=403548) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=403548) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=403548) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=403548) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=403548) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=403548) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=403548) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=403548) 	.loc	1 205 50                        // quant_slide_tuned_Llama3.2-3B.py:205:50
(EngineCore_DP0 pid=403548) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=403548) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=403548) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=403548) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=403548) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=403548) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=403548) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=403548) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=403548) $L__tmp1:
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	bar.sync 	0;
(EngineCore_DP0 pid=403548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=403548) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=403548) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=403548) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=403548) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=403548) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=403548) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=403548) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=403548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=403548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=403548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=403548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=403548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	bar.sync 	0;
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=403548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=403548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=403548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=403548) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=403548) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Llama3.2-3B.py:205:43 ]
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	bar.sync 	0;
(EngineCore_DP0 pid=403548) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=403548) $L__tmp2:
(EngineCore_DP0 pid=403548) 	.loc	1 205 36                        // quant_slide_tuned_Llama3.2-3B.py:205:36
(EngineCore_DP0 pid=403548) 	max.f32 	%r148, %r148, %r73;
(EngineCore_DP0 pid=403548) 	.loc	1 201 35                        // quant_slide_tuned_Llama3.2-3B.py:201:35
(EngineCore_DP0 pid=403548) 	add.s32 	%r149, %r149, 4096;
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p6, %r149, %r24;
(EngineCore_DP0 pid=403548) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=403548) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=403548) 	.loc	1 207 32                        // quant_slide_tuned_Llama3.2-3B.py:207:32
(EngineCore_DP0 pid=403548) 	max.f32 	%r150, %r148, 0f2B8CBCCC;
(EngineCore_DP0 pid=403548) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=403548) 	.loc	1 0 32                          // quant_slide_tuned_Llama3.2-3B.py:0:32
(EngineCore_DP0 pid=403548) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=403548) 	.loc	1 208 32                        // quant_slide_tuned_Llama3.2-3B.py:208:32
(EngineCore_DP0 pid=403548) 	div.full.f32 	%r76, %r150, %r75;
(EngineCore_DP0 pid=403548) 	.loc	1 208 41                        // quant_slide_tuned_Llama3.2-3B.py:208:41
(EngineCore_DP0 pid=403548) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=403548) 	.loc	1 210 25                        // quant_slide_tuned_Llama3.2-3B.py:210:25
(EngineCore_DP0 pid=403548) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=403548) 	.loc	1 210 30                        // quant_slide_tuned_Llama3.2-3B.py:210:30
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	.loc	1 213 29                        // quant_slide_tuned_Llama3.2-3B.py:213:29
(EngineCore_DP0 pid=403548) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=403548) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=403548) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=403548) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=403548) 	.loc	1 0 41                          // quant_slide_tuned_Llama3.2-3B.py:0:41
(EngineCore_DP0 pid=403548) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=403548) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=403548) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=403548) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=403548) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=403548) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=403548) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=403548) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=403548) 	div.full.f32 	%r14, %r75, %r150;
(EngineCore_DP0 pid=403548) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=403548) 	mov.b32 	%r151, 0;
(EngineCore_DP0 pid=403548) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=403548)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=403548) 	.loc	1 216 31                        // quant_slide_tuned_Llama3.2-3B.py:216:31
(EngineCore_DP0 pid=403548) 	add.s32 	%r89, %r16, %r151;
(EngineCore_DP0 pid=403548) 	.loc	1 217 30                        // quant_slide_tuned_Llama3.2-3B.py:217:30
(EngineCore_DP0 pid=403548) 	add.s32 	%r90, %r89, 1;
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p17, %r89, %r15;
(EngineCore_DP0 pid=403548) 	.loc	1 220 24                        // quant_slide_tuned_Llama3.2-3B.py:220:24
(EngineCore_DP0 pid=403548) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=403548) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=403548) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=403548) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=403548) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=403548) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=403548) 	.loc	1 221 23                        // quant_slide_tuned_Llama3.2-3B.py:221:23
(EngineCore_DP0 pid=403548) 	mul.lo.s32 	%r97, %r96, 3;
(EngineCore_DP0 pid=403548) 	mul.lo.s32 	%r98, %r93, 3;
(EngineCore_DP0 pid=403548) 	sub.s32 	%r99, %r90, %r98;
(EngineCore_DP0 pid=403548) 	sub.s32 	%r100, %r89, %r97;
(EngineCore_DP0 pid=403548) 	.loc	1 222 22                        // quant_slide_tuned_Llama3.2-3B.py:222:22
(EngineCore_DP0 pid=403548) 	shl.b32 	%r101, %r96, 3;
(EngineCore_DP0 pid=403548) 	shl.b32 	%r102, %r93, 3;
(EngineCore_DP0 pid=403548) 	.loc	1 222 30                        // quant_slide_tuned_Llama3.2-3B.py:222:30
(EngineCore_DP0 pid=403548) 	shl.b32 	%r103, %r100, 1;
(EngineCore_DP0 pid=403548) 	shl.b32 	%r104, %r99, 1;
(EngineCore_DP0 pid=403548) 	.loc	1 222 26                        // quant_slide_tuned_Llama3.2-3B.py:222:26
(EngineCore_DP0 pid=403548) 	add.s32 	%r105, %r102, %r104;
(EngineCore_DP0 pid=403548) 	add.s32 	%r106, %r101, %r103;
(EngineCore_DP0 pid=403548) 	.loc	1 225 53                        // quant_slide_tuned_Llama3.2-3B.py:225:53
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p18, %r106, %r23;
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p19, %r105, %r23;
(EngineCore_DP0 pid=403548) 	.loc	1 225 37                        // quant_slide_tuned_Llama3.2-3B.py:225:37
(EngineCore_DP0 pid=403548) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=403548) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=403548) 	.loc	1 224 29                        // quant_slide_tuned_Llama3.2-3B.py:224:29
(EngineCore_DP0 pid=403548) 	mad.wide.s32 	%rd8, %r106, 2, %rd1;
(EngineCore_DP0 pid=403548) 	mad.wide.s32 	%rd9, %r105, 2, %rd1;
(EngineCore_DP0 pid=403548) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=403548) 	.loc	1 224 21                        // quant_slide_tuned_Llama3.2-3B.py:224:21
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=403548) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=403548) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	.loc	1 225 79                        // quant_slide_tuned_Llama3.2-3B.py:225:79
(EngineCore_DP0 pid=403548) 	cvt.f32.bf16 	%r107, %rs24;
(EngineCore_DP0 pid=403548) 	cvt.f32.bf16 	%r108, %rs26;
(EngineCore_DP0 pid=403548) 	.loc	1 227 48                        // quant_slide_tuned_Llama3.2-3B.py:227:48
(EngineCore_DP0 pid=403548) 	or.b32 	%r109, %r106, 1;
(EngineCore_DP0 pid=403548) 	or.b32 	%r110, %r105, 1;
(EngineCore_DP0 pid=403548) 	.loc	1 227 53                        // quant_slide_tuned_Llama3.2-3B.py:227:53
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p20, %r109, %r23;
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p21, %r110, %r23;
(EngineCore_DP0 pid=403548) 	.loc	1 227 37                        // quant_slide_tuned_Llama3.2-3B.py:227:37
(EngineCore_DP0 pid=403548) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=403548) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=403548) 	.loc	1 226 39                        // quant_slide_tuned_Llama3.2-3B.py:226:39
(EngineCore_DP0 pid=403548) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=403548) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=403548) 	.loc	1 226 21                        // quant_slide_tuned_Llama3.2-3B.py:226:21
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=403548) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=403548) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	.loc	1 227 79                        // quant_slide_tuned_Llama3.2-3B.py:227:79
(EngineCore_DP0 pid=403548) 	cvt.f32.bf16 	%r111, %rs28;
(EngineCore_DP0 pid=403548) 	cvt.f32.bf16 	%r112, %rs30;
(EngineCore_DP0 pid=403548) 	.loc	1 231 48                        // quant_slide_tuned_Llama3.2-3B.py:231:48
(EngineCore_DP0 pid=403548) 	add.s32 	%r113, %r106, 2;
(EngineCore_DP0 pid=403548) 	add.s32 	%r114, %r105, 2;
(EngineCore_DP0 pid=403548) 	add.s32 	%r115, %r106, 3;
(EngineCore_DP0 pid=403548) 	add.s32 	%r116, %r105, 3;
(EngineCore_DP0 pid=403548) 	.loc	1 231 53                        // quant_slide_tuned_Llama3.2-3B.py:231:53
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p22, %r116, %r23;
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p23, %r115, %r23;
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p24, %r114, %r23;
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p25, %r113, %r23;
(EngineCore_DP0 pid=403548) 	.loc	1 229 37                        // quant_slide_tuned_Llama3.2-3B.py:229:37
(EngineCore_DP0 pid=403548) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=403548) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=403548) 	.loc	1 228 39                        // quant_slide_tuned_Llama3.2-3B.py:228:39
(EngineCore_DP0 pid=403548) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=403548) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=403548) 	.loc	1 228 21                        // quant_slide_tuned_Llama3.2-3B.py:228:21
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=403548) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=403548) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	.loc	1 229 79                        // quant_slide_tuned_Llama3.2-3B.py:229:79
(EngineCore_DP0 pid=403548) 	cvt.f32.bf16 	%r117, %rs32;
(EngineCore_DP0 pid=403548) 	cvt.f32.bf16 	%r118, %rs34;
(EngineCore_DP0 pid=403548) 	.loc	1 231 37                        // quant_slide_tuned_Llama3.2-3B.py:231:37
(EngineCore_DP0 pid=403548) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=403548) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=403548) 	.loc	1 230 39                        // quant_slide_tuned_Llama3.2-3B.py:230:39
(EngineCore_DP0 pid=403548) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=403548) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=403548) 	.loc	1 230 21                        // quant_slide_tuned_Llama3.2-3B.py:230:21
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=403548) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=403548) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	.loc	1 231 79                        // quant_slide_tuned_Llama3.2-3B.py:231:79
(EngineCore_DP0 pid=403548) 	cvt.f32.bf16 	%r119, %rs36;
(EngineCore_DP0 pid=403548) 	cvt.f32.bf16 	%r120, %rs38;
(EngineCore_DP0 pid=403548) 	.loc	1 233 27                        // quant_slide_tuned_Llama3.2-3B.py:233:27
(EngineCore_DP0 pid=403548) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=403548) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=403548) 	mov.b32 	%r123, 0f43E00000;
(EngineCore_DP0 pid=403548) 	.loc	1 233 48                        // quant_slide_tuned_Llama3.2-3B.py:233:48
(EngineCore_DP0 pid=403548) 	min.xorsign.abs.f32 	%r78, %r121, %r123;
(EngineCore_DP0 pid=403548) 	min.xorsign.abs.f32 	%r79, %r122, %r123;
(EngineCore_DP0 pid=403548) 	.loc	1 233 60                        // quant_slide_tuned_Llama3.2-3B.py:233:60
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=403548) 	.loc	1 234 27                        // quant_slide_tuned_Llama3.2-3B.py:234:27
(EngineCore_DP0 pid=403548) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=403548) 	mul.f32 	%r125, %r14, %r112;
(EngineCore_DP0 pid=403548) 	.loc	1 234 48                        // quant_slide_tuned_Llama3.2-3B.py:234:48
(EngineCore_DP0 pid=403548) 	min.xorsign.abs.f32 	%r80, %r124, %r123;
(EngineCore_DP0 pid=403548) 	min.xorsign.abs.f32 	%r81, %r125, %r123;
(EngineCore_DP0 pid=403548) 	.loc	1 234 60                        // quant_slide_tuned_Llama3.2-3B.py:234:60
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=403548) 	.loc	1 235 27                        // quant_slide_tuned_Llama3.2-3B.py:235:27
(EngineCore_DP0 pid=403548) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=403548) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=403548) 	.loc	1 235 48                        // quant_slide_tuned_Llama3.2-3B.py:235:48
(EngineCore_DP0 pid=403548) 	min.xorsign.abs.f32 	%r82, %r126, %r123;
(EngineCore_DP0 pid=403548) 	min.xorsign.abs.f32 	%r83, %r127, %r123;
(EngineCore_DP0 pid=403548) 	.loc	1 235 60                        // quant_slide_tuned_Llama3.2-3B.py:235:60
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=403548) 	.loc	1 236 27                        // quant_slide_tuned_Llama3.2-3B.py:236:27
(EngineCore_DP0 pid=403548) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=403548) 	mul.f32 	%r129, %r14, %r120;
(EngineCore_DP0 pid=403548) 	.loc	1 236 48                        // quant_slide_tuned_Llama3.2-3B.py:236:48
(EngineCore_DP0 pid=403548) 	min.xorsign.abs.f32 	%r84, %r128, %r123;
(EngineCore_DP0 pid=403548) 	min.xorsign.abs.f32 	%r85, %r129, %r123;
(EngineCore_DP0 pid=403548) 	.loc	1 236 60                        // quant_slide_tuned_Llama3.2-3B.py:236:60
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=403548) 	.loc	1 238 45                        // quant_slide_tuned_Llama3.2-3B.py:238:45
(EngineCore_DP0 pid=403548) 	cvt.u32.u16 	%r130, %rs40;
(EngineCore_DP0 pid=403548) 	and.b32 	%r131, %r130, 255;
(EngineCore_DP0 pid=403548) 	cvt.u32.u16 	%r132, %rs44;
(EngineCore_DP0 pid=403548) 	.loc	1 240 45                        // quant_slide_tuned_Llama3.2-3B.py:240:45
(EngineCore_DP0 pid=403548) 	cvt.u32.u16 	%r133, %rs42;
(EngineCore_DP0 pid=403548) 	and.b32 	%r134, %r133, 255;
(EngineCore_DP0 pid=403548) 	cvt.u32.u16 	%r135, %rs46;
(EngineCore_DP0 pid=403548) 	.loc	1 241 45                        // quant_slide_tuned_Llama3.2-3B.py:241:45
(EngineCore_DP0 pid=403548) 	cvt.u32.u16 	%r136, %rs43;
(EngineCore_DP0 pid=403548) 	cvt.u32.u16 	%r137, %rs47;
(EngineCore_DP0 pid=403548) 	.loc	1 243 30                        // quant_slide_tuned_Llama3.2-3B.py:243:30
(EngineCore_DP0 pid=403548) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=403548) 	mul.wide.u16 	%r138, %rs48, 256;
(EngineCore_DP0 pid=403548) 	mul.wide.u16 	%r139, %rs45, 256;
(EngineCore_DP0 pid=403548) 	.loc	1 243 24                        // quant_slide_tuned_Llama3.2-3B.py:243:24
(EngineCore_DP0 pid=403548) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=403548) 	or.b32 	%r141, %r139, %r132;
(EngineCore_DP0 pid=403548) 	.loc	1 243 42                        // quant_slide_tuned_Llama3.2-3B.py:243:42
(EngineCore_DP0 pid=403548) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=403548) 	shl.b32 	%r143, %r135, 16;
(EngineCore_DP0 pid=403548) 	.loc	1 243 36                        // quant_slide_tuned_Llama3.2-3B.py:243:36
(EngineCore_DP0 pid=403548) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=403548) 	or.b32 	%r145, %r141, %r143;
(EngineCore_DP0 pid=403548) 	.loc	1 243 55                        // quant_slide_tuned_Llama3.2-3B.py:243:55
(EngineCore_DP0 pid=403548) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=403548) 	shl.b32 	%r147, %r137, 24;
(EngineCore_DP0 pid=403548) 	.loc	1 243 49                        // quant_slide_tuned_Llama3.2-3B.py:243:49
(EngineCore_DP0 pid=403548) 	or.b32 	%r86, %r144, %r146;
(EngineCore_DP0 pid=403548) 	or.b32 	%r87, %r145, %r147;
(EngineCore_DP0 pid=403548) 	.loc	1 244 29                        // quant_slide_tuned_Llama3.2-3B.py:244:29
(EngineCore_DP0 pid=403548) 	mad.wide.s32 	%rd16, %r89, 4, %rd2;
(EngineCore_DP0 pid=403548) 	.loc	1 244 39                        // quant_slide_tuned_Llama3.2-3B.py:244:39
(EngineCore_DP0 pid=403548) 	// begin inline asm
(EngineCore_DP0 pid=403548) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=403548) 	// end inline asm
(EngineCore_DP0 pid=403548) 	.loc	1 215 41                        // quant_slide_tuned_Llama3.2-3B.py:215:41
(EngineCore_DP0 pid=403548) 	add.s32 	%r151, %r151, 1024;
(EngineCore_DP0 pid=403548) 	setp.lt.s32 	%p26, %r151, %r15;
(EngineCore_DP0 pid=403548) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=403548) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=403548) 	.loc	1 215 4                         // quant_slide_tuned_Llama3.2-3B.py:215:4
(EngineCore_DP0 pid=403548) 	ret;
(EngineCore_DP0 pid=403548) $L__tmp3:
(EngineCore_DP0 pid=403548) $L__func_end0:
(EngineCore_DP0 pid=403548)                                         // -- End function
(EngineCore_DP0 pid=403548) }
(EngineCore_DP0 pid=403548) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py"
(EngineCore_DP0 pid=403548) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=403548) 	.section	.debug_abbrev
(EngineCore_DP0 pid=403548) 	{
(EngineCore_DP0 pid=403548) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=403548) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=403548) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=403548) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=403548) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=403548) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=403548) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=403548) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=403548) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=403548) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=403548) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=403548) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=403548) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=403548) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=403548) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=403548) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=403548) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=403548) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=403548) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=403548) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=403548) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=403548) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=403548) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=403548) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=403548) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=403548) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=403548) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=403548) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=403548) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=403548) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=403548) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=403548) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=403548) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=403548) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=403548) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=403548) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=403548) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=403548) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=403548) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=403548) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=403548) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=403548) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=403548) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=403548) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=403548) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=403548) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=403548) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=403548) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=403548) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=403548) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=403548) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=403548) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=403548) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=403548) 	}
(EngineCore_DP0 pid=403548) 	.section	.debug_info
(EngineCore_DP0 pid=403548) 	{
(EngineCore_DP0 pid=403548) .b32 222                                // Length of Unit
(EngineCore_DP0 pid=403548) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=403548) .b8 0
(EngineCore_DP0 pid=403548) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=403548) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=403548) .b8 1                                   // Abbrev [1] 0xb:0xd7 DW_TAG_compile_unit
(EngineCore_DP0 pid=403548) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=403548) .b8 114
(EngineCore_DP0 pid=403548) .b8 105
(EngineCore_DP0 pid=403548) .b8 116
(EngineCore_DP0 pid=403548) .b8 111
(EngineCore_DP0 pid=403548) .b8 110
(EngineCore_DP0 pid=403548) .b8 0
(EngineCore_DP0 pid=403548) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=403548) .b8 0
(EngineCore_DP0 pid=403548) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=403548) .b8 117
(EngineCore_DP0 pid=403548) .b8 97
(EngineCore_DP0 pid=403548) .b8 110
(EngineCore_DP0 pid=403548) .b8 116
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 115
(EngineCore_DP0 pid=403548) .b8 108
(EngineCore_DP0 pid=403548) .b8 105
(EngineCore_DP0 pid=403548) .b8 100
(EngineCore_DP0 pid=403548) .b8 101
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 116
(EngineCore_DP0 pid=403548) .b8 117
(EngineCore_DP0 pid=403548) .b8 110
(EngineCore_DP0 pid=403548) .b8 101
(EngineCore_DP0 pid=403548) .b8 100
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 76
(EngineCore_DP0 pid=403548) .b8 108
(EngineCore_DP0 pid=403548) .b8 97
(EngineCore_DP0 pid=403548) .b8 109
(EngineCore_DP0 pid=403548) .b8 97
(EngineCore_DP0 pid=403548) .b8 51
(EngineCore_DP0 pid=403548) .b8 46
(EngineCore_DP0 pid=403548) .b8 50
(EngineCore_DP0 pid=403548) .b8 45
(EngineCore_DP0 pid=403548) .b8 51
(EngineCore_DP0 pid=403548) .b8 66
(EngineCore_DP0 pid=403548) .b8 46
(EngineCore_DP0 pid=403548) .b8 112
(EngineCore_DP0 pid=403548) .b8 121
(EngineCore_DP0 pid=403548) .b8 0
(EngineCore_DP0 pid=403548) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=403548) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=403548) .b8 114
(EngineCore_DP0 pid=403548) .b8 111
(EngineCore_DP0 pid=403548) .b8 111
(EngineCore_DP0 pid=403548) .b8 116
(EngineCore_DP0 pid=403548) .b8 47
(EngineCore_DP0 pid=403548) .b8 118
(EngineCore_DP0 pid=403548) .b8 108
(EngineCore_DP0 pid=403548) .b8 108
(EngineCore_DP0 pid=403548) .b8 109
(EngineCore_DP0 pid=403548) .b8 98
(EngineCore_DP0 pid=403548) .b8 101
(EngineCore_DP0 pid=403548) .b8 110
(EngineCore_DP0 pid=403548) .b8 99
(EngineCore_DP0 pid=403548) .b8 104
(EngineCore_DP0 pid=403548) .b8 47
(EngineCore_DP0 pid=403548) .b8 115
(EngineCore_DP0 pid=403548) .b8 108
(EngineCore_DP0 pid=403548) .b8 105
(EngineCore_DP0 pid=403548) .b8 100
(EngineCore_DP0 pid=403548) .b8 101
(EngineCore_DP0 pid=403548) .b8 115
(EngineCore_DP0 pid=403548) .b8 112
(EngineCore_DP0 pid=403548) .b8 97
(EngineCore_DP0 pid=403548) .b8 114
(EngineCore_DP0 pid=403548) .b8 115
(EngineCore_DP0 pid=403548) .b8 101
(EngineCore_DP0 pid=403548) .b8 47
(EngineCore_DP0 pid=403548) .b8 99
(EngineCore_DP0 pid=403548) .b8 115
(EngineCore_DP0 pid=403548) .b8 114
(EngineCore_DP0 pid=403548) .b8 99
(EngineCore_DP0 pid=403548) .b8 47
(EngineCore_DP0 pid=403548) .b8 102
(EngineCore_DP0 pid=403548) .b8 117
(EngineCore_DP0 pid=403548) .b8 115
(EngineCore_DP0 pid=403548) .b8 101
(EngineCore_DP0 pid=403548) .b8 100
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 113
(EngineCore_DP0 pid=403548) .b8 117
(EngineCore_DP0 pid=403548) .b8 97
(EngineCore_DP0 pid=403548) .b8 110
(EngineCore_DP0 pid=403548) .b8 116
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 115
(EngineCore_DP0 pid=403548) .b8 108
(EngineCore_DP0 pid=403548) .b8 105
(EngineCore_DP0 pid=403548) .b8 100
(EngineCore_DP0 pid=403548) .b8 101
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 116
(EngineCore_DP0 pid=403548) .b8 114
(EngineCore_DP0 pid=403548) .b8 105
(EngineCore_DP0 pid=403548) .b8 116
(EngineCore_DP0 pid=403548) .b8 111
(EngineCore_DP0 pid=403548) .b8 110
(EngineCore_DP0 pid=403548) .b8 47
(EngineCore_DP0 pid=403548) .b8 98
(EngineCore_DP0 pid=403548) .b8 117
(EngineCore_DP0 pid=403548) .b8 105
(EngineCore_DP0 pid=403548) .b8 108
(EngineCore_DP0 pid=403548) .b8 100
(EngineCore_DP0 pid=403548) .b8 47
(EngineCore_DP0 pid=403548) .b8 71
(EngineCore_DP0 pid=403548) .b8 66
(EngineCore_DP0 pid=403548) .b8 49
(EngineCore_DP0 pid=403548) .b8 48
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 99
(EngineCore_DP0 pid=403548) .b8 99
(EngineCore_DP0 pid=403548) .b8 49
(EngineCore_DP0 pid=403548) .b8 50
(EngineCore_DP0 pid=403548) .b8 49
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 112
(EngineCore_DP0 pid=403548) .b8 121
(EngineCore_DP0 pid=403548) .b8 51
(EngineCore_DP0 pid=403548) .b8 49
(EngineCore_DP0 pid=403548) .b8 50
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 99
(EngineCore_DP0 pid=403548) .b8 117
(EngineCore_DP0 pid=403548) .b8 49
(EngineCore_DP0 pid=403548) .b8 50
(EngineCore_DP0 pid=403548) .b8 57
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 97
(EngineCore_DP0 pid=403548) .b8 97
(EngineCore_DP0 pid=403548) .b8 114
(EngineCore_DP0 pid=403548) .b8 99
(EngineCore_DP0 pid=403548) .b8 104
(EngineCore_DP0 pid=403548) .b8 54
(EngineCore_DP0 pid=403548) .b8 52
(EngineCore_DP0 pid=403548) .b8 0
(EngineCore_DP0 pid=403548) .b8 2                                   // Abbrev [2] 0x99:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=403548) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=403548) .b8 113
(EngineCore_DP0 pid=403548) .b8 117
(EngineCore_DP0 pid=403548) .b8 97
(EngineCore_DP0 pid=403548) .b8 110
(EngineCore_DP0 pid=403548) .b8 116
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 115
(EngineCore_DP0 pid=403548) .b8 108
(EngineCore_DP0 pid=403548) .b8 105
(EngineCore_DP0 pid=403548) .b8 100
(EngineCore_DP0 pid=403548) .b8 101
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 102
(EngineCore_DP0 pid=403548) .b8 112
(EngineCore_DP0 pid=403548) .b8 56
(EngineCore_DP0 pid=403548) .b8 95
(EngineCore_DP0 pid=403548) .b8 107
(EngineCore_DP0 pid=403548) .b8 101
(EngineCore_DP0 pid=403548) .b8 114
(EngineCore_DP0 pid=403548) .b8 110
(EngineCore_DP0 pid=403548) .b8 101
(EngineCore_DP0 pid=403548) .b8 108
(EngineCore_DP0 pid=403548) .b8 0
(EngineCore_DP0 pid=403548) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=403548) .b8 3                                   // Abbrev [3] 0xb3:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=403548) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=403548) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=403548) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=403548) .b8 4                                   // Abbrev [4] 0xc8:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=403548) .b32 153                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=403548) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=403548) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=403548) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=403548) .b8 205                                 // DW_AT_call_line
(EngineCore_DP0 pid=403548) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=403548) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=403548) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=403548) 	}
(EngineCore_DP0 pid=403548) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) ================================================================
(EngineCore_DP0 pid=403548) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmptim53djk.ptx', '-o', '/tmp/tmptim53djk.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] 
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] 
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] 
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptim53djk.ptx -o /tmp/tmptim53djk.ptx.o
(EngineCore_DP0 pid=403548) ERROR 01-25 20:14:50 [core.py:866] 

STDERR:
[2026-01-25 20:14:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:14:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:14:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:14:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:14:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:14:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:14:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:14:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:14:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 20:14:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 20:14:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 20:14:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 20:14:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 20:14:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 20:14:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 20:14:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 20:14:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 20:14:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 20:14:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=403548) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=403548) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.24s/it]
(EngineCore_DP0 pid=403548) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.24s/it]
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=403548) [2026-01-25 20:14:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=403548) Process EngineCore_DP0:
(EngineCore_DP0 pid=403548) Traceback (most recent call last):
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=403548)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=403548)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=403548)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=403548) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmptim53djk.ptx', '-o', '/tmp/tmptim53djk.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) Traceback (most recent call last):
(EngineCore_DP0 pid=403548)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=403548)     self.run()
(EngineCore_DP0 pid=403548)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=403548)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=403548)     raise e
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=403548)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=403548)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=403548)     super().__init__(
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=403548)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=403548)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=403548)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=403548)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=403548)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=403548)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=403548)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=403548)     return func(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=403548)     return func(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=403548)     self.model_runner.profile_run()
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=403548)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=403548)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=403548)     return func(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=403548)     outputs = self.model(
(EngineCore_DP0 pid=403548)               ^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=403548)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=403548)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=403548)     model_output = self.model(
(EngineCore_DP0 pid=403548)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=403548)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 436, in forward
(EngineCore_DP0 pid=403548)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=403548)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=403548)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=403548)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 342, in forward
(EngineCore_DP0 pid=403548)     hidden_states = self.self_attn(positions=positions, hidden_states=hidden_states)
(EngineCore_DP0 pid=403548)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=403548)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=403548)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 240, in forward
(EngineCore_DP0 pid=403548)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=403548)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=403548)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=403548)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=403548)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=403548)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=403548)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=403548)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=403548)     return self._linear_fn(
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=403548)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=403548)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=403548)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=403548)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=403548)     return fn(input, L)
(EngineCore_DP0 pid=403548)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Llama3.2-3B.py", line 273, in quant_slide_fp8_triton
(EngineCore_DP0 pid=403548)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=403548)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=403548)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=403548)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=403548)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=403548)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=403548)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=403548)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=403548)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=403548)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=403548)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=403548)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=403548)     raise PTXASError(error)
(EngineCore_DP0 pid=403548) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=403548) `ptxas` stderr:
(EngineCore_DP0 pid=403548) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=403548) 
(EngineCore_DP0 pid=403548) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmptim53djk.ptx -o /tmp/tmptim53djk.ptx.o
(EngineCore_DP0 pid=403548) 
[rank0]:[W125 20:14:50.139793529 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-25 21:35:17
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:35:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:35:21 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=484861) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) ================================================================
(EngineCore_DP0 pid=484861) Internal Triton PTX codegen error
(EngineCore_DP0 pid=484861) `ptxas` stderr:
(EngineCore_DP0 pid=484861) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpghehsd_f.ptx -o /tmp/tmpghehsd_f.ptx.o
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) //
(EngineCore_DP0 pid=484861) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=484861) //
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) .version 8.7
(EngineCore_DP0 pid=484861) .target sm_121a
(EngineCore_DP0 pid=484861) .address_size 64
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=484861) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=484861)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=484861) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=484861) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=484861) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=484861) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=484861) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=484861) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=484861) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=484861) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=484861) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=484861) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=484861) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=484861) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=484861) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=484861) )
(EngineCore_DP0 pid=484861) .reqntid 1024
(EngineCore_DP0 pid=484861) {
(EngineCore_DP0 pid=484861) 	.reg .pred 	%p<20>;
(EngineCore_DP0 pid=484861) 	.reg .b16 	%rs<25>;
(EngineCore_DP0 pid=484861) 	.reg .b32 	%r<115>;
(EngineCore_DP0 pid=484861) 	.reg .b64 	%rd<13>;
(EngineCore_DP0 pid=484861) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=484861) $L__func_begin0:
(EngineCore_DP0 pid=484861) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) // %bb.0:
(EngineCore_DP0 pid=484861) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=484861) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=484861) 	ld.param.b32 	%r17, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=484861) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=484861) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=484861) $L__tmp0:
(EngineCore_DP0 pid=484861) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=484861) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=484861) 	ld.param.b32 	%r21, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=484861) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=484861) 	mul.lo.s32 	%r22, %r21, %r1;
(EngineCore_DP0 pid=484861) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=484861) 	mad.wide.s32 	%rd1, %r22, 2, %rd4;
(EngineCore_DP0 pid=484861) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=484861) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=484861) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=484861) 	setp.lt.s32 	%p1, %r18, 1;
(EngineCore_DP0 pid=484861) 	mov.b32 	%r113, 0f2B8CBCCC;
(EngineCore_DP0 pid=484861) 	setp.eq.b32 	%p19, %r2, 0;
(EngineCore_DP0 pid=484861) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=484861) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=484861) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=484861) 	shl.b32 	%r3, %r2, 2;
(EngineCore_DP0 pid=484861) 	and.b32 	%r4, %r2, 31;
(EngineCore_DP0 pid=484861) 	shr.u32 	%r31, %r2, 3;
(EngineCore_DP0 pid=484861) 	and.b32 	%r32, %r31, 124;
(EngineCore_DP0 pid=484861) 	mov.b32 	%r33, global_smem;
(EngineCore_DP0 pid=484861) 	add.s32 	%r39, %r33, %r32;
(EngineCore_DP0 pid=484861) 	add.s32 	%r42, %r33, %r3;
(EngineCore_DP0 pid=484861) 	mov.b32 	%r37, 0;
(EngineCore_DP0 pid=484861) 	mov.b32 	%r111, 0f00000000;
(EngineCore_DP0 pid=484861) 	setp.lt.u32 	%p4, %r2, 32;
(EngineCore_DP0 pid=484861) 	setp.eq.b32 	%p3, %r4, 0;
(EngineCore_DP0 pid=484861) 	mov.b32 	%r112, %r37;
(EngineCore_DP0 pid=484861) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=484861) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=484861) 	add.s32 	%r45, %r3, %r112;
(EngineCore_DP0 pid=484861) 	setp.lt.s32 	%p2, %r45, %r17;
(EngineCore_DP0 pid=484861) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=484861) 	mad.wide.s32 	%rd6, %r45, 2, %rd1;
(EngineCore_DP0 pid=484861) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	mov.u32 %r35, %r37;
(EngineCore_DP0 pid=484861) 	mov.u32 %r36, %r37;
(EngineCore_DP0 pid=484861) 	@%p2 ld.global.v2.b32 { %r35, %r36 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	mov.b32 	{%rs1, %rs2}, %r35;
(EngineCore_DP0 pid=484861) 	mov.b32 	{%rs3, %rs4}, %r36;
(EngineCore_DP0 pid=484861) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=484861) 	abs.bf16 	%rs5, %rs1;
(EngineCore_DP0 pid=484861) 	abs.bf16 	%rs6, %rs2;
(EngineCore_DP0 pid=484861) 	abs.bf16 	%rs7, %rs3;
(EngineCore_DP0 pid=484861) 	abs.bf16 	%rs8, %rs4;
(EngineCore_DP0 pid=484861) $L__tmp1:
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	bar.sync 	0;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.bf16 	%rs9, %rs5, %rs6;
(EngineCore_DP0 pid=484861) 	max.bf16 	%rs10, %rs9, %rs7;
(EngineCore_DP0 pid=484861) 	max.bf16 	%rs11, %rs10, %rs8;
(EngineCore_DP0 pid=484861) 	cvt.f32.bf16 	%r46, %rs11;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	shfl.sync.bfly.b32 	%r47, %r46, 16, 31, -1;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.f32 	%r48, %r46, %r47;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	shfl.sync.bfly.b32 	%r49, %r48, 8, 31, -1;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.f32 	%r50, %r48, %r49;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	shfl.sync.bfly.b32 	%r51, %r50, 4, 31, -1;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.f32 	%r52, %r50, %r51;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	shfl.sync.bfly.b32 	%r53, %r52, 2, 31, -1;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.f32 	%r54, %r52, %r53;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	shfl.sync.bfly.b32 	%r55, %r54, 1, 31, -1;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.f32 	%r40, %r54, %r55;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	@%p3 st.shared.b32 [ %r39 + 0 ], %r40;
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	bar.sync 	0;
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	@%p4 ld.shared.b32 %r41, [ %r42 + 0 ];
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	shfl.sync.bfly.b32 	%r56, %r41, 16, 31, -1;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.f32 	%r57, %r41, %r56;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	shfl.sync.bfly.b32 	%r58, %r57, 8, 31, -1;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.f32 	%r59, %r57, %r58;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	shfl.sync.bfly.b32 	%r60, %r59, 4, 31, -1;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.f32 	%r61, %r59, %r60;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	shfl.sync.bfly.b32 	%r62, %r61, 2, 31, -1;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.f32 	%r63, %r61, %r62;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	shfl.sync.bfly.b32 	%r64, %r63, 1, 31, -1;
(EngineCore_DP0 pid=484861) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	max.f32 	%r44, %r63, %r64;
(EngineCore_DP0 pid=484861) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	@%p19 st.shared.b32 [ %r42 + 0 ], %r44;
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	bar.sync 	0;
(EngineCore_DP0 pid=484861) 	ld.shared.b32 	%r65, [global_smem];
(EngineCore_DP0 pid=484861) $L__tmp2:
(EngineCore_DP0 pid=484861) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=484861) 	max.f32 	%r111, %r111, %r65;
(EngineCore_DP0 pid=484861) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=484861) 	add.s32 	%r112, %r112, 4096;
(EngineCore_DP0 pid=484861) 	setp.lt.s32 	%p6, %r112, %r18;
(EngineCore_DP0 pid=484861) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=484861) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=484861) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=484861) 	max.f32 	%r113, %r111, 0f2B8CBCCC;
(EngineCore_DP0 pid=484861) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=484861) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=484861) 	mov.b32 	%r67, 0f43E00000;
(EngineCore_DP0 pid=484861) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=484861) 	div.full.f32 	%r68, %r113, %r67;
(EngineCore_DP0 pid=484861) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=484861) 	max.f32 	%r66, %r68, 0f36924925;
(EngineCore_DP0 pid=484861) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=484861) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=484861) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	@%p19 st.global.b32 [ %rd7 + 0 ], { %r66 };
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=484861) 	mul.lo.s32 	%r14, %r19, 3;
(EngineCore_DP0 pid=484861) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=484861) 	setp.lt.s32 	%p8, %r14, 1;
(EngineCore_DP0 pid=484861) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=484861) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=484861) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=484861) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=484861) 	shr.s32 	%r24, %r23, 31;
(EngineCore_DP0 pid=484861) 	shr.u32 	%r25, %r24, 30;
(EngineCore_DP0 pid=484861) 	add.s32 	%r26, %r23, %r25;
(EngineCore_DP0 pid=484861) 	shr.s32 	%r27, %r26, 2;
(EngineCore_DP0 pid=484861) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=484861) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=484861) 	mad.wide.s32 	%rd2, %r28, 4, %rd5;
(EngineCore_DP0 pid=484861) 	div.full.f32 	%r13, %r67, %r113;
(EngineCore_DP0 pid=484861) 	mov.b32 	%r114, 0;
(EngineCore_DP0 pid=484861) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=484861)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=484861) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=484861) 	add.s32 	%r80, %r2, %r114;
(EngineCore_DP0 pid=484861) 	setp.lt.s32 	%p13, %r80, %r14;
(EngineCore_DP0 pid=484861) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=484861) 	mul.hi.s32 	%r81, %r80, 1431655766;
(EngineCore_DP0 pid=484861) 	shr.u32 	%r82, %r81, 31;
(EngineCore_DP0 pid=484861) 	add.s32 	%r83, %r81, %r82;
(EngineCore_DP0 pid=484861) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=484861) 	mul.lo.s32 	%r84, %r83, 3;
(EngineCore_DP0 pid=484861) 	sub.s32 	%r85, %r80, %r84;
(EngineCore_DP0 pid=484861) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=484861) 	shl.b32 	%r86, %r83, 3;
(EngineCore_DP0 pid=484861) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=484861) 	shl.b32 	%r87, %r85, 1;
(EngineCore_DP0 pid=484861) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=484861) 	add.s32 	%r88, %r86, %r87;
(EngineCore_DP0 pid=484861) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=484861) 	setp.lt.s32 	%p14, %r88, %r17;
(EngineCore_DP0 pid=484861) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=484861) 	and.pred 	%p9, %p13, %p14;
(EngineCore_DP0 pid=484861) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=484861) 	mad.wide.s32 	%rd8, %r88, 2, %rd1;
(EngineCore_DP0 pid=484861) 	mov.b16 	%rs13, 0;
(EngineCore_DP0 pid=484861) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	mov.u16 %rs12, %rs13;
(EngineCore_DP0 pid=484861) 	@%p9 ld.global.b16 { %rs12 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=484861) 	cvt.f32.bf16 	%r89, %rs12;
(EngineCore_DP0 pid=484861) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=484861) 	or.b32 	%r90, %r88, 1;
(EngineCore_DP0 pid=484861) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=484861) 	setp.lt.s32 	%p15, %r90, %r17;
(EngineCore_DP0 pid=484861) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=484861) 	and.pred 	%p10, %p13, %p15;
(EngineCore_DP0 pid=484861) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=484861) 	add.s64 	%rd9, %rd8, 2;
(EngineCore_DP0 pid=484861) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	mov.u16 %rs14, %rs13;
(EngineCore_DP0 pid=484861) 	@%p10 ld.global.b16 { %rs14 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=484861) 	cvt.f32.bf16 	%r91, %rs14;
(EngineCore_DP0 pid=484861) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=484861) 	add.s32 	%r92, %r88, 2;
(EngineCore_DP0 pid=484861) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=484861) 	setp.lt.s32 	%p16, %r92, %r17;
(EngineCore_DP0 pid=484861) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=484861) 	and.pred 	%p11, %p13, %p16;
(EngineCore_DP0 pid=484861) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=484861) 	add.s64 	%rd10, %rd8, 4;
(EngineCore_DP0 pid=484861) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	mov.u16 %rs16, %rs13;
(EngineCore_DP0 pid=484861) 	@%p11 ld.global.b16 { %rs16 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=484861) 	cvt.f32.bf16 	%r93, %rs16;
(EngineCore_DP0 pid=484861) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=484861) 	add.s32 	%r94, %r88, 3;
(EngineCore_DP0 pid=484861) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=484861) 	setp.lt.s32 	%p17, %r94, %r17;
(EngineCore_DP0 pid=484861) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=484861) 	and.pred 	%p12, %p13, %p17;
(EngineCore_DP0 pid=484861) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=484861) 	add.s64 	%rd11, %rd8, 6;
(EngineCore_DP0 pid=484861) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	mov.u16 %rs18, %rs13;
(EngineCore_DP0 pid=484861) 	@%p12 ld.global.b16 { %rs18 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=484861) 	cvt.f32.bf16 	%r95, %rs18;
(EngineCore_DP0 pid=484861) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=484861) 	mul.f32 	%r96, %r13, %r89;
(EngineCore_DP0 pid=484861) 	mov.b32 	%r97, 0f43E00000;
(EngineCore_DP0 pid=484861) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=484861) 	min.xorsign.abs.f32 	%r70, %r96, %r97;
(EngineCore_DP0 pid=484861) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	cvt.rn.satfinite.e4m3x2.f32  %rs20, %r71, %r70; 
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=484861) 	mul.f32 	%r98, %r13, %r91;
(EngineCore_DP0 pid=484861) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=484861) 	min.xorsign.abs.f32 	%r72, %r98, %r97;
(EngineCore_DP0 pid=484861) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	cvt.rn.satfinite.e4m3x2.f32  %rs21, %r73, %r72; 
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=484861) 	mul.f32 	%r99, %r13, %r93;
(EngineCore_DP0 pid=484861) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=484861) 	min.xorsign.abs.f32 	%r74, %r99, %r97;
(EngineCore_DP0 pid=484861) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	cvt.rn.satfinite.e4m3x2.f32  %rs22, %r75, %r74; 
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=484861) 	mul.f32 	%r100, %r13, %r95;
(EngineCore_DP0 pid=484861) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=484861) 	min.xorsign.abs.f32 	%r76, %r100, %r97;
(EngineCore_DP0 pid=484861) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	cvt.rn.satfinite.e4m3x2.f32  %rs23, %r77, %r76; 
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=484861) 	cvt.u32.u16 	%r101, %rs20;
(EngineCore_DP0 pid=484861) 	and.b32 	%r102, %r101, 255;
(EngineCore_DP0 pid=484861) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=484861) 	cvt.u32.u16 	%r103, %rs22;
(EngineCore_DP0 pid=484861) 	and.b32 	%r104, %r103, 255;
(EngineCore_DP0 pid=484861) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=484861) 	cvt.u32.u16 	%r105, %rs23;
(EngineCore_DP0 pid=484861) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=484861) 	and.b16 	%rs24, %rs21, 255;
(EngineCore_DP0 pid=484861) 	mul.wide.u16 	%r106, %rs24, 256;
(EngineCore_DP0 pid=484861) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=484861) 	or.b32 	%r107, %r106, %r102;
(EngineCore_DP0 pid=484861) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=484861) 	shl.b32 	%r108, %r104, 16;
(EngineCore_DP0 pid=484861) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=484861) 	or.b32 	%r109, %r107, %r108;
(EngineCore_DP0 pid=484861) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=484861) 	shl.b32 	%r110, %r105, 24;
(EngineCore_DP0 pid=484861) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=484861) 	or.b32 	%r78, %r109, %r110;
(EngineCore_DP0 pid=484861) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=484861) 	mad.wide.s32 	%rd12, %r80, 4, %rd2;
(EngineCore_DP0 pid=484861) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=484861) 	// begin inline asm
(EngineCore_DP0 pid=484861) 	@%p13 st.global.b32 [ %rd12 + 0 ], { %r78 };
(EngineCore_DP0 pid=484861) 	// end inline asm
(EngineCore_DP0 pid=484861) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=484861) 	add.s32 	%r114, %r114, 1024;
(EngineCore_DP0 pid=484861) 	setp.lt.s32 	%p18, %r114, %r14;
(EngineCore_DP0 pid=484861) 	@%p18 bra 	$L__BB0_6;
(EngineCore_DP0 pid=484861) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=484861) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=484861) 	ret;
(EngineCore_DP0 pid=484861) $L__tmp3:
(EngineCore_DP0 pid=484861) $L__func_end0:
(EngineCore_DP0 pid=484861)                                         // -- End function
(EngineCore_DP0 pid=484861) }
(EngineCore_DP0 pid=484861) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=484861) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=484861) 	.section	.debug_abbrev
(EngineCore_DP0 pid=484861) 	{
(EngineCore_DP0 pid=484861) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=484861) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=484861) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=484861) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=484861) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=484861) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=484861) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=484861) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=484861) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=484861) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=484861) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=484861) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=484861) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=484861) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=484861) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=484861) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=484861) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=484861) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=484861) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=484861) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=484861) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=484861) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=484861) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=484861) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=484861) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=484861) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=484861) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=484861) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=484861) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=484861) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=484861) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=484861) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=484861) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=484861) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=484861) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=484861) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=484861) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=484861) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=484861) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=484861) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=484861) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=484861) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=484861) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=484861) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=484861) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=484861) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=484861) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=484861) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=484861) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=484861) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=484861) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=484861) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=484861) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=484861) 	}
(EngineCore_DP0 pid=484861) 	.section	.debug_info
(EngineCore_DP0 pid=484861) 	{
(EngineCore_DP0 pid=484861) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=484861) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=484861) .b8 0
(EngineCore_DP0 pid=484861) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=484861) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=484861) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=484861) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=484861) .b8 114
(EngineCore_DP0 pid=484861) .b8 105
(EngineCore_DP0 pid=484861) .b8 116
(EngineCore_DP0 pid=484861) .b8 111
(EngineCore_DP0 pid=484861) .b8 110
(EngineCore_DP0 pid=484861) .b8 0
(EngineCore_DP0 pid=484861) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=484861) .b8 0
(EngineCore_DP0 pid=484861) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=484861) .b8 117
(EngineCore_DP0 pid=484861) .b8 97
(EngineCore_DP0 pid=484861) .b8 110
(EngineCore_DP0 pid=484861) .b8 116
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 115
(EngineCore_DP0 pid=484861) .b8 108
(EngineCore_DP0 pid=484861) .b8 105
(EngineCore_DP0 pid=484861) .b8 100
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 116
(EngineCore_DP0 pid=484861) .b8 117
(EngineCore_DP0 pid=484861) .b8 110
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 100
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 81
(EngineCore_DP0 pid=484861) .b8 119
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 110
(EngineCore_DP0 pid=484861) .b8 50
(EngineCore_DP0 pid=484861) .b8 46
(EngineCore_DP0 pid=484861) .b8 53
(EngineCore_DP0 pid=484861) .b8 45
(EngineCore_DP0 pid=484861) .b8 55
(EngineCore_DP0 pid=484861) .b8 66
(EngineCore_DP0 pid=484861) .b8 46
(EngineCore_DP0 pid=484861) .b8 112
(EngineCore_DP0 pid=484861) .b8 121
(EngineCore_DP0 pid=484861) .b8 0
(EngineCore_DP0 pid=484861) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=484861) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=484861) .b8 114
(EngineCore_DP0 pid=484861) .b8 111
(EngineCore_DP0 pid=484861) .b8 111
(EngineCore_DP0 pid=484861) .b8 116
(EngineCore_DP0 pid=484861) .b8 47
(EngineCore_DP0 pid=484861) .b8 118
(EngineCore_DP0 pid=484861) .b8 108
(EngineCore_DP0 pid=484861) .b8 108
(EngineCore_DP0 pid=484861) .b8 109
(EngineCore_DP0 pid=484861) .b8 98
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 110
(EngineCore_DP0 pid=484861) .b8 99
(EngineCore_DP0 pid=484861) .b8 104
(EngineCore_DP0 pid=484861) .b8 47
(EngineCore_DP0 pid=484861) .b8 115
(EngineCore_DP0 pid=484861) .b8 108
(EngineCore_DP0 pid=484861) .b8 105
(EngineCore_DP0 pid=484861) .b8 100
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 115
(EngineCore_DP0 pid=484861) .b8 112
(EngineCore_DP0 pid=484861) .b8 97
(EngineCore_DP0 pid=484861) .b8 114
(EngineCore_DP0 pid=484861) .b8 115
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 47
(EngineCore_DP0 pid=484861) .b8 99
(EngineCore_DP0 pid=484861) .b8 115
(EngineCore_DP0 pid=484861) .b8 114
(EngineCore_DP0 pid=484861) .b8 99
(EngineCore_DP0 pid=484861) .b8 47
(EngineCore_DP0 pid=484861) .b8 102
(EngineCore_DP0 pid=484861) .b8 117
(EngineCore_DP0 pid=484861) .b8 115
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 100
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 113
(EngineCore_DP0 pid=484861) .b8 117
(EngineCore_DP0 pid=484861) .b8 97
(EngineCore_DP0 pid=484861) .b8 110
(EngineCore_DP0 pid=484861) .b8 116
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 115
(EngineCore_DP0 pid=484861) .b8 108
(EngineCore_DP0 pid=484861) .b8 105
(EngineCore_DP0 pid=484861) .b8 100
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 116
(EngineCore_DP0 pid=484861) .b8 114
(EngineCore_DP0 pid=484861) .b8 105
(EngineCore_DP0 pid=484861) .b8 116
(EngineCore_DP0 pid=484861) .b8 111
(EngineCore_DP0 pid=484861) .b8 110
(EngineCore_DP0 pid=484861) .b8 47
(EngineCore_DP0 pid=484861) .b8 98
(EngineCore_DP0 pid=484861) .b8 117
(EngineCore_DP0 pid=484861) .b8 105
(EngineCore_DP0 pid=484861) .b8 108
(EngineCore_DP0 pid=484861) .b8 100
(EngineCore_DP0 pid=484861) .b8 47
(EngineCore_DP0 pid=484861) .b8 71
(EngineCore_DP0 pid=484861) .b8 66
(EngineCore_DP0 pid=484861) .b8 49
(EngineCore_DP0 pid=484861) .b8 48
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 99
(EngineCore_DP0 pid=484861) .b8 99
(EngineCore_DP0 pid=484861) .b8 49
(EngineCore_DP0 pid=484861) .b8 50
(EngineCore_DP0 pid=484861) .b8 49
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 112
(EngineCore_DP0 pid=484861) .b8 121
(EngineCore_DP0 pid=484861) .b8 51
(EngineCore_DP0 pid=484861) .b8 49
(EngineCore_DP0 pid=484861) .b8 50
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 99
(EngineCore_DP0 pid=484861) .b8 117
(EngineCore_DP0 pid=484861) .b8 49
(EngineCore_DP0 pid=484861) .b8 50
(EngineCore_DP0 pid=484861) .b8 57
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 97
(EngineCore_DP0 pid=484861) .b8 97
(EngineCore_DP0 pid=484861) .b8 114
(EngineCore_DP0 pid=484861) .b8 99
(EngineCore_DP0 pid=484861) .b8 104
(EngineCore_DP0 pid=484861) .b8 54
(EngineCore_DP0 pid=484861) .b8 52
(EngineCore_DP0 pid=484861) .b8 0
(EngineCore_DP0 pid=484861) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=484861) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=484861) .b8 113
(EngineCore_DP0 pid=484861) .b8 117
(EngineCore_DP0 pid=484861) .b8 97
(EngineCore_DP0 pid=484861) .b8 110
(EngineCore_DP0 pid=484861) .b8 116
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 115
(EngineCore_DP0 pid=484861) .b8 108
(EngineCore_DP0 pid=484861) .b8 105
(EngineCore_DP0 pid=484861) .b8 100
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 102
(EngineCore_DP0 pid=484861) .b8 112
(EngineCore_DP0 pid=484861) .b8 56
(EngineCore_DP0 pid=484861) .b8 95
(EngineCore_DP0 pid=484861) .b8 107
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 114
(EngineCore_DP0 pid=484861) .b8 110
(EngineCore_DP0 pid=484861) .b8 101
(EngineCore_DP0 pid=484861) .b8 108
(EngineCore_DP0 pid=484861) .b8 0
(EngineCore_DP0 pid=484861) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=484861) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=484861) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=484861) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=484861) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=484861) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=484861) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=484861) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=484861) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=484861) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=484861) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=484861) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=484861) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=484861) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=484861) 	}
(EngineCore_DP0 pid=484861) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) ================================================================
(EngineCore_DP0 pid=484861) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpghehsd_f.ptx', '-o', '/tmp/tmpghehsd_f.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] 
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] 
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] 
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpghehsd_f.ptx -o /tmp/tmpghehsd_f.ptx.o
(EngineCore_DP0 pid=484861) ERROR 01-25 21:36:30 [core.py:866] 

STDERR:
[2026-01-25 21:35:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:35:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:35:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:35:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:35:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:35:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:35:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:35:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:35:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:35:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:35:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:35:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:35:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:35:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:35:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:35:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:35:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=484861) [2026-01-25 21:35:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=484861) [2026-01-25 21:35:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=484861) [2026-01-25 21:35:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=484861) [2026-01-25 21:35:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=484861) [2026-01-25 21:35:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=484861) [2026-01-25 21:35:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=484861) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=484861) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.42s/it]
(EngineCore_DP0 pid=484861) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.63s/it]
(EngineCore_DP0 pid=484861) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.15s/it]
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) [2026-01-25 21:36:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=484861) [2026-01-25 21:36:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=484861) [2026-01-25 21:36:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=484861) [2026-01-25 21:36:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=484861) [2026-01-25 21:36:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=484861) [2026-01-25 21:36:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=484861) [2026-01-25 21:36:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=484861) [2026-01-25 21:36:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=484861) Process EngineCore_DP0:
(EngineCore_DP0 pid=484861) Traceback (most recent call last):
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=484861)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=484861)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=484861)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=484861) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpghehsd_f.ptx', '-o', '/tmp/tmpghehsd_f.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) Traceback (most recent call last):
(EngineCore_DP0 pid=484861)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=484861)     self.run()
(EngineCore_DP0 pid=484861)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=484861)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=484861)     raise e
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=484861)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=484861)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=484861)     super().__init__(
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=484861)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=484861)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=484861)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=484861)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=484861)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=484861)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=484861)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=484861)     return func(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=484861)     return func(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=484861)     self.model_runner.profile_run()
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=484861)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=484861)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=484861)     return func(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=484861)     outputs = self.model(
(EngineCore_DP0 pid=484861)               ^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=484861)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=484861)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=484861)     hidden_states = self.model(
(EngineCore_DP0 pid=484861)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=484861)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=484861)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=484861)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=484861)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=484861)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=484861)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=484861)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=484861)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=484861)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=484861)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=484861)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=484861)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=484861)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=484861)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=484861)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=484861)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=484861)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=484861)     return self._linear_fn(
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=484861)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=484861)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=484861)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=484861)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=484861)     return fn(input, L)
(EngineCore_DP0 pid=484861)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=484861)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=484861)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=484861)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=484861)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=484861)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=484861)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=484861)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=484861)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=484861)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=484861)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=484861)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=484861)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=484861)     raise PTXASError(error)
(EngineCore_DP0 pid=484861) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=484861) `ptxas` stderr:
(EngineCore_DP0 pid=484861) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=484861) 
(EngineCore_DP0 pid=484861) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpghehsd_f.ptx -o /tmp/tmpghehsd_f.ptx.o
(EngineCore_DP0 pid=484861) 
[rank0]:[W125 21:36:30.721298413 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=1024 ==========
Time: 2026-01-25 21:36:33
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:36:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:36:37 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=486111) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) ================================================================
(EngineCore_DP0 pid=486111) Internal Triton PTX codegen error
(EngineCore_DP0 pid=486111) `ptxas` stderr:
(EngineCore_DP0 pid=486111) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqgjjw4rg.ptx -o /tmp/tmpqgjjw4rg.ptx.o
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) //
(EngineCore_DP0 pid=486111) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=486111) //
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) .version 8.7
(EngineCore_DP0 pid=486111) .target sm_121a
(EngineCore_DP0 pid=486111) .address_size 64
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=486111) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=486111)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=486111) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=486111) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=486111) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=486111) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=486111) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=486111) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=486111) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=486111) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=486111) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=486111) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=486111) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=486111) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=486111) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=486111) )
(EngineCore_DP0 pid=486111) .reqntid 512
(EngineCore_DP0 pid=486111) {
(EngineCore_DP0 pid=486111) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=486111) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=486111) 	.reg .b32 	%r<152>;
(EngineCore_DP0 pid=486111) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=486111) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=486111) $L__func_begin0:
(EngineCore_DP0 pid=486111) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) // %bb.0:
(EngineCore_DP0 pid=486111) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=486111) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=486111) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=486111) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=486111) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=486111) $L__tmp0:
(EngineCore_DP0 pid=486111) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=486111) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=486111) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=486111) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=486111) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=486111) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=486111) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=486111) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=486111) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=486111) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=486111) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=486111) 	mov.b32 	%r150, 0f2B8CBCCC;
(EngineCore_DP0 pid=486111) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=486111) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=486111) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=486111) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=486111) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=486111) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=486111) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=486111) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=486111) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=486111) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=486111) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=486111) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=486111) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=486111) 	mov.b32 	%r148, 0f00000000;
(EngineCore_DP0 pid=486111) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=486111) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=486111) 	mov.b32 	%r149, %r45;
(EngineCore_DP0 pid=486111) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=486111) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=486111) 	add.s32 	%r55, %r4, %r149;
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=486111) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=486111) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=486111) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=486111) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=486111) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=486111) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=486111) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=486111) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=486111) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=486111) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=486111) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=486111) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=486111) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=486111) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=486111) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=486111) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=486111) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=486111) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=486111) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=486111) $L__tmp1:
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	bar.sync 	0;
(EngineCore_DP0 pid=486111) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=486111) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=486111) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=486111) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=486111) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=486111) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=486111) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=486111) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=486111) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=486111) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=486111) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=486111) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=486111) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	bar.sync 	0;
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=486111) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=486111) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=486111) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=486111) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=486111) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	bar.sync 	0;
(EngineCore_DP0 pid=486111) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=486111) $L__tmp2:
(EngineCore_DP0 pid=486111) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=486111) 	max.f32 	%r148, %r148, %r73;
(EngineCore_DP0 pid=486111) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=486111) 	add.s32 	%r149, %r149, 4096;
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p6, %r149, %r24;
(EngineCore_DP0 pid=486111) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=486111) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=486111) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=486111) 	max.f32 	%r150, %r148, 0f2B8CBCCC;
(EngineCore_DP0 pid=486111) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=486111) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=486111) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=486111) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=486111) 	div.full.f32 	%r76, %r150, %r75;
(EngineCore_DP0 pid=486111) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=486111) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=486111) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=486111) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=486111) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=486111) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=486111) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=486111) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=486111) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=486111) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=486111) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=486111) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=486111) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=486111) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=486111) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=486111) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=486111) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=486111) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=486111) 	div.full.f32 	%r14, %r75, %r150;
(EngineCore_DP0 pid=486111) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=486111) 	mov.b32 	%r151, 0;
(EngineCore_DP0 pid=486111) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=486111)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=486111) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=486111) 	add.s32 	%r89, %r16, %r151;
(EngineCore_DP0 pid=486111) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=486111) 	add.s32 	%r90, %r89, 1;
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p17, %r89, %r15;
(EngineCore_DP0 pid=486111) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=486111) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=486111) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=486111) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=486111) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=486111) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=486111) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=486111) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=486111) 	mul.lo.s32 	%r97, %r96, 3;
(EngineCore_DP0 pid=486111) 	mul.lo.s32 	%r98, %r93, 3;
(EngineCore_DP0 pid=486111) 	sub.s32 	%r99, %r90, %r98;
(EngineCore_DP0 pid=486111) 	sub.s32 	%r100, %r89, %r97;
(EngineCore_DP0 pid=486111) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=486111) 	shl.b32 	%r101, %r96, 3;
(EngineCore_DP0 pid=486111) 	shl.b32 	%r102, %r93, 3;
(EngineCore_DP0 pid=486111) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=486111) 	shl.b32 	%r103, %r100, 1;
(EngineCore_DP0 pid=486111) 	shl.b32 	%r104, %r99, 1;
(EngineCore_DP0 pid=486111) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=486111) 	add.s32 	%r105, %r102, %r104;
(EngineCore_DP0 pid=486111) 	add.s32 	%r106, %r101, %r103;
(EngineCore_DP0 pid=486111) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p18, %r106, %r23;
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p19, %r105, %r23;
(EngineCore_DP0 pid=486111) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=486111) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=486111) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=486111) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=486111) 	mad.wide.s32 	%rd8, %r106, 2, %rd1;
(EngineCore_DP0 pid=486111) 	mad.wide.s32 	%rd9, %r105, 2, %rd1;
(EngineCore_DP0 pid=486111) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=486111) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=486111) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=486111) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=486111) 	cvt.f32.bf16 	%r107, %rs24;
(EngineCore_DP0 pid=486111) 	cvt.f32.bf16 	%r108, %rs26;
(EngineCore_DP0 pid=486111) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=486111) 	or.b32 	%r109, %r106, 1;
(EngineCore_DP0 pid=486111) 	or.b32 	%r110, %r105, 1;
(EngineCore_DP0 pid=486111) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p20, %r109, %r23;
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p21, %r110, %r23;
(EngineCore_DP0 pid=486111) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=486111) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=486111) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=486111) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=486111) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=486111) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=486111) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=486111) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=486111) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=486111) 	cvt.f32.bf16 	%r111, %rs28;
(EngineCore_DP0 pid=486111) 	cvt.f32.bf16 	%r112, %rs30;
(EngineCore_DP0 pid=486111) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=486111) 	add.s32 	%r113, %r106, 2;
(EngineCore_DP0 pid=486111) 	add.s32 	%r114, %r105, 2;
(EngineCore_DP0 pid=486111) 	add.s32 	%r115, %r106, 3;
(EngineCore_DP0 pid=486111) 	add.s32 	%r116, %r105, 3;
(EngineCore_DP0 pid=486111) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p22, %r116, %r23;
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p23, %r115, %r23;
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p24, %r114, %r23;
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p25, %r113, %r23;
(EngineCore_DP0 pid=486111) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=486111) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=486111) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=486111) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=486111) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=486111) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=486111) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=486111) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=486111) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=486111) 	cvt.f32.bf16 	%r117, %rs32;
(EngineCore_DP0 pid=486111) 	cvt.f32.bf16 	%r118, %rs34;
(EngineCore_DP0 pid=486111) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=486111) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=486111) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=486111) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=486111) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=486111) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=486111) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=486111) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=486111) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=486111) 	cvt.f32.bf16 	%r119, %rs36;
(EngineCore_DP0 pid=486111) 	cvt.f32.bf16 	%r120, %rs38;
(EngineCore_DP0 pid=486111) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=486111) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=486111) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=486111) 	mov.b32 	%r123, 0f43E00000;
(EngineCore_DP0 pid=486111) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=486111) 	min.xorsign.abs.f32 	%r78, %r121, %r123;
(EngineCore_DP0 pid=486111) 	min.xorsign.abs.f32 	%r79, %r122, %r123;
(EngineCore_DP0 pid=486111) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=486111) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=486111) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=486111) 	mul.f32 	%r125, %r14, %r112;
(EngineCore_DP0 pid=486111) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=486111) 	min.xorsign.abs.f32 	%r80, %r124, %r123;
(EngineCore_DP0 pid=486111) 	min.xorsign.abs.f32 	%r81, %r125, %r123;
(EngineCore_DP0 pid=486111) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=486111) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=486111) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=486111) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=486111) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=486111) 	min.xorsign.abs.f32 	%r82, %r126, %r123;
(EngineCore_DP0 pid=486111) 	min.xorsign.abs.f32 	%r83, %r127, %r123;
(EngineCore_DP0 pid=486111) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=486111) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=486111) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=486111) 	mul.f32 	%r129, %r14, %r120;
(EngineCore_DP0 pid=486111) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=486111) 	min.xorsign.abs.f32 	%r84, %r128, %r123;
(EngineCore_DP0 pid=486111) 	min.xorsign.abs.f32 	%r85, %r129, %r123;
(EngineCore_DP0 pid=486111) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=486111) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=486111) 	cvt.u32.u16 	%r130, %rs40;
(EngineCore_DP0 pid=486111) 	and.b32 	%r131, %r130, 255;
(EngineCore_DP0 pid=486111) 	cvt.u32.u16 	%r132, %rs44;
(EngineCore_DP0 pid=486111) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=486111) 	cvt.u32.u16 	%r133, %rs42;
(EngineCore_DP0 pid=486111) 	and.b32 	%r134, %r133, 255;
(EngineCore_DP0 pid=486111) 	cvt.u32.u16 	%r135, %rs46;
(EngineCore_DP0 pid=486111) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=486111) 	cvt.u32.u16 	%r136, %rs43;
(EngineCore_DP0 pid=486111) 	cvt.u32.u16 	%r137, %rs47;
(EngineCore_DP0 pid=486111) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=486111) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=486111) 	mul.wide.u16 	%r138, %rs48, 256;
(EngineCore_DP0 pid=486111) 	mul.wide.u16 	%r139, %rs45, 256;
(EngineCore_DP0 pid=486111) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=486111) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=486111) 	or.b32 	%r141, %r139, %r132;
(EngineCore_DP0 pid=486111) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=486111) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=486111) 	shl.b32 	%r143, %r135, 16;
(EngineCore_DP0 pid=486111) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=486111) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=486111) 	or.b32 	%r145, %r141, %r143;
(EngineCore_DP0 pid=486111) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=486111) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=486111) 	shl.b32 	%r147, %r137, 24;
(EngineCore_DP0 pid=486111) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=486111) 	or.b32 	%r86, %r144, %r146;
(EngineCore_DP0 pid=486111) 	or.b32 	%r87, %r145, %r147;
(EngineCore_DP0 pid=486111) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=486111) 	mad.wide.s32 	%rd16, %r89, 4, %rd2;
(EngineCore_DP0 pid=486111) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=486111) 	// begin inline asm
(EngineCore_DP0 pid=486111) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=486111) 	// end inline asm
(EngineCore_DP0 pid=486111) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=486111) 	add.s32 	%r151, %r151, 1024;
(EngineCore_DP0 pid=486111) 	setp.lt.s32 	%p26, %r151, %r15;
(EngineCore_DP0 pid=486111) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=486111) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=486111) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=486111) 	ret;
(EngineCore_DP0 pid=486111) $L__tmp3:
(EngineCore_DP0 pid=486111) $L__func_end0:
(EngineCore_DP0 pid=486111)                                         // -- End function
(EngineCore_DP0 pid=486111) }
(EngineCore_DP0 pid=486111) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=486111) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=486111) 	.section	.debug_abbrev
(EngineCore_DP0 pid=486111) 	{
(EngineCore_DP0 pid=486111) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=486111) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=486111) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=486111) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=486111) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=486111) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=486111) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=486111) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=486111) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=486111) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=486111) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=486111) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=486111) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=486111) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=486111) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=486111) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=486111) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=486111) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=486111) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=486111) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=486111) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=486111) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=486111) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=486111) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=486111) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=486111) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=486111) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=486111) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=486111) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=486111) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=486111) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=486111) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=486111) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=486111) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=486111) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=486111) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=486111) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=486111) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=486111) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=486111) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=486111) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=486111) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=486111) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=486111) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=486111) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=486111) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=486111) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=486111) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=486111) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=486111) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=486111) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=486111) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=486111) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=486111) 	}
(EngineCore_DP0 pid=486111) 	.section	.debug_info
(EngineCore_DP0 pid=486111) 	{
(EngineCore_DP0 pid=486111) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=486111) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=486111) .b8 0
(EngineCore_DP0 pid=486111) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=486111) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=486111) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=486111) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=486111) .b8 114
(EngineCore_DP0 pid=486111) .b8 105
(EngineCore_DP0 pid=486111) .b8 116
(EngineCore_DP0 pid=486111) .b8 111
(EngineCore_DP0 pid=486111) .b8 110
(EngineCore_DP0 pid=486111) .b8 0
(EngineCore_DP0 pid=486111) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=486111) .b8 0
(EngineCore_DP0 pid=486111) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=486111) .b8 117
(EngineCore_DP0 pid=486111) .b8 97
(EngineCore_DP0 pid=486111) .b8 110
(EngineCore_DP0 pid=486111) .b8 116
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 115
(EngineCore_DP0 pid=486111) .b8 108
(EngineCore_DP0 pid=486111) .b8 105
(EngineCore_DP0 pid=486111) .b8 100
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 116
(EngineCore_DP0 pid=486111) .b8 117
(EngineCore_DP0 pid=486111) .b8 110
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 100
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 81
(EngineCore_DP0 pid=486111) .b8 119
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 110
(EngineCore_DP0 pid=486111) .b8 50
(EngineCore_DP0 pid=486111) .b8 46
(EngineCore_DP0 pid=486111) .b8 53
(EngineCore_DP0 pid=486111) .b8 45
(EngineCore_DP0 pid=486111) .b8 55
(EngineCore_DP0 pid=486111) .b8 66
(EngineCore_DP0 pid=486111) .b8 46
(EngineCore_DP0 pid=486111) .b8 112
(EngineCore_DP0 pid=486111) .b8 121
(EngineCore_DP0 pid=486111) .b8 0
(EngineCore_DP0 pid=486111) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=486111) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=486111) .b8 114
(EngineCore_DP0 pid=486111) .b8 111
(EngineCore_DP0 pid=486111) .b8 111
(EngineCore_DP0 pid=486111) .b8 116
(EngineCore_DP0 pid=486111) .b8 47
(EngineCore_DP0 pid=486111) .b8 118
(EngineCore_DP0 pid=486111) .b8 108
(EngineCore_DP0 pid=486111) .b8 108
(EngineCore_DP0 pid=486111) .b8 109
(EngineCore_DP0 pid=486111) .b8 98
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 110
(EngineCore_DP0 pid=486111) .b8 99
(EngineCore_DP0 pid=486111) .b8 104
(EngineCore_DP0 pid=486111) .b8 47
(EngineCore_DP0 pid=486111) .b8 115
(EngineCore_DP0 pid=486111) .b8 108
(EngineCore_DP0 pid=486111) .b8 105
(EngineCore_DP0 pid=486111) .b8 100
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 115
(EngineCore_DP0 pid=486111) .b8 112
(EngineCore_DP0 pid=486111) .b8 97
(EngineCore_DP0 pid=486111) .b8 114
(EngineCore_DP0 pid=486111) .b8 115
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 47
(EngineCore_DP0 pid=486111) .b8 99
(EngineCore_DP0 pid=486111) .b8 115
(EngineCore_DP0 pid=486111) .b8 114
(EngineCore_DP0 pid=486111) .b8 99
(EngineCore_DP0 pid=486111) .b8 47
(EngineCore_DP0 pid=486111) .b8 102
(EngineCore_DP0 pid=486111) .b8 117
(EngineCore_DP0 pid=486111) .b8 115
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 100
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 113
(EngineCore_DP0 pid=486111) .b8 117
(EngineCore_DP0 pid=486111) .b8 97
(EngineCore_DP0 pid=486111) .b8 110
(EngineCore_DP0 pid=486111) .b8 116
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 115
(EngineCore_DP0 pid=486111) .b8 108
(EngineCore_DP0 pid=486111) .b8 105
(EngineCore_DP0 pid=486111) .b8 100
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 116
(EngineCore_DP0 pid=486111) .b8 114
(EngineCore_DP0 pid=486111) .b8 105
(EngineCore_DP0 pid=486111) .b8 116
(EngineCore_DP0 pid=486111) .b8 111
(EngineCore_DP0 pid=486111) .b8 110
(EngineCore_DP0 pid=486111) .b8 47
(EngineCore_DP0 pid=486111) .b8 98
(EngineCore_DP0 pid=486111) .b8 117
(EngineCore_DP0 pid=486111) .b8 105
(EngineCore_DP0 pid=486111) .b8 108
(EngineCore_DP0 pid=486111) .b8 100
(EngineCore_DP0 pid=486111) .b8 47
(EngineCore_DP0 pid=486111) .b8 71
(EngineCore_DP0 pid=486111) .b8 66
(EngineCore_DP0 pid=486111) .b8 49
(EngineCore_DP0 pid=486111) .b8 48
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 99
(EngineCore_DP0 pid=486111) .b8 99
(EngineCore_DP0 pid=486111) .b8 49
(EngineCore_DP0 pid=486111) .b8 50
(EngineCore_DP0 pid=486111) .b8 49
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 112
(EngineCore_DP0 pid=486111) .b8 121
(EngineCore_DP0 pid=486111) .b8 51
(EngineCore_DP0 pid=486111) .b8 49
(EngineCore_DP0 pid=486111) .b8 50
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 99
(EngineCore_DP0 pid=486111) .b8 117
(EngineCore_DP0 pid=486111) .b8 49
(EngineCore_DP0 pid=486111) .b8 50
(EngineCore_DP0 pid=486111) .b8 57
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 97
(EngineCore_DP0 pid=486111) .b8 97
(EngineCore_DP0 pid=486111) .b8 114
(EngineCore_DP0 pid=486111) .b8 99
(EngineCore_DP0 pid=486111) .b8 104
(EngineCore_DP0 pid=486111) .b8 54
(EngineCore_DP0 pid=486111) .b8 52
(EngineCore_DP0 pid=486111) .b8 0
(EngineCore_DP0 pid=486111) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=486111) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=486111) .b8 113
(EngineCore_DP0 pid=486111) .b8 117
(EngineCore_DP0 pid=486111) .b8 97
(EngineCore_DP0 pid=486111) .b8 110
(EngineCore_DP0 pid=486111) .b8 116
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 115
(EngineCore_DP0 pid=486111) .b8 108
(EngineCore_DP0 pid=486111) .b8 105
(EngineCore_DP0 pid=486111) .b8 100
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 102
(EngineCore_DP0 pid=486111) .b8 112
(EngineCore_DP0 pid=486111) .b8 56
(EngineCore_DP0 pid=486111) .b8 95
(EngineCore_DP0 pid=486111) .b8 107
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 114
(EngineCore_DP0 pid=486111) .b8 110
(EngineCore_DP0 pid=486111) .b8 101
(EngineCore_DP0 pid=486111) .b8 108
(EngineCore_DP0 pid=486111) .b8 0
(EngineCore_DP0 pid=486111) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=486111) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=486111) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=486111) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=486111) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=486111) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=486111) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=486111) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=486111) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=486111) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=486111) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=486111) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=486111) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=486111) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=486111) 	}
(EngineCore_DP0 pid=486111) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) ================================================================
(EngineCore_DP0 pid=486111) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpqgjjw4rg.ptx', '-o', '/tmp/tmpqgjjw4rg.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] 
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] 
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] 
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqgjjw4rg.ptx -o /tmp/tmpqgjjw4rg.ptx.o
(EngineCore_DP0 pid=486111) ERROR 01-25 21:37:44 [core.py:866] 

STDERR:
[2026-01-25 21:36:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:36:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:36:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:36:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:36:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:36:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:36:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:36:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:36:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:36:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:36:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:36:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:36:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:36:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:36:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:36:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:36:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=486111) [2026-01-25 21:36:42] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=486111) [2026-01-25 21:36:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=486111) [2026-01-25 21:36:42] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=486111) [2026-01-25 21:36:42] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=486111) [2026-01-25 21:36:42] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=486111) [2026-01-25 21:36:42] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=486111) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=486111) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.45s/it]
(EngineCore_DP0 pid=486111) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.55s/it]
(EngineCore_DP0 pid=486111) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.09s/it]
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) [2026-01-25 21:37:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=486111) [2026-01-25 21:37:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=486111) [2026-01-25 21:37:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=486111) [2026-01-25 21:37:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=486111) [2026-01-25 21:37:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=486111) [2026-01-25 21:37:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=486111) [2026-01-25 21:37:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=486111) [2026-01-25 21:37:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=486111) Process EngineCore_DP0:
(EngineCore_DP0 pid=486111) Traceback (most recent call last):
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=486111)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=486111)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=486111)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=486111) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpqgjjw4rg.ptx', '-o', '/tmp/tmpqgjjw4rg.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) Traceback (most recent call last):
(EngineCore_DP0 pid=486111)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=486111)     self.run()
(EngineCore_DP0 pid=486111)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=486111)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=486111)     raise e
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=486111)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=486111)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=486111)     super().__init__(
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=486111)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=486111)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=486111)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=486111)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=486111)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=486111)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=486111)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=486111)     return func(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=486111)     return func(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=486111)     self.model_runner.profile_run()
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=486111)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=486111)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=486111)     return func(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=486111)     outputs = self.model(
(EngineCore_DP0 pid=486111)               ^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=486111)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=486111)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=486111)     hidden_states = self.model(
(EngineCore_DP0 pid=486111)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=486111)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=486111)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=486111)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=486111)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=486111)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=486111)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=486111)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=486111)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=486111)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=486111)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=486111)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=486111)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=486111)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=486111)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=486111)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=486111)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=486111)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=486111)     return self._linear_fn(
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=486111)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=486111)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=486111)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=486111)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=486111)     return fn(input, L)
(EngineCore_DP0 pid=486111)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=486111)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=486111)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=486111)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=486111)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=486111)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=486111)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=486111)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=486111)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=486111)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=486111)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=486111)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=486111)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=486111)     raise PTXASError(error)
(EngineCore_DP0 pid=486111) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=486111) `ptxas` stderr:
(EngineCore_DP0 pid=486111) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=486111) 
(EngineCore_DP0 pid=486111) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpqgjjw4rg.ptx -o /tmp/tmpqgjjw4rg.ptx.o
(EngineCore_DP0 pid=486111) 
[rank0]:[W125 21:37:45.270330658 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=1024

========== M=2048 ==========
Time: 2026-01-25 21:37:46
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:37:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:37:51 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=487301) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) ================================================================
(EngineCore_DP0 pid=487301) Internal Triton PTX codegen error
(EngineCore_DP0 pid=487301) `ptxas` stderr:
(EngineCore_DP0 pid=487301) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8l32zlcd.ptx -o /tmp/tmp8l32zlcd.ptx.o
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) //
(EngineCore_DP0 pid=487301) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=487301) //
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) .version 8.7
(EngineCore_DP0 pid=487301) .target sm_121a
(EngineCore_DP0 pid=487301) .address_size 64
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=487301) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=487301)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=487301) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=487301) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=487301) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=487301) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=487301) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=487301) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=487301) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=487301) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=487301) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=487301) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=487301) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=487301) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=487301) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=487301) )
(EngineCore_DP0 pid=487301) .reqntid 512
(EngineCore_DP0 pid=487301) {
(EngineCore_DP0 pid=487301) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=487301) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=487301) 	.reg .b32 	%r<152>;
(EngineCore_DP0 pid=487301) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=487301) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=487301) $L__func_begin0:
(EngineCore_DP0 pid=487301) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) // %bb.0:
(EngineCore_DP0 pid=487301) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=487301) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=487301) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=487301) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=487301) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=487301) $L__tmp0:
(EngineCore_DP0 pid=487301) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=487301) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=487301) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=487301) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=487301) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=487301) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=487301) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=487301) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=487301) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=487301) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=487301) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=487301) 	mov.b32 	%r150, 0f2B8CBCCC;
(EngineCore_DP0 pid=487301) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=487301) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=487301) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=487301) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=487301) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=487301) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=487301) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=487301) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=487301) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=487301) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=487301) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=487301) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=487301) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=487301) 	mov.b32 	%r148, 0f00000000;
(EngineCore_DP0 pid=487301) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=487301) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=487301) 	mov.b32 	%r149, %r45;
(EngineCore_DP0 pid=487301) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=487301) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=487301) 	add.s32 	%r55, %r4, %r149;
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=487301) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=487301) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=487301) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=487301) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=487301) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=487301) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=487301) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=487301) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=487301) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=487301) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=487301) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=487301) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=487301) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=487301) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=487301) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=487301) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=487301) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=487301) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=487301) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=487301) $L__tmp1:
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	bar.sync 	0;
(EngineCore_DP0 pid=487301) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=487301) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=487301) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=487301) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=487301) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=487301) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=487301) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=487301) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=487301) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=487301) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=487301) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=487301) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=487301) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	bar.sync 	0;
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=487301) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=487301) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=487301) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=487301) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=487301) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	bar.sync 	0;
(EngineCore_DP0 pid=487301) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=487301) $L__tmp2:
(EngineCore_DP0 pid=487301) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=487301) 	max.f32 	%r148, %r148, %r73;
(EngineCore_DP0 pid=487301) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=487301) 	add.s32 	%r149, %r149, 4096;
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p6, %r149, %r24;
(EngineCore_DP0 pid=487301) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=487301) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=487301) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=487301) 	max.f32 	%r150, %r148, 0f2B8CBCCC;
(EngineCore_DP0 pid=487301) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=487301) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=487301) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=487301) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=487301) 	div.full.f32 	%r76, %r150, %r75;
(EngineCore_DP0 pid=487301) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=487301) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=487301) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=487301) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=487301) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=487301) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=487301) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=487301) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=487301) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=487301) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=487301) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=487301) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=487301) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=487301) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=487301) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=487301) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=487301) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=487301) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=487301) 	div.full.f32 	%r14, %r75, %r150;
(EngineCore_DP0 pid=487301) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=487301) 	mov.b32 	%r151, 0;
(EngineCore_DP0 pid=487301) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=487301)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=487301) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=487301) 	add.s32 	%r89, %r16, %r151;
(EngineCore_DP0 pid=487301) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=487301) 	add.s32 	%r90, %r89, 1;
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p17, %r89, %r15;
(EngineCore_DP0 pid=487301) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=487301) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=487301) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=487301) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=487301) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=487301) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=487301) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=487301) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=487301) 	mul.lo.s32 	%r97, %r96, 3;
(EngineCore_DP0 pid=487301) 	mul.lo.s32 	%r98, %r93, 3;
(EngineCore_DP0 pid=487301) 	sub.s32 	%r99, %r90, %r98;
(EngineCore_DP0 pid=487301) 	sub.s32 	%r100, %r89, %r97;
(EngineCore_DP0 pid=487301) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=487301) 	shl.b32 	%r101, %r96, 3;
(EngineCore_DP0 pid=487301) 	shl.b32 	%r102, %r93, 3;
(EngineCore_DP0 pid=487301) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=487301) 	shl.b32 	%r103, %r100, 1;
(EngineCore_DP0 pid=487301) 	shl.b32 	%r104, %r99, 1;
(EngineCore_DP0 pid=487301) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=487301) 	add.s32 	%r105, %r102, %r104;
(EngineCore_DP0 pid=487301) 	add.s32 	%r106, %r101, %r103;
(EngineCore_DP0 pid=487301) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p18, %r106, %r23;
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p19, %r105, %r23;
(EngineCore_DP0 pid=487301) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=487301) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=487301) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=487301) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=487301) 	mad.wide.s32 	%rd8, %r106, 2, %rd1;
(EngineCore_DP0 pid=487301) 	mad.wide.s32 	%rd9, %r105, 2, %rd1;
(EngineCore_DP0 pid=487301) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=487301) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=487301) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=487301) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=487301) 	cvt.f32.bf16 	%r107, %rs24;
(EngineCore_DP0 pid=487301) 	cvt.f32.bf16 	%r108, %rs26;
(EngineCore_DP0 pid=487301) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=487301) 	or.b32 	%r109, %r106, 1;
(EngineCore_DP0 pid=487301) 	or.b32 	%r110, %r105, 1;
(EngineCore_DP0 pid=487301) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p20, %r109, %r23;
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p21, %r110, %r23;
(EngineCore_DP0 pid=487301) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=487301) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=487301) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=487301) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=487301) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=487301) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=487301) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=487301) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=487301) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=487301) 	cvt.f32.bf16 	%r111, %rs28;
(EngineCore_DP0 pid=487301) 	cvt.f32.bf16 	%r112, %rs30;
(EngineCore_DP0 pid=487301) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=487301) 	add.s32 	%r113, %r106, 2;
(EngineCore_DP0 pid=487301) 	add.s32 	%r114, %r105, 2;
(EngineCore_DP0 pid=487301) 	add.s32 	%r115, %r106, 3;
(EngineCore_DP0 pid=487301) 	add.s32 	%r116, %r105, 3;
(EngineCore_DP0 pid=487301) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p22, %r116, %r23;
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p23, %r115, %r23;
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p24, %r114, %r23;
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p25, %r113, %r23;
(EngineCore_DP0 pid=487301) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=487301) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=487301) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=487301) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=487301) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=487301) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=487301) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=487301) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=487301) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=487301) 	cvt.f32.bf16 	%r117, %rs32;
(EngineCore_DP0 pid=487301) 	cvt.f32.bf16 	%r118, %rs34;
(EngineCore_DP0 pid=487301) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=487301) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=487301) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=487301) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=487301) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=487301) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=487301) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=487301) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=487301) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=487301) 	cvt.f32.bf16 	%r119, %rs36;
(EngineCore_DP0 pid=487301) 	cvt.f32.bf16 	%r120, %rs38;
(EngineCore_DP0 pid=487301) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=487301) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=487301) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=487301) 	mov.b32 	%r123, 0f43E00000;
(EngineCore_DP0 pid=487301) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=487301) 	min.xorsign.abs.f32 	%r78, %r121, %r123;
(EngineCore_DP0 pid=487301) 	min.xorsign.abs.f32 	%r79, %r122, %r123;
(EngineCore_DP0 pid=487301) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=487301) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=487301) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=487301) 	mul.f32 	%r125, %r14, %r112;
(EngineCore_DP0 pid=487301) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=487301) 	min.xorsign.abs.f32 	%r80, %r124, %r123;
(EngineCore_DP0 pid=487301) 	min.xorsign.abs.f32 	%r81, %r125, %r123;
(EngineCore_DP0 pid=487301) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=487301) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=487301) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=487301) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=487301) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=487301) 	min.xorsign.abs.f32 	%r82, %r126, %r123;
(EngineCore_DP0 pid=487301) 	min.xorsign.abs.f32 	%r83, %r127, %r123;
(EngineCore_DP0 pid=487301) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=487301) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=487301) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=487301) 	mul.f32 	%r129, %r14, %r120;
(EngineCore_DP0 pid=487301) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=487301) 	min.xorsign.abs.f32 	%r84, %r128, %r123;
(EngineCore_DP0 pid=487301) 	min.xorsign.abs.f32 	%r85, %r129, %r123;
(EngineCore_DP0 pid=487301) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=487301) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=487301) 	cvt.u32.u16 	%r130, %rs40;
(EngineCore_DP0 pid=487301) 	and.b32 	%r131, %r130, 255;
(EngineCore_DP0 pid=487301) 	cvt.u32.u16 	%r132, %rs44;
(EngineCore_DP0 pid=487301) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=487301) 	cvt.u32.u16 	%r133, %rs42;
(EngineCore_DP0 pid=487301) 	and.b32 	%r134, %r133, 255;
(EngineCore_DP0 pid=487301) 	cvt.u32.u16 	%r135, %rs46;
(EngineCore_DP0 pid=487301) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=487301) 	cvt.u32.u16 	%r136, %rs43;
(EngineCore_DP0 pid=487301) 	cvt.u32.u16 	%r137, %rs47;
(EngineCore_DP0 pid=487301) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=487301) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=487301) 	mul.wide.u16 	%r138, %rs48, 256;
(EngineCore_DP0 pid=487301) 	mul.wide.u16 	%r139, %rs45, 256;
(EngineCore_DP0 pid=487301) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=487301) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=487301) 	or.b32 	%r141, %r139, %r132;
(EngineCore_DP0 pid=487301) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=487301) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=487301) 	shl.b32 	%r143, %r135, 16;
(EngineCore_DP0 pid=487301) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=487301) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=487301) 	or.b32 	%r145, %r141, %r143;
(EngineCore_DP0 pid=487301) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=487301) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=487301) 	shl.b32 	%r147, %r137, 24;
(EngineCore_DP0 pid=487301) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=487301) 	or.b32 	%r86, %r144, %r146;
(EngineCore_DP0 pid=487301) 	or.b32 	%r87, %r145, %r147;
(EngineCore_DP0 pid=487301) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=487301) 	mad.wide.s32 	%rd16, %r89, 4, %rd2;
(EngineCore_DP0 pid=487301) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=487301) 	// begin inline asm
(EngineCore_DP0 pid=487301) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=487301) 	// end inline asm
(EngineCore_DP0 pid=487301) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=487301) 	add.s32 	%r151, %r151, 1024;
(EngineCore_DP0 pid=487301) 	setp.lt.s32 	%p26, %r151, %r15;
(EngineCore_DP0 pid=487301) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=487301) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=487301) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=487301) 	ret;
(EngineCore_DP0 pid=487301) $L__tmp3:
(EngineCore_DP0 pid=487301) $L__func_end0:
(EngineCore_DP0 pid=487301)                                         // -- End function
(EngineCore_DP0 pid=487301) }
(EngineCore_DP0 pid=487301) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=487301) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=487301) 	.section	.debug_abbrev
(EngineCore_DP0 pid=487301) 	{
(EngineCore_DP0 pid=487301) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=487301) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=487301) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=487301) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=487301) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=487301) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=487301) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=487301) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=487301) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=487301) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=487301) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=487301) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=487301) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=487301) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=487301) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=487301) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=487301) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=487301) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=487301) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=487301) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=487301) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=487301) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=487301) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=487301) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=487301) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=487301) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=487301) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=487301) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=487301) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=487301) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=487301) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=487301) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=487301) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=487301) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=487301) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=487301) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=487301) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=487301) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=487301) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=487301) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=487301) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=487301) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=487301) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=487301) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=487301) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=487301) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=487301) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=487301) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=487301) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=487301) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=487301) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=487301) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=487301) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=487301) 	}
(EngineCore_DP0 pid=487301) 	.section	.debug_info
(EngineCore_DP0 pid=487301) 	{
(EngineCore_DP0 pid=487301) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=487301) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=487301) .b8 0
(EngineCore_DP0 pid=487301) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=487301) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=487301) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=487301) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=487301) .b8 114
(EngineCore_DP0 pid=487301) .b8 105
(EngineCore_DP0 pid=487301) .b8 116
(EngineCore_DP0 pid=487301) .b8 111
(EngineCore_DP0 pid=487301) .b8 110
(EngineCore_DP0 pid=487301) .b8 0
(EngineCore_DP0 pid=487301) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=487301) .b8 0
(EngineCore_DP0 pid=487301) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=487301) .b8 117
(EngineCore_DP0 pid=487301) .b8 97
(EngineCore_DP0 pid=487301) .b8 110
(EngineCore_DP0 pid=487301) .b8 116
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 115
(EngineCore_DP0 pid=487301) .b8 108
(EngineCore_DP0 pid=487301) .b8 105
(EngineCore_DP0 pid=487301) .b8 100
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 116
(EngineCore_DP0 pid=487301) .b8 117
(EngineCore_DP0 pid=487301) .b8 110
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 100
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 81
(EngineCore_DP0 pid=487301) .b8 119
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 110
(EngineCore_DP0 pid=487301) .b8 50
(EngineCore_DP0 pid=487301) .b8 46
(EngineCore_DP0 pid=487301) .b8 53
(EngineCore_DP0 pid=487301) .b8 45
(EngineCore_DP0 pid=487301) .b8 55
(EngineCore_DP0 pid=487301) .b8 66
(EngineCore_DP0 pid=487301) .b8 46
(EngineCore_DP0 pid=487301) .b8 112
(EngineCore_DP0 pid=487301) .b8 121
(EngineCore_DP0 pid=487301) .b8 0
(EngineCore_DP0 pid=487301) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=487301) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=487301) .b8 114
(EngineCore_DP0 pid=487301) .b8 111
(EngineCore_DP0 pid=487301) .b8 111
(EngineCore_DP0 pid=487301) .b8 116
(EngineCore_DP0 pid=487301) .b8 47
(EngineCore_DP0 pid=487301) .b8 118
(EngineCore_DP0 pid=487301) .b8 108
(EngineCore_DP0 pid=487301) .b8 108
(EngineCore_DP0 pid=487301) .b8 109
(EngineCore_DP0 pid=487301) .b8 98
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 110
(EngineCore_DP0 pid=487301) .b8 99
(EngineCore_DP0 pid=487301) .b8 104
(EngineCore_DP0 pid=487301) .b8 47
(EngineCore_DP0 pid=487301) .b8 115
(EngineCore_DP0 pid=487301) .b8 108
(EngineCore_DP0 pid=487301) .b8 105
(EngineCore_DP0 pid=487301) .b8 100
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 115
(EngineCore_DP0 pid=487301) .b8 112
(EngineCore_DP0 pid=487301) .b8 97
(EngineCore_DP0 pid=487301) .b8 114
(EngineCore_DP0 pid=487301) .b8 115
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 47
(EngineCore_DP0 pid=487301) .b8 99
(EngineCore_DP0 pid=487301) .b8 115
(EngineCore_DP0 pid=487301) .b8 114
(EngineCore_DP0 pid=487301) .b8 99
(EngineCore_DP0 pid=487301) .b8 47
(EngineCore_DP0 pid=487301) .b8 102
(EngineCore_DP0 pid=487301) .b8 117
(EngineCore_DP0 pid=487301) .b8 115
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 100
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 113
(EngineCore_DP0 pid=487301) .b8 117
(EngineCore_DP0 pid=487301) .b8 97
(EngineCore_DP0 pid=487301) .b8 110
(EngineCore_DP0 pid=487301) .b8 116
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 115
(EngineCore_DP0 pid=487301) .b8 108
(EngineCore_DP0 pid=487301) .b8 105
(EngineCore_DP0 pid=487301) .b8 100
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 116
(EngineCore_DP0 pid=487301) .b8 114
(EngineCore_DP0 pid=487301) .b8 105
(EngineCore_DP0 pid=487301) .b8 116
(EngineCore_DP0 pid=487301) .b8 111
(EngineCore_DP0 pid=487301) .b8 110
(EngineCore_DP0 pid=487301) .b8 47
(EngineCore_DP0 pid=487301) .b8 98
(EngineCore_DP0 pid=487301) .b8 117
(EngineCore_DP0 pid=487301) .b8 105
(EngineCore_DP0 pid=487301) .b8 108
(EngineCore_DP0 pid=487301) .b8 100
(EngineCore_DP0 pid=487301) .b8 47
(EngineCore_DP0 pid=487301) .b8 71
(EngineCore_DP0 pid=487301) .b8 66
(EngineCore_DP0 pid=487301) .b8 49
(EngineCore_DP0 pid=487301) .b8 48
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 99
(EngineCore_DP0 pid=487301) .b8 99
(EngineCore_DP0 pid=487301) .b8 49
(EngineCore_DP0 pid=487301) .b8 50
(EngineCore_DP0 pid=487301) .b8 49
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 112
(EngineCore_DP0 pid=487301) .b8 121
(EngineCore_DP0 pid=487301) .b8 51
(EngineCore_DP0 pid=487301) .b8 49
(EngineCore_DP0 pid=487301) .b8 50
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 99
(EngineCore_DP0 pid=487301) .b8 117
(EngineCore_DP0 pid=487301) .b8 49
(EngineCore_DP0 pid=487301) .b8 50
(EngineCore_DP0 pid=487301) .b8 57
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 97
(EngineCore_DP0 pid=487301) .b8 97
(EngineCore_DP0 pid=487301) .b8 114
(EngineCore_DP0 pid=487301) .b8 99
(EngineCore_DP0 pid=487301) .b8 104
(EngineCore_DP0 pid=487301) .b8 54
(EngineCore_DP0 pid=487301) .b8 52
(EngineCore_DP0 pid=487301) .b8 0
(EngineCore_DP0 pid=487301) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=487301) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=487301) .b8 113
(EngineCore_DP0 pid=487301) .b8 117
(EngineCore_DP0 pid=487301) .b8 97
(EngineCore_DP0 pid=487301) .b8 110
(EngineCore_DP0 pid=487301) .b8 116
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 115
(EngineCore_DP0 pid=487301) .b8 108
(EngineCore_DP0 pid=487301) .b8 105
(EngineCore_DP0 pid=487301) .b8 100
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 102
(EngineCore_DP0 pid=487301) .b8 112
(EngineCore_DP0 pid=487301) .b8 56
(EngineCore_DP0 pid=487301) .b8 95
(EngineCore_DP0 pid=487301) .b8 107
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 114
(EngineCore_DP0 pid=487301) .b8 110
(EngineCore_DP0 pid=487301) .b8 101
(EngineCore_DP0 pid=487301) .b8 108
(EngineCore_DP0 pid=487301) .b8 0
(EngineCore_DP0 pid=487301) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=487301) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=487301) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=487301) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=487301) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=487301) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=487301) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=487301) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=487301) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=487301) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=487301) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=487301) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=487301) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=487301) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=487301) 	}
(EngineCore_DP0 pid=487301) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) ================================================================
(EngineCore_DP0 pid=487301) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp8l32zlcd.ptx', '-o', '/tmp/tmp8l32zlcd.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] 
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] 
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] 
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8l32zlcd.ptx -o /tmp/tmp8l32zlcd.ptx.o
(EngineCore_DP0 pid=487301) ERROR 01-25 21:38:57 [core.py:866] 

STDERR:
[2026-01-25 21:37:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:37:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:37:51] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:37:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:37:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:37:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:37:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:37:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:37:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:37:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:37:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:37:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:37:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:37:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:37:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:37:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:37:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=487301) [2026-01-25 21:37:55] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=487301) [2026-01-25 21:37:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=487301) [2026-01-25 21:37:55] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=487301) [2026-01-25 21:37:55] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=487301) [2026-01-25 21:37:55] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=487301) [2026-01-25 21:37:55] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=487301) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=487301) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.16s/it]
(EngineCore_DP0 pid=487301) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.65s/it]
(EngineCore_DP0 pid=487301) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.12s/it]
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) [2026-01-25 21:38:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=487301) [2026-01-25 21:38:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=487301) [2026-01-25 21:38:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=487301) [2026-01-25 21:38:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=487301) [2026-01-25 21:38:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=487301) [2026-01-25 21:38:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=487301) [2026-01-25 21:38:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=487301) [2026-01-25 21:38:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=487301) Process EngineCore_DP0:
(EngineCore_DP0 pid=487301) Traceback (most recent call last):
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=487301)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=487301)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=487301)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=487301) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp8l32zlcd.ptx', '-o', '/tmp/tmp8l32zlcd.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) Traceback (most recent call last):
(EngineCore_DP0 pid=487301)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=487301)     self.run()
(EngineCore_DP0 pid=487301)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=487301)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=487301)     raise e
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=487301)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=487301)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=487301)     super().__init__(
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=487301)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=487301)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=487301)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=487301)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=487301)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=487301)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=487301)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=487301)     return func(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=487301)     return func(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=487301)     self.model_runner.profile_run()
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=487301)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=487301)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=487301)     return func(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=487301)     outputs = self.model(
(EngineCore_DP0 pid=487301)               ^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=487301)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=487301)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=487301)     hidden_states = self.model(
(EngineCore_DP0 pid=487301)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=487301)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=487301)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=487301)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=487301)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=487301)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=487301)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=487301)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=487301)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=487301)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=487301)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=487301)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=487301)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=487301)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=487301)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=487301)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=487301)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=487301)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=487301)     return self._linear_fn(
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=487301)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=487301)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=487301)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=487301)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=487301)     return fn(input, L)
(EngineCore_DP0 pid=487301)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=487301)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=487301)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=487301)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=487301)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=487301)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=487301)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=487301)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=487301)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=487301)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=487301)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=487301)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=487301)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=487301)     raise PTXASError(error)
(EngineCore_DP0 pid=487301) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=487301) `ptxas` stderr:
(EngineCore_DP0 pid=487301) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=487301) 
(EngineCore_DP0 pid=487301) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp8l32zlcd.ptx -o /tmp/tmp8l32zlcd.ptx.o
(EngineCore_DP0 pid=487301) 
[rank0]:[W125 21:38:58.514928353 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=2048

========== M=4096 ==========
Time: 2026-01-25 21:39:00
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:39:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:39:05 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=488518) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) ================================================================
(EngineCore_DP0 pid=488518) Internal Triton PTX codegen error
(EngineCore_DP0 pid=488518) `ptxas` stderr:
(EngineCore_DP0 pid=488518) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9elt0d1k.ptx -o /tmp/tmp9elt0d1k.ptx.o
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) //
(EngineCore_DP0 pid=488518) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=488518) //
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) .version 8.7
(EngineCore_DP0 pid=488518) .target sm_121a
(EngineCore_DP0 pid=488518) .address_size 64
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=488518) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=488518)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=488518) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=488518) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=488518) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=488518) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=488518) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=488518) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=488518) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=488518) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=488518) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=488518) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=488518) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=488518) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=488518) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=488518) )
(EngineCore_DP0 pid=488518) .reqntid 512
(EngineCore_DP0 pid=488518) {
(EngineCore_DP0 pid=488518) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=488518) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=488518) 	.reg .b32 	%r<152>;
(EngineCore_DP0 pid=488518) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=488518) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=488518) $L__func_begin0:
(EngineCore_DP0 pid=488518) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) // %bb.0:
(EngineCore_DP0 pid=488518) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=488518) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=488518) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=488518) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=488518) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=488518) $L__tmp0:
(EngineCore_DP0 pid=488518) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=488518) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=488518) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=488518) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=488518) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=488518) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=488518) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=488518) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=488518) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=488518) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=488518) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=488518) 	mov.b32 	%r150, 0f2B8CBCCC;
(EngineCore_DP0 pid=488518) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=488518) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=488518) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=488518) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=488518) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=488518) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=488518) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=488518) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=488518) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=488518) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=488518) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=488518) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=488518) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=488518) 	mov.b32 	%r148, 0f00000000;
(EngineCore_DP0 pid=488518) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=488518) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=488518) 	mov.b32 	%r149, %r45;
(EngineCore_DP0 pid=488518) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=488518) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=488518) 	add.s32 	%r55, %r4, %r149;
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=488518) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=488518) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=488518) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=488518) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=488518) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=488518) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=488518) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=488518) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=488518) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=488518) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=488518) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=488518) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=488518) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=488518) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=488518) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=488518) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=488518) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=488518) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=488518) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=488518) $L__tmp1:
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	bar.sync 	0;
(EngineCore_DP0 pid=488518) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=488518) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=488518) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=488518) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=488518) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=488518) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=488518) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=488518) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=488518) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=488518) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=488518) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=488518) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=488518) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	bar.sync 	0;
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=488518) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=488518) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=488518) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=488518) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=488518) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	bar.sync 	0;
(EngineCore_DP0 pid=488518) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=488518) $L__tmp2:
(EngineCore_DP0 pid=488518) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=488518) 	max.f32 	%r148, %r148, %r73;
(EngineCore_DP0 pid=488518) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=488518) 	add.s32 	%r149, %r149, 4096;
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p6, %r149, %r24;
(EngineCore_DP0 pid=488518) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=488518) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=488518) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=488518) 	max.f32 	%r150, %r148, 0f2B8CBCCC;
(EngineCore_DP0 pid=488518) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=488518) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=488518) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=488518) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=488518) 	div.full.f32 	%r76, %r150, %r75;
(EngineCore_DP0 pid=488518) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=488518) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=488518) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=488518) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=488518) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=488518) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=488518) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=488518) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=488518) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=488518) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=488518) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=488518) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=488518) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=488518) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=488518) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=488518) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=488518) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=488518) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=488518) 	div.full.f32 	%r14, %r75, %r150;
(EngineCore_DP0 pid=488518) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=488518) 	mov.b32 	%r151, 0;
(EngineCore_DP0 pid=488518) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=488518)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=488518) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=488518) 	add.s32 	%r89, %r16, %r151;
(EngineCore_DP0 pid=488518) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=488518) 	add.s32 	%r90, %r89, 1;
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p17, %r89, %r15;
(EngineCore_DP0 pid=488518) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=488518) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=488518) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=488518) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=488518) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=488518) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=488518) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=488518) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=488518) 	mul.lo.s32 	%r97, %r96, 3;
(EngineCore_DP0 pid=488518) 	mul.lo.s32 	%r98, %r93, 3;
(EngineCore_DP0 pid=488518) 	sub.s32 	%r99, %r90, %r98;
(EngineCore_DP0 pid=488518) 	sub.s32 	%r100, %r89, %r97;
(EngineCore_DP0 pid=488518) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=488518) 	shl.b32 	%r101, %r96, 3;
(EngineCore_DP0 pid=488518) 	shl.b32 	%r102, %r93, 3;
(EngineCore_DP0 pid=488518) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=488518) 	shl.b32 	%r103, %r100, 1;
(EngineCore_DP0 pid=488518) 	shl.b32 	%r104, %r99, 1;
(EngineCore_DP0 pid=488518) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=488518) 	add.s32 	%r105, %r102, %r104;
(EngineCore_DP0 pid=488518) 	add.s32 	%r106, %r101, %r103;
(EngineCore_DP0 pid=488518) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p18, %r106, %r23;
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p19, %r105, %r23;
(EngineCore_DP0 pid=488518) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=488518) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=488518) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=488518) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=488518) 	mad.wide.s32 	%rd8, %r106, 2, %rd1;
(EngineCore_DP0 pid=488518) 	mad.wide.s32 	%rd9, %r105, 2, %rd1;
(EngineCore_DP0 pid=488518) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=488518) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=488518) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=488518) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=488518) 	cvt.f32.bf16 	%r107, %rs24;
(EngineCore_DP0 pid=488518) 	cvt.f32.bf16 	%r108, %rs26;
(EngineCore_DP0 pid=488518) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=488518) 	or.b32 	%r109, %r106, 1;
(EngineCore_DP0 pid=488518) 	or.b32 	%r110, %r105, 1;
(EngineCore_DP0 pid=488518) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p20, %r109, %r23;
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p21, %r110, %r23;
(EngineCore_DP0 pid=488518) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=488518) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=488518) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=488518) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=488518) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=488518) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=488518) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=488518) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=488518) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=488518) 	cvt.f32.bf16 	%r111, %rs28;
(EngineCore_DP0 pid=488518) 	cvt.f32.bf16 	%r112, %rs30;
(EngineCore_DP0 pid=488518) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=488518) 	add.s32 	%r113, %r106, 2;
(EngineCore_DP0 pid=488518) 	add.s32 	%r114, %r105, 2;
(EngineCore_DP0 pid=488518) 	add.s32 	%r115, %r106, 3;
(EngineCore_DP0 pid=488518) 	add.s32 	%r116, %r105, 3;
(EngineCore_DP0 pid=488518) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p22, %r116, %r23;
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p23, %r115, %r23;
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p24, %r114, %r23;
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p25, %r113, %r23;
(EngineCore_DP0 pid=488518) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=488518) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=488518) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=488518) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=488518) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=488518) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=488518) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=488518) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=488518) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=488518) 	cvt.f32.bf16 	%r117, %rs32;
(EngineCore_DP0 pid=488518) 	cvt.f32.bf16 	%r118, %rs34;
(EngineCore_DP0 pid=488518) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=488518) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=488518) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=488518) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=488518) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=488518) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=488518) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=488518) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=488518) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=488518) 	cvt.f32.bf16 	%r119, %rs36;
(EngineCore_DP0 pid=488518) 	cvt.f32.bf16 	%r120, %rs38;
(EngineCore_DP0 pid=488518) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=488518) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=488518) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=488518) 	mov.b32 	%r123, 0f43E00000;
(EngineCore_DP0 pid=488518) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=488518) 	min.xorsign.abs.f32 	%r78, %r121, %r123;
(EngineCore_DP0 pid=488518) 	min.xorsign.abs.f32 	%r79, %r122, %r123;
(EngineCore_DP0 pid=488518) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=488518) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=488518) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=488518) 	mul.f32 	%r125, %r14, %r112;
(EngineCore_DP0 pid=488518) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=488518) 	min.xorsign.abs.f32 	%r80, %r124, %r123;
(EngineCore_DP0 pid=488518) 	min.xorsign.abs.f32 	%r81, %r125, %r123;
(EngineCore_DP0 pid=488518) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=488518) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=488518) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=488518) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=488518) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=488518) 	min.xorsign.abs.f32 	%r82, %r126, %r123;
(EngineCore_DP0 pid=488518) 	min.xorsign.abs.f32 	%r83, %r127, %r123;
(EngineCore_DP0 pid=488518) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=488518) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=488518) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=488518) 	mul.f32 	%r129, %r14, %r120;
(EngineCore_DP0 pid=488518) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=488518) 	min.xorsign.abs.f32 	%r84, %r128, %r123;
(EngineCore_DP0 pid=488518) 	min.xorsign.abs.f32 	%r85, %r129, %r123;
(EngineCore_DP0 pid=488518) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=488518) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=488518) 	cvt.u32.u16 	%r130, %rs40;
(EngineCore_DP0 pid=488518) 	and.b32 	%r131, %r130, 255;
(EngineCore_DP0 pid=488518) 	cvt.u32.u16 	%r132, %rs44;
(EngineCore_DP0 pid=488518) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=488518) 	cvt.u32.u16 	%r133, %rs42;
(EngineCore_DP0 pid=488518) 	and.b32 	%r134, %r133, 255;
(EngineCore_DP0 pid=488518) 	cvt.u32.u16 	%r135, %rs46;
(EngineCore_DP0 pid=488518) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=488518) 	cvt.u32.u16 	%r136, %rs43;
(EngineCore_DP0 pid=488518) 	cvt.u32.u16 	%r137, %rs47;
(EngineCore_DP0 pid=488518) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=488518) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=488518) 	mul.wide.u16 	%r138, %rs48, 256;
(EngineCore_DP0 pid=488518) 	mul.wide.u16 	%r139, %rs45, 256;
(EngineCore_DP0 pid=488518) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=488518) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=488518) 	or.b32 	%r141, %r139, %r132;
(EngineCore_DP0 pid=488518) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=488518) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=488518) 	shl.b32 	%r143, %r135, 16;
(EngineCore_DP0 pid=488518) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=488518) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=488518) 	or.b32 	%r145, %r141, %r143;
(EngineCore_DP0 pid=488518) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=488518) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=488518) 	shl.b32 	%r147, %r137, 24;
(EngineCore_DP0 pid=488518) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=488518) 	or.b32 	%r86, %r144, %r146;
(EngineCore_DP0 pid=488518) 	or.b32 	%r87, %r145, %r147;
(EngineCore_DP0 pid=488518) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=488518) 	mad.wide.s32 	%rd16, %r89, 4, %rd2;
(EngineCore_DP0 pid=488518) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=488518) 	// begin inline asm
(EngineCore_DP0 pid=488518) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=488518) 	// end inline asm
(EngineCore_DP0 pid=488518) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=488518) 	add.s32 	%r151, %r151, 1024;
(EngineCore_DP0 pid=488518) 	setp.lt.s32 	%p26, %r151, %r15;
(EngineCore_DP0 pid=488518) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=488518) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=488518) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=488518) 	ret;
(EngineCore_DP0 pid=488518) $L__tmp3:
(EngineCore_DP0 pid=488518) $L__func_end0:
(EngineCore_DP0 pid=488518)                                         // -- End function
(EngineCore_DP0 pid=488518) }
(EngineCore_DP0 pid=488518) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=488518) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=488518) 	.section	.debug_abbrev
(EngineCore_DP0 pid=488518) 	{
(EngineCore_DP0 pid=488518) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=488518) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=488518) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=488518) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=488518) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=488518) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=488518) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=488518) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=488518) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=488518) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=488518) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=488518) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=488518) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=488518) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=488518) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=488518) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=488518) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=488518) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=488518) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=488518) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=488518) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=488518) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=488518) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=488518) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=488518) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=488518) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=488518) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=488518) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=488518) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=488518) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=488518) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=488518) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=488518) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=488518) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=488518) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=488518) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=488518) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=488518) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=488518) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=488518) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=488518) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=488518) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=488518) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=488518) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=488518) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=488518) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=488518) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=488518) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=488518) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=488518) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=488518) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=488518) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=488518) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=488518) 	}
(EngineCore_DP0 pid=488518) 	.section	.debug_info
(EngineCore_DP0 pid=488518) 	{
(EngineCore_DP0 pid=488518) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=488518) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=488518) .b8 0
(EngineCore_DP0 pid=488518) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=488518) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=488518) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=488518) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=488518) .b8 114
(EngineCore_DP0 pid=488518) .b8 105
(EngineCore_DP0 pid=488518) .b8 116
(EngineCore_DP0 pid=488518) .b8 111
(EngineCore_DP0 pid=488518) .b8 110
(EngineCore_DP0 pid=488518) .b8 0
(EngineCore_DP0 pid=488518) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=488518) .b8 0
(EngineCore_DP0 pid=488518) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=488518) .b8 117
(EngineCore_DP0 pid=488518) .b8 97
(EngineCore_DP0 pid=488518) .b8 110
(EngineCore_DP0 pid=488518) .b8 116
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 115
(EngineCore_DP0 pid=488518) .b8 108
(EngineCore_DP0 pid=488518) .b8 105
(EngineCore_DP0 pid=488518) .b8 100
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 116
(EngineCore_DP0 pid=488518) .b8 117
(EngineCore_DP0 pid=488518) .b8 110
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 100
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 81
(EngineCore_DP0 pid=488518) .b8 119
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 110
(EngineCore_DP0 pid=488518) .b8 50
(EngineCore_DP0 pid=488518) .b8 46
(EngineCore_DP0 pid=488518) .b8 53
(EngineCore_DP0 pid=488518) .b8 45
(EngineCore_DP0 pid=488518) .b8 55
(EngineCore_DP0 pid=488518) .b8 66
(EngineCore_DP0 pid=488518) .b8 46
(EngineCore_DP0 pid=488518) .b8 112
(EngineCore_DP0 pid=488518) .b8 121
(EngineCore_DP0 pid=488518) .b8 0
(EngineCore_DP0 pid=488518) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=488518) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=488518) .b8 114
(EngineCore_DP0 pid=488518) .b8 111
(EngineCore_DP0 pid=488518) .b8 111
(EngineCore_DP0 pid=488518) .b8 116
(EngineCore_DP0 pid=488518) .b8 47
(EngineCore_DP0 pid=488518) .b8 118
(EngineCore_DP0 pid=488518) .b8 108
(EngineCore_DP0 pid=488518) .b8 108
(EngineCore_DP0 pid=488518) .b8 109
(EngineCore_DP0 pid=488518) .b8 98
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 110
(EngineCore_DP0 pid=488518) .b8 99
(EngineCore_DP0 pid=488518) .b8 104
(EngineCore_DP0 pid=488518) .b8 47
(EngineCore_DP0 pid=488518) .b8 115
(EngineCore_DP0 pid=488518) .b8 108
(EngineCore_DP0 pid=488518) .b8 105
(EngineCore_DP0 pid=488518) .b8 100
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 115
(EngineCore_DP0 pid=488518) .b8 112
(EngineCore_DP0 pid=488518) .b8 97
(EngineCore_DP0 pid=488518) .b8 114
(EngineCore_DP0 pid=488518) .b8 115
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 47
(EngineCore_DP0 pid=488518) .b8 99
(EngineCore_DP0 pid=488518) .b8 115
(EngineCore_DP0 pid=488518) .b8 114
(EngineCore_DP0 pid=488518) .b8 99
(EngineCore_DP0 pid=488518) .b8 47
(EngineCore_DP0 pid=488518) .b8 102
(EngineCore_DP0 pid=488518) .b8 117
(EngineCore_DP0 pid=488518) .b8 115
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 100
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 113
(EngineCore_DP0 pid=488518) .b8 117
(EngineCore_DP0 pid=488518) .b8 97
(EngineCore_DP0 pid=488518) .b8 110
(EngineCore_DP0 pid=488518) .b8 116
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 115
(EngineCore_DP0 pid=488518) .b8 108
(EngineCore_DP0 pid=488518) .b8 105
(EngineCore_DP0 pid=488518) .b8 100
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 116
(EngineCore_DP0 pid=488518) .b8 114
(EngineCore_DP0 pid=488518) .b8 105
(EngineCore_DP0 pid=488518) .b8 116
(EngineCore_DP0 pid=488518) .b8 111
(EngineCore_DP0 pid=488518) .b8 110
(EngineCore_DP0 pid=488518) .b8 47
(EngineCore_DP0 pid=488518) .b8 98
(EngineCore_DP0 pid=488518) .b8 117
(EngineCore_DP0 pid=488518) .b8 105
(EngineCore_DP0 pid=488518) .b8 108
(EngineCore_DP0 pid=488518) .b8 100
(EngineCore_DP0 pid=488518) .b8 47
(EngineCore_DP0 pid=488518) .b8 71
(EngineCore_DP0 pid=488518) .b8 66
(EngineCore_DP0 pid=488518) .b8 49
(EngineCore_DP0 pid=488518) .b8 48
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 99
(EngineCore_DP0 pid=488518) .b8 99
(EngineCore_DP0 pid=488518) .b8 49
(EngineCore_DP0 pid=488518) .b8 50
(EngineCore_DP0 pid=488518) .b8 49
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 112
(EngineCore_DP0 pid=488518) .b8 121
(EngineCore_DP0 pid=488518) .b8 51
(EngineCore_DP0 pid=488518) .b8 49
(EngineCore_DP0 pid=488518) .b8 50
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 99
(EngineCore_DP0 pid=488518) .b8 117
(EngineCore_DP0 pid=488518) .b8 49
(EngineCore_DP0 pid=488518) .b8 50
(EngineCore_DP0 pid=488518) .b8 57
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 97
(EngineCore_DP0 pid=488518) .b8 97
(EngineCore_DP0 pid=488518) .b8 114
(EngineCore_DP0 pid=488518) .b8 99
(EngineCore_DP0 pid=488518) .b8 104
(EngineCore_DP0 pid=488518) .b8 54
(EngineCore_DP0 pid=488518) .b8 52
(EngineCore_DP0 pid=488518) .b8 0
(EngineCore_DP0 pid=488518) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=488518) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=488518) .b8 113
(EngineCore_DP0 pid=488518) .b8 117
(EngineCore_DP0 pid=488518) .b8 97
(EngineCore_DP0 pid=488518) .b8 110
(EngineCore_DP0 pid=488518) .b8 116
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 115
(EngineCore_DP0 pid=488518) .b8 108
(EngineCore_DP0 pid=488518) .b8 105
(EngineCore_DP0 pid=488518) .b8 100
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 102
(EngineCore_DP0 pid=488518) .b8 112
(EngineCore_DP0 pid=488518) .b8 56
(EngineCore_DP0 pid=488518) .b8 95
(EngineCore_DP0 pid=488518) .b8 107
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 114
(EngineCore_DP0 pid=488518) .b8 110
(EngineCore_DP0 pid=488518) .b8 101
(EngineCore_DP0 pid=488518) .b8 108
(EngineCore_DP0 pid=488518) .b8 0
(EngineCore_DP0 pid=488518) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=488518) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=488518) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=488518) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=488518) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=488518) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=488518) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=488518) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=488518) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=488518) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=488518) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=488518) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=488518) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=488518) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=488518) 	}
(EngineCore_DP0 pid=488518) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) ================================================================
(EngineCore_DP0 pid=488518) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp9elt0d1k.ptx', '-o', '/tmp/tmp9elt0d1k.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] 
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] 
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] 
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9elt0d1k.ptx -o /tmp/tmp9elt0d1k.ptx.o
(EngineCore_DP0 pid=488518) ERROR 01-25 21:40:11 [core.py:866] 

STDERR:
[2026-01-25 21:39:05] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:39:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:39:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:39:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:39:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:39:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:39:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:39:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:39:08] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:39:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:39:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:39:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:39:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:39:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:39:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:39:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:39:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=488518) [2026-01-25 21:39:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=488518) [2026-01-25 21:39:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=488518) [2026-01-25 21:39:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=488518) [2026-01-25 21:39:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=488518) [2026-01-25 21:39:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=488518) [2026-01-25 21:39:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=488518) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=488518) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.28s/it]
(EngineCore_DP0 pid=488518) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 30.48s/it]
(EngineCore_DP0 pid=488518) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:59<00:00, 30.00s/it]
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) [2026-01-25 21:40:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=488518) [2026-01-25 21:40:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=488518) [2026-01-25 21:40:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=488518) [2026-01-25 21:40:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=488518) [2026-01-25 21:40:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=488518) [2026-01-25 21:40:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=488518) [2026-01-25 21:40:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=488518) [2026-01-25 21:40:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=488518) Process EngineCore_DP0:
(EngineCore_DP0 pid=488518) Traceback (most recent call last):
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=488518)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=488518)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=488518)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=488518) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp9elt0d1k.ptx', '-o', '/tmp/tmp9elt0d1k.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) Traceback (most recent call last):
(EngineCore_DP0 pid=488518)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=488518)     self.run()
(EngineCore_DP0 pid=488518)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=488518)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=488518)     raise e
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=488518)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=488518)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=488518)     super().__init__(
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=488518)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=488518)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=488518)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=488518)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=488518)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=488518)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=488518)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=488518)     return func(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=488518)     return func(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=488518)     self.model_runner.profile_run()
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=488518)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=488518)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=488518)     return func(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=488518)     outputs = self.model(
(EngineCore_DP0 pid=488518)               ^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488518)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488518)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=488518)     hidden_states = self.model(
(EngineCore_DP0 pid=488518)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=488518)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=488518)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=488518)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488518)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488518)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=488518)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=488518)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488518)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488518)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=488518)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=488518)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=488518)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=488518)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=488518)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=488518)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=488518)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=488518)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=488518)     return self._linear_fn(
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=488518)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=488518)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=488518)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=488518)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=488518)     return fn(input, L)
(EngineCore_DP0 pid=488518)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=488518)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=488518)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=488518)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=488518)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=488518)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=488518)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=488518)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=488518)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=488518)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=488518)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=488518)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=488518)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=488518)     raise PTXASError(error)
(EngineCore_DP0 pid=488518) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=488518) `ptxas` stderr:
(EngineCore_DP0 pid=488518) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=488518) 
(EngineCore_DP0 pid=488518) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp9elt0d1k.ptx -o /tmp/tmp9elt0d1k.ptx.o
(EngineCore_DP0 pid=488518) 
[rank0]:[W125 21:40:12.290476464 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=4096

========== M=8192 ==========
Time: 2026-01-25 21:40:13
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:40:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:40:20 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=489744) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) ================================================================
(EngineCore_DP0 pid=489744) Internal Triton PTX codegen error
(EngineCore_DP0 pid=489744) `ptxas` stderr:
(EngineCore_DP0 pid=489744) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbfr1qp97.ptx -o /tmp/tmpbfr1qp97.ptx.o
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) //
(EngineCore_DP0 pid=489744) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=489744) //
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) .version 8.7
(EngineCore_DP0 pid=489744) .target sm_121a
(EngineCore_DP0 pid=489744) .address_size 64
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=489744) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=489744)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=489744) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=489744) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=489744) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=489744) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=489744) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=489744) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=489744) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=489744) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=489744) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=489744) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=489744) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=489744) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=489744) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=489744) )
(EngineCore_DP0 pid=489744) .reqntid 512
(EngineCore_DP0 pid=489744) {
(EngineCore_DP0 pid=489744) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=489744) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=489744) 	.reg .b32 	%r<161>;
(EngineCore_DP0 pid=489744) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=489744) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=489744) $L__func_begin0:
(EngineCore_DP0 pid=489744) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) // %bb.0:
(EngineCore_DP0 pid=489744) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=489744) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=489744) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=489744) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=489744) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=489744) $L__tmp0:
(EngineCore_DP0 pid=489744) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=489744) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=489744) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=489744) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=489744) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=489744) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=489744) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=489744) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=489744) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=489744) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=489744) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=489744) 	mov.b32 	%r159, 0f2B8CBCCC;
(EngineCore_DP0 pid=489744) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=489744) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=489744) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=489744) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=489744) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=489744) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=489744) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=489744) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=489744) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=489744) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=489744) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=489744) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=489744) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=489744) 	mov.b32 	%r157, 0f00000000;
(EngineCore_DP0 pid=489744) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=489744) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=489744) 	mov.b32 	%r158, %r45;
(EngineCore_DP0 pid=489744) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=489744) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=489744) 	add.s32 	%r63, %r4, %r158;
(EngineCore_DP0 pid=489744) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=489744) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=489744) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=489744) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=489744) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=489744) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=489744) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=489744) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=489744) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=489744) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=489744) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=489744) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=489744) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=489744) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=489744) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=489744) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=489744) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=489744) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=489744) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=489744) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=489744) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=489744) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=489744) $L__tmp1:
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	bar.sync 	0;
(EngineCore_DP0 pid=489744) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=489744) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=489744) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=489744) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=489744) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=489744) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=489744) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=489744) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	bar.sync 	0;
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=489744) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=489744) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=489744) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=489744) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=489744) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	bar.sync 	0;
(EngineCore_DP0 pid=489744) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=489744) $L__tmp2:
(EngineCore_DP0 pid=489744) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=489744) 	max.f32 	%r157, %r157, %r82;
(EngineCore_DP0 pid=489744) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=489744) 	add.s32 	%r158, %r158, 8192;
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p7, %r158, %r24;
(EngineCore_DP0 pid=489744) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=489744) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=489744) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=489744) 	max.f32 	%r159, %r157, 0f2B8CBCCC;
(EngineCore_DP0 pid=489744) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=489744) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=489744) 	mov.b32 	%r84, 0f43E00000;
(EngineCore_DP0 pid=489744) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=489744) 	div.full.f32 	%r85, %r159, %r84;
(EngineCore_DP0 pid=489744) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=489744) 	max.f32 	%r83, %r85, 0f36924925;
(EngineCore_DP0 pid=489744) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=489744) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=489744) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=489744) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=489744) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=489744) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=489744) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=489744) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=489744) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=489744) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=489744) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=489744) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=489744) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=489744) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=489744) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=489744) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=489744) 	div.full.f32 	%r14, %r84, %r159;
(EngineCore_DP0 pid=489744) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=489744) 	mov.b32 	%r160, 0;
(EngineCore_DP0 pid=489744) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=489744)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=489744) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=489744) 	add.s32 	%r98, %r16, %r160;
(EngineCore_DP0 pid=489744) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=489744) 	add.s32 	%r99, %r98, 1;
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p18, %r98, %r15;
(EngineCore_DP0 pid=489744) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=489744) 	mul.hi.s32 	%r100, %r99, 1431655766;
(EngineCore_DP0 pid=489744) 	shr.u32 	%r101, %r100, 31;
(EngineCore_DP0 pid=489744) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=489744) 	mul.hi.s32 	%r103, %r98, 1431655766;
(EngineCore_DP0 pid=489744) 	shr.u32 	%r104, %r103, 31;
(EngineCore_DP0 pid=489744) 	add.s32 	%r105, %r103, %r104;
(EngineCore_DP0 pid=489744) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=489744) 	mul.lo.s32 	%r106, %r105, 3;
(EngineCore_DP0 pid=489744) 	mul.lo.s32 	%r107, %r102, 3;
(EngineCore_DP0 pid=489744) 	sub.s32 	%r108, %r99, %r107;
(EngineCore_DP0 pid=489744) 	sub.s32 	%r109, %r98, %r106;
(EngineCore_DP0 pid=489744) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=489744) 	shl.b32 	%r110, %r105, 3;
(EngineCore_DP0 pid=489744) 	shl.b32 	%r111, %r102, 3;
(EngineCore_DP0 pid=489744) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=489744) 	shl.b32 	%r112, %r109, 1;
(EngineCore_DP0 pid=489744) 	shl.b32 	%r113, %r108, 1;
(EngineCore_DP0 pid=489744) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=489744) 	add.s32 	%r114, %r111, %r113;
(EngineCore_DP0 pid=489744) 	add.s32 	%r115, %r110, %r112;
(EngineCore_DP0 pid=489744) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p19, %r115, %r23;
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p20, %r114, %r23;
(EngineCore_DP0 pid=489744) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=489744) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=489744) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=489744) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=489744) 	mad.wide.s32 	%rd9, %r115, 2, %rd1;
(EngineCore_DP0 pid=489744) 	mad.wide.s32 	%rd10, %r114, 2, %rd1;
(EngineCore_DP0 pid=489744) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=489744) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=489744) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=489744) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=489744) 	cvt.f32.bf16 	%r116, %rs48;
(EngineCore_DP0 pid=489744) 	cvt.f32.bf16 	%r117, %rs50;
(EngineCore_DP0 pid=489744) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=489744) 	or.b32 	%r118, %r115, 1;
(EngineCore_DP0 pid=489744) 	or.b32 	%r119, %r114, 1;
(EngineCore_DP0 pid=489744) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p21, %r118, %r23;
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p22, %r119, %r23;
(EngineCore_DP0 pid=489744) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=489744) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=489744) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=489744) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=489744) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=489744) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=489744) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=489744) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=489744) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=489744) 	cvt.f32.bf16 	%r120, %rs52;
(EngineCore_DP0 pid=489744) 	cvt.f32.bf16 	%r121, %rs54;
(EngineCore_DP0 pid=489744) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=489744) 	add.s32 	%r122, %r115, 2;
(EngineCore_DP0 pid=489744) 	add.s32 	%r123, %r114, 2;
(EngineCore_DP0 pid=489744) 	add.s32 	%r124, %r115, 3;
(EngineCore_DP0 pid=489744) 	add.s32 	%r125, %r114, 3;
(EngineCore_DP0 pid=489744) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p23, %r125, %r23;
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p24, %r124, %r23;
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p25, %r123, %r23;
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p26, %r122, %r23;
(EngineCore_DP0 pid=489744) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=489744) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=489744) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=489744) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=489744) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=489744) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=489744) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=489744) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=489744) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=489744) 	cvt.f32.bf16 	%r126, %rs56;
(EngineCore_DP0 pid=489744) 	cvt.f32.bf16 	%r127, %rs58;
(EngineCore_DP0 pid=489744) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=489744) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=489744) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=489744) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=489744) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=489744) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=489744) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=489744) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=489744) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=489744) 	cvt.f32.bf16 	%r128, %rs60;
(EngineCore_DP0 pid=489744) 	cvt.f32.bf16 	%r129, %rs62;
(EngineCore_DP0 pid=489744) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=489744) 	mul.f32 	%r130, %r14, %r116;
(EngineCore_DP0 pid=489744) 	mul.f32 	%r131, %r14, %r117;
(EngineCore_DP0 pid=489744) 	mov.b32 	%r132, 0f43E00000;
(EngineCore_DP0 pid=489744) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=489744) 	min.xorsign.abs.f32 	%r87, %r130, %r132;
(EngineCore_DP0 pid=489744) 	min.xorsign.abs.f32 	%r88, %r131, %r132;
(EngineCore_DP0 pid=489744) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r88, %r87; 
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=489744) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=489744) 	mul.f32 	%r133, %r14, %r120;
(EngineCore_DP0 pid=489744) 	mul.f32 	%r134, %r14, %r121;
(EngineCore_DP0 pid=489744) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=489744) 	min.xorsign.abs.f32 	%r89, %r133, %r132;
(EngineCore_DP0 pid=489744) 	min.xorsign.abs.f32 	%r90, %r134, %r132;
(EngineCore_DP0 pid=489744) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r90, %r89; 
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=489744) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=489744) 	mul.f32 	%r135, %r14, %r126;
(EngineCore_DP0 pid=489744) 	mul.f32 	%r136, %r14, %r127;
(EngineCore_DP0 pid=489744) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=489744) 	min.xorsign.abs.f32 	%r91, %r135, %r132;
(EngineCore_DP0 pid=489744) 	min.xorsign.abs.f32 	%r92, %r136, %r132;
(EngineCore_DP0 pid=489744) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r92, %r91; 
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=489744) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=489744) 	mul.f32 	%r137, %r14, %r128;
(EngineCore_DP0 pid=489744) 	mul.f32 	%r138, %r14, %r129;
(EngineCore_DP0 pid=489744) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=489744) 	min.xorsign.abs.f32 	%r93, %r137, %r132;
(EngineCore_DP0 pid=489744) 	min.xorsign.abs.f32 	%r94, %r138, %r132;
(EngineCore_DP0 pid=489744) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r94, %r93; 
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=489744) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=489744) 	cvt.u32.u16 	%r139, %rs64;
(EngineCore_DP0 pid=489744) 	and.b32 	%r140, %r139, 255;
(EngineCore_DP0 pid=489744) 	cvt.u32.u16 	%r141, %rs68;
(EngineCore_DP0 pid=489744) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=489744) 	cvt.u32.u16 	%r142, %rs66;
(EngineCore_DP0 pid=489744) 	and.b32 	%r143, %r142, 255;
(EngineCore_DP0 pid=489744) 	cvt.u32.u16 	%r144, %rs70;
(EngineCore_DP0 pid=489744) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=489744) 	cvt.u32.u16 	%r145, %rs67;
(EngineCore_DP0 pid=489744) 	cvt.u32.u16 	%r146, %rs71;
(EngineCore_DP0 pid=489744) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=489744) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=489744) 	mul.wide.u16 	%r147, %rs72, 256;
(EngineCore_DP0 pid=489744) 	mul.wide.u16 	%r148, %rs69, 256;
(EngineCore_DP0 pid=489744) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=489744) 	or.b32 	%r149, %r147, %r140;
(EngineCore_DP0 pid=489744) 	or.b32 	%r150, %r148, %r141;
(EngineCore_DP0 pid=489744) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=489744) 	shl.b32 	%r151, %r143, 16;
(EngineCore_DP0 pid=489744) 	shl.b32 	%r152, %r144, 16;
(EngineCore_DP0 pid=489744) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=489744) 	or.b32 	%r153, %r149, %r151;
(EngineCore_DP0 pid=489744) 	or.b32 	%r154, %r150, %r152;
(EngineCore_DP0 pid=489744) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=489744) 	shl.b32 	%r155, %r145, 24;
(EngineCore_DP0 pid=489744) 	shl.b32 	%r156, %r146, 24;
(EngineCore_DP0 pid=489744) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=489744) 	or.b32 	%r95, %r153, %r155;
(EngineCore_DP0 pid=489744) 	or.b32 	%r96, %r154, %r156;
(EngineCore_DP0 pid=489744) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=489744) 	mad.wide.s32 	%rd17, %r98, 4, %rd2;
(EngineCore_DP0 pid=489744) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=489744) 	// begin inline asm
(EngineCore_DP0 pid=489744) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r95, %r96 };
(EngineCore_DP0 pid=489744) 	// end inline asm
(EngineCore_DP0 pid=489744) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=489744) 	add.s32 	%r160, %r160, 1024;
(EngineCore_DP0 pid=489744) 	setp.lt.s32 	%p27, %r160, %r15;
(EngineCore_DP0 pid=489744) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=489744) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=489744) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=489744) 	ret;
(EngineCore_DP0 pid=489744) $L__tmp3:
(EngineCore_DP0 pid=489744) $L__func_end0:
(EngineCore_DP0 pid=489744)                                         // -- End function
(EngineCore_DP0 pid=489744) }
(EngineCore_DP0 pid=489744) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=489744) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=489744) 	.section	.debug_abbrev
(EngineCore_DP0 pid=489744) 	{
(EngineCore_DP0 pid=489744) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=489744) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=489744) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=489744) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=489744) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=489744) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=489744) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=489744) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=489744) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=489744) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=489744) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=489744) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=489744) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=489744) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=489744) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=489744) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=489744) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=489744) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=489744) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=489744) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=489744) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=489744) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=489744) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=489744) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=489744) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=489744) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=489744) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=489744) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=489744) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=489744) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=489744) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=489744) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=489744) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=489744) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=489744) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=489744) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=489744) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=489744) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=489744) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=489744) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=489744) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=489744) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=489744) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=489744) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=489744) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=489744) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=489744) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=489744) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=489744) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=489744) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=489744) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=489744) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=489744) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=489744) 	}
(EngineCore_DP0 pid=489744) 	.section	.debug_info
(EngineCore_DP0 pid=489744) 	{
(EngineCore_DP0 pid=489744) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=489744) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=489744) .b8 0
(EngineCore_DP0 pid=489744) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=489744) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=489744) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=489744) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=489744) .b8 114
(EngineCore_DP0 pid=489744) .b8 105
(EngineCore_DP0 pid=489744) .b8 116
(EngineCore_DP0 pid=489744) .b8 111
(EngineCore_DP0 pid=489744) .b8 110
(EngineCore_DP0 pid=489744) .b8 0
(EngineCore_DP0 pid=489744) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=489744) .b8 0
(EngineCore_DP0 pid=489744) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=489744) .b8 117
(EngineCore_DP0 pid=489744) .b8 97
(EngineCore_DP0 pid=489744) .b8 110
(EngineCore_DP0 pid=489744) .b8 116
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 115
(EngineCore_DP0 pid=489744) .b8 108
(EngineCore_DP0 pid=489744) .b8 105
(EngineCore_DP0 pid=489744) .b8 100
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 116
(EngineCore_DP0 pid=489744) .b8 117
(EngineCore_DP0 pid=489744) .b8 110
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 100
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 81
(EngineCore_DP0 pid=489744) .b8 119
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 110
(EngineCore_DP0 pid=489744) .b8 50
(EngineCore_DP0 pid=489744) .b8 46
(EngineCore_DP0 pid=489744) .b8 53
(EngineCore_DP0 pid=489744) .b8 45
(EngineCore_DP0 pid=489744) .b8 55
(EngineCore_DP0 pid=489744) .b8 66
(EngineCore_DP0 pid=489744) .b8 46
(EngineCore_DP0 pid=489744) .b8 112
(EngineCore_DP0 pid=489744) .b8 121
(EngineCore_DP0 pid=489744) .b8 0
(EngineCore_DP0 pid=489744) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=489744) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=489744) .b8 114
(EngineCore_DP0 pid=489744) .b8 111
(EngineCore_DP0 pid=489744) .b8 111
(EngineCore_DP0 pid=489744) .b8 116
(EngineCore_DP0 pid=489744) .b8 47
(EngineCore_DP0 pid=489744) .b8 118
(EngineCore_DP0 pid=489744) .b8 108
(EngineCore_DP0 pid=489744) .b8 108
(EngineCore_DP0 pid=489744) .b8 109
(EngineCore_DP0 pid=489744) .b8 98
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 110
(EngineCore_DP0 pid=489744) .b8 99
(EngineCore_DP0 pid=489744) .b8 104
(EngineCore_DP0 pid=489744) .b8 47
(EngineCore_DP0 pid=489744) .b8 115
(EngineCore_DP0 pid=489744) .b8 108
(EngineCore_DP0 pid=489744) .b8 105
(EngineCore_DP0 pid=489744) .b8 100
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 115
(EngineCore_DP0 pid=489744) .b8 112
(EngineCore_DP0 pid=489744) .b8 97
(EngineCore_DP0 pid=489744) .b8 114
(EngineCore_DP0 pid=489744) .b8 115
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 47
(EngineCore_DP0 pid=489744) .b8 99
(EngineCore_DP0 pid=489744) .b8 115
(EngineCore_DP0 pid=489744) .b8 114
(EngineCore_DP0 pid=489744) .b8 99
(EngineCore_DP0 pid=489744) .b8 47
(EngineCore_DP0 pid=489744) .b8 102
(EngineCore_DP0 pid=489744) .b8 117
(EngineCore_DP0 pid=489744) .b8 115
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 100
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 113
(EngineCore_DP0 pid=489744) .b8 117
(EngineCore_DP0 pid=489744) .b8 97
(EngineCore_DP0 pid=489744) .b8 110
(EngineCore_DP0 pid=489744) .b8 116
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 115
(EngineCore_DP0 pid=489744) .b8 108
(EngineCore_DP0 pid=489744) .b8 105
(EngineCore_DP0 pid=489744) .b8 100
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 116
(EngineCore_DP0 pid=489744) .b8 114
(EngineCore_DP0 pid=489744) .b8 105
(EngineCore_DP0 pid=489744) .b8 116
(EngineCore_DP0 pid=489744) .b8 111
(EngineCore_DP0 pid=489744) .b8 110
(EngineCore_DP0 pid=489744) .b8 47
(EngineCore_DP0 pid=489744) .b8 98
(EngineCore_DP0 pid=489744) .b8 117
(EngineCore_DP0 pid=489744) .b8 105
(EngineCore_DP0 pid=489744) .b8 108
(EngineCore_DP0 pid=489744) .b8 100
(EngineCore_DP0 pid=489744) .b8 47
(EngineCore_DP0 pid=489744) .b8 71
(EngineCore_DP0 pid=489744) .b8 66
(EngineCore_DP0 pid=489744) .b8 49
(EngineCore_DP0 pid=489744) .b8 48
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 99
(EngineCore_DP0 pid=489744) .b8 99
(EngineCore_DP0 pid=489744) .b8 49
(EngineCore_DP0 pid=489744) .b8 50
(EngineCore_DP0 pid=489744) .b8 49
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 112
(EngineCore_DP0 pid=489744) .b8 121
(EngineCore_DP0 pid=489744) .b8 51
(EngineCore_DP0 pid=489744) .b8 49
(EngineCore_DP0 pid=489744) .b8 50
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 99
(EngineCore_DP0 pid=489744) .b8 117
(EngineCore_DP0 pid=489744) .b8 49
(EngineCore_DP0 pid=489744) .b8 50
(EngineCore_DP0 pid=489744) .b8 57
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 97
(EngineCore_DP0 pid=489744) .b8 97
(EngineCore_DP0 pid=489744) .b8 114
(EngineCore_DP0 pid=489744) .b8 99
(EngineCore_DP0 pid=489744) .b8 104
(EngineCore_DP0 pid=489744) .b8 54
(EngineCore_DP0 pid=489744) .b8 52
(EngineCore_DP0 pid=489744) .b8 0
(EngineCore_DP0 pid=489744) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=489744) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=489744) .b8 113
(EngineCore_DP0 pid=489744) .b8 117
(EngineCore_DP0 pid=489744) .b8 97
(EngineCore_DP0 pid=489744) .b8 110
(EngineCore_DP0 pid=489744) .b8 116
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 115
(EngineCore_DP0 pid=489744) .b8 108
(EngineCore_DP0 pid=489744) .b8 105
(EngineCore_DP0 pid=489744) .b8 100
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 102
(EngineCore_DP0 pid=489744) .b8 112
(EngineCore_DP0 pid=489744) .b8 56
(EngineCore_DP0 pid=489744) .b8 95
(EngineCore_DP0 pid=489744) .b8 107
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 114
(EngineCore_DP0 pid=489744) .b8 110
(EngineCore_DP0 pid=489744) .b8 101
(EngineCore_DP0 pid=489744) .b8 108
(EngineCore_DP0 pid=489744) .b8 0
(EngineCore_DP0 pid=489744) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=489744) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=489744) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=489744) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=489744) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=489744) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=489744) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=489744) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=489744) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=489744) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=489744) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=489744) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=489744) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=489744) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=489744) 	}
(EngineCore_DP0 pid=489744) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) ================================================================
(EngineCore_DP0 pid=489744) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpbfr1qp97.ptx', '-o', '/tmp/tmpbfr1qp97.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] 
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] 
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] 
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbfr1qp97.ptx -o /tmp/tmpbfr1qp97.ptx.o
(EngineCore_DP0 pid=489744) ERROR 01-25 21:41:28 [core.py:866] 

STDERR:
[2026-01-25 21:40:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:40:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:40:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:40:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:40:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:40:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:40:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:40:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:40:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:40:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:40:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:40:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:40:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:40:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:40:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:40:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:40:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=489744) [2026-01-25 21:40:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=489744) [2026-01-25 21:40:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=489744) [2026-01-25 21:40:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=489744) [2026-01-25 21:40:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=489744) [2026-01-25 21:40:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=489744) [2026-01-25 21:40:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=489744) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=489744) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.47s/it]
(EngineCore_DP0 pid=489744) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.82s/it]
(EngineCore_DP0 pid=489744) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.32s/it]
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) [2026-01-25 21:41:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=489744) [2026-01-25 21:41:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=489744) [2026-01-25 21:41:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=489744) [2026-01-25 21:41:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=489744) [2026-01-25 21:41:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=489744) [2026-01-25 21:41:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=489744) [2026-01-25 21:41:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=489744) [2026-01-25 21:41:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=489744) Process EngineCore_DP0:
(EngineCore_DP0 pid=489744) Traceback (most recent call last):
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=489744)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=489744)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=489744)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=489744) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpbfr1qp97.ptx', '-o', '/tmp/tmpbfr1qp97.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) Traceback (most recent call last):
(EngineCore_DP0 pid=489744)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=489744)     self.run()
(EngineCore_DP0 pid=489744)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=489744)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=489744)     raise e
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=489744)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=489744)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=489744)     super().__init__(
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=489744)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=489744)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=489744)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=489744)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=489744)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=489744)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=489744)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=489744)     return func(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=489744)     return func(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=489744)     self.model_runner.profile_run()
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=489744)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=489744)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=489744)     return func(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=489744)     outputs = self.model(
(EngineCore_DP0 pid=489744)               ^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=489744)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=489744)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=489744)     hidden_states = self.model(
(EngineCore_DP0 pid=489744)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=489744)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=489744)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=489744)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=489744)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=489744)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=489744)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=489744)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=489744)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=489744)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=489744)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=489744)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=489744)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=489744)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=489744)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=489744)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=489744)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=489744)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=489744)     return self._linear_fn(
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=489744)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=489744)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=489744)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=489744)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=489744)     return fn(input, L)
(EngineCore_DP0 pid=489744)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=489744)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=489744)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=489744)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=489744)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=489744)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=489744)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=489744)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=489744)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=489744)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=489744)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=489744)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=489744)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=489744)     raise PTXASError(error)
(EngineCore_DP0 pid=489744) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=489744) `ptxas` stderr:
(EngineCore_DP0 pid=489744) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=489744) 
(EngineCore_DP0 pid=489744) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpbfr1qp97.ptx -o /tmp/tmpbfr1qp97.ptx.o
(EngineCore_DP0 pid=489744) 
[rank0]:[W125 21:41:28.552557354 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=8192

========== M=16384 ==========
Time: 2026-01-25 21:41:30
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:41:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:41:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=491039) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) ================================================================
(EngineCore_DP0 pid=491039) Internal Triton PTX codegen error
(EngineCore_DP0 pid=491039) `ptxas` stderr:
(EngineCore_DP0 pid=491039) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnj9r_3zt.ptx -o /tmp/tmpnj9r_3zt.ptx.o
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) //
(EngineCore_DP0 pid=491039) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=491039) //
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) .version 8.7
(EngineCore_DP0 pid=491039) .target sm_121a
(EngineCore_DP0 pid=491039) .address_size 64
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=491039) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=491039)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=491039) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=491039) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=491039) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=491039) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=491039) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=491039) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=491039) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=491039) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=491039) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=491039) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=491039) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=491039) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=491039) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=491039) )
(EngineCore_DP0 pid=491039) .reqntid 512
(EngineCore_DP0 pid=491039) {
(EngineCore_DP0 pid=491039) 	.reg .pred 	%p<29>;
(EngineCore_DP0 pid=491039) 	.reg .b16 	%rs<73>;
(EngineCore_DP0 pid=491039) 	.reg .b32 	%r<161>;
(EngineCore_DP0 pid=491039) 	.reg .b64 	%rd<18>;
(EngineCore_DP0 pid=491039) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=491039) $L__func_begin0:
(EngineCore_DP0 pid=491039) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) // %bb.0:
(EngineCore_DP0 pid=491039) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=491039) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=491039) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=491039) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=491039) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=491039) $L__tmp0:
(EngineCore_DP0 pid=491039) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=491039) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=491039) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=491039) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=491039) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=491039) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=491039) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=491039) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=491039) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=491039) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=491039) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=491039) 	mov.b32 	%r159, 0f2B8CBCCC;
(EngineCore_DP0 pid=491039) 	setp.eq.b32 	%p28, %r2, 0;
(EngineCore_DP0 pid=491039) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=491039) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=491039) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=491039) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=491039) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=491039) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=491039) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=491039) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=491039) 	add.s32 	%r57, %r39, %r38;
(EngineCore_DP0 pid=491039) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=491039) 	add.s32 	%r60, %r39, %r40;
(EngineCore_DP0 pid=491039) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=491039) 	mov.b32 	%r157, 0f00000000;
(EngineCore_DP0 pid=491039) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=491039) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=491039) 	mov.b32 	%r158, %r45;
(EngineCore_DP0 pid=491039) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=491039) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=491039) 	add.s32 	%r63, %r4, %r158;
(EngineCore_DP0 pid=491039) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=491039) 	add.s32 	%r64, %r63, 4096;
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p2, %r63, %r23;
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p3, %r64, %r23;
(EngineCore_DP0 pid=491039) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=491039) 	mad.wide.s32 	%rd6, %r63, 2, %rd1;
(EngineCore_DP0 pid=491039) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=491039) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=491039) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=491039) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=491039) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=491039) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=491039) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=491039) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=491039) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	mov.u32 %r49, %r45;
(EngineCore_DP0 pid=491039) 	mov.u32 %r50, %r45;
(EngineCore_DP0 pid=491039) 	mov.u32 %r51, %r45;
(EngineCore_DP0 pid=491039) 	mov.u32 %r52, %r45;
(EngineCore_DP0 pid=491039) 	@%p3 ld.global.v4.b32 { %r49, %r50, %r51, %r52 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	mov.b32 	{%rs9, %rs10}, %r49;
(EngineCore_DP0 pid=491039) 	mov.b32 	{%rs11, %rs12}, %r50;
(EngineCore_DP0 pid=491039) 	mov.b32 	{%rs13, %rs14}, %r51;
(EngineCore_DP0 pid=491039) 	mov.b32 	{%rs15, %rs16}, %r52;
(EngineCore_DP0 pid=491039) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=491039) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=491039) $L__tmp1:
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	bar.sync 	0;
(EngineCore_DP0 pid=491039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=491039) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=491039) 	cvt.f32.bf16 	%r65, %rs47;
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	shfl.sync.bfly.b32 	%r66, %r65, 16, 31, -1;
(EngineCore_DP0 pid=491039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	max.f32 	%r67, %r65, %r66;
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	shfl.sync.bfly.b32 	%r68, %r67, 8, 31, -1;
(EngineCore_DP0 pid=491039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	shfl.sync.bfly.b32 	%r70, %r69, 4, 31, -1;
(EngineCore_DP0 pid=491039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	shfl.sync.bfly.b32 	%r72, %r71, 2, 31, -1;
(EngineCore_DP0 pid=491039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	shfl.sync.bfly.b32 	%r74, %r73, 1, 31, -1;
(EngineCore_DP0 pid=491039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	max.f32 	%r58, %r73, %r74;
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	@%p4 st.shared.b32 [ %r57 + 0 ], %r58;
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	bar.sync 	0;
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	@%p5 ld.shared.b32 %r59, [ %r60 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	shfl.sync.bfly.b32 	%r75, %r59, 8, 31, -1;
(EngineCore_DP0 pid=491039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	max.f32 	%r76, %r59, %r75;
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	shfl.sync.bfly.b32 	%r77, %r76, 4, 31, -1;
(EngineCore_DP0 pid=491039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	max.f32 	%r78, %r76, %r77;
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	shfl.sync.bfly.b32 	%r79, %r78, 2, 31, -1;
(EngineCore_DP0 pid=491039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	max.f32 	%r80, %r78, %r79;
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	shfl.sync.bfly.b32 	%r81, %r80, 1, 31, -1;
(EngineCore_DP0 pid=491039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	max.f32 	%r62, %r80, %r81;
(EngineCore_DP0 pid=491039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	@%p28 st.shared.b32 [ %r60 + 0 ], %r62;
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	bar.sync 	0;
(EngineCore_DP0 pid=491039) 	ld.shared.b32 	%r82, [global_smem];
(EngineCore_DP0 pid=491039) $L__tmp2:
(EngineCore_DP0 pid=491039) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=491039) 	max.f32 	%r157, %r157, %r82;
(EngineCore_DP0 pid=491039) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=491039) 	add.s32 	%r158, %r158, 8192;
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p7, %r158, %r24;
(EngineCore_DP0 pid=491039) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=491039) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=491039) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=491039) 	max.f32 	%r159, %r157, 0f2B8CBCCC;
(EngineCore_DP0 pid=491039) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=491039) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=491039) 	mov.b32 	%r84, 0f43E00000;
(EngineCore_DP0 pid=491039) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=491039) 	div.full.f32 	%r85, %r159, %r84;
(EngineCore_DP0 pid=491039) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=491039) 	max.f32 	%r83, %r85, 0f36924925;
(EngineCore_DP0 pid=491039) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=491039) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=491039) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	@%p28 st.global.b32 [ %rd8 + 0 ], { %r83 };
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=491039) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=491039) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=491039) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=491039) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=491039) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=491039) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=491039) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=491039) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=491039) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=491039) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=491039) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=491039) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=491039) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=491039) 	div.full.f32 	%r14, %r84, %r159;
(EngineCore_DP0 pid=491039) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=491039) 	mov.b32 	%r160, 0;
(EngineCore_DP0 pid=491039) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=491039)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=491039) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=491039) 	add.s32 	%r98, %r16, %r160;
(EngineCore_DP0 pid=491039) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=491039) 	add.s32 	%r99, %r98, 1;
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p18, %r98, %r15;
(EngineCore_DP0 pid=491039) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=491039) 	mul.hi.s32 	%r100, %r99, 1431655766;
(EngineCore_DP0 pid=491039) 	shr.u32 	%r101, %r100, 31;
(EngineCore_DP0 pid=491039) 	add.s32 	%r102, %r100, %r101;
(EngineCore_DP0 pid=491039) 	mul.hi.s32 	%r103, %r98, 1431655766;
(EngineCore_DP0 pid=491039) 	shr.u32 	%r104, %r103, 31;
(EngineCore_DP0 pid=491039) 	add.s32 	%r105, %r103, %r104;
(EngineCore_DP0 pid=491039) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=491039) 	mul.lo.s32 	%r106, %r105, 3;
(EngineCore_DP0 pid=491039) 	mul.lo.s32 	%r107, %r102, 3;
(EngineCore_DP0 pid=491039) 	sub.s32 	%r108, %r99, %r107;
(EngineCore_DP0 pid=491039) 	sub.s32 	%r109, %r98, %r106;
(EngineCore_DP0 pid=491039) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=491039) 	shl.b32 	%r110, %r105, 3;
(EngineCore_DP0 pid=491039) 	shl.b32 	%r111, %r102, 3;
(EngineCore_DP0 pid=491039) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=491039) 	shl.b32 	%r112, %r109, 1;
(EngineCore_DP0 pid=491039) 	shl.b32 	%r113, %r108, 1;
(EngineCore_DP0 pid=491039) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=491039) 	add.s32 	%r114, %r111, %r113;
(EngineCore_DP0 pid=491039) 	add.s32 	%r115, %r110, %r112;
(EngineCore_DP0 pid=491039) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p19, %r115, %r23;
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p20, %r114, %r23;
(EngineCore_DP0 pid=491039) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=491039) 	and.pred 	%p10, %p18, %p19;
(EngineCore_DP0 pid=491039) 	and.pred 	%p11, %p18, %p20;
(EngineCore_DP0 pid=491039) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=491039) 	mad.wide.s32 	%rd9, %r115, 2, %rd1;
(EngineCore_DP0 pid=491039) 	mad.wide.s32 	%rd10, %r114, 2, %rd1;
(EngineCore_DP0 pid=491039) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=491039) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=491039) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=491039) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=491039) 	cvt.f32.bf16 	%r116, %rs48;
(EngineCore_DP0 pid=491039) 	cvt.f32.bf16 	%r117, %rs50;
(EngineCore_DP0 pid=491039) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=491039) 	or.b32 	%r118, %r115, 1;
(EngineCore_DP0 pid=491039) 	or.b32 	%r119, %r114, 1;
(EngineCore_DP0 pid=491039) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p21, %r118, %r23;
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p22, %r119, %r23;
(EngineCore_DP0 pid=491039) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=491039) 	and.pred 	%p12, %p18, %p21;
(EngineCore_DP0 pid=491039) 	and.pred 	%p13, %p18, %p22;
(EngineCore_DP0 pid=491039) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=491039) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=491039) 	add.s64 	%rd12, %rd10, 2;
(EngineCore_DP0 pid=491039) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=491039) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=491039) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=491039) 	cvt.f32.bf16 	%r120, %rs52;
(EngineCore_DP0 pid=491039) 	cvt.f32.bf16 	%r121, %rs54;
(EngineCore_DP0 pid=491039) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=491039) 	add.s32 	%r122, %r115, 2;
(EngineCore_DP0 pid=491039) 	add.s32 	%r123, %r114, 2;
(EngineCore_DP0 pid=491039) 	add.s32 	%r124, %r115, 3;
(EngineCore_DP0 pid=491039) 	add.s32 	%r125, %r114, 3;
(EngineCore_DP0 pid=491039) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p23, %r125, %r23;
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p24, %r124, %r23;
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p25, %r123, %r23;
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p26, %r122, %r23;
(EngineCore_DP0 pid=491039) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=491039) 	and.pred 	%p14, %p18, %p26;
(EngineCore_DP0 pid=491039) 	and.pred 	%p15, %p18, %p25;
(EngineCore_DP0 pid=491039) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=491039) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=491039) 	add.s64 	%rd14, %rd10, 4;
(EngineCore_DP0 pid=491039) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	mov.u16 %rs56, %rs49;
(EngineCore_DP0 pid=491039) 	@%p14 ld.global.b16 { %rs56 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	mov.u16 %rs58, %rs49;
(EngineCore_DP0 pid=491039) 	@%p15 ld.global.b16 { %rs58 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=491039) 	cvt.f32.bf16 	%r126, %rs56;
(EngineCore_DP0 pid=491039) 	cvt.f32.bf16 	%r127, %rs58;
(EngineCore_DP0 pid=491039) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=491039) 	and.pred 	%p16, %p18, %p24;
(EngineCore_DP0 pid=491039) 	and.pred 	%p17, %p18, %p23;
(EngineCore_DP0 pid=491039) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=491039) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=491039) 	add.s64 	%rd16, %rd10, 6;
(EngineCore_DP0 pid=491039) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	mov.u16 %rs60, %rs49;
(EngineCore_DP0 pid=491039) 	@%p16 ld.global.b16 { %rs60 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	mov.u16 %rs62, %rs49;
(EngineCore_DP0 pid=491039) 	@%p17 ld.global.b16 { %rs62 }, [ %rd16 + 0 ];
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=491039) 	cvt.f32.bf16 	%r128, %rs60;
(EngineCore_DP0 pid=491039) 	cvt.f32.bf16 	%r129, %rs62;
(EngineCore_DP0 pid=491039) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=491039) 	mul.f32 	%r130, %r14, %r116;
(EngineCore_DP0 pid=491039) 	mul.f32 	%r131, %r14, %r117;
(EngineCore_DP0 pid=491039) 	mov.b32 	%r132, 0f43E00000;
(EngineCore_DP0 pid=491039) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=491039) 	min.xorsign.abs.f32 	%r87, %r130, %r132;
(EngineCore_DP0 pid=491039) 	min.xorsign.abs.f32 	%r88, %r131, %r132;
(EngineCore_DP0 pid=491039) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	cvt.rn.satfinite.e4m3x2.f32  %rs64, %r88, %r87; 
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	shr.u16 	%rs68, %rs64, 8;
(EngineCore_DP0 pid=491039) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=491039) 	mul.f32 	%r133, %r14, %r120;
(EngineCore_DP0 pid=491039) 	mul.f32 	%r134, %r14, %r121;
(EngineCore_DP0 pid=491039) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=491039) 	min.xorsign.abs.f32 	%r89, %r133, %r132;
(EngineCore_DP0 pid=491039) 	min.xorsign.abs.f32 	%r90, %r134, %r132;
(EngineCore_DP0 pid=491039) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	cvt.rn.satfinite.e4m3x2.f32  %rs65, %r90, %r89; 
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	shr.u16 	%rs69, %rs65, 8;
(EngineCore_DP0 pid=491039) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=491039) 	mul.f32 	%r135, %r14, %r126;
(EngineCore_DP0 pid=491039) 	mul.f32 	%r136, %r14, %r127;
(EngineCore_DP0 pid=491039) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=491039) 	min.xorsign.abs.f32 	%r91, %r135, %r132;
(EngineCore_DP0 pid=491039) 	min.xorsign.abs.f32 	%r92, %r136, %r132;
(EngineCore_DP0 pid=491039) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	cvt.rn.satfinite.e4m3x2.f32  %rs66, %r92, %r91; 
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	shr.u16 	%rs70, %rs66, 8;
(EngineCore_DP0 pid=491039) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=491039) 	mul.f32 	%r137, %r14, %r128;
(EngineCore_DP0 pid=491039) 	mul.f32 	%r138, %r14, %r129;
(EngineCore_DP0 pid=491039) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=491039) 	min.xorsign.abs.f32 	%r93, %r137, %r132;
(EngineCore_DP0 pid=491039) 	min.xorsign.abs.f32 	%r94, %r138, %r132;
(EngineCore_DP0 pid=491039) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	cvt.rn.satfinite.e4m3x2.f32  %rs67, %r94, %r93; 
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	shr.u16 	%rs71, %rs67, 8;
(EngineCore_DP0 pid=491039) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=491039) 	cvt.u32.u16 	%r139, %rs64;
(EngineCore_DP0 pid=491039) 	and.b32 	%r140, %r139, 255;
(EngineCore_DP0 pid=491039) 	cvt.u32.u16 	%r141, %rs68;
(EngineCore_DP0 pid=491039) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=491039) 	cvt.u32.u16 	%r142, %rs66;
(EngineCore_DP0 pid=491039) 	and.b32 	%r143, %r142, 255;
(EngineCore_DP0 pid=491039) 	cvt.u32.u16 	%r144, %rs70;
(EngineCore_DP0 pid=491039) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=491039) 	cvt.u32.u16 	%r145, %rs67;
(EngineCore_DP0 pid=491039) 	cvt.u32.u16 	%r146, %rs71;
(EngineCore_DP0 pid=491039) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=491039) 	and.b16 	%rs72, %rs65, 255;
(EngineCore_DP0 pid=491039) 	mul.wide.u16 	%r147, %rs72, 256;
(EngineCore_DP0 pid=491039) 	mul.wide.u16 	%r148, %rs69, 256;
(EngineCore_DP0 pid=491039) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=491039) 	or.b32 	%r149, %r147, %r140;
(EngineCore_DP0 pid=491039) 	or.b32 	%r150, %r148, %r141;
(EngineCore_DP0 pid=491039) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=491039) 	shl.b32 	%r151, %r143, 16;
(EngineCore_DP0 pid=491039) 	shl.b32 	%r152, %r144, 16;
(EngineCore_DP0 pid=491039) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=491039) 	or.b32 	%r153, %r149, %r151;
(EngineCore_DP0 pid=491039) 	or.b32 	%r154, %r150, %r152;
(EngineCore_DP0 pid=491039) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=491039) 	shl.b32 	%r155, %r145, 24;
(EngineCore_DP0 pid=491039) 	shl.b32 	%r156, %r146, 24;
(EngineCore_DP0 pid=491039) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=491039) 	or.b32 	%r95, %r153, %r155;
(EngineCore_DP0 pid=491039) 	or.b32 	%r96, %r154, %r156;
(EngineCore_DP0 pid=491039) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=491039) 	mad.wide.s32 	%rd17, %r98, 4, %rd2;
(EngineCore_DP0 pid=491039) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=491039) 	// begin inline asm
(EngineCore_DP0 pid=491039) 	@%p18 st.global.v2.b32 [ %rd17 + 0 ], { %r95, %r96 };
(EngineCore_DP0 pid=491039) 	// end inline asm
(EngineCore_DP0 pid=491039) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=491039) 	add.s32 	%r160, %r160, 1024;
(EngineCore_DP0 pid=491039) 	setp.lt.s32 	%p27, %r160, %r15;
(EngineCore_DP0 pid=491039) 	@%p27 bra 	$L__BB0_6;
(EngineCore_DP0 pid=491039) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=491039) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=491039) 	ret;
(EngineCore_DP0 pid=491039) $L__tmp3:
(EngineCore_DP0 pid=491039) $L__func_end0:
(EngineCore_DP0 pid=491039)                                         // -- End function
(EngineCore_DP0 pid=491039) }
(EngineCore_DP0 pid=491039) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=491039) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=491039) 	.section	.debug_abbrev
(EngineCore_DP0 pid=491039) 	{
(EngineCore_DP0 pid=491039) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=491039) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=491039) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=491039) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=491039) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=491039) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=491039) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=491039) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=491039) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=491039) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=491039) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=491039) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=491039) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=491039) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=491039) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=491039) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=491039) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=491039) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=491039) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=491039) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=491039) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=491039) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=491039) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=491039) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=491039) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=491039) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=491039) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=491039) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=491039) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=491039) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=491039) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=491039) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=491039) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=491039) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=491039) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=491039) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=491039) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=491039) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=491039) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=491039) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=491039) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=491039) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=491039) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=491039) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=491039) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=491039) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=491039) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=491039) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=491039) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=491039) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=491039) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=491039) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=491039) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=491039) 	}
(EngineCore_DP0 pid=491039) 	.section	.debug_info
(EngineCore_DP0 pid=491039) 	{
(EngineCore_DP0 pid=491039) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=491039) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=491039) .b8 0
(EngineCore_DP0 pid=491039) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=491039) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=491039) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=491039) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=491039) .b8 114
(EngineCore_DP0 pid=491039) .b8 105
(EngineCore_DP0 pid=491039) .b8 116
(EngineCore_DP0 pid=491039) .b8 111
(EngineCore_DP0 pid=491039) .b8 110
(EngineCore_DP0 pid=491039) .b8 0
(EngineCore_DP0 pid=491039) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=491039) .b8 0
(EngineCore_DP0 pid=491039) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=491039) .b8 117
(EngineCore_DP0 pid=491039) .b8 97
(EngineCore_DP0 pid=491039) .b8 110
(EngineCore_DP0 pid=491039) .b8 116
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 115
(EngineCore_DP0 pid=491039) .b8 108
(EngineCore_DP0 pid=491039) .b8 105
(EngineCore_DP0 pid=491039) .b8 100
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 116
(EngineCore_DP0 pid=491039) .b8 117
(EngineCore_DP0 pid=491039) .b8 110
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 100
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 81
(EngineCore_DP0 pid=491039) .b8 119
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 110
(EngineCore_DP0 pid=491039) .b8 50
(EngineCore_DP0 pid=491039) .b8 46
(EngineCore_DP0 pid=491039) .b8 53
(EngineCore_DP0 pid=491039) .b8 45
(EngineCore_DP0 pid=491039) .b8 55
(EngineCore_DP0 pid=491039) .b8 66
(EngineCore_DP0 pid=491039) .b8 46
(EngineCore_DP0 pid=491039) .b8 112
(EngineCore_DP0 pid=491039) .b8 121
(EngineCore_DP0 pid=491039) .b8 0
(EngineCore_DP0 pid=491039) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=491039) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=491039) .b8 114
(EngineCore_DP0 pid=491039) .b8 111
(EngineCore_DP0 pid=491039) .b8 111
(EngineCore_DP0 pid=491039) .b8 116
(EngineCore_DP0 pid=491039) .b8 47
(EngineCore_DP0 pid=491039) .b8 118
(EngineCore_DP0 pid=491039) .b8 108
(EngineCore_DP0 pid=491039) .b8 108
(EngineCore_DP0 pid=491039) .b8 109
(EngineCore_DP0 pid=491039) .b8 98
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 110
(EngineCore_DP0 pid=491039) .b8 99
(EngineCore_DP0 pid=491039) .b8 104
(EngineCore_DP0 pid=491039) .b8 47
(EngineCore_DP0 pid=491039) .b8 115
(EngineCore_DP0 pid=491039) .b8 108
(EngineCore_DP0 pid=491039) .b8 105
(EngineCore_DP0 pid=491039) .b8 100
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 115
(EngineCore_DP0 pid=491039) .b8 112
(EngineCore_DP0 pid=491039) .b8 97
(EngineCore_DP0 pid=491039) .b8 114
(EngineCore_DP0 pid=491039) .b8 115
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 47
(EngineCore_DP0 pid=491039) .b8 99
(EngineCore_DP0 pid=491039) .b8 115
(EngineCore_DP0 pid=491039) .b8 114
(EngineCore_DP0 pid=491039) .b8 99
(EngineCore_DP0 pid=491039) .b8 47
(EngineCore_DP0 pid=491039) .b8 102
(EngineCore_DP0 pid=491039) .b8 117
(EngineCore_DP0 pid=491039) .b8 115
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 100
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 113
(EngineCore_DP0 pid=491039) .b8 117
(EngineCore_DP0 pid=491039) .b8 97
(EngineCore_DP0 pid=491039) .b8 110
(EngineCore_DP0 pid=491039) .b8 116
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 115
(EngineCore_DP0 pid=491039) .b8 108
(EngineCore_DP0 pid=491039) .b8 105
(EngineCore_DP0 pid=491039) .b8 100
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 116
(EngineCore_DP0 pid=491039) .b8 114
(EngineCore_DP0 pid=491039) .b8 105
(EngineCore_DP0 pid=491039) .b8 116
(EngineCore_DP0 pid=491039) .b8 111
(EngineCore_DP0 pid=491039) .b8 110
(EngineCore_DP0 pid=491039) .b8 47
(EngineCore_DP0 pid=491039) .b8 98
(EngineCore_DP0 pid=491039) .b8 117
(EngineCore_DP0 pid=491039) .b8 105
(EngineCore_DP0 pid=491039) .b8 108
(EngineCore_DP0 pid=491039) .b8 100
(EngineCore_DP0 pid=491039) .b8 47
(EngineCore_DP0 pid=491039) .b8 71
(EngineCore_DP0 pid=491039) .b8 66
(EngineCore_DP0 pid=491039) .b8 49
(EngineCore_DP0 pid=491039) .b8 48
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 99
(EngineCore_DP0 pid=491039) .b8 99
(EngineCore_DP0 pid=491039) .b8 49
(EngineCore_DP0 pid=491039) .b8 50
(EngineCore_DP0 pid=491039) .b8 49
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 112
(EngineCore_DP0 pid=491039) .b8 121
(EngineCore_DP0 pid=491039) .b8 51
(EngineCore_DP0 pid=491039) .b8 49
(EngineCore_DP0 pid=491039) .b8 50
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 99
(EngineCore_DP0 pid=491039) .b8 117
(EngineCore_DP0 pid=491039) .b8 49
(EngineCore_DP0 pid=491039) .b8 50
(EngineCore_DP0 pid=491039) .b8 57
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 97
(EngineCore_DP0 pid=491039) .b8 97
(EngineCore_DP0 pid=491039) .b8 114
(EngineCore_DP0 pid=491039) .b8 99
(EngineCore_DP0 pid=491039) .b8 104
(EngineCore_DP0 pid=491039) .b8 54
(EngineCore_DP0 pid=491039) .b8 52
(EngineCore_DP0 pid=491039) .b8 0
(EngineCore_DP0 pid=491039) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=491039) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=491039) .b8 113
(EngineCore_DP0 pid=491039) .b8 117
(EngineCore_DP0 pid=491039) .b8 97
(EngineCore_DP0 pid=491039) .b8 110
(EngineCore_DP0 pid=491039) .b8 116
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 115
(EngineCore_DP0 pid=491039) .b8 108
(EngineCore_DP0 pid=491039) .b8 105
(EngineCore_DP0 pid=491039) .b8 100
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 102
(EngineCore_DP0 pid=491039) .b8 112
(EngineCore_DP0 pid=491039) .b8 56
(EngineCore_DP0 pid=491039) .b8 95
(EngineCore_DP0 pid=491039) .b8 107
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 114
(EngineCore_DP0 pid=491039) .b8 110
(EngineCore_DP0 pid=491039) .b8 101
(EngineCore_DP0 pid=491039) .b8 108
(EngineCore_DP0 pid=491039) .b8 0
(EngineCore_DP0 pid=491039) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=491039) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=491039) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=491039) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=491039) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=491039) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=491039) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=491039) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=491039) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=491039) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=491039) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=491039) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=491039) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=491039) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=491039) 	}
(EngineCore_DP0 pid=491039) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) ================================================================
(EngineCore_DP0 pid=491039) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpnj9r_3zt.ptx', '-o', '/tmp/tmpnj9r_3zt.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] 
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] 
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] 
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnj9r_3zt.ptx -o /tmp/tmpnj9r_3zt.ptx.o
(EngineCore_DP0 pid=491039) ERROR 01-25 21:42:47 [core.py:866] 

STDERR:
[2026-01-25 21:41:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:41:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:41:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:41:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:41:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:41:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:41:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:41:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:41:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:41:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:41:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:41:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:41:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:41:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:41:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:41:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:41:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=491039) [2026-01-25 21:41:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=491039) [2026-01-25 21:41:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=491039) [2026-01-25 21:41:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=491039) [2026-01-25 21:41:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=491039) [2026-01-25 21:41:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=491039) [2026-01-25 21:41:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=491039) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=491039) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.48s/it]
(EngineCore_DP0 pid=491039) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.77s/it]
(EngineCore_DP0 pid=491039) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.27s/it]
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) [2026-01-25 21:42:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=491039) [2026-01-25 21:42:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=491039) [2026-01-25 21:42:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=491039) [2026-01-25 21:42:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=491039) [2026-01-25 21:42:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=491039) [2026-01-25 21:42:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=491039) [2026-01-25 21:42:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=491039) [2026-01-25 21:42:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=491039) Process EngineCore_DP0:
(EngineCore_DP0 pid=491039) Traceback (most recent call last):
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=491039)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=491039)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=491039)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=491039) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmpnj9r_3zt.ptx', '-o', '/tmp/tmpnj9r_3zt.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) Traceback (most recent call last):
(EngineCore_DP0 pid=491039)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=491039)     self.run()
(EngineCore_DP0 pid=491039)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=491039)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=491039)     raise e
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=491039)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=491039)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=491039)     super().__init__(
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=491039)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=491039)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=491039)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=491039)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=491039)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=491039)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=491039)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=491039)     return func(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=491039)     return func(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=491039)     self.model_runner.profile_run()
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=491039)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=491039)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=491039)     return func(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=491039)     outputs = self.model(
(EngineCore_DP0 pid=491039)               ^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=491039)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=491039)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=491039)     hidden_states = self.model(
(EngineCore_DP0 pid=491039)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=491039)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=491039)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=491039)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=491039)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=491039)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=491039)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=491039)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=491039)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=491039)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=491039)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=491039)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=491039)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=491039)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=491039)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=491039)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=491039)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=491039)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=491039)     return self._linear_fn(
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=491039)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=491039)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=491039)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=491039)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=491039)     return fn(input, L)
(EngineCore_DP0 pid=491039)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=491039)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=491039)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=491039)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=491039)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=491039)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=491039)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=491039)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=491039)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=491039)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=491039)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=491039)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=491039)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=491039)     raise PTXASError(error)
(EngineCore_DP0 pid=491039) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=491039) `ptxas` stderr:
(EngineCore_DP0 pid=491039) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=491039) 
(EngineCore_DP0 pid=491039) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmpnj9r_3zt.ptx -o /tmp/tmpnj9r_3zt.ptx.o
(EngineCore_DP0 pid=491039) 
[rank0]:[W125 21:42:48.450128019 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=16384

========== M=32768 ==========
Time: 2026-01-25 21:42:49
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:43:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:43:07 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=492453) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) ================================================================
(EngineCore_DP0 pid=492453) Internal Triton PTX codegen error
(EngineCore_DP0 pid=492453) `ptxas` stderr:
(EngineCore_DP0 pid=492453) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp000mrvu0.ptx -o /tmp/tmp000mrvu0.ptx.o
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) //
(EngineCore_DP0 pid=492453) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=492453) //
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) .version 8.7
(EngineCore_DP0 pid=492453) .target sm_121a
(EngineCore_DP0 pid=492453) .address_size 64
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=492453) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=492453)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=492453) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=492453) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=492453) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=492453) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=492453) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=492453) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=492453) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=492453) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=492453) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=492453) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=492453) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=492453) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=492453) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=492453) )
(EngineCore_DP0 pid=492453) .reqntid 512
(EngineCore_DP0 pid=492453) {
(EngineCore_DP0 pid=492453) 	.reg .pred 	%p<28>;
(EngineCore_DP0 pid=492453) 	.reg .b16 	%rs<49>;
(EngineCore_DP0 pid=492453) 	.reg .b32 	%r<152>;
(EngineCore_DP0 pid=492453) 	.reg .b64 	%rd<17>;
(EngineCore_DP0 pid=492453) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=492453) $L__func_begin0:
(EngineCore_DP0 pid=492453) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) // %bb.0:
(EngineCore_DP0 pid=492453) 	ld.param.b32 	%r25, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=492453) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=492453) 	ld.param.b32 	%r23, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=492453) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=492453) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=492453) $L__tmp0:
(EngineCore_DP0 pid=492453) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=492453) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=492453) 	ld.param.b32 	%r27, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=492453) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=492453) 	mul.lo.s32 	%r28, %r27, %r1;
(EngineCore_DP0 pid=492453) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=492453) 	mad.wide.s32 	%rd1, %r28, 2, %rd4;
(EngineCore_DP0 pid=492453) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=492453) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=492453) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=492453) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p1, %r24, 1;
(EngineCore_DP0 pid=492453) 	mov.b32 	%r150, 0f2B8CBCCC;
(EngineCore_DP0 pid=492453) 	setp.eq.b32 	%p27, %r2, 0;
(EngineCore_DP0 pid=492453) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=492453) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=492453) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=492453) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=492453) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=492453) 	shr.u32 	%r37, %r2, 3;
(EngineCore_DP0 pid=492453) 	and.b32 	%r38, %r37, 60;
(EngineCore_DP0 pid=492453) 	mov.b32 	%r39, global_smem;
(EngineCore_DP0 pid=492453) 	add.s32 	%r49, %r39, %r38;
(EngineCore_DP0 pid=492453) 	shl.b32 	%r40, %r2, 2;
(EngineCore_DP0 pid=492453) 	add.s32 	%r52, %r39, %r40;
(EngineCore_DP0 pid=492453) 	mov.b32 	%r45, 0;
(EngineCore_DP0 pid=492453) 	mov.b32 	%r148, 0f00000000;
(EngineCore_DP0 pid=492453) 	setp.lt.u32 	%p4, %r2, 16;
(EngineCore_DP0 pid=492453) 	setp.eq.b32 	%p3, %r5, 0;
(EngineCore_DP0 pid=492453) 	mov.b32 	%r149, %r45;
(EngineCore_DP0 pid=492453) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=492453) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=492453) 	add.s32 	%r55, %r4, %r149;
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p2, %r55, %r23;
(EngineCore_DP0 pid=492453) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=492453) 	mad.wide.s32 	%rd6, %r55, 2, %rd1;
(EngineCore_DP0 pid=492453) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	mov.u32 %r41, %r45;
(EngineCore_DP0 pid=492453) 	mov.u32 %r42, %r45;
(EngineCore_DP0 pid=492453) 	mov.u32 %r43, %r45;
(EngineCore_DP0 pid=492453) 	mov.u32 %r44, %r45;
(EngineCore_DP0 pid=492453) 	@%p2 ld.global.v4.b32 { %r41, %r42, %r43, %r44 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	mov.b32 	{%rs1, %rs2}, %r41;
(EngineCore_DP0 pid=492453) 	mov.b32 	{%rs3, %rs4}, %r42;
(EngineCore_DP0 pid=492453) 	mov.b32 	{%rs5, %rs6}, %r43;
(EngineCore_DP0 pid=492453) 	mov.b32 	{%rs7, %rs8}, %r44;
(EngineCore_DP0 pid=492453) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=492453) 	abs.bf16 	%rs9, %rs1;
(EngineCore_DP0 pid=492453) 	abs.bf16 	%rs10, %rs2;
(EngineCore_DP0 pid=492453) 	abs.bf16 	%rs11, %rs3;
(EngineCore_DP0 pid=492453) 	abs.bf16 	%rs12, %rs4;
(EngineCore_DP0 pid=492453) 	abs.bf16 	%rs13, %rs5;
(EngineCore_DP0 pid=492453) 	abs.bf16 	%rs14, %rs6;
(EngineCore_DP0 pid=492453) 	abs.bf16 	%rs15, %rs7;
(EngineCore_DP0 pid=492453) 	abs.bf16 	%rs16, %rs8;
(EngineCore_DP0 pid=492453) $L__tmp1:
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	bar.sync 	0;
(EngineCore_DP0 pid=492453) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	max.bf16 	%rs17, %rs9, %rs10;
(EngineCore_DP0 pid=492453) 	max.bf16 	%rs18, %rs17, %rs11;
(EngineCore_DP0 pid=492453) 	max.bf16 	%rs19, %rs18, %rs12;
(EngineCore_DP0 pid=492453) 	max.bf16 	%rs20, %rs19, %rs13;
(EngineCore_DP0 pid=492453) 	max.bf16 	%rs21, %rs20, %rs14;
(EngineCore_DP0 pid=492453) 	max.bf16 	%rs22, %rs21, %rs15;
(EngineCore_DP0 pid=492453) 	max.bf16 	%rs23, %rs22, %rs16;
(EngineCore_DP0 pid=492453) 	cvt.f32.bf16 	%r56, %rs23;
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	shfl.sync.bfly.b32 	%r57, %r56, 16, 31, -1;
(EngineCore_DP0 pid=492453) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	max.f32 	%r58, %r56, %r57;
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	shfl.sync.bfly.b32 	%r59, %r58, 8, 31, -1;
(EngineCore_DP0 pid=492453) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	max.f32 	%r60, %r58, %r59;
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	shfl.sync.bfly.b32 	%r61, %r60, 4, 31, -1;
(EngineCore_DP0 pid=492453) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	shfl.sync.bfly.b32 	%r63, %r62, 2, 31, -1;
(EngineCore_DP0 pid=492453) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	shfl.sync.bfly.b32 	%r65, %r64, 1, 31, -1;
(EngineCore_DP0 pid=492453) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	max.f32 	%r50, %r64, %r65;
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	@%p3 st.shared.b32 [ %r49 + 0 ], %r50;
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	bar.sync 	0;
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	@%p4 ld.shared.b32 %r51, [ %r52 + 0 ];
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	shfl.sync.bfly.b32 	%r66, %r51, 8, 31, -1;
(EngineCore_DP0 pid=492453) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	max.f32 	%r67, %r51, %r66;
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	shfl.sync.bfly.b32 	%r68, %r67, 4, 31, -1;
(EngineCore_DP0 pid=492453) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	max.f32 	%r69, %r67, %r68;
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	shfl.sync.bfly.b32 	%r70, %r69, 2, 31, -1;
(EngineCore_DP0 pid=492453) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	max.f32 	%r71, %r69, %r70;
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	shfl.sync.bfly.b32 	%r72, %r71, 1, 31, -1;
(EngineCore_DP0 pid=492453) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	max.f32 	%r54, %r71, %r72;
(EngineCore_DP0 pid=492453) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	@%p27 st.shared.b32 [ %r52 + 0 ], %r54;
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	bar.sync 	0;
(EngineCore_DP0 pid=492453) 	ld.shared.b32 	%r73, [global_smem];
(EngineCore_DP0 pid=492453) $L__tmp2:
(EngineCore_DP0 pid=492453) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=492453) 	max.f32 	%r148, %r148, %r73;
(EngineCore_DP0 pid=492453) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=492453) 	add.s32 	%r149, %r149, 4096;
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p6, %r149, %r24;
(EngineCore_DP0 pid=492453) 	@%p6 bra 	$L__BB0_2;
(EngineCore_DP0 pid=492453) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=492453) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=492453) 	max.f32 	%r150, %r148, 0f2B8CBCCC;
(EngineCore_DP0 pid=492453) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=492453) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=492453) 	mov.b32 	%r75, 0f43E00000;
(EngineCore_DP0 pid=492453) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=492453) 	div.full.f32 	%r76, %r150, %r75;
(EngineCore_DP0 pid=492453) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=492453) 	max.f32 	%r74, %r76, 0f36924925;
(EngineCore_DP0 pid=492453) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=492453) 	mad.wide.u32 	%rd7, %r1, 4, %rd3;
(EngineCore_DP0 pid=492453) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	@%p27 st.global.b32 [ %rd7 + 0 ], { %r74 };
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=492453) 	mul.lo.s32 	%r15, %r25, 3;
(EngineCore_DP0 pid=492453) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p8, %r15, 1;
(EngineCore_DP0 pid=492453) 	@%p8 bra 	$L__BB0_7;
(EngineCore_DP0 pid=492453) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=492453) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=492453) 	ld.param.b32 	%r29, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=492453) 	shr.s32 	%r30, %r29, 31;
(EngineCore_DP0 pid=492453) 	shr.u32 	%r31, %r30, 30;
(EngineCore_DP0 pid=492453) 	add.s32 	%r32, %r29, %r31;
(EngineCore_DP0 pid=492453) 	shr.s32 	%r33, %r32, 2;
(EngineCore_DP0 pid=492453) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=492453) 	mul.lo.s32 	%r34, %r33, %r1;
(EngineCore_DP0 pid=492453) 	mad.wide.s32 	%rd2, %r34, 4, %rd5;
(EngineCore_DP0 pid=492453) 	div.full.f32 	%r14, %r75, %r150;
(EngineCore_DP0 pid=492453) 	shl.b32 	%r16, %r3, 1;
(EngineCore_DP0 pid=492453) 	mov.b32 	%r151, 0;
(EngineCore_DP0 pid=492453) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=492453)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=492453) 	.loc	1 168 31                        // quant_slide_tuned_Qwen2.5-7B.py:168:31
(EngineCore_DP0 pid=492453) 	add.s32 	%r89, %r16, %r151;
(EngineCore_DP0 pid=492453) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=492453) 	add.s32 	%r90, %r89, 1;
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p17, %r89, %r15;
(EngineCore_DP0 pid=492453) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=492453) 	mul.hi.s32 	%r91, %r90, 1431655766;
(EngineCore_DP0 pid=492453) 	shr.u32 	%r92, %r91, 31;
(EngineCore_DP0 pid=492453) 	add.s32 	%r93, %r91, %r92;
(EngineCore_DP0 pid=492453) 	mul.hi.s32 	%r94, %r89, 1431655766;
(EngineCore_DP0 pid=492453) 	shr.u32 	%r95, %r94, 31;
(EngineCore_DP0 pid=492453) 	add.s32 	%r96, %r94, %r95;
(EngineCore_DP0 pid=492453) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=492453) 	mul.lo.s32 	%r97, %r96, 3;
(EngineCore_DP0 pid=492453) 	mul.lo.s32 	%r98, %r93, 3;
(EngineCore_DP0 pid=492453) 	sub.s32 	%r99, %r90, %r98;
(EngineCore_DP0 pid=492453) 	sub.s32 	%r100, %r89, %r97;
(EngineCore_DP0 pid=492453) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=492453) 	shl.b32 	%r101, %r96, 3;
(EngineCore_DP0 pid=492453) 	shl.b32 	%r102, %r93, 3;
(EngineCore_DP0 pid=492453) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=492453) 	shl.b32 	%r103, %r100, 1;
(EngineCore_DP0 pid=492453) 	shl.b32 	%r104, %r99, 1;
(EngineCore_DP0 pid=492453) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=492453) 	add.s32 	%r105, %r102, %r104;
(EngineCore_DP0 pid=492453) 	add.s32 	%r106, %r101, %r103;
(EngineCore_DP0 pid=492453) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p18, %r106, %r23;
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p19, %r105, %r23;
(EngineCore_DP0 pid=492453) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=492453) 	and.pred 	%p9, %p17, %p18;
(EngineCore_DP0 pid=492453) 	and.pred 	%p10, %p17, %p19;
(EngineCore_DP0 pid=492453) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=492453) 	mad.wide.s32 	%rd8, %r106, 2, %rd1;
(EngineCore_DP0 pid=492453) 	mad.wide.s32 	%rd9, %r105, 2, %rd1;
(EngineCore_DP0 pid=492453) 	mov.b16 	%rs25, 0;
(EngineCore_DP0 pid=492453) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	mov.u16 %rs24, %rs25;
(EngineCore_DP0 pid=492453) 	@%p9 ld.global.b16 { %rs24 }, [ %rd8 + 0 ];
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	mov.u16 %rs26, %rs25;
(EngineCore_DP0 pid=492453) 	@%p10 ld.global.b16 { %rs26 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=492453) 	cvt.f32.bf16 	%r107, %rs24;
(EngineCore_DP0 pid=492453) 	cvt.f32.bf16 	%r108, %rs26;
(EngineCore_DP0 pid=492453) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=492453) 	or.b32 	%r109, %r106, 1;
(EngineCore_DP0 pid=492453) 	or.b32 	%r110, %r105, 1;
(EngineCore_DP0 pid=492453) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p20, %r109, %r23;
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p21, %r110, %r23;
(EngineCore_DP0 pid=492453) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=492453) 	and.pred 	%p11, %p17, %p20;
(EngineCore_DP0 pid=492453) 	and.pred 	%p12, %p17, %p21;
(EngineCore_DP0 pid=492453) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=492453) 	add.s64 	%rd10, %rd8, 2;
(EngineCore_DP0 pid=492453) 	add.s64 	%rd11, %rd9, 2;
(EngineCore_DP0 pid=492453) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	mov.u16 %rs28, %rs25;
(EngineCore_DP0 pid=492453) 	@%p11 ld.global.b16 { %rs28 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	mov.u16 %rs30, %rs25;
(EngineCore_DP0 pid=492453) 	@%p12 ld.global.b16 { %rs30 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=492453) 	cvt.f32.bf16 	%r111, %rs28;
(EngineCore_DP0 pid=492453) 	cvt.f32.bf16 	%r112, %rs30;
(EngineCore_DP0 pid=492453) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=492453) 	add.s32 	%r113, %r106, 2;
(EngineCore_DP0 pid=492453) 	add.s32 	%r114, %r105, 2;
(EngineCore_DP0 pid=492453) 	add.s32 	%r115, %r106, 3;
(EngineCore_DP0 pid=492453) 	add.s32 	%r116, %r105, 3;
(EngineCore_DP0 pid=492453) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p22, %r116, %r23;
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p23, %r115, %r23;
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p24, %r114, %r23;
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p25, %r113, %r23;
(EngineCore_DP0 pid=492453) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=492453) 	and.pred 	%p13, %p17, %p25;
(EngineCore_DP0 pid=492453) 	and.pred 	%p14, %p17, %p24;
(EngineCore_DP0 pid=492453) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=492453) 	add.s64 	%rd12, %rd8, 4;
(EngineCore_DP0 pid=492453) 	add.s64 	%rd13, %rd9, 4;
(EngineCore_DP0 pid=492453) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	mov.u16 %rs32, %rs25;
(EngineCore_DP0 pid=492453) 	@%p13 ld.global.b16 { %rs32 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	mov.u16 %rs34, %rs25;
(EngineCore_DP0 pid=492453) 	@%p14 ld.global.b16 { %rs34 }, [ %rd13 + 0 ];
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=492453) 	cvt.f32.bf16 	%r117, %rs32;
(EngineCore_DP0 pid=492453) 	cvt.f32.bf16 	%r118, %rs34;
(EngineCore_DP0 pid=492453) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=492453) 	and.pred 	%p15, %p17, %p23;
(EngineCore_DP0 pid=492453) 	and.pred 	%p16, %p17, %p22;
(EngineCore_DP0 pid=492453) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=492453) 	add.s64 	%rd14, %rd8, 6;
(EngineCore_DP0 pid=492453) 	add.s64 	%rd15, %rd9, 6;
(EngineCore_DP0 pid=492453) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	mov.u16 %rs36, %rs25;
(EngineCore_DP0 pid=492453) 	@%p15 ld.global.b16 { %rs36 }, [ %rd14 + 0 ];
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	mov.u16 %rs38, %rs25;
(EngineCore_DP0 pid=492453) 	@%p16 ld.global.b16 { %rs38 }, [ %rd15 + 0 ];
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=492453) 	cvt.f32.bf16 	%r119, %rs36;
(EngineCore_DP0 pid=492453) 	cvt.f32.bf16 	%r120, %rs38;
(EngineCore_DP0 pid=492453) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=492453) 	mul.f32 	%r121, %r14, %r107;
(EngineCore_DP0 pid=492453) 	mul.f32 	%r122, %r14, %r108;
(EngineCore_DP0 pid=492453) 	mov.b32 	%r123, 0f43E00000;
(EngineCore_DP0 pid=492453) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=492453) 	min.xorsign.abs.f32 	%r78, %r121, %r123;
(EngineCore_DP0 pid=492453) 	min.xorsign.abs.f32 	%r79, %r122, %r123;
(EngineCore_DP0 pid=492453) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	cvt.rn.satfinite.e4m3x2.f32  %rs40, %r79, %r78; 
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	shr.u16 	%rs44, %rs40, 8;
(EngineCore_DP0 pid=492453) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=492453) 	mul.f32 	%r124, %r14, %r111;
(EngineCore_DP0 pid=492453) 	mul.f32 	%r125, %r14, %r112;
(EngineCore_DP0 pid=492453) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=492453) 	min.xorsign.abs.f32 	%r80, %r124, %r123;
(EngineCore_DP0 pid=492453) 	min.xorsign.abs.f32 	%r81, %r125, %r123;
(EngineCore_DP0 pid=492453) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	cvt.rn.satfinite.e4m3x2.f32  %rs41, %r81, %r80; 
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	shr.u16 	%rs45, %rs41, 8;
(EngineCore_DP0 pid=492453) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=492453) 	mul.f32 	%r126, %r14, %r117;
(EngineCore_DP0 pid=492453) 	mul.f32 	%r127, %r14, %r118;
(EngineCore_DP0 pid=492453) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=492453) 	min.xorsign.abs.f32 	%r82, %r126, %r123;
(EngineCore_DP0 pid=492453) 	min.xorsign.abs.f32 	%r83, %r127, %r123;
(EngineCore_DP0 pid=492453) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	cvt.rn.satfinite.e4m3x2.f32  %rs42, %r83, %r82; 
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	shr.u16 	%rs46, %rs42, 8;
(EngineCore_DP0 pid=492453) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=492453) 	mul.f32 	%r128, %r14, %r119;
(EngineCore_DP0 pid=492453) 	mul.f32 	%r129, %r14, %r120;
(EngineCore_DP0 pid=492453) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=492453) 	min.xorsign.abs.f32 	%r84, %r128, %r123;
(EngineCore_DP0 pid=492453) 	min.xorsign.abs.f32 	%r85, %r129, %r123;
(EngineCore_DP0 pid=492453) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	cvt.rn.satfinite.e4m3x2.f32  %rs43, %r85, %r84; 
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	shr.u16 	%rs47, %rs43, 8;
(EngineCore_DP0 pid=492453) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=492453) 	cvt.u32.u16 	%r130, %rs40;
(EngineCore_DP0 pid=492453) 	and.b32 	%r131, %r130, 255;
(EngineCore_DP0 pid=492453) 	cvt.u32.u16 	%r132, %rs44;
(EngineCore_DP0 pid=492453) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=492453) 	cvt.u32.u16 	%r133, %rs42;
(EngineCore_DP0 pid=492453) 	and.b32 	%r134, %r133, 255;
(EngineCore_DP0 pid=492453) 	cvt.u32.u16 	%r135, %rs46;
(EngineCore_DP0 pid=492453) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=492453) 	cvt.u32.u16 	%r136, %rs43;
(EngineCore_DP0 pid=492453) 	cvt.u32.u16 	%r137, %rs47;
(EngineCore_DP0 pid=492453) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=492453) 	and.b16 	%rs48, %rs41, 255;
(EngineCore_DP0 pid=492453) 	mul.wide.u16 	%r138, %rs48, 256;
(EngineCore_DP0 pid=492453) 	mul.wide.u16 	%r139, %rs45, 256;
(EngineCore_DP0 pid=492453) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=492453) 	or.b32 	%r140, %r138, %r131;
(EngineCore_DP0 pid=492453) 	or.b32 	%r141, %r139, %r132;
(EngineCore_DP0 pid=492453) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=492453) 	shl.b32 	%r142, %r134, 16;
(EngineCore_DP0 pid=492453) 	shl.b32 	%r143, %r135, 16;
(EngineCore_DP0 pid=492453) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=492453) 	or.b32 	%r144, %r140, %r142;
(EngineCore_DP0 pid=492453) 	or.b32 	%r145, %r141, %r143;
(EngineCore_DP0 pid=492453) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=492453) 	shl.b32 	%r146, %r136, 24;
(EngineCore_DP0 pid=492453) 	shl.b32 	%r147, %r137, 24;
(EngineCore_DP0 pid=492453) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=492453) 	or.b32 	%r86, %r144, %r146;
(EngineCore_DP0 pid=492453) 	or.b32 	%r87, %r145, %r147;
(EngineCore_DP0 pid=492453) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=492453) 	mad.wide.s32 	%rd16, %r89, 4, %rd2;
(EngineCore_DP0 pid=492453) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=492453) 	// begin inline asm
(EngineCore_DP0 pid=492453) 	@%p17 st.global.v2.b32 [ %rd16 + 0 ], { %r86, %r87 };
(EngineCore_DP0 pid=492453) 	// end inline asm
(EngineCore_DP0 pid=492453) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=492453) 	add.s32 	%r151, %r151, 1024;
(EngineCore_DP0 pid=492453) 	setp.lt.s32 	%p26, %r151, %r15;
(EngineCore_DP0 pid=492453) 	@%p26 bra 	$L__BB0_6;
(EngineCore_DP0 pid=492453) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=492453) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=492453) 	ret;
(EngineCore_DP0 pid=492453) $L__tmp3:
(EngineCore_DP0 pid=492453) $L__func_end0:
(EngineCore_DP0 pid=492453)                                         // -- End function
(EngineCore_DP0 pid=492453) }
(EngineCore_DP0 pid=492453) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=492453) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=492453) 	.section	.debug_abbrev
(EngineCore_DP0 pid=492453) 	{
(EngineCore_DP0 pid=492453) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=492453) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=492453) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=492453) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=492453) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=492453) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=492453) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=492453) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=492453) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=492453) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=492453) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=492453) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=492453) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=492453) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=492453) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=492453) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=492453) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=492453) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=492453) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=492453) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=492453) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=492453) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=492453) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=492453) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=492453) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=492453) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=492453) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=492453) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=492453) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=492453) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=492453) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=492453) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=492453) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=492453) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=492453) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=492453) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=492453) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=492453) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=492453) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=492453) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=492453) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=492453) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=492453) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=492453) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=492453) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=492453) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=492453) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=492453) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=492453) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=492453) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=492453) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=492453) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=492453) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=492453) 	}
(EngineCore_DP0 pid=492453) 	.section	.debug_info
(EngineCore_DP0 pid=492453) 	{
(EngineCore_DP0 pid=492453) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=492453) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=492453) .b8 0
(EngineCore_DP0 pid=492453) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=492453) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=492453) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=492453) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=492453) .b8 114
(EngineCore_DP0 pid=492453) .b8 105
(EngineCore_DP0 pid=492453) .b8 116
(EngineCore_DP0 pid=492453) .b8 111
(EngineCore_DP0 pid=492453) .b8 110
(EngineCore_DP0 pid=492453) .b8 0
(EngineCore_DP0 pid=492453) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=492453) .b8 0
(EngineCore_DP0 pid=492453) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=492453) .b8 117
(EngineCore_DP0 pid=492453) .b8 97
(EngineCore_DP0 pid=492453) .b8 110
(EngineCore_DP0 pid=492453) .b8 116
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 115
(EngineCore_DP0 pid=492453) .b8 108
(EngineCore_DP0 pid=492453) .b8 105
(EngineCore_DP0 pid=492453) .b8 100
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 116
(EngineCore_DP0 pid=492453) .b8 117
(EngineCore_DP0 pid=492453) .b8 110
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 100
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 81
(EngineCore_DP0 pid=492453) .b8 119
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 110
(EngineCore_DP0 pid=492453) .b8 50
(EngineCore_DP0 pid=492453) .b8 46
(EngineCore_DP0 pid=492453) .b8 53
(EngineCore_DP0 pid=492453) .b8 45
(EngineCore_DP0 pid=492453) .b8 55
(EngineCore_DP0 pid=492453) .b8 66
(EngineCore_DP0 pid=492453) .b8 46
(EngineCore_DP0 pid=492453) .b8 112
(EngineCore_DP0 pid=492453) .b8 121
(EngineCore_DP0 pid=492453) .b8 0
(EngineCore_DP0 pid=492453) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=492453) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=492453) .b8 114
(EngineCore_DP0 pid=492453) .b8 111
(EngineCore_DP0 pid=492453) .b8 111
(EngineCore_DP0 pid=492453) .b8 116
(EngineCore_DP0 pid=492453) .b8 47
(EngineCore_DP0 pid=492453) .b8 118
(EngineCore_DP0 pid=492453) .b8 108
(EngineCore_DP0 pid=492453) .b8 108
(EngineCore_DP0 pid=492453) .b8 109
(EngineCore_DP0 pid=492453) .b8 98
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 110
(EngineCore_DP0 pid=492453) .b8 99
(EngineCore_DP0 pid=492453) .b8 104
(EngineCore_DP0 pid=492453) .b8 47
(EngineCore_DP0 pid=492453) .b8 115
(EngineCore_DP0 pid=492453) .b8 108
(EngineCore_DP0 pid=492453) .b8 105
(EngineCore_DP0 pid=492453) .b8 100
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 115
(EngineCore_DP0 pid=492453) .b8 112
(EngineCore_DP0 pid=492453) .b8 97
(EngineCore_DP0 pid=492453) .b8 114
(EngineCore_DP0 pid=492453) .b8 115
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 47
(EngineCore_DP0 pid=492453) .b8 99
(EngineCore_DP0 pid=492453) .b8 115
(EngineCore_DP0 pid=492453) .b8 114
(EngineCore_DP0 pid=492453) .b8 99
(EngineCore_DP0 pid=492453) .b8 47
(EngineCore_DP0 pid=492453) .b8 102
(EngineCore_DP0 pid=492453) .b8 117
(EngineCore_DP0 pid=492453) .b8 115
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 100
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 113
(EngineCore_DP0 pid=492453) .b8 117
(EngineCore_DP0 pid=492453) .b8 97
(EngineCore_DP0 pid=492453) .b8 110
(EngineCore_DP0 pid=492453) .b8 116
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 115
(EngineCore_DP0 pid=492453) .b8 108
(EngineCore_DP0 pid=492453) .b8 105
(EngineCore_DP0 pid=492453) .b8 100
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 116
(EngineCore_DP0 pid=492453) .b8 114
(EngineCore_DP0 pid=492453) .b8 105
(EngineCore_DP0 pid=492453) .b8 116
(EngineCore_DP0 pid=492453) .b8 111
(EngineCore_DP0 pid=492453) .b8 110
(EngineCore_DP0 pid=492453) .b8 47
(EngineCore_DP0 pid=492453) .b8 98
(EngineCore_DP0 pid=492453) .b8 117
(EngineCore_DP0 pid=492453) .b8 105
(EngineCore_DP0 pid=492453) .b8 108
(EngineCore_DP0 pid=492453) .b8 100
(EngineCore_DP0 pid=492453) .b8 47
(EngineCore_DP0 pid=492453) .b8 71
(EngineCore_DP0 pid=492453) .b8 66
(EngineCore_DP0 pid=492453) .b8 49
(EngineCore_DP0 pid=492453) .b8 48
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 99
(EngineCore_DP0 pid=492453) .b8 99
(EngineCore_DP0 pid=492453) .b8 49
(EngineCore_DP0 pid=492453) .b8 50
(EngineCore_DP0 pid=492453) .b8 49
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 112
(EngineCore_DP0 pid=492453) .b8 121
(EngineCore_DP0 pid=492453) .b8 51
(EngineCore_DP0 pid=492453) .b8 49
(EngineCore_DP0 pid=492453) .b8 50
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 99
(EngineCore_DP0 pid=492453) .b8 117
(EngineCore_DP0 pid=492453) .b8 49
(EngineCore_DP0 pid=492453) .b8 50
(EngineCore_DP0 pid=492453) .b8 57
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 97
(EngineCore_DP0 pid=492453) .b8 97
(EngineCore_DP0 pid=492453) .b8 114
(EngineCore_DP0 pid=492453) .b8 99
(EngineCore_DP0 pid=492453) .b8 104
(EngineCore_DP0 pid=492453) .b8 54
(EngineCore_DP0 pid=492453) .b8 52
(EngineCore_DP0 pid=492453) .b8 0
(EngineCore_DP0 pid=492453) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=492453) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=492453) .b8 113
(EngineCore_DP0 pid=492453) .b8 117
(EngineCore_DP0 pid=492453) .b8 97
(EngineCore_DP0 pid=492453) .b8 110
(EngineCore_DP0 pid=492453) .b8 116
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 115
(EngineCore_DP0 pid=492453) .b8 108
(EngineCore_DP0 pid=492453) .b8 105
(EngineCore_DP0 pid=492453) .b8 100
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 102
(EngineCore_DP0 pid=492453) .b8 112
(EngineCore_DP0 pid=492453) .b8 56
(EngineCore_DP0 pid=492453) .b8 95
(EngineCore_DP0 pid=492453) .b8 107
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 114
(EngineCore_DP0 pid=492453) .b8 110
(EngineCore_DP0 pid=492453) .b8 101
(EngineCore_DP0 pid=492453) .b8 108
(EngineCore_DP0 pid=492453) .b8 0
(EngineCore_DP0 pid=492453) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=492453) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=492453) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=492453) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=492453) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=492453) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=492453) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=492453) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=492453) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=492453) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=492453) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=492453) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=492453) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=492453) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=492453) 	}
(EngineCore_DP0 pid=492453) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) ================================================================
(EngineCore_DP0 pid=492453) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp000mrvu0.ptx', '-o', '/tmp/tmp000mrvu0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] 
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] 
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] 
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp000mrvu0.ptx -o /tmp/tmp000mrvu0.ptx.o
(EngineCore_DP0 pid=492453) ERROR 01-25 21:44:15 [core.py:866] 

STDERR:
[2026-01-25 21:43:07] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:43:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:43:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:43:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:43:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:43:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:43:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:43:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:43:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:43:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:43:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:43:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:43:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:43:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:43:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:43:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:43:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=492453) [2026-01-25 21:43:12] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=492453) [2026-01-25 21:43:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=492453) [2026-01-25 21:43:12] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=492453) [2026-01-25 21:43:12] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=492453) [2026-01-25 21:43:12] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=492453) [2026-01-25 21:43:12] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=492453) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=492453) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.76s/it]
(EngineCore_DP0 pid=492453) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.78s/it]
(EngineCore_DP0 pid=492453) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.33s/it]
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) [2026-01-25 21:44:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=492453) [2026-01-25 21:44:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=492453) [2026-01-25 21:44:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=492453) [2026-01-25 21:44:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=492453) [2026-01-25 21:44:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=492453) [2026-01-25 21:44:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=492453) [2026-01-25 21:44:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=492453) [2026-01-25 21:44:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=492453) Process EngineCore_DP0:
(EngineCore_DP0 pid=492453) Traceback (most recent call last):
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=492453)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=492453)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=492453)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=492453) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp000mrvu0.ptx', '-o', '/tmp/tmp000mrvu0.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) Traceback (most recent call last):
(EngineCore_DP0 pid=492453)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=492453)     self.run()
(EngineCore_DP0 pid=492453)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=492453)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=492453)     raise e
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=492453)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=492453)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=492453)     super().__init__(
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=492453)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=492453)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=492453)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=492453)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=492453)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=492453)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=492453)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=492453)     return func(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=492453)     return func(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=492453)     self.model_runner.profile_run()
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=492453)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=492453)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=492453)     return func(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=492453)     outputs = self.model(
(EngineCore_DP0 pid=492453)               ^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=492453)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=492453)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=492453)     hidden_states = self.model(
(EngineCore_DP0 pid=492453)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=492453)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=492453)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=492453)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=492453)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=492453)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=492453)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=492453)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=492453)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=492453)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=492453)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=492453)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=492453)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=492453)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=492453)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=492453)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=492453)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=492453)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=492453)     return self._linear_fn(
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=492453)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=492453)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=492453)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=492453)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=492453)     return fn(input, L)
(EngineCore_DP0 pid=492453)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=492453)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=492453)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=492453)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=492453)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=492453)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=492453)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=492453)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=492453)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=492453)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=492453)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=492453)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=492453)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=492453)     raise PTXASError(error)
(EngineCore_DP0 pid=492453) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=492453) `ptxas` stderr:
(EngineCore_DP0 pid=492453) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=492453) 
(EngineCore_DP0 pid=492453) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp000mrvu0.ptx -o /tmp/tmp000mrvu0.ptx.o
(EngineCore_DP0 pid=492453) 
[rank0]:[W125 21:44:15.767925700 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-25 21:44:17
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 21:44:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 21:44:49 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=494039) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) ================================================================
(EngineCore_DP0 pid=494039) Internal Triton PTX codegen error
(EngineCore_DP0 pid=494039) `ptxas` stderr:
(EngineCore_DP0 pid=494039) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_ygcnbaq.ptx -o /tmp/tmp_ygcnbaq.ptx.o
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) //
(EngineCore_DP0 pid=494039) // Generated by LLVM NVPTX Back-End
(EngineCore_DP0 pid=494039) //
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) .version 8.7
(EngineCore_DP0 pid=494039) .target sm_121a
(EngineCore_DP0 pid=494039) .address_size 64
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) 	// .globl	_quant_slide_fp8_kernel // -- Begin function _quant_slide_fp8_kernel
(EngineCore_DP0 pid=494039) .extern .shared .align 16 .b8 global_smem[];
(EngineCore_DP0 pid=494039)                                         // @_quant_slide_fp8_kernel
(EngineCore_DP0 pid=494039) .visible .entry _quant_slide_fp8_kernel(
(EngineCore_DP0 pid=494039) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_0,
(EngineCore_DP0 pid=494039) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_1,
(EngineCore_DP0 pid=494039) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_2,
(EngineCore_DP0 pid=494039) 	.param .u32 _quant_slide_fp8_kernel_param_3,
(EngineCore_DP0 pid=494039) 	.param .u32 _quant_slide_fp8_kernel_param_4,
(EngineCore_DP0 pid=494039) 	.param .u32 _quant_slide_fp8_kernel_param_5,
(EngineCore_DP0 pid=494039) 	.param .u32 _quant_slide_fp8_kernel_param_6,
(EngineCore_DP0 pid=494039) 	.param .u32 _quant_slide_fp8_kernel_param_7,
(EngineCore_DP0 pid=494039) 	.param .u32 _quant_slide_fp8_kernel_param_8,
(EngineCore_DP0 pid=494039) 	.param .u32 _quant_slide_fp8_kernel_param_9,
(EngineCore_DP0 pid=494039) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_10,
(EngineCore_DP0 pid=494039) 	.param .u64 .ptr .global .align 1 _quant_slide_fp8_kernel_param_11
(EngineCore_DP0 pid=494039) )
(EngineCore_DP0 pid=494039) .reqntid 512
(EngineCore_DP0 pid=494039) {
(EngineCore_DP0 pid=494039) 	.reg .pred 	%p<21>;
(EngineCore_DP0 pid=494039) 	.reg .b16 	%rs<61>;
(EngineCore_DP0 pid=494039) 	.reg .b32 	%r<127>;
(EngineCore_DP0 pid=494039) 	.reg .b64 	%rd<14>;
(EngineCore_DP0 pid=494039) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=494039) $L__func_begin0:
(EngineCore_DP0 pid=494039) 	.loc	1 133 0                         // quant_slide_tuned_Qwen2.5-7B.py:133:0
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) // %bb.0:
(EngineCore_DP0 pid=494039) 	ld.param.b32 	%r20, [_quant_slide_fp8_kernel_param_7];
(EngineCore_DP0 pid=494039) 	ld.param.b32 	%r19, [_quant_slide_fp8_kernel_param_5];
(EngineCore_DP0 pid=494039) 	ld.param.b32 	%r18, [_quant_slide_fp8_kernel_param_4];
(EngineCore_DP0 pid=494039) 	ld.param.b64 	%rd3, [_quant_slide_fp8_kernel_param_2];
(EngineCore_DP0 pid=494039) 	ld.param.b64 	%rd4, [_quant_slide_fp8_kernel_param_0];
(EngineCore_DP0 pid=494039) $L__tmp0:
(EngineCore_DP0 pid=494039) 	.loc	1 143 24                        // quant_slide_tuned_Qwen2.5-7B.py:143:24
(EngineCore_DP0 pid=494039) 	mov.u32 	%r1, %ctaid.x;
(EngineCore_DP0 pid=494039) 	ld.param.b32 	%r22, [_quant_slide_fp8_kernel_param_8];
(EngineCore_DP0 pid=494039) 	.loc	1 148 26                        // quant_slide_tuned_Qwen2.5-7B.py:148:26
(EngineCore_DP0 pid=494039) 	mul.lo.s32 	%r23, %r22, %r1;
(EngineCore_DP0 pid=494039) 	.loc	1 148 20                        // quant_slide_tuned_Qwen2.5-7B.py:148:20
(EngineCore_DP0 pid=494039) 	mad.wide.s32 	%rd1, %r23, 2, %rd4;
(EngineCore_DP0 pid=494039) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=494039) 	mov.u32 	%r2, %tid.x;
(EngineCore_DP0 pid=494039) 	and.b32 	%r3, %r2, 511;
(EngineCore_DP0 pid=494039) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p1, %r19, 1;
(EngineCore_DP0 pid=494039) 	mov.b32 	%r125, 0f2B8CBCCC;
(EngineCore_DP0 pid=494039) 	setp.eq.b32 	%p20, %r2, 0;
(EngineCore_DP0 pid=494039) 	@%p1 bra 	$L__BB0_4;
(EngineCore_DP0 pid=494039) // %bb.1:                               // %.lr.ph
(EngineCore_DP0 pid=494039) 	.loc	1 154 32                        // quant_slide_tuned_Qwen2.5-7B.py:154:32
(EngineCore_DP0 pid=494039) 	shl.b32 	%r4, %r3, 3;
(EngineCore_DP0 pid=494039) 	and.b32 	%r5, %r2, 31;
(EngineCore_DP0 pid=494039) 	shr.u32 	%r32, %r2, 3;
(EngineCore_DP0 pid=494039) 	and.b32 	%r33, %r32, 60;
(EngineCore_DP0 pid=494039) 	mov.b32 	%r34, global_smem;
(EngineCore_DP0 pid=494039) 	add.s32 	%r52, %r34, %r33;
(EngineCore_DP0 pid=494039) 	shl.b32 	%r35, %r2, 2;
(EngineCore_DP0 pid=494039) 	add.s32 	%r55, %r34, %r35;
(EngineCore_DP0 pid=494039) 	mov.b32 	%r40, 0;
(EngineCore_DP0 pid=494039) 	mov.b32 	%r123, 0f00000000;
(EngineCore_DP0 pid=494039) 	setp.lt.u32 	%p5, %r2, 16;
(EngineCore_DP0 pid=494039) 	setp.eq.b32 	%p4, %r5, 0;
(EngineCore_DP0 pid=494039) 	mov.b32 	%r124, %r40;
(EngineCore_DP0 pid=494039) $L__BB0_2:                              // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=494039) 	.loc	1 154 19                        // quant_slide_tuned_Qwen2.5-7B.py:154:19
(EngineCore_DP0 pid=494039) 	add.s32 	%r58, %r4, %r124;
(EngineCore_DP0 pid=494039) 	.loc	1 155 22                        // quant_slide_tuned_Qwen2.5-7B.py:155:22
(EngineCore_DP0 pid=494039) 	add.s32 	%r59, %r58, 4096;
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p2, %r58, %r18;
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p3, %r59, %r18;
(EngineCore_DP0 pid=494039) 	.loc	1 156 29                        // quant_slide_tuned_Qwen2.5-7B.py:156:29
(EngineCore_DP0 pid=494039) 	mad.wide.s32 	%rd6, %r58, 2, %rd1;
(EngineCore_DP0 pid=494039) 	add.s64 	%rd7, %rd6, 8192;
(EngineCore_DP0 pid=494039) 	.loc	1 156 21                        // quant_slide_tuned_Qwen2.5-7B.py:156:21
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	mov.u32 %r36, %r40;
(EngineCore_DP0 pid=494039) 	mov.u32 %r37, %r40;
(EngineCore_DP0 pid=494039) 	mov.u32 %r38, %r40;
(EngineCore_DP0 pid=494039) 	mov.u32 %r39, %r40;
(EngineCore_DP0 pid=494039) 	@%p2 ld.global.v4.b32 { %r36, %r37, %r38, %r39 }, [ %rd6 + 0 ];
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	mov.b32 	{%rs1, %rs2}, %r36;
(EngineCore_DP0 pid=494039) 	mov.b32 	{%rs3, %rs4}, %r37;
(EngineCore_DP0 pid=494039) 	mov.b32 	{%rs5, %rs6}, %r38;
(EngineCore_DP0 pid=494039) 	mov.b32 	{%rs7, %rs8}, %r39;
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	mov.u32 %r44, %r40;
(EngineCore_DP0 pid=494039) 	mov.u32 %r45, %r40;
(EngineCore_DP0 pid=494039) 	mov.u32 %r46, %r40;
(EngineCore_DP0 pid=494039) 	mov.u32 %r47, %r40;
(EngineCore_DP0 pid=494039) 	@%p3 ld.global.v4.b32 { %r44, %r45, %r46, %r47 }, [ %rd7 + 0 ];
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	mov.b32 	{%rs9, %rs10}, %r44;
(EngineCore_DP0 pid=494039) 	mov.b32 	{%rs11, %rs12}, %r45;
(EngineCore_DP0 pid=494039) 	mov.b32 	{%rs13, %rs14}, %r46;
(EngineCore_DP0 pid=494039) 	mov.b32 	{%rs15, %rs16}, %r47;
(EngineCore_DP0 pid=494039) 	.loc	1 157 50                        // quant_slide_tuned_Qwen2.5-7B.py:157:50
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs17, %rs1;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs18, %rs2;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs19, %rs3;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs20, %rs4;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs21, %rs5;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs22, %rs6;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs23, %rs7;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs24, %rs8;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs25, %rs9;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs26, %rs10;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs27, %rs11;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs28, %rs12;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs29, %rs13;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs30, %rs14;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs31, %rs15;
(EngineCore_DP0 pid=494039) 	abs.bf16 	%rs32, %rs16;
(EngineCore_DP0 pid=494039) $L__tmp1:
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	bar.sync 	0;
(EngineCore_DP0 pid=494039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs33, %rs17, %rs18;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs34, %rs33, %rs19;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs35, %rs34, %rs20;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs36, %rs35, %rs21;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs37, %rs36, %rs22;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs38, %rs37, %rs23;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs39, %rs38, %rs24;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs40, %rs39, %rs25;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs41, %rs40, %rs26;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs42, %rs41, %rs27;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs43, %rs42, %rs28;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs44, %rs43, %rs29;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs45, %rs44, %rs30;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs46, %rs45, %rs31;
(EngineCore_DP0 pid=494039) 	max.bf16 	%rs47, %rs46, %rs32;
(EngineCore_DP0 pid=494039) 	cvt.f32.bf16 	%r60, %rs47;
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	shfl.sync.bfly.b32 	%r61, %r60, 16, 31, -1;
(EngineCore_DP0 pid=494039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	max.f32 	%r62, %r60, %r61;
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	shfl.sync.bfly.b32 	%r63, %r62, 8, 31, -1;
(EngineCore_DP0 pid=494039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	max.f32 	%r64, %r62, %r63;
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	shfl.sync.bfly.b32 	%r65, %r64, 4, 31, -1;
(EngineCore_DP0 pid=494039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	max.f32 	%r66, %r64, %r65;
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	shfl.sync.bfly.b32 	%r67, %r66, 2, 31, -1;
(EngineCore_DP0 pid=494039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	max.f32 	%r68, %r66, %r67;
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	shfl.sync.bfly.b32 	%r69, %r68, 1, 31, -1;
(EngineCore_DP0 pid=494039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	max.f32 	%r53, %r68, %r69;
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	@%p4 st.shared.b32 [ %r52 + 0 ], %r53;
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	bar.sync 	0;
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	@%p5 ld.shared.b32 %r54, [ %r55 + 0 ];
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	shfl.sync.bfly.b32 	%r70, %r54, 8, 31, -1;
(EngineCore_DP0 pid=494039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	max.f32 	%r71, %r54, %r70;
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	shfl.sync.bfly.b32 	%r72, %r71, 4, 31, -1;
(EngineCore_DP0 pid=494039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	max.f32 	%r73, %r71, %r72;
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	shfl.sync.bfly.b32 	%r74, %r73, 2, 31, -1;
(EngineCore_DP0 pid=494039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	max.f32 	%r75, %r73, %r74;
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	shfl.sync.bfly.b32 	%r76, %r75, 1, 31, -1;
(EngineCore_DP0 pid=494039) 	.loc	2 168 27                        // standard.py:168:27 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	max.f32 	%r57, %r75, %r76;
(EngineCore_DP0 pid=494039) 	.loc	2 189 40                        // standard.py:189:40 @[ quant_slide_tuned_Qwen2.5-7B.py:157:43 ]
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	@%p20 st.shared.b32 [ %r55 + 0 ], %r57;
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	bar.sync 	0;
(EngineCore_DP0 pid=494039) 	ld.shared.b32 	%r77, [global_smem];
(EngineCore_DP0 pid=494039) $L__tmp2:
(EngineCore_DP0 pid=494039) 	.loc	1 157 36                        // quant_slide_tuned_Qwen2.5-7B.py:157:36
(EngineCore_DP0 pid=494039) 	max.f32 	%r123, %r123, %r77;
(EngineCore_DP0 pid=494039) 	.loc	1 153 35                        // quant_slide_tuned_Qwen2.5-7B.py:153:35
(EngineCore_DP0 pid=494039) 	add.s32 	%r124, %r124, 8192;
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p7, %r124, %r19;
(EngineCore_DP0 pid=494039) 	@%p7 bra 	$L__BB0_2;
(EngineCore_DP0 pid=494039) // %bb.3:                               // %._crit_edge.loopexit
(EngineCore_DP0 pid=494039) 	.loc	1 159 32                        // quant_slide_tuned_Qwen2.5-7B.py:159:32
(EngineCore_DP0 pid=494039) 	max.f32 	%r125, %r123, 0f2B8CBCCC;
(EngineCore_DP0 pid=494039) $L__BB0_4:                              // %._crit_edge
(EngineCore_DP0 pid=494039) 	.loc	1 0 32                          // quant_slide_tuned_Qwen2.5-7B.py:0:32
(EngineCore_DP0 pid=494039) 	mov.b32 	%r79, 0f43E00000;
(EngineCore_DP0 pid=494039) 	.loc	1 160 32                        // quant_slide_tuned_Qwen2.5-7B.py:160:32
(EngineCore_DP0 pid=494039) 	div.full.f32 	%r80, %r125, %r79;
(EngineCore_DP0 pid=494039) 	.loc	1 160 41                        // quant_slide_tuned_Qwen2.5-7B.py:160:41
(EngineCore_DP0 pid=494039) 	max.f32 	%r78, %r80, 0f36924925;
(EngineCore_DP0 pid=494039) 	.loc	1 162 25                        // quant_slide_tuned_Qwen2.5-7B.py:162:25
(EngineCore_DP0 pid=494039) 	mad.wide.u32 	%rd8, %r1, 4, %rd3;
(EngineCore_DP0 pid=494039) 	.loc	1 162 30                        // quant_slide_tuned_Qwen2.5-7B.py:162:30
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	@%p20 st.global.b32 [ %rd8 + 0 ], { %r78 };
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	.loc	1 165 29                        // quant_slide_tuned_Qwen2.5-7B.py:165:29
(EngineCore_DP0 pid=494039) 	mul.lo.s32 	%r15, %r20, 3;
(EngineCore_DP0 pid=494039) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p9, %r15, 1;
(EngineCore_DP0 pid=494039) 	@%p9 bra 	$L__BB0_7;
(EngineCore_DP0 pid=494039) // %bb.5:                               // %.lr.ph4.preheader
(EngineCore_DP0 pid=494039) 	.loc	1 0 41                          // quant_slide_tuned_Qwen2.5-7B.py:0:41
(EngineCore_DP0 pid=494039) 	ld.param.b32 	%r24, [_quant_slide_fp8_kernel_param_9];
(EngineCore_DP0 pid=494039) 	shr.s32 	%r25, %r24, 31;
(EngineCore_DP0 pid=494039) 	shr.u32 	%r26, %r25, 30;
(EngineCore_DP0 pid=494039) 	add.s32 	%r27, %r24, %r26;
(EngineCore_DP0 pid=494039) 	shr.s32 	%r28, %r27, 2;
(EngineCore_DP0 pid=494039) 	ld.param.b64 	%rd5, [_quant_slide_fp8_kernel_param_1];
(EngineCore_DP0 pid=494039) 	mul.lo.s32 	%r29, %r28, %r1;
(EngineCore_DP0 pid=494039) 	mad.wide.s32 	%rd2, %r29, 4, %rd5;
(EngineCore_DP0 pid=494039) 	div.full.f32 	%r14, %r79, %r125;
(EngineCore_DP0 pid=494039) 	mov.b32 	%r126, 0;
(EngineCore_DP0 pid=494039) $L__BB0_6:                              // %.lr.ph4
(EngineCore_DP0 pid=494039)                                         // =>This Inner Loop Header: Depth=1
(EngineCore_DP0 pid=494039) 	.loc	1 169 30                        // quant_slide_tuned_Qwen2.5-7B.py:169:30
(EngineCore_DP0 pid=494039) 	add.s32 	%r92, %r3, %r126;
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p14, %r92, %r15;
(EngineCore_DP0 pid=494039) 	.loc	1 172 24                        // quant_slide_tuned_Qwen2.5-7B.py:172:24
(EngineCore_DP0 pid=494039) 	mul.hi.s32 	%r93, %r92, 1431655766;
(EngineCore_DP0 pid=494039) 	shr.u32 	%r94, %r93, 31;
(EngineCore_DP0 pid=494039) 	add.s32 	%r95, %r93, %r94;
(EngineCore_DP0 pid=494039) 	.loc	1 173 23                        // quant_slide_tuned_Qwen2.5-7B.py:173:23
(EngineCore_DP0 pid=494039) 	mul.lo.s32 	%r96, %r95, 3;
(EngineCore_DP0 pid=494039) 	sub.s32 	%r97, %r92, %r96;
(EngineCore_DP0 pid=494039) 	.loc	1 174 22                        // quant_slide_tuned_Qwen2.5-7B.py:174:22
(EngineCore_DP0 pid=494039) 	shl.b32 	%r98, %r95, 3;
(EngineCore_DP0 pid=494039) 	.loc	1 174 30                        // quant_slide_tuned_Qwen2.5-7B.py:174:30
(EngineCore_DP0 pid=494039) 	shl.b32 	%r99, %r97, 1;
(EngineCore_DP0 pid=494039) 	.loc	1 174 26                        // quant_slide_tuned_Qwen2.5-7B.py:174:26
(EngineCore_DP0 pid=494039) 	add.s32 	%r100, %r98, %r99;
(EngineCore_DP0 pid=494039) 	.loc	1 177 53                        // quant_slide_tuned_Qwen2.5-7B.py:177:53
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p15, %r100, %r18;
(EngineCore_DP0 pid=494039) 	.loc	1 177 37                        // quant_slide_tuned_Qwen2.5-7B.py:177:37
(EngineCore_DP0 pid=494039) 	and.pred 	%p10, %p14, %p15;
(EngineCore_DP0 pid=494039) 	.loc	1 176 29                        // quant_slide_tuned_Qwen2.5-7B.py:176:29
(EngineCore_DP0 pid=494039) 	mad.wide.s32 	%rd9, %r100, 2, %rd1;
(EngineCore_DP0 pid=494039) 	mov.b16 	%rs49, 0;
(EngineCore_DP0 pid=494039) 	.loc	1 176 21                        // quant_slide_tuned_Qwen2.5-7B.py:176:21
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	mov.u16 %rs48, %rs49;
(EngineCore_DP0 pid=494039) 	@%p10 ld.global.b16 { %rs48 }, [ %rd9 + 0 ];
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	.loc	1 177 79                        // quant_slide_tuned_Qwen2.5-7B.py:177:79
(EngineCore_DP0 pid=494039) 	cvt.f32.bf16 	%r101, %rs48;
(EngineCore_DP0 pid=494039) 	.loc	1 179 48                        // quant_slide_tuned_Qwen2.5-7B.py:179:48
(EngineCore_DP0 pid=494039) 	or.b32 	%r102, %r100, 1;
(EngineCore_DP0 pid=494039) 	.loc	1 179 53                        // quant_slide_tuned_Qwen2.5-7B.py:179:53
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p16, %r102, %r18;
(EngineCore_DP0 pid=494039) 	.loc	1 179 37                        // quant_slide_tuned_Qwen2.5-7B.py:179:37
(EngineCore_DP0 pid=494039) 	and.pred 	%p11, %p14, %p16;
(EngineCore_DP0 pid=494039) 	.loc	1 178 39                        // quant_slide_tuned_Qwen2.5-7B.py:178:39
(EngineCore_DP0 pid=494039) 	add.s64 	%rd10, %rd9, 2;
(EngineCore_DP0 pid=494039) 	.loc	1 178 21                        // quant_slide_tuned_Qwen2.5-7B.py:178:21
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	mov.u16 %rs50, %rs49;
(EngineCore_DP0 pid=494039) 	@%p11 ld.global.b16 { %rs50 }, [ %rd10 + 0 ];
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	.loc	1 179 79                        // quant_slide_tuned_Qwen2.5-7B.py:179:79
(EngineCore_DP0 pid=494039) 	cvt.f32.bf16 	%r103, %rs50;
(EngineCore_DP0 pid=494039) 	.loc	1 181 48                        // quant_slide_tuned_Qwen2.5-7B.py:181:48
(EngineCore_DP0 pid=494039) 	add.s32 	%r104, %r100, 2;
(EngineCore_DP0 pid=494039) 	.loc	1 181 53                        // quant_slide_tuned_Qwen2.5-7B.py:181:53
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p17, %r104, %r18;
(EngineCore_DP0 pid=494039) 	.loc	1 181 37                        // quant_slide_tuned_Qwen2.5-7B.py:181:37
(EngineCore_DP0 pid=494039) 	and.pred 	%p12, %p14, %p17;
(EngineCore_DP0 pid=494039) 	.loc	1 180 39                        // quant_slide_tuned_Qwen2.5-7B.py:180:39
(EngineCore_DP0 pid=494039) 	add.s64 	%rd11, %rd9, 4;
(EngineCore_DP0 pid=494039) 	.loc	1 180 21                        // quant_slide_tuned_Qwen2.5-7B.py:180:21
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	mov.u16 %rs52, %rs49;
(EngineCore_DP0 pid=494039) 	@%p12 ld.global.b16 { %rs52 }, [ %rd11 + 0 ];
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	.loc	1 181 79                        // quant_slide_tuned_Qwen2.5-7B.py:181:79
(EngineCore_DP0 pid=494039) 	cvt.f32.bf16 	%r105, %rs52;
(EngineCore_DP0 pid=494039) 	.loc	1 183 48                        // quant_slide_tuned_Qwen2.5-7B.py:183:48
(EngineCore_DP0 pid=494039) 	add.s32 	%r106, %r100, 3;
(EngineCore_DP0 pid=494039) 	.loc	1 183 53                        // quant_slide_tuned_Qwen2.5-7B.py:183:53
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p18, %r106, %r18;
(EngineCore_DP0 pid=494039) 	.loc	1 183 37                        // quant_slide_tuned_Qwen2.5-7B.py:183:37
(EngineCore_DP0 pid=494039) 	and.pred 	%p13, %p14, %p18;
(EngineCore_DP0 pid=494039) 	.loc	1 182 39                        // quant_slide_tuned_Qwen2.5-7B.py:182:39
(EngineCore_DP0 pid=494039) 	add.s64 	%rd12, %rd9, 6;
(EngineCore_DP0 pid=494039) 	.loc	1 182 21                        // quant_slide_tuned_Qwen2.5-7B.py:182:21
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	mov.u16 %rs54, %rs49;
(EngineCore_DP0 pid=494039) 	@%p13 ld.global.b16 { %rs54 }, [ %rd12 + 0 ];
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	.loc	1 183 79                        // quant_slide_tuned_Qwen2.5-7B.py:183:79
(EngineCore_DP0 pid=494039) 	cvt.f32.bf16 	%r107, %rs54;
(EngineCore_DP0 pid=494039) 	.loc	1 185 27                        // quant_slide_tuned_Qwen2.5-7B.py:185:27
(EngineCore_DP0 pid=494039) 	mul.f32 	%r108, %r14, %r101;
(EngineCore_DP0 pid=494039) 	mov.b32 	%r109, 0f43E00000;
(EngineCore_DP0 pid=494039) 	.loc	1 185 48                        // quant_slide_tuned_Qwen2.5-7B.py:185:48
(EngineCore_DP0 pid=494039) 	min.xorsign.abs.f32 	%r82, %r108, %r109;
(EngineCore_DP0 pid=494039) 	.loc	1 185 60                        // quant_slide_tuned_Qwen2.5-7B.py:185:60
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	cvt.rn.satfinite.e4m3x2.f32  %rs56, %r83, %r82; 
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	.loc	1 186 27                        // quant_slide_tuned_Qwen2.5-7B.py:186:27
(EngineCore_DP0 pid=494039) 	mul.f32 	%r110, %r14, %r103;
(EngineCore_DP0 pid=494039) 	.loc	1 186 48                        // quant_slide_tuned_Qwen2.5-7B.py:186:48
(EngineCore_DP0 pid=494039) 	min.xorsign.abs.f32 	%r84, %r110, %r109;
(EngineCore_DP0 pid=494039) 	.loc	1 186 60                        // quant_slide_tuned_Qwen2.5-7B.py:186:60
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	cvt.rn.satfinite.e4m3x2.f32  %rs57, %r85, %r84; 
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	.loc	1 187 27                        // quant_slide_tuned_Qwen2.5-7B.py:187:27
(EngineCore_DP0 pid=494039) 	mul.f32 	%r111, %r14, %r105;
(EngineCore_DP0 pid=494039) 	.loc	1 187 48                        // quant_slide_tuned_Qwen2.5-7B.py:187:48
(EngineCore_DP0 pid=494039) 	min.xorsign.abs.f32 	%r86, %r111, %r109;
(EngineCore_DP0 pid=494039) 	.loc	1 187 60                        // quant_slide_tuned_Qwen2.5-7B.py:187:60
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	cvt.rn.satfinite.e4m3x2.f32  %rs58, %r87, %r86; 
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	.loc	1 188 27                        // quant_slide_tuned_Qwen2.5-7B.py:188:27
(EngineCore_DP0 pid=494039) 	mul.f32 	%r112, %r14, %r107;
(EngineCore_DP0 pid=494039) 	.loc	1 188 48                        // quant_slide_tuned_Qwen2.5-7B.py:188:48
(EngineCore_DP0 pid=494039) 	min.xorsign.abs.f32 	%r88, %r112, %r109;
(EngineCore_DP0 pid=494039) 	.loc	1 188 60                        // quant_slide_tuned_Qwen2.5-7B.py:188:60
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	cvt.rn.satfinite.e4m3x2.f32  %rs59, %r89, %r88; 
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	.loc	1 190 45                        // quant_slide_tuned_Qwen2.5-7B.py:190:45
(EngineCore_DP0 pid=494039) 	cvt.u32.u16 	%r113, %rs56;
(EngineCore_DP0 pid=494039) 	and.b32 	%r114, %r113, 255;
(EngineCore_DP0 pid=494039) 	.loc	1 192 45                        // quant_slide_tuned_Qwen2.5-7B.py:192:45
(EngineCore_DP0 pid=494039) 	cvt.u32.u16 	%r115, %rs58;
(EngineCore_DP0 pid=494039) 	and.b32 	%r116, %r115, 255;
(EngineCore_DP0 pid=494039) 	.loc	1 193 45                        // quant_slide_tuned_Qwen2.5-7B.py:193:45
(EngineCore_DP0 pid=494039) 	cvt.u32.u16 	%r117, %rs59;
(EngineCore_DP0 pid=494039) 	.loc	1 195 30                        // quant_slide_tuned_Qwen2.5-7B.py:195:30
(EngineCore_DP0 pid=494039) 	and.b16 	%rs60, %rs57, 255;
(EngineCore_DP0 pid=494039) 	mul.wide.u16 	%r118, %rs60, 256;
(EngineCore_DP0 pid=494039) 	.loc	1 195 24                        // quant_slide_tuned_Qwen2.5-7B.py:195:24
(EngineCore_DP0 pid=494039) 	or.b32 	%r119, %r118, %r114;
(EngineCore_DP0 pid=494039) 	.loc	1 195 42                        // quant_slide_tuned_Qwen2.5-7B.py:195:42
(EngineCore_DP0 pid=494039) 	shl.b32 	%r120, %r116, 16;
(EngineCore_DP0 pid=494039) 	.loc	1 195 36                        // quant_slide_tuned_Qwen2.5-7B.py:195:36
(EngineCore_DP0 pid=494039) 	or.b32 	%r121, %r119, %r120;
(EngineCore_DP0 pid=494039) 	.loc	1 195 55                        // quant_slide_tuned_Qwen2.5-7B.py:195:55
(EngineCore_DP0 pid=494039) 	shl.b32 	%r122, %r117, 24;
(EngineCore_DP0 pid=494039) 	.loc	1 195 49                        // quant_slide_tuned_Qwen2.5-7B.py:195:49
(EngineCore_DP0 pid=494039) 	or.b32 	%r90, %r121, %r122;
(EngineCore_DP0 pid=494039) 	.loc	1 196 29                        // quant_slide_tuned_Qwen2.5-7B.py:196:29
(EngineCore_DP0 pid=494039) 	mad.wide.s32 	%rd13, %r92, 4, %rd2;
(EngineCore_DP0 pid=494039) 	.loc	1 196 39                        // quant_slide_tuned_Qwen2.5-7B.py:196:39
(EngineCore_DP0 pid=494039) 	// begin inline asm
(EngineCore_DP0 pid=494039) 	@%p14 st.global.b32 [ %rd13 + 0 ], { %r90 };
(EngineCore_DP0 pid=494039) 	// end inline asm
(EngineCore_DP0 pid=494039) 	.loc	1 167 41                        // quant_slide_tuned_Qwen2.5-7B.py:167:41
(EngineCore_DP0 pid=494039) 	add.s32 	%r126, %r126, 512;
(EngineCore_DP0 pid=494039) 	setp.lt.s32 	%p19, %r126, %r15;
(EngineCore_DP0 pid=494039) 	@%p19 bra 	$L__BB0_6;
(EngineCore_DP0 pid=494039) $L__BB0_7:                              // %._crit_edge5
(EngineCore_DP0 pid=494039) 	.loc	1 167 4                         // quant_slide_tuned_Qwen2.5-7B.py:167:4
(EngineCore_DP0 pid=494039) 	ret;
(EngineCore_DP0 pid=494039) $L__tmp3:
(EngineCore_DP0 pid=494039) $L__func_end0:
(EngineCore_DP0 pid=494039)                                         // -- End function
(EngineCore_DP0 pid=494039) }
(EngineCore_DP0 pid=494039) 	.file	1 "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py"
(EngineCore_DP0 pid=494039) 	.file	2 "/usr/local/lib/python3.12/dist-packages/triton/language/standard.py"
(EngineCore_DP0 pid=494039) 	.section	.debug_abbrev
(EngineCore_DP0 pid=494039) 	{
(EngineCore_DP0 pid=494039) .b8 1                                   // Abbreviation Code
(EngineCore_DP0 pid=494039) .b8 17                                  // DW_TAG_compile_unit
(EngineCore_DP0 pid=494039) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=494039) .b8 37                                  // DW_AT_producer
(EngineCore_DP0 pid=494039) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=494039) .b8 19                                  // DW_AT_language
(EngineCore_DP0 pid=494039) .b8 5                                   // DW_FORM_data2
(EngineCore_DP0 pid=494039) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=494039) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=494039) .b8 16                                  // DW_AT_stmt_list
(EngineCore_DP0 pid=494039) .b8 6                                   // DW_FORM_data4
(EngineCore_DP0 pid=494039) .b8 27                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=494039) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=494039) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=494039) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=494039) .b8 2                                   // Abbreviation Code
(EngineCore_DP0 pid=494039) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=494039) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=494039) .b8 3                                   // DW_AT_name
(EngineCore_DP0 pid=494039) .b8 8                                   // DW_FORM_string
(EngineCore_DP0 pid=494039) .b8 32                                  // DW_AT_inline
(EngineCore_DP0 pid=494039) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=494039) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=494039) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=494039) .b8 3                                   // Abbreviation Code
(EngineCore_DP0 pid=494039) .b8 46                                  // DW_TAG_subprogram
(EngineCore_DP0 pid=494039) .b8 1                                   // DW_CHILDREN_yes
(EngineCore_DP0 pid=494039) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=494039) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=494039) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=494039) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=494039) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=494039) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=494039) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=494039) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=494039) .b8 4                                   // Abbreviation Code
(EngineCore_DP0 pid=494039) .b8 29                                  // DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=494039) .b8 0                                   // DW_CHILDREN_no
(EngineCore_DP0 pid=494039) .b8 49                                  // DW_AT_abstract_origin
(EngineCore_DP0 pid=494039) .b8 19                                  // DW_FORM_ref4
(EngineCore_DP0 pid=494039) .b8 17                                  // DW_AT_low_pc
(EngineCore_DP0 pid=494039) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=494039) .b8 18                                  // DW_AT_high_pc
(EngineCore_DP0 pid=494039) .b8 1                                   // DW_FORM_addr
(EngineCore_DP0 pid=494039) .b8 88                                  // DW_AT_call_file
(EngineCore_DP0 pid=494039) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=494039) .b8 89                                  // DW_AT_call_line
(EngineCore_DP0 pid=494039) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=494039) .b8 87                                  // DW_AT_call_column
(EngineCore_DP0 pid=494039) .b8 11                                  // DW_FORM_data1
(EngineCore_DP0 pid=494039) .b8 0                                   // EOM(1)
(EngineCore_DP0 pid=494039) .b8 0                                   // EOM(2)
(EngineCore_DP0 pid=494039) .b8 0                                   // EOM(3)
(EngineCore_DP0 pid=494039) 	}
(EngineCore_DP0 pid=494039) 	.section	.debug_info
(EngineCore_DP0 pid=494039) 	{
(EngineCore_DP0 pid=494039) .b32 221                                // Length of Unit
(EngineCore_DP0 pid=494039) .b8 2                                   // DWARF version number
(EngineCore_DP0 pid=494039) .b8 0
(EngineCore_DP0 pid=494039) .b32 .debug_abbrev                      // Offset Into Abbrev. Section
(EngineCore_DP0 pid=494039) .b8 8                                   // Address Size (in bytes)
(EngineCore_DP0 pid=494039) .b8 1                                   // Abbrev [1] 0xb:0xd6 DW_TAG_compile_unit
(EngineCore_DP0 pid=494039) .b8 116                                 // DW_AT_producer
(EngineCore_DP0 pid=494039) .b8 114
(EngineCore_DP0 pid=494039) .b8 105
(EngineCore_DP0 pid=494039) .b8 116
(EngineCore_DP0 pid=494039) .b8 111
(EngineCore_DP0 pid=494039) .b8 110
(EngineCore_DP0 pid=494039) .b8 0
(EngineCore_DP0 pid=494039) .b8 2                                   // DW_AT_language
(EngineCore_DP0 pid=494039) .b8 0
(EngineCore_DP0 pid=494039) .b8 113                                 // DW_AT_name
(EngineCore_DP0 pid=494039) .b8 117
(EngineCore_DP0 pid=494039) .b8 97
(EngineCore_DP0 pid=494039) .b8 110
(EngineCore_DP0 pid=494039) .b8 116
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 115
(EngineCore_DP0 pid=494039) .b8 108
(EngineCore_DP0 pid=494039) .b8 105
(EngineCore_DP0 pid=494039) .b8 100
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 116
(EngineCore_DP0 pid=494039) .b8 117
(EngineCore_DP0 pid=494039) .b8 110
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 100
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 81
(EngineCore_DP0 pid=494039) .b8 119
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 110
(EngineCore_DP0 pid=494039) .b8 50
(EngineCore_DP0 pid=494039) .b8 46
(EngineCore_DP0 pid=494039) .b8 53
(EngineCore_DP0 pid=494039) .b8 45
(EngineCore_DP0 pid=494039) .b8 55
(EngineCore_DP0 pid=494039) .b8 66
(EngineCore_DP0 pid=494039) .b8 46
(EngineCore_DP0 pid=494039) .b8 112
(EngineCore_DP0 pid=494039) .b8 121
(EngineCore_DP0 pid=494039) .b8 0
(EngineCore_DP0 pid=494039) .b32 .debug_line                        // DW_AT_stmt_list
(EngineCore_DP0 pid=494039) .b8 47                                  // DW_AT_comp_dir
(EngineCore_DP0 pid=494039) .b8 114
(EngineCore_DP0 pid=494039) .b8 111
(EngineCore_DP0 pid=494039) .b8 111
(EngineCore_DP0 pid=494039) .b8 116
(EngineCore_DP0 pid=494039) .b8 47
(EngineCore_DP0 pid=494039) .b8 118
(EngineCore_DP0 pid=494039) .b8 108
(EngineCore_DP0 pid=494039) .b8 108
(EngineCore_DP0 pid=494039) .b8 109
(EngineCore_DP0 pid=494039) .b8 98
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 110
(EngineCore_DP0 pid=494039) .b8 99
(EngineCore_DP0 pid=494039) .b8 104
(EngineCore_DP0 pid=494039) .b8 47
(EngineCore_DP0 pid=494039) .b8 115
(EngineCore_DP0 pid=494039) .b8 108
(EngineCore_DP0 pid=494039) .b8 105
(EngineCore_DP0 pid=494039) .b8 100
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 115
(EngineCore_DP0 pid=494039) .b8 112
(EngineCore_DP0 pid=494039) .b8 97
(EngineCore_DP0 pid=494039) .b8 114
(EngineCore_DP0 pid=494039) .b8 115
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 47
(EngineCore_DP0 pid=494039) .b8 99
(EngineCore_DP0 pid=494039) .b8 115
(EngineCore_DP0 pid=494039) .b8 114
(EngineCore_DP0 pid=494039) .b8 99
(EngineCore_DP0 pid=494039) .b8 47
(EngineCore_DP0 pid=494039) .b8 102
(EngineCore_DP0 pid=494039) .b8 117
(EngineCore_DP0 pid=494039) .b8 115
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 100
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 113
(EngineCore_DP0 pid=494039) .b8 117
(EngineCore_DP0 pid=494039) .b8 97
(EngineCore_DP0 pid=494039) .b8 110
(EngineCore_DP0 pid=494039) .b8 116
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 115
(EngineCore_DP0 pid=494039) .b8 108
(EngineCore_DP0 pid=494039) .b8 105
(EngineCore_DP0 pid=494039) .b8 100
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 116
(EngineCore_DP0 pid=494039) .b8 114
(EngineCore_DP0 pid=494039) .b8 105
(EngineCore_DP0 pid=494039) .b8 116
(EngineCore_DP0 pid=494039) .b8 111
(EngineCore_DP0 pid=494039) .b8 110
(EngineCore_DP0 pid=494039) .b8 47
(EngineCore_DP0 pid=494039) .b8 98
(EngineCore_DP0 pid=494039) .b8 117
(EngineCore_DP0 pid=494039) .b8 105
(EngineCore_DP0 pid=494039) .b8 108
(EngineCore_DP0 pid=494039) .b8 100
(EngineCore_DP0 pid=494039) .b8 47
(EngineCore_DP0 pid=494039) .b8 71
(EngineCore_DP0 pid=494039) .b8 66
(EngineCore_DP0 pid=494039) .b8 49
(EngineCore_DP0 pid=494039) .b8 48
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 99
(EngineCore_DP0 pid=494039) .b8 99
(EngineCore_DP0 pid=494039) .b8 49
(EngineCore_DP0 pid=494039) .b8 50
(EngineCore_DP0 pid=494039) .b8 49
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 112
(EngineCore_DP0 pid=494039) .b8 121
(EngineCore_DP0 pid=494039) .b8 51
(EngineCore_DP0 pid=494039) .b8 49
(EngineCore_DP0 pid=494039) .b8 50
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 99
(EngineCore_DP0 pid=494039) .b8 117
(EngineCore_DP0 pid=494039) .b8 49
(EngineCore_DP0 pid=494039) .b8 50
(EngineCore_DP0 pid=494039) .b8 57
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 97
(EngineCore_DP0 pid=494039) .b8 97
(EngineCore_DP0 pid=494039) .b8 114
(EngineCore_DP0 pid=494039) .b8 99
(EngineCore_DP0 pid=494039) .b8 104
(EngineCore_DP0 pid=494039) .b8 54
(EngineCore_DP0 pid=494039) .b8 52
(EngineCore_DP0 pid=494039) .b8 0
(EngineCore_DP0 pid=494039) .b8 2                                   // Abbrev [2] 0x98:0x1a DW_TAG_subprogram
(EngineCore_DP0 pid=494039) .b8 95                                  // DW_AT_name
(EngineCore_DP0 pid=494039) .b8 113
(EngineCore_DP0 pid=494039) .b8 117
(EngineCore_DP0 pid=494039) .b8 97
(EngineCore_DP0 pid=494039) .b8 110
(EngineCore_DP0 pid=494039) .b8 116
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 115
(EngineCore_DP0 pid=494039) .b8 108
(EngineCore_DP0 pid=494039) .b8 105
(EngineCore_DP0 pid=494039) .b8 100
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 102
(EngineCore_DP0 pid=494039) .b8 112
(EngineCore_DP0 pid=494039) .b8 56
(EngineCore_DP0 pid=494039) .b8 95
(EngineCore_DP0 pid=494039) .b8 107
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 114
(EngineCore_DP0 pid=494039) .b8 110
(EngineCore_DP0 pid=494039) .b8 101
(EngineCore_DP0 pid=494039) .b8 108
(EngineCore_DP0 pid=494039) .b8 0
(EngineCore_DP0 pid=494039) .b8 1                                   // DW_AT_inline
(EngineCore_DP0 pid=494039) .b8 3                                   // Abbrev [3] 0xb2:0x2e DW_TAG_subprogram
(EngineCore_DP0 pid=494039) .b64 $L__func_begin0                    // DW_AT_low_pc
(EngineCore_DP0 pid=494039) .b64 $L__func_end0                      // DW_AT_high_pc
(EngineCore_DP0 pid=494039) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=494039) .b8 4                                   // Abbrev [4] 0xc7:0x18 DW_TAG_inlined_subroutine
(EngineCore_DP0 pid=494039) .b32 152                                // DW_AT_abstract_origin
(EngineCore_DP0 pid=494039) .b64 $L__tmp1                           // DW_AT_low_pc
(EngineCore_DP0 pid=494039) .b64 $L__tmp2                           // DW_AT_high_pc
(EngineCore_DP0 pid=494039) .b8 1                                   // DW_AT_call_file
(EngineCore_DP0 pid=494039) .b8 157                                 // DW_AT_call_line
(EngineCore_DP0 pid=494039) .b8 43                                  // DW_AT_call_column
(EngineCore_DP0 pid=494039) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=494039) .b8 0                                   // End Of Children Mark
(EngineCore_DP0 pid=494039) 	}
(EngineCore_DP0 pid=494039) 	.section	.debug_macinfo	{	}
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) ================================================================
(EngineCore_DP0 pid=494039) please share the reproducer above with Triton project.
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_ygcnbaq.ptx', '-o', '/tmp/tmp_ygcnbaq.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] 
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] 
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     hidden_states = self.self_attn(
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866]     raise PTXASError(error)
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] `ptxas` stderr:
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] 
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_ygcnbaq.ptx -o /tmp/tmp_ygcnbaq.ptx.o
(EngineCore_DP0 pid=494039) ERROR 01-25 21:45:56 [core.py:866] 

STDERR:
[2026-01-25 21:44:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:44:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:44:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:44:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:44:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:44:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:44:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:44:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 21:44:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-25 21:44:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:44:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-25 21:44:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-25 21:44:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=0 models
[2026-01-25 21:44:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 21:44:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 21:44:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 21:44:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=494039) [2026-01-25 21:44:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=494039) [2026-01-25 21:44:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=494039) [2026-01-25 21:44:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=494039) [2026-01-25 21:44:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=494039) [2026-01-25 21:44:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=494039) [2026-01-25 21:44:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=494039) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=494039) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.76s/it]
(EngineCore_DP0 pid=494039) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.72s/it]
(EngineCore_DP0 pid=494039) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.28s/it]
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) [2026-01-25 21:45:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=494039) [2026-01-25 21:45:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=494039) [2026-01-25 21:45:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=494039) [2026-01-25 21:45:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=494039) [2026-01-25 21:45:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=494039) [2026-01-25 21:45:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=494039) [2026-01-25 21:45:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=494039) [2026-01-25 21:45:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=494039) Process EngineCore_DP0:
(EngineCore_DP0 pid=494039) Traceback (most recent call last):
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 468, in make_cubin
(EngineCore_DP0 pid=494039)     subprocess.run(ptxas_cmd, check=True, close_fds=False, stderr=flog)
(EngineCore_DP0 pid=494039)   File "/usr/lib/python3.12/subprocess.py", line 571, in run
(EngineCore_DP0 pid=494039)     raise CalledProcessError(retcode, process.args,
(EngineCore_DP0 pid=494039) subprocess.CalledProcessError: Command '['/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas', '-lineinfo', '-v', '--gpu-name=sm_121a', '/tmp/tmp_ygcnbaq.ptx', '-o', '/tmp/tmp_ygcnbaq.ptx.o']' returned non-zero exit status 255.
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) During handling of the above exception, another exception occurred:
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) Traceback (most recent call last):
(EngineCore_DP0 pid=494039)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=494039)     self.run()
(EngineCore_DP0 pid=494039)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=494039)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=494039)     raise e
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=494039)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=494039)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=494039)     super().__init__(
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=494039)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=494039)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=494039)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=494039)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=494039)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=494039)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=494039)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=494039)     return func(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=494039)     return func(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=494039)     self.model_runner.profile_run()
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=494039)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=494039)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=494039)     return func(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=494039)     outputs = self.model(
(EngineCore_DP0 pid=494039)               ^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=494039)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=494039)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=494039)     hidden_states = self.model(
(EngineCore_DP0 pid=494039)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=494039)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=494039)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=494039)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=494039)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=494039)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 296, in forward
(EngineCore_DP0 pid=494039)     hidden_states = self.self_attn(
(EngineCore_DP0 pid=494039)                     ^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=494039)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=494039)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 206, in forward
(EngineCore_DP0 pid=494039)     qkv, _ = self.qkv_proj(hidden_states)
(EngineCore_DP0 pid=494039)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=494039)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=494039)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 565, in forward
(EngineCore_DP0 pid=494039)     output_parallel = self.quant_method.apply(self, input_, bias)
(EngineCore_DP0 pid=494039)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=494039)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=494039)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=494039)     return self._linear_fn(
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=494039)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=494039)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=494039)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=494039)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=494039)     return fn(input, L)
(EngineCore_DP0 pid=494039)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 225, in quant_slide_fp8_triton
(EngineCore_DP0 pid=494039)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=494039)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=494039)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 733, in run
(EngineCore_DP0 pid=494039)     kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
(EngineCore_DP0 pid=494039)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 861, in _do_compile
(EngineCore_DP0 pid=494039)     kernel = self.compile(src, target=target, options=options.__dict__)
(EngineCore_DP0 pid=494039)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 320, in compile
(EngineCore_DP0 pid=494039)     next_module = compile_ir(module, metadata)
(EngineCore_DP0 pid=494039)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 520, in <lambda>
(EngineCore_DP0 pid=494039)     stages["cubin"] = lambda src, metadata: self.make_cubin(src, metadata, options, self.target.arch)
(EngineCore_DP0 pid=494039)                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=494039)   File "/usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/compiler.py", line 503, in make_cubin
(EngineCore_DP0 pid=494039)     raise PTXASError(error)
(EngineCore_DP0 pid=494039) triton.runtime.errors.PTXASError: PTXAS error: Internal Triton PTX codegen error
(EngineCore_DP0 pid=494039) `ptxas` stderr:
(EngineCore_DP0 pid=494039) ptxas fatal   : Value 'sm_121a' is not defined for option 'gpu-name'
(EngineCore_DP0 pid=494039) 
(EngineCore_DP0 pid=494039) Repro command: /usr/local/lib/python3.12/dist-packages/triton/backends/nvidia/bin/ptxas -lineinfo -v --gpu-name=sm_121a /tmp/tmp_ygcnbaq.ptx -o /tmp/tmp_ygcnbaq.ptx.o
(EngineCore_DP0 pid=494039) 
[rank0]:[W125 21:45:56.098508092 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-26 08:27:47
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:27:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:27:51 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1074368) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1074368) WARNING 01-26 08:28:13 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 48.19 requests/s, 24719.22 total tokens/s, 48.19 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 08:27:51] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:27:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:27:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:27:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:27:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:27:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:27:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:27:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:27:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:27:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:27:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:27:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:27:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:27:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:27:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:27:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:27:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:27:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:27:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:27:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:27:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:27:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:27:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:27:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:27:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:27:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:27:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:27:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1074368) [2026-01-26 08:27:55] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1074368) [2026-01-26 08:27:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1074368) [2026-01-26 08:27:55] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1074368) [2026-01-26 08:27:55] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1074368) [2026-01-26 08:27:55] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1074368) [2026-01-26 08:27:55] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1074368) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1074368) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.69s/it]
(EngineCore_DP0 pid=1074368) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.70s/it]
(EngineCore_DP0 pid=1074368) 
(EngineCore_DP0 pid=1074368) [2026-01-26 08:28:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1074368) [2026-01-26 08:28:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1074368) [2026-01-26 08:28:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1074368) [2026-01-26 08:28:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1074368) [2026-01-26 08:28:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1074368) [2026-01-26 08:28:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1074368) [2026-01-26 08:28:07] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1074368) [2026-01-26 08:28:07] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1074368) 2026-01-26 08:28:12,388 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1074368) 2026-01-26 08:28:12,394 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  96%|| 123/128 [00:00<00:00, 1224.16it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1223.08it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:14,  8.72it/s, est. speed input: 4466.88 toks/s, output: 8.72 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:03, 33.80it/s, est. speed input: 15410.51 toks/s, output: 30.10 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:02, 42.17it/s, est. speed input: 19163.84 toks/s, output: 37.43 toks/s]
Processed prompts:  15%|        | 19/128 [00:00<00:02, 46.11it/s, est. speed input: 21043.49 toks/s, output: 41.10 toks/s]
Processed prompts:  20%|        | 25/128 [00:00<00:02, 48.50it/s, est. speed input: 22224.96 toks/s, output: 43.41 toks/s]
Processed prompts:  23%|       | 30/128 [00:00<00:02, 48.62it/s, est. speed input: 22648.67 toks/s, output: 44.23 toks/s]
Processed prompts:  28%|       | 36/128 [00:00<00:01, 49.93it/s, est. speed input: 23260.82 toks/s, output: 45.43 toks/s]
Processed prompts:  33%|      | 42/128 [00:00<00:01, 51.00it/s, est. speed input: 23760.29 toks/s, output: 46.41 toks/s]
Processed prompts:  38%|      | 48/128 [00:01<00:01, 51.18it/s, est. speed input: 24061.66 toks/s, output: 46.99 toks/s]
Processed prompts:  42%|     | 54/128 [00:01<00:01, 51.68it/s, est. speed input: 24359.16 toks/s, output: 47.58 toks/s]
Processed prompts:  47%|     | 60/128 [00:01<00:01, 51.87it/s, est. speed input: 24581.12 toks/s, output: 48.01 toks/s]
Processed prompts:  52%|    | 66/128 [00:01<00:01, 52.20it/s, est. speed input: 24792.02 toks/s, output: 48.42 toks/s]
Processed prompts:  56%|    | 72/128 [00:01<00:01, 52.19it/s, est. speed input: 24940.76 toks/s, output: 48.71 toks/s]
Processed prompts:  61%|    | 78/128 [00:01<00:00, 52.37it/s, est. speed input: 25089.39 toks/s, output: 49.00 toks/s]
Processed prompts:  66%|   | 84/128 [00:01<00:00, 51.65it/s, est. speed input: 25128.02 toks/s, output: 49.08 toks/s]
Processed prompts:  70%|   | 90/128 [00:01<00:00, 51.62it/s, est. speed input: 25208.68 toks/s, output: 49.24 toks/s]
Processed prompts:  75%|  | 96/128 [00:01<00:00, 51.88it/s, est. speed input: 25307.15 toks/s, output: 49.43 toks/s]
Processed prompts:  80%|  | 102/128 [00:02<00:00, 51.78it/s, est. speed input: 25368.57 toks/s, output: 49.55 toks/s]
Processed prompts:  84%| | 108/128 [00:02<00:00, 52.15it/s, est. speed input: 25461.19 toks/s, output: 49.73 toks/s]
Processed prompts:  89%| | 114/128 [00:02<00:00, 52.31it/s, est. speed input: 25536.94 toks/s, output: 49.88 toks/s]
Processed prompts:  94%|| 120/128 [00:02<00:00, 52.42it/s, est. speed input: 25605.15 toks/s, output: 50.01 toks/s]
Processed prompts:  98%|| 126/128 [00:02<00:00, 52.59it/s, est. speed input: 25673.65 toks/s, output: 50.14 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 52.59it/s, est. speed input: 25691.26 toks/s, output: 50.18 toks/s]
Processed prompts: 100%|| 128/128 [00:02<00:00, 50.18it/s, est. speed input: 25691.26 toks/s, output: 50.18 toks/s]
[rank0]:[W126 08:28:16.200376383 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 08:28:18
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:28:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:28:22 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1074991) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1074991) WARNING 01-26 08:28:43 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.04 requests/s, 27720.88 total tokens/s, 27.04 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 08:28:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:28:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:28:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:28:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:28:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:28:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:28:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:28:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:28:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:28:25] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:28:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:28:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:28:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:28:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:28:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:28:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:28:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:28:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1074991) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1074991) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.90s/it]
(EngineCore_DP0 pid=1074991) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.90s/it]
(EngineCore_DP0 pid=1074991) 
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1074991) [2026-01-26 08:28:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1074991) 2026-01-26 08:28:43,265 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1074991) 2026-01-26 08:28:43,271 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  44%|     | 56/128 [00:00<00:00, 555.92it/s]
Adding requests:  88%| | 112/128 [00:00<00:00, 518.60it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 523.66it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:01, 68.73it/s, est. speed input: 70401.22 toks/s, output: 68.74 toks/s]
Processed prompts:  12%|        | 15/128 [00:00<00:03, 37.05it/s, est. speed input: 40963.44 toks/s, output: 40.00 toks/s]
Processed prompts:  16%|        | 20/128 [00:00<00:03, 32.89it/s, est. speed input: 36758.95 toks/s, output: 35.90 toks/s]
Processed prompts:  19%|        | 24/128 [00:00<00:03, 31.13it/s, est. speed input: 34998.94 toks/s, output: 34.18 toks/s]
Processed prompts:  22%|       | 28/128 [00:00<00:03, 29.98it/s, est. speed input: 33834.36 toks/s, output: 33.04 toks/s]
Processed prompts:  25%|       | 32/128 [00:00<00:03, 29.16it/s, est. speed input: 32983.56 toks/s, output: 32.21 toks/s]
Processed prompts:  27%|       | 35/128 [00:01<00:03, 28.63it/s, est. speed input: 32455.26 toks/s, output: 31.69 toks/s]
Processed prompts:  30%|       | 38/128 [00:01<00:03, 28.26it/s, est. speed input: 32040.65 toks/s, output: 31.29 toks/s]
Processed prompts:  32%|      | 41/128 [00:01<00:03, 27.98it/s, est. speed input: 31695.66 toks/s, output: 30.95 toks/s]
Processed prompts:  34%|      | 44/128 [00:01<00:03, 27.79it/s, est. speed input: 31411.55 toks/s, output: 30.67 toks/s]
Processed prompts:  37%|      | 47/128 [00:01<00:02, 27.66it/s, est. speed input: 31166.92 toks/s, output: 30.44 toks/s]
Processed prompts:  39%|      | 50/128 [00:01<00:02, 27.86it/s, est. speed input: 31030.81 toks/s, output: 30.30 toks/s]
Processed prompts:  41%|     | 53/128 [00:01<00:02, 27.96it/s, est. speed input: 30901.86 toks/s, output: 30.18 toks/s]
Processed prompts:  44%|     | 56/128 [00:01<00:02, 27.64it/s, est. speed input: 30702.14 toks/s, output: 29.98 toks/s]
Processed prompts:  46%|     | 59/128 [00:01<00:02, 27.63it/s, est. speed input: 30567.97 toks/s, output: 29.85 toks/s]
Processed prompts:  48%|     | 62/128 [00:02<00:02, 27.58it/s, est. speed input: 30439.39 toks/s, output: 29.73 toks/s]
Processed prompts:  51%|     | 65/128 [00:02<00:02, 27.53it/s, est. speed input: 30321.40 toks/s, output: 29.61 toks/s]
Processed prompts:  53%|    | 68/128 [00:02<00:02, 27.28it/s, est. speed input: 30176.71 toks/s, output: 29.47 toks/s]
Processed prompts:  55%|    | 71/128 [00:02<00:02, 27.28it/s, est. speed input: 30075.16 toks/s, output: 29.37 toks/s]
Processed prompts:  58%|    | 74/128 [00:02<00:01, 27.60it/s, est. speed input: 30031.79 toks/s, output: 29.33 toks/s]
Processed prompts:  60%|    | 77/128 [00:02<00:01, 27.69it/s, est. speed input: 29971.78 toks/s, output: 29.27 toks/s]
Processed prompts:  62%|   | 80/128 [00:02<00:01, 27.78it/s, est. speed input: 29920.64 toks/s, output: 29.22 toks/s]
Processed prompts:  65%|   | 83/128 [00:02<00:01, 27.67it/s, est. speed input: 29850.21 toks/s, output: 29.15 toks/s]
Processed prompts:  67%|   | 86/128 [00:02<00:01, 27.63it/s, est. speed input: 29789.25 toks/s, output: 29.09 toks/s]
Processed prompts:  70%|   | 89/128 [00:03<00:01, 27.61it/s, est. speed input: 29733.51 toks/s, output: 29.04 toks/s]
Processed prompts:  72%|  | 92/128 [00:03<00:01, 27.55it/s, est. speed input: 29676.22 toks/s, output: 28.98 toks/s]
Processed prompts:  74%|  | 95/128 [00:03<00:01, 27.69it/s, est. speed input: 29644.27 toks/s, output: 28.95 toks/s]
Processed prompts:  77%|  | 98/128 [00:03<00:01, 27.10it/s, est. speed input: 29535.07 toks/s, output: 28.84 toks/s]
Processed prompts:  79%|  | 101/128 [00:03<00:00, 27.28it/s, est. speed input: 29498.61 toks/s, output: 28.81 toks/s]
Processed prompts:  81%| | 104/128 [00:03<00:00, 27.44it/s, est. speed input: 29469.16 toks/s, output: 28.78 toks/s]
Processed prompts:  84%| | 107/128 [00:03<00:00, 27.44it/s, est. speed input: 29428.57 toks/s, output: 28.74 toks/s]
Processed prompts:  86%| | 110/128 [00:03<00:00, 27.51it/s, est. speed input: 29397.56 toks/s, output: 28.71 toks/s]
Processed prompts:  88%| | 113/128 [00:03<00:00, 27.55it/s, est. speed input: 29367.68 toks/s, output: 28.68 toks/s]
Processed prompts:  91%| | 116/128 [00:04<00:00, 27.67it/s, est. speed input: 29348.12 toks/s, output: 28.66 toks/s]
Processed prompts:  93%|| 119/128 [00:04<00:00, 27.41it/s, est. speed input: 29297.25 toks/s, output: 28.61 toks/s]
Processed prompts:  95%|| 122/128 [00:04<00:00, 27.58it/s, est. speed input: 29281.66 toks/s, output: 28.60 toks/s]
Processed prompts:  98%|| 125/128 [00:04<00:00, 27.46it/s, est. speed input: 29244.70 toks/s, output: 28.56 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 27.37it/s, est. speed input: 29209.31 toks/s, output: 28.52 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 27.37it/s, est. speed input: 29209.31 toks/s, output: 28.52 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.52it/s, est. speed input: 29209.31 toks/s, output: 28.52 toks/s]
[rank0]:[W126 08:28:48.056954788 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 08:28:51
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:28:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:28:55 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1075653) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1075653) WARNING 01-26 08:29:17 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.76 requests/s, 28459.12 total tokens/s, 27.76 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 08:28:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:28:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:28:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:28:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:28:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:28:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:28:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:28:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:28:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:28:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:28:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:28:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:28:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:28:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:28:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:28:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:28:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:28:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:28:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1075653) [2026-01-26 08:28:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1075653) [2026-01-26 08:28:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1075653) [2026-01-26 08:28:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1075653) [2026-01-26 08:28:59] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1075653) [2026-01-26 08:28:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1075653) [2026-01-26 08:28:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1075653) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1075653) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.87s/it]
(EngineCore_DP0 pid=1075653) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.87s/it]
(EngineCore_DP0 pid=1075653) 
(EngineCore_DP0 pid=1075653) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1075653) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1075653) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1075653) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1075653) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1075653) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1075653) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1075653) [2026-01-26 08:29:11] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1075653) 2026-01-26 08:29:16,534 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1075653) 2026-01-26 08:29:16,541 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  24%|       | 62/256 [00:00<00:00, 612.97it/s]
Adding requests:  48%|     | 124/256 [00:00<00:00, 594.27it/s]
Adding requests:  72%|  | 184/256 [00:00<00:00, 562.56it/s]
Adding requests:  94%|| 241/256 [00:00<00:00, 544.90it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 555.68it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 12/256 [00:00<00:02, 103.52it/s, est. speed input: 106025.23 toks/s, output: 103.53 toks/s]
Processed prompts:   9%|         | 23/256 [00:00<00:05, 43.62it/s, est. speed input: 49118.92 toks/s, output: 47.97 toks/s]   
Processed prompts:  12%|        | 30/256 [00:00<00:06, 34.63it/s, est. speed input: 40290.90 toks/s, output: 39.35 toks/s]
Processed prompts:  14%|        | 35/256 [00:00<00:06, 34.82it/s, est. speed input: 39656.74 toks/s, output: 38.73 toks/s]
Processed prompts:  16%|        | 40/256 [00:01<00:06, 30.93it/s, est. speed input: 36751.69 toks/s, output: 35.89 toks/s]
Processed prompts:  17%|        | 44/256 [00:01<00:07, 30.27it/s, est. speed input: 35877.94 toks/s, output: 35.04 toks/s]
Processed prompts:  19%|        | 48/256 [00:01<00:07, 29.43it/s, est. speed input: 35037.20 toks/s, output: 34.22 toks/s]
Processed prompts:  20%|        | 52/256 [00:01<00:06, 29.23it/s, est. speed input: 34525.58 toks/s, output: 33.72 toks/s]
Processed prompts:  22%|       | 56/256 [00:01<00:06, 29.09it/s, est. speed input: 34099.99 toks/s, output: 33.30 toks/s]
Processed prompts:  23%|       | 60/256 [00:01<00:06, 28.78it/s, est. speed input: 33678.26 toks/s, output: 32.89 toks/s]
Processed prompts:  25%|       | 64/256 [00:01<00:06, 28.76it/s, est. speed input: 33373.98 toks/s, output: 32.59 toks/s]
Processed prompts:  27%|       | 68/256 [00:02<00:06, 28.68it/s, est. speed input: 33093.96 toks/s, output: 32.32 toks/s]
Processed prompts:  28%|       | 72/256 [00:02<00:06, 28.53it/s, est. speed input: 32824.32 toks/s, output: 32.05 toks/s]
Processed prompts:  30%|       | 76/256 [00:02<00:06, 28.23it/s, est. speed input: 32544.94 toks/s, output: 31.78 toks/s]
Processed prompts:  31%|      | 80/256 [00:02<00:06, 28.34it/s, est. speed input: 32365.37 toks/s, output: 31.61 toks/s]
Processed prompts:  33%|      | 84/256 [00:02<00:06, 28.33it/s, est. speed input: 32185.59 toks/s, output: 31.43 toks/s]
Processed prompts:  34%|      | 88/256 [00:02<00:05, 28.35it/s, est. speed input: 32029.84 toks/s, output: 31.28 toks/s]
Processed prompts:  36%|      | 92/256 [00:02<00:05, 28.26it/s, est. speed input: 31871.53 toks/s, output: 31.12 toks/s]
Processed prompts:  38%|      | 96/256 [00:03<00:05, 28.22it/s, est. speed input: 31729.57 toks/s, output: 30.99 toks/s]
Processed prompts:  39%|      | 100/256 [00:03<00:05, 28.21it/s, est. speed input: 31604.32 toks/s, output: 30.86 toks/s]
Processed prompts:  41%|      | 104/256 [00:03<00:05, 28.40it/s, est. speed input: 31519.14 toks/s, output: 30.78 toks/s]
Processed prompts:  42%|     | 108/256 [00:03<00:05, 27.99it/s, est. speed input: 31361.47 toks/s, output: 30.63 toks/s]
Processed prompts:  44%|     | 112/256 [00:03<00:05, 28.16it/s, est. speed input: 31281.02 toks/s, output: 30.55 toks/s]
Processed prompts:  45%|     | 116/256 [00:03<00:04, 28.23it/s, est. speed input: 31198.73 toks/s, output: 30.47 toks/s]
Processed prompts:  47%|     | 120/256 [00:03<00:04, 28.27it/s, est. speed input: 31121.79 toks/s, output: 30.39 toks/s]
Processed prompts:  48%|     | 124/256 [00:04<00:04, 28.16it/s, est. speed input: 31032.79 toks/s, output: 30.31 toks/s]
Processed prompts:  50%|     | 128/256 [00:04<00:04, 28.29it/s, est. speed input: 30975.10 toks/s, output: 30.25 toks/s]
Processed prompts:  52%|    | 132/256 [00:04<00:04, 28.24it/s, est. speed input: 30904.71 toks/s, output: 30.18 toks/s]
Processed prompts:  53%|    | 136/256 [00:04<00:04, 27.94it/s, est. speed input: 30807.69 toks/s, output: 30.09 toks/s]
Processed prompts:  55%|    | 140/256 [00:04<00:04, 27.94it/s, est. speed input: 30740.41 toks/s, output: 30.02 toks/s]
Processed prompts:  56%|    | 144/256 [00:04<00:03, 28.07it/s, est. speed input: 30690.35 toks/s, output: 29.97 toks/s]
Processed prompts:  58%|    | 148/256 [00:04<00:03, 28.10it/s, est. speed input: 30637.29 toks/s, output: 29.92 toks/s]
Processed prompts:  59%|    | 152/256 [00:05<00:03, 28.15it/s, est. speed input: 30590.54 toks/s, output: 29.87 toks/s]
Processed prompts:  61%|    | 156/256 [00:05<00:03, 28.22it/s, est. speed input: 30549.27 toks/s, output: 29.83 toks/s]
Processed prompts:  62%|   | 160/256 [00:05<00:03, 28.12it/s, est. speed input: 30496.10 toks/s, output: 29.78 toks/s]
Processed prompts:  64%|   | 164/256 [00:05<00:03, 28.12it/s, est. speed input: 30452.73 toks/s, output: 29.74 toks/s]
Processed prompts:  66%|   | 168/256 [00:05<00:03, 27.86it/s, est. speed input: 30386.95 toks/s, output: 29.67 toks/s]
Processed prompts:  67%|   | 172/256 [00:05<00:03, 27.90it/s, est. speed input: 30344.19 toks/s, output: 29.63 toks/s]
Processed prompts:  69%|   | 176/256 [00:05<00:02, 27.96it/s, est. speed input: 30307.30 toks/s, output: 29.60 toks/s]
Processed prompts:  70%|   | 180/256 [00:06<00:02, 28.12it/s, est. speed input: 30281.27 toks/s, output: 29.57 toks/s]
Processed prompts:  72%|  | 184/256 [00:06<00:02, 28.04it/s, est. speed input: 30240.73 toks/s, output: 29.53 toks/s]
Processed prompts:  73%|  | 188/256 [00:06<00:02, 28.17it/s, est. speed input: 30217.01 toks/s, output: 29.51 toks/s]
Processed prompts:  75%|  | 192/256 [00:06<00:02, 28.19it/s, est. speed input: 30188.76 toks/s, output: 29.48 toks/s]
Processed prompts:  77%|  | 196/256 [00:06<00:02, 27.84it/s, est. speed input: 30133.84 toks/s, output: 29.43 toks/s]
Processed prompts:  78%|  | 200/256 [00:06<00:02, 27.96it/s, est. speed input: 30108.11 toks/s, output: 29.40 toks/s]
Processed prompts:  80%|  | 204/256 [00:06<00:01, 28.08it/s, est. speed input: 30086.90 toks/s, output: 29.38 toks/s]
Processed prompts:  81%| | 208/256 [00:07<00:01, 28.21it/s, est. speed input: 30069.18 toks/s, output: 29.36 toks/s]
Processed prompts:  83%| | 212/256 [00:07<00:01, 28.19it/s, est. speed input: 30044.60 toks/s, output: 29.34 toks/s]
Processed prompts:  84%| | 216/256 [00:07<00:01, 28.26it/s, est. speed input: 30026.77 toks/s, output: 29.32 toks/s]
Processed prompts:  86%| | 220/256 [00:07<00:01, 28.26it/s, est. speed input: 30006.28 toks/s, output: 29.30 toks/s]
Processed prompts:  88%| | 224/256 [00:07<00:01, 28.07it/s, est. speed input: 29973.62 toks/s, output: 29.27 toks/s]
Processed prompts:  89%| | 228/256 [00:07<00:01, 27.92it/s, est. speed input: 29941.28 toks/s, output: 29.24 toks/s]
Processed prompts:  91%| | 232/256 [00:07<00:00, 28.10it/s, est. speed input: 29928.86 toks/s, output: 29.23 toks/s]
Processed prompts:  92%|| 236/256 [00:08<00:00, 28.13it/s, est. speed input: 29910.32 toks/s, output: 29.21 toks/s]
Processed prompts:  94%|| 240/256 [00:08<00:00, 27.97it/s, est. speed input: 29881.27 toks/s, output: 29.18 toks/s]
Processed prompts:  95%|| 244/256 [00:08<00:00, 28.11it/s, est. speed input: 29868.88 toks/s, output: 29.17 toks/s]
Processed prompts:  97%|| 248/256 [00:08<00:00, 28.25it/s, est. speed input: 29858.77 toks/s, output: 29.16 toks/s]
Processed prompts:  98%|| 252/256 [00:08<00:00, 28.27it/s, est. speed input: 29844.47 toks/s, output: 29.14 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 30.15it/s, est. speed input: 29930.22 toks/s, output: 29.23 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 30.15it/s, est. speed input: 29930.22 toks/s, output: 29.23 toks/s]
Processed prompts: 100%|| 256/256 [00:08<00:00, 29.23it/s, est. speed input: 29930.22 toks/s, output: 29.23 toks/s]
[rank0]:[W126 08:29:26.944010822 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 08:29:29
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:29:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:29:34 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1076385) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1076385) WARNING 01-26 08:29:55 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.31 requests/s, 29020.46 total tokens/s, 28.31 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 08:29:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:29:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:29:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:29:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:29:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:29:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:29:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:29:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:29:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:29:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:29:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:29:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:29:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:29:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:29:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:29:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:29:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:29:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:29:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:29:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:29:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:29:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:29:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:29:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:29:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:29:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:29:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:29:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:38] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:38] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:38] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:38] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:38] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1076385) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1076385) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.78s/it]
(EngineCore_DP0 pid=1076385) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.78s/it]
(EngineCore_DP0 pid=1076385) 
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1076385) [2026-01-26 08:29:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1076385) 2026-01-26 08:29:54,935 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1076385) 2026-01-26 08:29:54,952 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  11%|         | 57/512 [00:00<00:00, 562.14it/s]
Adding requests:  22%|       | 114/512 [00:00<00:00, 526.48it/s]
Adding requests:  33%|      | 167/512 [00:00<00:00, 515.27it/s]
Adding requests:  43%|     | 219/512 [00:00<00:00, 511.19it/s]
Adding requests:  53%|    | 273/512 [00:00<00:00, 518.41it/s]
Adding requests:  63%|   | 325/512 [00:00<00:00, 504.96it/s]
Adding requests:  74%|  | 379/512 [00:00<00:00, 512.47it/s]
Adding requests:  84%| | 432/512 [00:00<00:00, 515.96it/s]
Adding requests:  95%|| 484/512 [00:00<00:00, 507.36it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 512.30it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 26/512 [00:00<00:02, 193.43it/s, est. speed input: 198099.62 toks/s, output: 193.44 toks/s]
Processed prompts:   9%|         | 46/512 [00:00<00:09, 48.38it/s, est. speed input: 56759.20 toks/s, output: 55.43 toks/s]   
Processed prompts:  11%|         | 56/512 [00:01<00:10, 44.21it/s, est. speed input: 51744.10 toks/s, output: 50.53 toks/s]
Processed prompts:  12%|        | 63/512 [00:01<00:11, 37.79it/s, est. speed input: 46333.54 toks/s, output: 45.25 toks/s]
Processed prompts:  13%|        | 69/512 [00:01<00:11, 38.80it/s, est. speed input: 46145.47 toks/s, output: 45.06 toks/s]
Processed prompts:  14%|        | 74/512 [00:01<00:13, 31.48it/s, est. speed input: 41839.44 toks/s, output: 40.86 toks/s]
Processed prompts:  15%|        | 78/512 [00:01<00:14, 30.93it/s, est. speed input: 40949.70 toks/s, output: 39.99 toks/s]
Processed prompts:  16%|        | 82/512 [00:02<00:14, 30.42it/s, est. speed input: 40171.91 toks/s, output: 39.23 toks/s]
Processed prompts:  17%|        | 86/512 [00:02<00:14, 29.72it/s, est. speed input: 39398.61 toks/s, output: 38.47 toks/s]
Processed prompts:  18%|        | 90/512 [00:02<00:14, 29.33it/s, est. speed input: 38770.80 toks/s, output: 37.86 toks/s]
Processed prompts:  18%|        | 94/512 [00:02<00:14, 29.19it/s, est. speed input: 38258.65 toks/s, output: 37.36 toks/s]
Processed prompts:  19%|        | 98/512 [00:02<00:14, 29.04it/s, est. speed input: 37788.56 toks/s, output: 36.90 toks/s]
Processed prompts:  20%|        | 102/512 [00:02<00:14, 28.81it/s, est. speed input: 37340.40 toks/s, output: 36.46 toks/s]
Processed prompts:  21%|        | 106/512 [00:02<00:14, 28.87it/s, est. speed input: 36981.06 toks/s, output: 36.11 toks/s]
Processed prompts:  21%|       | 110/512 [00:03<00:13, 28.88it/s, est. speed input: 36649.45 toks/s, output: 35.79 toks/s]
Processed prompts:  22%|       | 114/512 [00:03<00:13, 28.71it/s, est. speed input: 36312.70 toks/s, output: 35.46 toks/s]
Processed prompts:  23%|       | 118/512 [00:03<00:13, 28.41it/s, est. speed input: 35971.79 toks/s, output: 35.13 toks/s]
Processed prompts:  24%|       | 122/512 [00:03<00:13, 28.32it/s, est. speed input: 35679.52 toks/s, output: 34.84 toks/s]
Processed prompts:  25%|       | 126/512 [00:03<00:13, 28.33it/s, est. speed input: 35422.39 toks/s, output: 34.59 toks/s]
Processed prompts:  25%|       | 130/512 [00:03<00:13, 28.33it/s, est. speed input: 35182.70 toks/s, output: 34.36 toks/s]
Processed prompts:  26%|       | 134/512 [00:03<00:13, 28.34it/s, est. speed input: 34961.79 toks/s, output: 34.14 toks/s]
Processed prompts:  27%|       | 138/512 [00:04<00:13, 28.47it/s, est. speed input: 34773.64 toks/s, output: 33.96 toks/s]
Processed prompts:  28%|       | 142/512 [00:04<00:12, 28.58it/s, est. speed input: 34601.22 toks/s, output: 33.79 toks/s]
Processed prompts:  29%|       | 146/512 [00:04<00:12, 28.53it/s, est. speed input: 34422.66 toks/s, output: 33.62 toks/s]
Processed prompts:  29%|       | 150/512 [00:04<00:12, 28.37it/s, est. speed input: 34239.56 toks/s, output: 33.44 toks/s]
Processed prompts:  30%|       | 154/512 [00:04<00:12, 28.54it/s, est. speed input: 34101.88 toks/s, output: 33.30 toks/s]
Processed prompts:  31%|       | 158/512 [00:04<00:12, 28.59it/s, est. speed input: 33964.32 toks/s, output: 33.17 toks/s]
Processed prompts:  32%|      | 162/512 [00:04<00:12, 28.77it/s, est. speed input: 33850.31 toks/s, output: 33.06 toks/s]
Processed prompts:  32%|      | 166/512 [00:05<00:12, 28.73it/s, est. speed input: 33725.36 toks/s, output: 32.93 toks/s]
Processed prompts:  33%|      | 170/512 [00:05<00:11, 28.77it/s, est. speed input: 33613.56 toks/s, output: 32.83 toks/s]
Processed prompts:  34%|      | 174/512 [00:05<00:11, 28.84it/s, est. speed input: 33511.57 toks/s, output: 32.73 toks/s]
Processed prompts:  35%|      | 178/512 [00:05<00:11, 28.56it/s, est. speed input: 33383.44 toks/s, output: 32.60 toks/s]
Processed prompts:  36%|      | 182/512 [00:05<00:11, 28.50it/s, est. speed input: 33274.31 toks/s, output: 32.49 toks/s]
Processed prompts:  36%|      | 186/512 [00:05<00:11, 28.58it/s, est. speed input: 33181.16 toks/s, output: 32.40 toks/s]
Processed prompts:  37%|      | 190/512 [00:05<00:11, 28.71it/s, est. speed input: 33099.85 toks/s, output: 32.32 toks/s]
Processed prompts:  38%|      | 194/512 [00:06<00:11, 28.69it/s, est. speed input: 33012.26 toks/s, output: 32.24 toks/s]
Processed prompts:  39%|      | 198/512 [00:06<00:10, 28.71it/s, est. speed input: 32931.81 toks/s, output: 32.16 toks/s]
Processed prompts:  39%|      | 202/512 [00:06<00:10, 28.69it/s, est. speed input: 32851.77 toks/s, output: 32.08 toks/s]
Processed prompts:  40%|      | 206/512 [00:06<00:10, 28.69it/s, est. speed input: 32776.28 toks/s, output: 32.01 toks/s]
Processed prompts:  41%|      | 210/512 [00:06<00:10, 28.29it/s, est. speed input: 32671.47 toks/s, output: 31.91 toks/s]
Processed prompts:  42%|     | 214/512 [00:06<00:10, 28.36it/s, est. speed input: 32599.40 toks/s, output: 31.84 toks/s]
Processed prompts:  43%|     | 218/512 [00:06<00:10, 28.39it/s, est. speed input: 32528.34 toks/s, output: 31.77 toks/s]
Processed prompts:  43%|     | 222/512 [00:07<00:10, 28.42it/s, est. speed input: 32461.29 toks/s, output: 31.70 toks/s]
Processed prompts:  44%|     | 226/512 [00:07<00:09, 28.65it/s, est. speed input: 32412.64 toks/s, output: 31.65 toks/s]
Processed prompts:  45%|     | 230/512 [00:07<00:09, 28.83it/s, est. speed input: 32366.05 toks/s, output: 31.61 toks/s]
Processed prompts:  46%|     | 234/512 [00:07<00:09, 28.85it/s, est. speed input: 32314.54 toks/s, output: 31.56 toks/s]
Processed prompts:  46%|     | 238/512 [00:07<00:09, 28.56it/s, est. speed input: 32243.26 toks/s, output: 31.49 toks/s]
Processed prompts:  47%|     | 242/512 [00:07<00:09, 28.68it/s, est. speed input: 32197.15 toks/s, output: 31.44 toks/s]
Processed prompts:  48%|     | 246/512 [00:07<00:09, 28.68it/s, est. speed input: 32146.91 toks/s, output: 31.39 toks/s]
Processed prompts:  49%|     | 250/512 [00:07<00:09, 28.72it/s, est. speed input: 32100.72 toks/s, output: 31.35 toks/s]
Processed prompts:  50%|     | 254/512 [00:08<00:08, 28.73it/s, est. speed input: 32055.08 toks/s, output: 31.30 toks/s]
Processed prompts:  50%|     | 258/512 [00:08<00:08, 28.64it/s, est. speed input: 32004.85 toks/s, output: 31.25 toks/s]
Processed prompts:  51%|     | 262/512 [00:08<00:08, 28.53it/s, est. speed input: 31953.87 toks/s, output: 31.20 toks/s]
Processed prompts:  52%|    | 266/512 [00:08<00:08, 28.47it/s, est. speed input: 31905.13 toks/s, output: 31.16 toks/s]
Processed prompts:  53%|    | 270/512 [00:08<00:08, 28.30it/s, est. speed input: 31850.08 toks/s, output: 31.10 toks/s]
Processed prompts:  54%|    | 274/512 [00:08<00:08, 28.28it/s, est. speed input: 31802.83 toks/s, output: 31.06 toks/s]
Processed prompts:  54%|    | 278/512 [00:08<00:08, 28.41it/s, est. speed input: 31765.42 toks/s, output: 31.02 toks/s]
Processed prompts:  55%|    | 282/512 [00:09<00:08, 28.31it/s, est. speed input: 31718.42 toks/s, output: 30.97 toks/s]
Processed prompts:  56%|    | 286/512 [00:09<00:07, 28.42it/s, est. speed input: 31682.73 toks/s, output: 30.94 toks/s]
Processed prompts:  57%|    | 290/512 [00:09<00:07, 28.52it/s, est. speed input: 31649.58 toks/s, output: 30.91 toks/s]
Processed prompts:  57%|    | 294/512 [00:09<00:07, 28.54it/s, est. speed input: 31614.82 toks/s, output: 30.87 toks/s]
Processed prompts:  58%|    | 298/512 [00:09<00:07, 28.26it/s, est. speed input: 31564.97 toks/s, output: 30.83 toks/s]
Processed prompts:  59%|    | 302/512 [00:09<00:07, 28.19it/s, est. speed input: 31523.63 toks/s, output: 30.78 toks/s]
Processed prompts:  60%|    | 306/512 [00:09<00:07, 28.30it/s, est. speed input: 31491.14 toks/s, output: 30.75 toks/s]
Processed prompts:  61%|    | 310/512 [00:10<00:07, 28.44it/s, est. speed input: 31463.25 toks/s, output: 30.73 toks/s]
Processed prompts:  61%|   | 314/512 [00:10<00:06, 28.38it/s, est. speed input: 31428.23 toks/s, output: 30.69 toks/s]
Processed prompts:  62%|   | 318/512 [00:10<00:06, 28.40it/s, est. speed input: 31396.92 toks/s, output: 30.66 toks/s]
Processed prompts:  63%|   | 322/512 [00:10<00:06, 28.60it/s, est. speed input: 31375.94 toks/s, output: 30.64 toks/s]
Processed prompts:  64%|   | 326/512 [00:10<00:06, 28.64it/s, est. speed input: 31350.47 toks/s, output: 30.62 toks/s]
Processed prompts:  64%|   | 330/512 [00:10<00:06, 28.33it/s, est. speed input: 31309.19 toks/s, output: 30.58 toks/s]
Processed prompts:  65%|   | 334/512 [00:10<00:06, 28.52it/s, est. speed input: 31288.65 toks/s, output: 30.56 toks/s]
Processed prompts:  66%|   | 338/512 [00:11<00:06, 28.54it/s, est. speed input: 31262.94 toks/s, output: 30.53 toks/s]
Processed prompts:  67%|   | 342/512 [00:11<00:05, 28.86it/s, est. speed input: 31251.90 toks/s, output: 30.52 toks/s]
Processed prompts:  68%|   | 346/512 [00:11<00:05, 28.64it/s, est. speed input: 31221.44 toks/s, output: 30.49 toks/s]
Processed prompts:  68%|   | 350/512 [00:11<00:05, 28.72it/s, est. speed input: 31201.82 toks/s, output: 30.47 toks/s]
Processed prompts:  69%|   | 354/512 [00:11<00:05, 28.67it/s, est. speed input: 31178.29 toks/s, output: 30.45 toks/s]
Processed prompts:  70%|   | 358/512 [00:11<00:05, 28.62it/s, est. speed input: 31154.35 toks/s, output: 30.42 toks/s]
Processed prompts:  71%|   | 362/512 [00:11<00:05, 28.21it/s, est. speed input: 31114.92 toks/s, output: 30.39 toks/s]
Processed prompts:  71%|  | 366/512 [00:12<00:05, 28.40it/s, est. speed input: 31097.17 toks/s, output: 30.37 toks/s]
Processed prompts:  72%|  | 370/512 [00:12<00:04, 28.45it/s, est. speed input: 31075.91 toks/s, output: 30.35 toks/s]
Processed prompts:  73%|  | 374/512 [00:12<00:04, 28.48it/s, est. speed input: 31055.01 toks/s, output: 30.33 toks/s]
Processed prompts:  74%|  | 378/512 [00:12<00:04, 28.43it/s, est. speed input: 31031.41 toks/s, output: 30.30 toks/s]
Processed prompts:  75%|  | 382/512 [00:12<00:04, 28.56it/s, est. speed input: 31015.25 toks/s, output: 30.29 toks/s]
Processed prompts:  75%|  | 386/512 [00:12<00:04, 28.69it/s, est. speed input: 31001.09 toks/s, output: 30.27 toks/s]
Processed prompts:  76%|  | 390/512 [00:12<00:04, 28.28it/s, est. speed input: 30967.17 toks/s, output: 30.24 toks/s]
Processed prompts:  77%|  | 394/512 [00:13<00:04, 28.37it/s, est. speed input: 30949.05 toks/s, output: 30.22 toks/s]
Processed prompts:  78%|  | 398/512 [00:13<00:03, 28.53it/s, est. speed input: 30935.00 toks/s, output: 30.21 toks/s]
Processed prompts:  79%|  | 402/512 [00:13<00:03, 28.78it/s, est. speed input: 30926.23 toks/s, output: 30.20 toks/s]
Processed prompts:  79%|  | 406/512 [00:13<00:03, 28.57it/s, est. speed input: 30903.48 toks/s, output: 30.18 toks/s]
Processed prompts:  80%|  | 410/512 [00:13<00:03, 28.70it/s, est. speed input: 30891.09 toks/s, output: 30.17 toks/s]
Processed prompts:  81%|  | 414/512 [00:13<00:03, 28.70it/s, est. speed input: 30876.02 toks/s, output: 30.15 toks/s]
Processed prompts:  82%| | 418/512 [00:13<00:03, 28.64it/s, est. speed input: 30859.03 toks/s, output: 30.14 toks/s]
Processed prompts:  82%| | 422/512 [00:14<00:03, 28.32it/s, est. speed input: 30832.07 toks/s, output: 30.11 toks/s]
Processed prompts:  83%| | 426/512 [00:14<00:03, 28.38it/s, est. speed input: 30815.99 toks/s, output: 30.09 toks/s]
Processed prompts:  84%| | 430/512 [00:14<00:02, 28.45it/s, est. speed input: 30801.10 toks/s, output: 30.08 toks/s]
Processed prompts:  85%| | 434/512 [00:14<00:02, 28.43it/s, est. speed input: 30784.24 toks/s, output: 30.06 toks/s]
Processed prompts:  86%| | 438/512 [00:14<00:02, 28.42it/s, est. speed input: 30767.68 toks/s, output: 30.05 toks/s]
Processed prompts:  86%| | 442/512 [00:14<00:02, 28.47it/s, est. speed input: 30753.49 toks/s, output: 30.03 toks/s]
Processed prompts:  87%| | 446/512 [00:14<00:02, 28.42it/s, est. speed input: 30736.53 toks/s, output: 30.02 toks/s]
Processed prompts:  88%| | 450/512 [00:14<00:02, 29.38it/s, est. speed input: 30752.74 toks/s, output: 30.03 toks/s]
Processed prompts:  89%| | 454/512 [00:15<00:02, 28.91it/s, est. speed input: 30731.77 toks/s, output: 30.01 toks/s]
Processed prompts:  89%| | 458/512 [00:15<00:01, 28.76it/s, est. speed input: 30716.68 toks/s, output: 30.00 toks/s]
Processed prompts:  90%| | 462/512 [00:15<00:01, 28.66it/s, est. speed input: 30701.85 toks/s, output: 29.98 toks/s]
Processed prompts:  91%| | 466/512 [00:15<00:01, 28.56it/s, est. speed input: 30686.65 toks/s, output: 29.97 toks/s]
Processed prompts:  92%|| 470/512 [00:15<00:01, 28.48it/s, est. speed input: 30671.22 toks/s, output: 29.95 toks/s]
Processed prompts:  93%|| 474/512 [00:15<00:01, 28.48it/s, est. speed input: 30657.77 toks/s, output: 29.94 toks/s]
Processed prompts:  93%|| 478/512 [00:15<00:01, 28.53it/s, est. speed input: 30646.32 toks/s, output: 29.93 toks/s]
Processed prompts:  94%|| 482/512 [00:16<00:01, 28.27it/s, est. speed input: 30625.77 toks/s, output: 29.91 toks/s]
Processed prompts:  95%|| 486/512 [00:16<00:00, 28.28it/s, est. speed input: 30611.48 toks/s, output: 29.89 toks/s]
Processed prompts:  96%|| 490/512 [00:16<00:00, 28.26it/s, est. speed input: 30596.58 toks/s, output: 29.88 toks/s]
Processed prompts:  96%|| 494/512 [00:16<00:00, 28.38it/s, est. speed input: 30586.10 toks/s, output: 29.87 toks/s]
Processed prompts:  97%|| 498/512 [00:16<00:00, 28.46it/s, est. speed input: 30575.70 toks/s, output: 29.86 toks/s]
Processed prompts:  98%|| 502/512 [00:16<00:00, 28.62it/s, est. speed input: 30568.33 toks/s, output: 29.85 toks/s]
Processed prompts:  99%|| 506/512 [00:16<00:00, 28.56it/s, est. speed input: 30556.17 toks/s, output: 29.84 toks/s]
Processed prompts: 100%|| 510/512 [00:17<00:00, 29.43it/s, est. speed input: 30570.13 toks/s, output: 29.85 toks/s]
Processed prompts: 100%|| 512/512 [00:17<00:00, 29.43it/s, est. speed input: 30689.76 toks/s, output: 29.97 toks/s]
Processed prompts: 100%|| 512/512 [00:17<00:00, 29.97it/s, est. speed input: 30689.76 toks/s, output: 29.97 toks/s]
[rank0]:[W126 08:30:14.214498207 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 08:30:16
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:30:22 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:30:22 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1077232) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1077232) WARNING 01-26 08:30:44 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.79 requests/s, 28484.29 total tokens/s, 27.79 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 08:30:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:30:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:30:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:30:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:30:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:30:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:30:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:30:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:30:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:30:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:30:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:30:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:30:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:30:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:30:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:30:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:30:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:30:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:30:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:30:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:30:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:30:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:30:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:30:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:30:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:30:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:30:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:30:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:27] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:27] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:27] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:27] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:27] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1077232) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1077232) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.96s/it]
(EngineCore_DP0 pid=1077232) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.96s/it]
(EngineCore_DP0 pid=1077232) 
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1077232) [2026-01-26 08:30:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1077232) 2026-01-26 08:30:44,051 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1077232) 2026-01-26 08:30:44,100 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 58/1024 [00:00<00:01, 569.38it/s]
Adding requests:  11%|         | 115/1024 [00:00<00:01, 537.05it/s]
Adding requests:  17%|        | 169/1024 [00:00<00:01, 514.20it/s]
Adding requests:  22%|       | 221/1024 [00:00<00:01, 513.37it/s]
Adding requests:  27%|       | 273/1024 [00:00<00:01, 511.78it/s]
Adding requests:  32%|      | 326/1024 [00:00<00:01, 513.46it/s]
Adding requests:  37%|      | 378/1024 [00:00<00:01, 512.43it/s]
Adding requests:  42%|     | 430/1024 [00:00<00:01, 511.54it/s]
Adding requests:  47%|     | 482/1024 [00:00<00:01, 498.82it/s]
Adding requests:  52%|    | 532/1024 [00:01<00:01, 486.70it/s]
Adding requests:  57%|    | 583/1024 [00:01<00:00, 491.11it/s]
Adding requests:  62%|   | 633/1024 [00:01<00:00, 486.54it/s]
Adding requests:  67%|   | 682/1024 [00:01<00:00, 481.20it/s]
Adding requests:  72%|  | 734/1024 [00:01<00:00, 489.98it/s]
Adding requests:  77%|  | 784/1024 [00:01<00:00, 489.32it/s]
Adding requests:  81%| | 833/1024 [00:01<00:00, 484.16it/s]
Adding requests:  86%| | 882/1024 [00:01<00:00, 484.45it/s]
Adding requests:  91%| | 933/1024 [00:01<00:00, 491.09it/s]
Adding requests:  96%|| 983/1024 [00:01<00:00, 487.78it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 497.07it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 50/1024 [00:00<00:02, 465.91it/s, est. speed input: 477231.31 toks/s, output: 465.97 toks/s]
Processed prompts:   9%|         | 97/1024 [00:01<00:17, 54.36it/s, est. speed input: 64477.07 toks/s, output: 62.97 toks/s]   
Processed prompts:  12%|        | 119/1024 [00:02<00:21, 41.41it/s, est. speed input: 50730.09 toks/s, output: 49.54 toks/s]
Processed prompts:  13%|        | 132/1024 [00:02<00:24, 35.74it/s, est. speed input: 45380.91 toks/s, output: 44.32 toks/s]
Processed prompts:  14%|        | 141/1024 [00:03<00:25, 34.97it/s, est. speed input: 44215.76 toks/s, output: 43.18 toks/s]
Processed prompts:  14%|        | 148/1024 [00:03<00:26, 32.88it/s, est. speed input: 42680.87 toks/s, output: 41.68 toks/s]
Processed prompts:  15%|        | 154/1024 [00:03<00:28, 30.22it/s, est. speed input: 41096.91 toks/s, output: 40.13 toks/s]
Processed prompts:  16%|        | 162/1024 [00:04<00:29, 29.53it/s, est. speed input: 40172.15 toks/s, output: 39.23 toks/s]
Processed prompts:  17%|        | 170/1024 [00:04<00:29, 29.07it/s, est. speed input: 39405.25 toks/s, output: 38.48 toks/s]
Processed prompts:  17%|        | 178/1024 [00:04<00:29, 28.77it/s, est. speed input: 38748.16 toks/s, output: 37.84 toks/s]
Processed prompts:  18%|        | 186/1024 [00:04<00:29, 28.42it/s, est. speed input: 38133.29 toks/s, output: 37.24 toks/s]
Processed prompts:  19%|        | 194/1024 [00:05<00:29, 28.27it/s, est. speed input: 37612.32 toks/s, output: 36.73 toks/s]
Processed prompts:  20%|        | 202/1024 [00:05<00:29, 28.19it/s, est. speed input: 37154.59 toks/s, output: 36.28 toks/s]
Processed prompts:  21%|        | 210/1024 [00:05<00:28, 28.17it/s, est. speed input: 36748.38 toks/s, output: 35.89 toks/s]
Processed prompts:  21%|       | 218/1024 [00:06<00:28, 27.92it/s, est. speed input: 36331.15 toks/s, output: 35.48 toks/s]
Processed prompts:  22%|       | 226/1024 [00:06<00:28, 27.99it/s, est. speed input: 35998.92 toks/s, output: 35.16 toks/s]
Processed prompts:  23%|       | 234/1024 [00:06<00:28, 27.98it/s, est. speed input: 35685.52 toks/s, output: 34.85 toks/s]
Processed prompts:  24%|       | 242/1024 [00:06<00:27, 28.02it/s, est. speed input: 35405.53 toks/s, output: 34.58 toks/s]
Processed prompts:  24%|       | 250/1024 [00:07<00:27, 27.83it/s, est. speed input: 35110.50 toks/s, output: 34.29 toks/s]
Processed prompts:  25%|       | 258/1024 [00:07<00:27, 27.88it/s, est. speed input: 34867.93 toks/s, output: 34.05 toks/s]
Processed prompts:  26%|       | 266/1024 [00:07<00:27, 27.88it/s, est. speed input: 34636.76 toks/s, output: 33.82 toks/s]
Processed prompts:  27%|       | 274/1024 [00:08<00:27, 27.72it/s, est. speed input: 34399.76 toks/s, output: 33.59 toks/s]
Processed prompts:  28%|       | 282/1024 [00:08<00:26, 27.85it/s, est. speed input: 34212.03 toks/s, output: 33.41 toks/s]
Processed prompts:  28%|       | 290/1024 [00:08<00:26, 27.84it/s, est. speed input: 34023.95 toks/s, output: 33.23 toks/s]
Processed prompts:  29%|       | 298/1024 [00:09<00:26, 27.89it/s, est. speed input: 33854.02 toks/s, output: 33.06 toks/s]
Processed prompts:  30%|       | 306/1024 [00:09<00:25, 27.76it/s, est. speed input: 33674.41 toks/s, output: 32.89 toks/s]
Processed prompts:  31%|       | 314/1024 [00:09<00:25, 27.86it/s, est. speed input: 33529.17 toks/s, output: 32.74 toks/s]
Processed prompts:  31%|      | 322/1024 [00:09<00:25, 27.88it/s, est. speed input: 33386.16 toks/s, output: 32.60 toks/s]
Processed prompts:  32%|      | 330/1024 [00:10<00:24, 27.84it/s, est. speed input: 33245.18 toks/s, output: 32.47 toks/s]
Processed prompts:  33%|      | 338/1024 [00:10<00:24, 27.89it/s, est. speed input: 33120.70 toks/s, output: 32.34 toks/s]
Processed prompts:  34%|      | 346/1024 [00:10<00:24, 27.88it/s, est. speed input: 32997.40 toks/s, output: 32.22 toks/s]
Processed prompts:  35%|      | 354/1024 [00:11<00:23, 27.94it/s, est. speed input: 32887.37 toks/s, output: 32.12 toks/s]
Processed prompts:  35%|      | 362/1024 [00:11<00:23, 27.82it/s, est. speed input: 32767.81 toks/s, output: 32.00 toks/s]
Processed prompts:  36%|      | 370/1024 [00:11<00:23, 27.78it/s, est. speed input: 32657.10 toks/s, output: 31.89 toks/s]
Processed prompts:  37%|      | 378/1024 [00:11<00:23, 27.78it/s, est. speed input: 32555.57 toks/s, output: 31.79 toks/s]
Processed prompts:  38%|      | 386/1024 [00:12<00:22, 27.86it/s, est. speed input: 32465.59 toks/s, output: 31.70 toks/s]
Processed prompts:  38%|      | 394/1024 [00:12<00:22, 27.78it/s, est. speed input: 32367.72 toks/s, output: 31.61 toks/s]
Processed prompts:  39%|      | 402/1024 [00:12<00:22, 27.85it/s, est. speed input: 32285.38 toks/s, output: 31.53 toks/s]
Processed prompts:  40%|      | 410/1024 [00:13<00:22, 27.86it/s, est. speed input: 32202.78 toks/s, output: 31.45 toks/s]
Processed prompts:  41%|      | 418/1024 [00:13<00:21, 27.93it/s, est. speed input: 32129.37 toks/s, output: 31.38 toks/s]
Processed prompts:  42%|     | 426/1024 [00:13<00:21, 27.80it/s, est. speed input: 32044.44 toks/s, output: 31.29 toks/s]
Processed prompts:  42%|     | 434/1024 [00:13<00:21, 27.82it/s, est. speed input: 31972.74 toks/s, output: 31.22 toks/s]
Processed prompts:  43%|     | 442/1024 [00:14<00:20, 27.90it/s, est. speed input: 31908.18 toks/s, output: 31.16 toks/s]
Processed prompts:  44%|     | 450/1024 [00:14<00:20, 28.39it/s, est. speed input: 31878.39 toks/s, output: 31.13 toks/s]
Processed prompts:  45%|     | 458/1024 [00:14<00:20, 28.14it/s, est. speed input: 31806.36 toks/s, output: 31.06 toks/s]
Processed prompts:  46%|     | 466/1024 [00:15<00:19, 28.03it/s, est. speed input: 31741.92 toks/s, output: 31.00 toks/s]
Processed prompts:  46%|     | 474/1024 [00:15<00:19, 28.00it/s, est. speed input: 31682.90 toks/s, output: 30.94 toks/s]
Processed prompts:  47%|     | 482/1024 [00:15<00:19, 27.84it/s, est. speed input: 31617.13 toks/s, output: 30.88 toks/s]
Processed prompts:  48%|     | 490/1024 [00:15<00:19, 27.88it/s, est. speed input: 31563.70 toks/s, output: 30.82 toks/s]
Processed prompts:  49%|     | 498/1024 [00:16<00:18, 27.85it/s, est. speed input: 31508.24 toks/s, output: 30.77 toks/s]
Processed prompts:  49%|     | 506/1024 [00:16<00:18, 27.99it/s, est. speed input: 31465.02 toks/s, output: 30.73 toks/s]
Processed prompts:  50%|     | 514/1024 [00:16<00:18, 27.77it/s, est. speed input: 31403.18 toks/s, output: 30.67 toks/s]
Processed prompts:  51%|     | 522/1024 [00:17<00:18, 27.87it/s, est. speed input: 31359.16 toks/s, output: 30.62 toks/s]
Processed prompts:  52%|    | 530/1024 [00:17<00:17, 27.86it/s, est. speed input: 31311.75 toks/s, output: 30.58 toks/s]
Processed prompts:  53%|    | 538/1024 [00:17<00:17, 27.90it/s, est. speed input: 31268.92 toks/s, output: 30.54 toks/s]
Processed prompts:  53%|    | 546/1024 [00:17<00:17, 27.79it/s, est. speed input: 31219.08 toks/s, output: 30.49 toks/s]
Processed prompts:  54%|    | 554/1024 [00:18<00:16, 27.85it/s, est. speed input: 31178.86 toks/s, output: 30.45 toks/s]
Processed prompts:  55%|    | 562/1024 [00:18<00:16, 27.89it/s, est. speed input: 31139.77 toks/s, output: 30.41 toks/s]
Processed prompts:  56%|    | 570/1024 [00:18<00:16, 27.88it/s, est. speed input: 31099.94 toks/s, output: 30.37 toks/s]
Processed prompts:  56%|    | 578/1024 [00:19<00:16, 27.82it/s, est. speed input: 31058.15 toks/s, output: 30.33 toks/s]
Processed prompts:  57%|    | 586/1024 [00:19<00:15, 27.88it/s, est. speed input: 31023.35 toks/s, output: 30.30 toks/s]
Processed prompts:  58%|    | 594/1024 [00:19<00:15, 27.89it/s, est. speed input: 30987.53 toks/s, output: 30.26 toks/s]
Processed prompts:  59%|    | 602/1024 [00:19<00:15, 27.80it/s, est. speed input: 30947.63 toks/s, output: 30.22 toks/s]
Processed prompts:  60%|    | 610/1024 [00:20<00:14, 27.85it/s, est. speed input: 30915.25 toks/s, output: 30.19 toks/s]
Processed prompts:  60%|    | 618/1024 [00:20<00:14, 27.93it/s, est. speed input: 30885.43 toks/s, output: 30.16 toks/s]
Processed prompts:  61%|    | 626/1024 [00:20<00:14, 27.90it/s, est. speed input: 30852.35 toks/s, output: 30.13 toks/s]
Processed prompts:  62%|   | 634/1024 [00:21<00:14, 27.80it/s, est. speed input: 30816.22 toks/s, output: 30.09 toks/s]
Processed prompts:  63%|   | 642/1024 [00:21<00:13, 27.83it/s, est. speed input: 30786.19 toks/s, output: 30.06 toks/s]
Processed prompts:  63%|   | 650/1024 [00:21<00:13, 27.84it/s, est. speed input: 30756.35 toks/s, output: 30.04 toks/s]
Processed prompts:  64%|   | 658/1024 [00:21<00:13, 27.86it/s, est. speed input: 30727.94 toks/s, output: 30.01 toks/s]
Processed prompts:  65%|   | 666/1024 [00:22<00:12, 27.71it/s, est. speed input: 30692.16 toks/s, output: 29.97 toks/s]
Processed prompts:  66%|   | 674/1024 [00:22<00:12, 27.77it/s, est. speed input: 30665.44 toks/s, output: 29.95 toks/s]
Processed prompts:  67%|   | 682/1024 [00:22<00:12, 27.84it/s, est. speed input: 30640.43 toks/s, output: 29.92 toks/s]
Processed prompts:  67%|   | 690/1024 [00:23<00:11, 27.90it/s, est. speed input: 30616.62 toks/s, output: 29.90 toks/s]
Processed prompts:  68%|   | 698/1024 [00:23<00:11, 27.83it/s, est. speed input: 30588.24 toks/s, output: 29.87 toks/s]
Processed prompts:  69%|   | 706/1024 [00:23<00:11, 27.88it/s, est. speed input: 30565.04 toks/s, output: 29.85 toks/s]
Processed prompts:  70%|   | 714/1024 [00:23<00:11, 27.86it/s, est. speed input: 30540.13 toks/s, output: 29.82 toks/s]
Processed prompts:  71%|   | 722/1024 [00:24<00:10, 27.76it/s, est. speed input: 30511.72 toks/s, output: 29.80 toks/s]
Processed prompts:  71%|  | 730/1024 [00:24<00:10, 27.83it/s, est. speed input: 30490.24 toks/s, output: 29.78 toks/s]
Processed prompts:  72%|  | 738/1024 [00:24<00:10, 27.87it/s, est. speed input: 30469.14 toks/s, output: 29.75 toks/s]
Processed prompts:  73%|  | 746/1024 [00:25<00:09, 27.87it/s, est. speed input: 30446.78 toks/s, output: 29.73 toks/s]
Processed prompts:  74%|  | 754/1024 [00:25<00:09, 27.73it/s, est. speed input: 30419.64 toks/s, output: 29.71 toks/s]
Processed prompts:  74%|  | 762/1024 [00:25<00:09, 27.81it/s, est. speed input: 30399.94 toks/s, output: 29.69 toks/s]
Processed prompts:  75%|  | 770/1024 [00:25<00:09, 27.86it/s, est. speed input: 30380.87 toks/s, output: 29.67 toks/s]
Processed prompts:  76%|  | 778/1024 [00:26<00:08, 27.88it/s, est. speed input: 30361.36 toks/s, output: 29.65 toks/s]
Processed prompts:  77%|  | 786/1024 [00:26<00:08, 27.81it/s, est. speed input: 30338.95 toks/s, output: 29.63 toks/s]
Processed prompts:  78%|  | 794/1024 [00:26<00:08, 27.83it/s, est. speed input: 30319.64 toks/s, output: 29.61 toks/s]
Processed prompts:  78%|  | 802/1024 [00:27<00:07, 27.88it/s, est. speed input: 30302.15 toks/s, output: 29.59 toks/s]
Processed prompts:  79%|  | 810/1024 [00:27<00:07, 27.84it/s, est. speed input: 30282.22 toks/s, output: 29.57 toks/s]
Processed prompts:  80%|  | 818/1024 [00:27<00:07, 27.84it/s, est. speed input: 30263.78 toks/s, output: 29.55 toks/s]
Processed prompts:  81%|  | 826/1024 [00:27<00:07, 27.81it/s, est. speed input: 30244.73 toks/s, output: 29.54 toks/s]
Processed prompts:  81%| | 834/1024 [00:28<00:06, 27.80it/s, est. speed input: 30226.58 toks/s, output: 29.52 toks/s]
Processed prompts:  82%| | 842/1024 [00:28<00:06, 27.65it/s, est. speed input: 30202.99 toks/s, output: 29.50 toks/s]
Processed prompts:  83%| | 850/1024 [00:28<00:06, 27.75it/s, est. speed input: 30187.91 toks/s, output: 29.48 toks/s]
Processed prompts:  84%| | 858/1024 [00:29<00:05, 27.80it/s, est. speed input: 30172.15 toks/s, output: 29.46 toks/s]
Processed prompts:  85%| | 866/1024 [00:29<00:05, 27.83it/s, est. speed input: 30156.41 toks/s, output: 29.45 toks/s]
Processed prompts:  85%| | 874/1024 [00:29<00:05, 27.71it/s, est. speed input: 30136.18 toks/s, output: 29.43 toks/s]
Processed prompts:  86%| | 882/1024 [00:29<00:05, 27.76it/s, est. speed input: 30120.92 toks/s, output: 29.41 toks/s]
Processed prompts:  87%| | 890/1024 [00:30<00:04, 27.78it/s, est. speed input: 30105.64 toks/s, output: 29.40 toks/s]
Processed prompts:  88%| | 898/1024 [00:30<00:04, 27.86it/s, est. speed input: 30092.74 toks/s, output: 29.39 toks/s]
Processed prompts:  88%| | 906/1024 [00:30<00:04, 27.71it/s, est. speed input: 30073.14 toks/s, output: 29.37 toks/s]
Processed prompts:  89%| | 914/1024 [00:31<00:03, 27.78it/s, est. speed input: 30059.82 toks/s, output: 29.36 toks/s]
Processed prompts:  90%| | 922/1024 [00:31<00:03, 27.83it/s, est. speed input: 30046.43 toks/s, output: 29.34 toks/s]
Processed prompts:  91%| | 930/1024 [00:31<00:03, 27.73it/s, est. speed input: 30029.08 toks/s, output: 29.33 toks/s]
Processed prompts:  92%|| 938/1024 [00:31<00:02, 28.87it/s, est. speed input: 30050.27 toks/s, output: 29.35 toks/s]
Processed prompts:  92%|| 946/1024 [00:32<00:02, 28.62it/s, est. speed input: 30038.37 toks/s, output: 29.33 toks/s]
Processed prompts:  93%|| 954/1024 [00:32<00:02, 28.35it/s, est. speed input: 30023.83 toks/s, output: 29.32 toks/s]
Processed prompts:  94%|| 962/1024 [00:32<00:02, 28.09it/s, est. speed input: 30007.42 toks/s, output: 29.30 toks/s]
Processed prompts:  95%|| 970/1024 [00:33<00:01, 27.96it/s, est. speed input: 29992.85 toks/s, output: 29.29 toks/s]
Processed prompts:  96%|| 978/1024 [00:33<00:01, 27.99it/s, est. speed input: 29981.92 toks/s, output: 29.28 toks/s]
Processed prompts:  96%|| 986/1024 [00:33<00:01, 28.96it/s, est. speed input: 29999.26 toks/s, output: 29.30 toks/s]
Processed prompts:  97%|| 994/1024 [00:33<00:01, 28.51it/s, est. speed input: 29983.59 toks/s, output: 29.28 toks/s]
Processed prompts:  98%|| 1002/1024 [00:34<00:00, 28.30it/s, est. speed input: 29971.06 toks/s, output: 29.27 toks/s]
Processed prompts:  99%|| 1010/1024 [00:34<00:00, 28.17it/s, est. speed input: 29959.15 toks/s, output: 29.26 toks/s]
Processed prompts:  99%|| 1018/1024 [00:34<00:00, 28.75it/s, est. speed input: 29966.54 toks/s, output: 29.26 toks/s]
Processed prompts: 100%|| 1024/1024 [00:34<00:00, 28.75it/s, est. speed input: 30143.05 toks/s, output: 29.44 toks/s]
Processed prompts: 100%|| 1024/1024 [00:34<00:00, 29.44it/s, est. speed input: 30143.05 toks/s, output: 29.44 toks/s]
[rank0]:[W126 08:31:22.215854986 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 08:31:24
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:31:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:31:33 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1078419) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1078419) WARNING 01-26 08:31:56 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.24 requests/s, 28947.66 total tokens/s, 28.24 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 08:31:33] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:31:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:31:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:31:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:31:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:31:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:31:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:31:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:31:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:31:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:31:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:31:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:31:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:31:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:31:37] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:31:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:31:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:31:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:31:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:31:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:31:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:31:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:31:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:31:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:31:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:31:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:31:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:31:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:37] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1078419) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1078419) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.84s/it]
(EngineCore_DP0 pid=1078419) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.84s/it]
(EngineCore_DP0 pid=1078419) 
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1078419) [2026-01-26 08:31:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1078419) 2026-01-26 08:31:54,929 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1078419) 2026-01-26 08:31:55,007 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 57/2048 [00:00<00:03, 565.86it/s]
Adding requests:   6%|         | 114/2048 [00:00<00:03, 519.76it/s]
Adding requests:   8%|         | 167/2048 [00:00<00:03, 499.69it/s]
Adding requests:  11%|         | 218/2048 [00:00<00:03, 490.83it/s]
Adding requests:  13%|        | 268/2048 [00:00<00:03, 489.38it/s]
Adding requests:  15%|        | 317/2048 [00:00<00:03, 474.37it/s]
Adding requests:  18%|        | 365/2048 [00:00<00:03, 471.71it/s]
Adding requests:  20%|        | 413/2048 [00:00<00:03, 462.14it/s]
Adding requests:  22%|       | 460/2048 [00:00<00:03, 462.93it/s]
Adding requests:  25%|       | 507/2048 [00:01<00:03, 463.11it/s]
Adding requests:  27%|       | 554/2048 [00:01<00:03, 458.95it/s]
Adding requests:  29%|       | 600/2048 [00:01<00:03, 455.74it/s]
Adding requests:  32%|      | 648/2048 [00:01<00:03, 461.87it/s]
Adding requests:  34%|      | 697/2048 [00:01<00:02, 468.57it/s]
Adding requests:  36%|      | 745/2048 [00:01<00:02, 469.16it/s]
Adding requests:  39%|      | 792/2048 [00:01<00:02, 443.95it/s]
Adding requests:  41%|      | 837/2048 [00:01<00:02, 435.18it/s]
Adding requests:  43%|     | 881/2048 [00:02<00:07, 161.22it/s]
Adding requests:  45%|     | 929/2048 [00:02<00:05, 202.85it/s]
Adding requests:  48%|     | 975/2048 [00:02<00:04, 243.26it/s]
Adding requests:  50%|     | 1023/2048 [00:02<00:03, 286.53it/s]
Adding requests:  52%|    | 1069/2048 [00:02<00:03, 321.06it/s]
Adding requests:  54%|    | 1115/2048 [00:03<00:02, 352.52it/s]
Adding requests:  57%|    | 1160/2048 [00:03<00:02, 376.26it/s]
Adding requests:  59%|    | 1208/2048 [00:03<00:02, 403.07it/s]
Adding requests:  61%|    | 1254/2048 [00:03<00:01, 415.20it/s]
Adding requests:  63%|   | 1300/2048 [00:03<00:01, 418.37it/s]
Adding requests:  66%|   | 1347/2048 [00:03<00:01, 431.86it/s]
Adding requests:  68%|   | 1396/2048 [00:03<00:01, 446.28it/s]
Adding requests:  70%|   | 1443/2048 [00:03<00:01, 450.06it/s]
Adding requests:  73%|  | 1493/2048 [00:03<00:01, 461.33it/s]
Adding requests:  75%|  | 1540/2048 [00:03<00:01, 459.69it/s]
Adding requests:  77%|  | 1587/2048 [00:04<00:00, 462.23it/s]
Adding requests:  80%|  | 1634/2048 [00:04<00:00, 459.52it/s]
Adding requests:  82%| | 1681/2048 [00:04<00:00, 455.95it/s]
Adding requests:  84%| | 1727/2048 [00:04<00:00, 452.99it/s]
Adding requests:  87%| | 1774/2048 [00:04<00:00, 457.04it/s]
Adding requests:  89%| | 1821/2048 [00:04<00:00, 459.41it/s]
Adding requests:  91%| | 1868/2048 [00:04<00:00, 460.42it/s]
Adding requests:  94%|| 1915/2048 [00:04<00:00, 461.22it/s]
Adding requests:  96%|| 1962/2048 [00:04<00:00, 462.02it/s]
Adding requests:  98%|| 2009/2048 [00:04<00:00, 450.40it/s]
Adding requests: 100%|| 2048/2048 [00:05<00:00, 406.15it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 130/2048 [00:00<00:03, 624.71it/s, est. speed input: 639872.55 toks/s, output: 624.76 toks/s]
Processed prompts:   9%|         | 193/2048 [00:01<00:22, 83.47it/s, est. speed input: 103611.37 toks/s, output: 101.18 toks/s] 
Processed prompts:  11%|         | 221/2048 [00:03<00:32, 56.06it/s, est. speed input: 74482.25 toks/s, output: 72.74 toks/s]  
Processed prompts:  12%|        | 238/2048 [00:03<00:36, 49.70it/s, est. speed input: 67743.73 toks/s, output: 66.16 toks/s]
Processed prompts:  12%|        | 250/2048 [00:04<00:42, 42.14it/s, est. speed input: 61460.83 toks/s, output: 60.02 toks/s]
Processed prompts:  13%|        | 258/2048 [00:04<00:51, 34.58it/s, est. speed input: 55915.01 toks/s, output: 54.60 toks/s]
Processed prompts:  13%|        | 274/2048 [00:05<00:54, 32.75it/s, est. speed input: 52995.45 toks/s, output: 51.75 toks/s]
Processed prompts:  14%|        | 290/2048 [00:05<00:55, 31.55it/s, est. speed input: 50720.73 toks/s, output: 49.53 toks/s]
Processed prompts:  15%|        | 306/2048 [00:06<00:57, 30.55it/s, est. speed input: 48775.86 toks/s, output: 47.63 toks/s]
Processed prompts:  16%|        | 322/2048 [00:06<00:57, 29.96it/s, est. speed input: 47208.62 toks/s, output: 46.10 toks/s]
Processed prompts:  17%|        | 338/2048 [00:07<01:00, 28.09it/s, est. speed input: 45280.51 toks/s, output: 44.22 toks/s]
Processed prompts:  17%|        | 354/2048 [00:08<01:08, 24.68it/s, est. speed input: 42716.99 toks/s, output: 41.72 toks/s]
Processed prompts:  18%|        | 370/2048 [00:09<01:05, 25.61it/s, est. speed input: 41848.23 toks/s, output: 40.87 toks/s]
Processed prompts:  19%|        | 386/2048 [00:09<01:03, 26.34it/s, est. speed input: 41087.82 toks/s, output: 40.12 toks/s]
Processed prompts:  20%|        | 402/2048 [00:10<01:01, 26.95it/s, est. speed input: 40433.18 toks/s, output: 39.49 toks/s]
Processed prompts:  20%|        | 418/2048 [00:10<00:59, 27.29it/s, est. speed input: 39817.92 toks/s, output: 38.88 toks/s]
Processed prompts:  21%|        | 434/2048 [00:11<00:58, 27.61it/s, est. speed input: 39282.05 toks/s, output: 38.36 toks/s]
Processed prompts:  22%|       | 450/2048 [00:11<00:56, 28.08it/s, est. speed input: 38851.86 toks/s, output: 37.94 toks/s]
Processed prompts:  23%|       | 466/2048 [00:12<00:56, 28.09it/s, est. speed input: 38391.91 toks/s, output: 37.49 toks/s]
Processed prompts:  24%|       | 482/2048 [00:12<00:55, 28.18it/s, est. speed input: 37988.27 toks/s, output: 37.10 toks/s]
Processed prompts:  24%|       | 498/2048 [00:13<00:54, 28.19it/s, est. speed input: 37607.20 toks/s, output: 36.73 toks/s]
Processed prompts:  25%|       | 514/2048 [00:14<00:54, 28.28it/s, est. speed input: 37272.20 toks/s, output: 36.40 toks/s]
Processed prompts:  26%|       | 530/2048 [00:14<00:53, 28.27it/s, est. speed input: 36950.60 toks/s, output: 36.08 toks/s]
Processed prompts:  27%|       | 546/2048 [00:15<00:53, 28.33it/s, est. speed input: 36662.46 toks/s, output: 35.80 toks/s]
Processed prompts:  27%|       | 562/2048 [00:15<00:52, 28.27it/s, est. speed input: 36380.64 toks/s, output: 35.53 toks/s]
Processed prompts:  28%|       | 578/2048 [00:16<00:51, 28.36it/s, est. speed input: 36136.13 toks/s, output: 35.29 toks/s]
Processed prompts:  29%|       | 594/2048 [00:16<00:51, 28.31it/s, est. speed input: 35893.63 toks/s, output: 35.05 toks/s]
Processed prompts:  30%|       | 610/2048 [00:17<00:50, 28.37it/s, est. speed input: 35678.88 toks/s, output: 34.84 toks/s]
Processed prompts:  31%|       | 626/2048 [00:18<00:50, 28.30it/s, est. speed input: 35462.40 toks/s, output: 34.63 toks/s]
Processed prompts:  31%|      | 642/2048 [00:18<00:49, 28.39it/s, est. speed input: 35277.28 toks/s, output: 34.45 toks/s]
Processed prompts:  32%|      | 658/2048 [00:19<00:49, 28.31it/s, est. speed input: 35085.98 toks/s, output: 34.26 toks/s]
Processed prompts:  33%|      | 674/2048 [00:19<00:48, 28.41it/s, est. speed input: 34922.93 toks/s, output: 34.10 toks/s]
Processed prompts:  34%|      | 690/2048 [00:20<00:47, 28.32it/s, est. speed input: 34751.70 toks/s, output: 33.94 toks/s]
Processed prompts:  34%|      | 706/2048 [00:20<00:47, 28.23it/s, est. speed input: 34586.23 toks/s, output: 33.78 toks/s]
Processed prompts:  35%|      | 722/2048 [00:21<00:46, 28.28it/s, est. speed input: 34441.20 toks/s, output: 33.63 toks/s]
Processed prompts:  36%|      | 738/2048 [00:22<00:46, 28.24it/s, est. speed input: 34296.61 toks/s, output: 33.49 toks/s]
Processed prompts:  37%|      | 754/2048 [00:22<00:45, 28.26it/s, est. speed input: 34163.81 toks/s, output: 33.36 toks/s]
Processed prompts:  38%|      | 770/2048 [00:23<00:45, 28.23it/s, est. speed input: 34033.11 toks/s, output: 33.24 toks/s]
Processed prompts:  38%|      | 786/2048 [00:23<00:44, 28.29it/s, est. speed input: 33916.42 toks/s, output: 33.12 toks/s]
Processed prompts:  39%|      | 802/2048 [00:24<00:44, 28.24it/s, est. speed input: 33796.87 toks/s, output: 33.00 toks/s]
Processed prompts:  40%|      | 818/2048 [00:24<00:43, 28.33it/s, est. speed input: 33693.28 toks/s, output: 32.90 toks/s]
Processed prompts:  41%|      | 834/2048 [00:25<00:42, 28.28it/s, est. speed input: 33585.49 toks/s, output: 32.80 toks/s]
Processed prompts:  42%|     | 850/2048 [00:25<00:42, 28.27it/s, est. speed input: 33483.65 toks/s, output: 32.70 toks/s]
Processed prompts:  42%|     | 866/2048 [00:26<00:41, 28.24it/s, est. speed input: 33384.13 toks/s, output: 32.60 toks/s]
Processed prompts:  43%|     | 882/2048 [00:27<00:41, 28.30it/s, est. speed input: 33295.99 toks/s, output: 32.52 toks/s]
Processed prompts:  44%|     | 898/2048 [00:27<00:40, 28.28it/s, est. speed input: 33206.03 toks/s, output: 32.43 toks/s]
Processed prompts:  45%|     | 914/2048 [00:28<00:39, 28.36it/s, est. speed input: 33127.39 toks/s, output: 32.35 toks/s]
Processed prompts:  45%|     | 930/2048 [00:28<00:38, 28.85it/s, est. speed input: 33083.78 toks/s, output: 32.31 toks/s]
Processed prompts:  46%|     | 946/2048 [00:29<00:38, 28.73it/s, est. speed input: 33008.57 toks/s, output: 32.23 toks/s]
Processed prompts:  47%|     | 962/2048 [00:29<00:38, 28.54it/s, est. speed input: 32927.72 toks/s, output: 32.16 toks/s]
Processed prompts:  48%|     | 978/2048 [00:30<00:36, 29.06it/s, est. speed input: 32895.98 toks/s, output: 32.12 toks/s]
Processed prompts:  49%|     | 994/2048 [00:31<00:36, 28.79it/s, est. speed input: 32822.02 toks/s, output: 32.05 toks/s]
Processed prompts:  49%|     | 1010/2048 [00:31<00:36, 28.60it/s, est. speed input: 32750.53 toks/s, output: 31.98 toks/s]
Processed prompts:  50%|     | 1026/2048 [00:32<00:35, 28.54it/s, est. speed input: 32685.79 toks/s, output: 31.92 toks/s]
Processed prompts:  51%|     | 1042/2048 [00:32<00:35, 28.42it/s, est. speed input: 32618.90 toks/s, output: 31.85 toks/s]
Processed prompts:  52%|    | 1058/2048 [00:33<00:34, 28.45it/s, est. speed input: 32561.38 toks/s, output: 31.80 toks/s]
Processed prompts:  52%|    | 1074/2048 [00:33<00:34, 28.36it/s, est. speed input: 32498.73 toks/s, output: 31.74 toks/s]
Processed prompts:  53%|    | 1090/2048 [00:34<00:33, 28.41it/s, est. speed input: 32445.11 toks/s, output: 31.68 toks/s]
Processed prompts:  54%|    | 1106/2048 [00:34<00:33, 28.33it/s, est. speed input: 32386.16 toks/s, output: 31.63 toks/s]
Processed prompts:  55%|    | 1122/2048 [00:35<00:32, 28.35it/s, est. speed input: 32333.81 toks/s, output: 31.58 toks/s]
Processed prompts:  56%|    | 1138/2048 [00:36<00:32, 28.28it/s, est. speed input: 32277.89 toks/s, output: 31.52 toks/s]
Processed prompts:  56%|    | 1154/2048 [00:36<00:31, 28.84it/s, est. speed input: 32258.78 toks/s, output: 31.50 toks/s]
Processed prompts:  57%|    | 1170/2048 [00:37<00:30, 28.61it/s, est. speed input: 32205.13 toks/s, output: 31.45 toks/s]
Processed prompts:  58%|    | 1186/2048 [00:37<00:30, 28.52it/s, est. speed input: 32157.34 toks/s, output: 31.40 toks/s]
Processed prompts:  59%|    | 1202/2048 [00:38<00:29, 28.43it/s, est. speed input: 32109.14 toks/s, output: 31.36 toks/s]
Processed prompts:  59%|    | 1218/2048 [00:38<00:29, 28.47it/s, est. speed input: 32068.01 toks/s, output: 31.32 toks/s]
Processed prompts:  60%|    | 1234/2048 [00:39<00:28, 28.37it/s, est. speed input: 32021.05 toks/s, output: 31.27 toks/s]
Processed prompts:  61%|    | 1250/2048 [00:40<00:28, 28.40it/s, est. speed input: 31980.79 toks/s, output: 31.23 toks/s]
Processed prompts:  62%|   | 1266/2048 [00:40<00:27, 28.86it/s, est. speed input: 31964.05 toks/s, output: 31.21 toks/s]
Processed prompts:  63%|   | 1282/2048 [00:41<00:26, 28.68it/s, est. speed input: 31922.56 toks/s, output: 31.17 toks/s]
Processed prompts:  63%|   | 1298/2048 [00:41<00:25, 29.07it/s, est. speed input: 31907.30 toks/s, output: 31.16 toks/s]
Processed prompts:  64%|   | 1314/2048 [00:42<00:25, 28.85it/s, est. speed input: 31868.97 toks/s, output: 31.12 toks/s]
Processed prompts:  65%|   | 1330/2048 [00:42<00:25, 28.62it/s, est. speed input: 31827.89 toks/s, output: 31.08 toks/s]
Processed prompts:  66%|   | 1346/2048 [00:43<00:24, 28.45it/s, est. speed input: 31787.28 toks/s, output: 31.04 toks/s]
Processed prompts:  67%|   | 1362/2048 [00:43<00:24, 28.43it/s, est. speed input: 31752.21 toks/s, output: 31.01 toks/s]
Processed prompts:  67%|   | 1378/2048 [00:44<00:23, 28.39it/s, est. speed input: 31716.93 toks/s, output: 30.97 toks/s]
Processed prompts:  68%|   | 1394/2048 [00:45<00:22, 28.45it/s, est. speed input: 31686.63 toks/s, output: 30.94 toks/s]
Processed prompts:  69%|   | 1410/2048 [00:45<00:22, 28.36it/s, est. speed input: 31650.78 toks/s, output: 30.91 toks/s]
Processed prompts:  70%|   | 1426/2048 [00:46<00:21, 28.37it/s, est. speed input: 31619.40 toks/s, output: 30.88 toks/s]
Processed prompts:  70%|   | 1442/2048 [00:46<00:21, 28.26it/s, est. speed input: 31583.71 toks/s, output: 30.84 toks/s]
Processed prompts:  71%|   | 1458/2048 [00:47<00:20, 28.34it/s, est. speed input: 31555.33 toks/s, output: 30.82 toks/s]
Processed prompts:  72%|  | 1474/2048 [00:47<00:20, 28.28it/s, est. speed input: 31522.94 toks/s, output: 30.78 toks/s]
Processed prompts:  73%|  | 1490/2048 [00:48<00:19, 28.37it/s, est. speed input: 31496.81 toks/s, output: 30.76 toks/s]
Processed prompts:  74%|  | 1506/2048 [00:49<00:19, 28.33it/s, est. speed input: 31466.99 toks/s, output: 30.73 toks/s]
Processed prompts:  74%|  | 1522/2048 [00:49<00:18, 28.31it/s, est. speed input: 31438.08 toks/s, output: 30.70 toks/s]
Processed prompts:  75%|  | 1538/2048 [00:50<00:18, 28.25it/s, est. speed input: 31407.88 toks/s, output: 30.67 toks/s]
Processed prompts:  76%|  | 1554/2048 [00:50<00:17, 28.33it/s, est. speed input: 31383.45 toks/s, output: 30.65 toks/s]
Processed prompts:  77%|  | 1570/2048 [00:51<00:16, 28.26it/s, est. speed input: 31354.61 toks/s, output: 30.62 toks/s]
Processed prompts:  77%|  | 1586/2048 [00:51<00:16, 28.82it/s, est. speed input: 31350.35 toks/s, output: 30.62 toks/s]
Processed prompts:  78%|  | 1602/2048 [00:52<00:15, 28.58it/s, est. speed input: 31321.70 toks/s, output: 30.59 toks/s]
Processed prompts:  79%|  | 1618/2048 [00:52<00:15, 28.47it/s, est. speed input: 31295.56 toks/s, output: 30.56 toks/s]
Processed prompts:  80%|  | 1634/2048 [00:53<00:14, 28.37it/s, est. speed input: 31269.14 toks/s, output: 30.54 toks/s]
Processed prompts:  81%|  | 1650/2048 [00:54<00:13, 28.82it/s, est. speed input: 31263.04 toks/s, output: 30.53 toks/s]
Processed prompts:  81%| | 1666/2048 [00:54<00:13, 28.63it/s, est. speed input: 31238.21 toks/s, output: 30.51 toks/s]
Processed prompts:  82%| | 1682/2048 [00:55<00:12, 28.49it/s, est. speed input: 31213.72 toks/s, output: 30.48 toks/s]
Processed prompts:  83%| | 1698/2048 [00:55<00:12, 28.42it/s, est. speed input: 31190.48 toks/s, output: 30.46 toks/s]
Processed prompts:  84%| | 1714/2048 [00:56<00:11, 28.35it/s, est. speed input: 31167.06 toks/s, output: 30.44 toks/s]
Processed prompts:  84%| | 1730/2048 [00:56<00:11, 28.38it/s, est. speed input: 31147.03 toks/s, output: 30.42 toks/s]
Processed prompts:  85%| | 1746/2048 [00:57<00:10, 28.26it/s, est. speed input: 31122.14 toks/s, output: 30.39 toks/s]
Processed prompts:  86%| | 1762/2048 [00:58<00:10, 28.27it/s, est. speed input: 31101.37 toks/s, output: 30.37 toks/s]
Processed prompts:  87%| | 1778/2048 [00:58<00:09, 28.23it/s, est. speed input: 31079.15 toks/s, output: 30.35 toks/s]
Processed prompts:  88%| | 1794/2048 [00:59<00:08, 28.26it/s, est. speed input: 31059.38 toks/s, output: 30.33 toks/s]
Processed prompts:  88%| | 1810/2048 [00:59<00:08, 28.22it/s, est. speed input: 31037.78 toks/s, output: 30.31 toks/s]
Processed prompts:  89%| | 1826/2048 [01:00<00:07, 28.26it/s, est. speed input: 31018.94 toks/s, output: 30.29 toks/s]
Processed prompts:  90%| | 1842/2048 [01:00<00:07, 28.22it/s, est. speed input: 30998.49 toks/s, output: 30.27 toks/s]
Processed prompts:  91%| | 1858/2048 [01:01<00:06, 28.22it/s, est. speed input: 30979.02 toks/s, output: 30.25 toks/s]
Processed prompts:  92%|| 1874/2048 [01:01<00:06, 28.73it/s, est. speed input: 30976.57 toks/s, output: 30.25 toks/s]
Processed prompts:  92%|| 1890/2048 [01:02<00:05, 28.60it/s, est. speed input: 30958.51 toks/s, output: 30.23 toks/s]
Processed prompts:  93%|| 1906/2048 [01:03<00:04, 28.45it/s, est. speed input: 30938.96 toks/s, output: 30.21 toks/s]
Processed prompts:  94%|| 1922/2048 [01:03<00:04, 28.31it/s, est. speed input: 30918.33 toks/s, output: 30.19 toks/s]
Processed prompts:  95%|| 1938/2048 [01:04<00:03, 28.31it/s, est. speed input: 30901.51 toks/s, output: 30.18 toks/s]
Processed prompts:  95%|| 1954/2048 [01:04<00:03, 28.81it/s, est. speed input: 30900.32 toks/s, output: 30.18 toks/s]
Processed prompts:  96%|| 1970/2048 [01:05<00:02, 28.73it/s, est. speed input: 30886.14 toks/s, output: 30.16 toks/s]
Processed prompts:  97%|| 1986/2048 [01:05<00:02, 29.10it/s, est. speed input: 30884.57 toks/s, output: 30.16 toks/s]
Processed prompts:  98%|| 2002/2048 [01:06<00:01, 29.69it/s, est. speed input: 30892.67 toks/s, output: 30.17 toks/s]
Processed prompts:  99%|| 2018/2048 [01:06<00:01, 29.18it/s, est. speed input: 30874.34 toks/s, output: 30.15 toks/s]
Processed prompts:  99%|| 2034/2048 [01:07<00:00, 29.27it/s, est. speed input: 30868.86 toks/s, output: 30.15 toks/s]
Processed prompts: 100%|| 2048/2048 [01:07<00:00, 29.27it/s, est. speed input: 31081.24 toks/s, output: 30.35 toks/s]
Processed prompts: 100%|| 2048/2048 [01:07<00:00, 30.35it/s, est. speed input: 31081.24 toks/s, output: 30.35 toks/s]
[rank0]:[W126 08:33:08.173742895 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 08:33:11
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:33:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:33:26 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1080155) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1080155) WARNING 01-26 08:33:49 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.72 requests/s, 29442.88 total tokens/s, 28.72 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 08:33:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:33:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:33:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:33:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:33:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:33:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:33:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:33:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:33:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:33:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:33:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:33:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:33:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:33:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:33:29] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:33:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:33:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:33:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:33:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:33:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:33:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:33:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:33:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:33:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:33:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:33:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:33:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:33:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:30] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:30] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:30] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:30] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:30] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:30] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1080155) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1080155) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.48s/it]
(EngineCore_DP0 pid=1080155) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.48s/it]
(EngineCore_DP0 pid=1080155) 
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:41] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1080155) [2026-01-26 08:33:41] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1080155) 2026-01-26 08:33:48,096 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1080155) 2026-01-26 08:33:48,327 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 61/4096 [00:00<00:06, 608.60it/s]
Adding requests:   3%|         | 122/4096 [00:00<00:06, 576.74it/s]
Adding requests:   4%|         | 180/4096 [00:00<00:07, 531.84it/s]
Adding requests:   6%|         | 234/4096 [00:00<00:07, 513.23it/s]
Adding requests:   7%|         | 286/4096 [00:00<00:07, 506.41it/s]
Adding requests:   8%|         | 337/4096 [00:00<00:07, 491.61it/s]
Adding requests:   9%|         | 388/4096 [00:00<00:07, 496.85it/s]
Adding requests:  11%|         | 438/4096 [00:00<00:07, 486.88it/s]
Adding requests:  12%|        | 487/4096 [00:00<00:07, 480.39it/s]
Adding requests:  13%|        | 536/4096 [00:01<00:07, 465.12it/s]
Adding requests:  14%|        | 583/4096 [00:01<00:07, 459.16it/s]
Adding requests:  15%|        | 632/4096 [00:01<00:07, 467.00it/s]
Adding requests:  17%|        | 679/4096 [00:01<00:07, 466.75it/s]
Adding requests:  18%|        | 726/4096 [00:01<00:07, 467.23it/s]
Adding requests:  19%|        | 774/4096 [00:01<00:07, 468.69it/s]
Adding requests:  20%|        | 821/4096 [00:01<00:07, 445.83it/s]
Adding requests:  21%|        | 868/4096 [00:01<00:07, 452.20it/s]
Adding requests:  22%|       | 914/4096 [00:01<00:07, 448.54it/s]
Adding requests:  23%|       | 960/4096 [00:02<00:06, 450.33it/s]
Adding requests:  25%|       | 1006/4096 [00:02<00:06, 449.53it/s]
Adding requests:  26%|       | 1055/4096 [00:02<00:06, 457.66it/s]
Adding requests:  27%|       | 1101/4096 [00:02<00:06, 451.10it/s]
Adding requests:  28%|       | 1148/4096 [00:02<00:06, 455.37it/s]
Adding requests:  29%|       | 1194/4096 [00:02<00:06, 429.69it/s]
Adding requests:  30%|       | 1238/4096 [00:02<00:06, 431.56it/s]
Adding requests:  31%|      | 1282/4096 [00:02<00:06, 429.02it/s]
Adding requests:  32%|      | 1329/4096 [00:02<00:06, 440.81it/s]
Adding requests:  34%|      | 1375/4096 [00:02<00:06, 444.07it/s]
Adding requests:  35%|      | 1423/4096 [00:03<00:05, 453.13it/s]
Adding requests:  36%|      | 1470/4096 [00:03<00:05, 451.30it/s]
Adding requests:  37%|      | 1518/4096 [00:03<00:05, 458.96it/s]
Adding requests:  38%|      | 1569/4096 [00:03<00:05, 470.42it/s]
Adding requests:  40%|      | 1618/4096 [00:03<00:05, 473.01it/s]
Adding requests:  41%|      | 1666/4096 [00:03<00:05, 470.10it/s]
Adding requests:  42%|     | 1714/4096 [00:03<00:05, 461.11it/s]
Adding requests:  43%|     | 1761/4096 [00:03<00:05, 460.43it/s]
Adding requests:  44%|     | 1809/4096 [00:03<00:04, 464.84it/s]
Adding requests:  45%|     | 1859/4096 [00:03<00:04, 472.39it/s]
Adding requests:  47%|     | 1907/4096 [00:04<00:04, 463.08it/s]
Adding requests:  48%|     | 1955/4096 [00:04<00:04, 465.65it/s]
Adding requests:  49%|     | 2002/4096 [00:04<00:04, 459.10it/s]
Adding requests:  50%|     | 2050/4096 [00:04<00:04, 464.45it/s]
Adding requests:  51%|     | 2097/4096 [00:04<00:04, 459.66it/s]
Adding requests:  52%|    | 2143/4096 [00:04<00:04, 448.83it/s]
Adding requests:  53%|    | 2188/4096 [00:04<00:04, 439.74it/s]
Adding requests:  55%|    | 2234/4096 [00:04<00:04, 444.67it/s]
Adding requests:  56%|    | 2282/4096 [00:04<00:04, 452.37it/s]
Adding requests:  57%|    | 2328/4096 [00:05<00:03, 449.26it/s]
Adding requests:  58%|    | 2377/4096 [00:05<00:03, 459.38it/s]
Adding requests:  59%|    | 2423/4096 [00:05<00:03, 420.58it/s]
Adding requests:  60%|    | 2469/4096 [00:05<00:03, 428.36it/s]
Adding requests:  61%|   | 2519/4096 [00:05<00:03, 446.04it/s]
Adding requests:  63%|   | 2565/4096 [00:05<00:03, 440.57it/s]
Adding requests:  64%|   | 2612/4096 [00:05<00:03, 447.67it/s]
Adding requests:  65%|   | 2658/4096 [00:05<00:03, 450.86it/s]
Adding requests:  66%|   | 2704/4096 [00:05<00:03, 443.16it/s]
Adding requests:  67%|   | 2751/4096 [00:05<00:02, 448.38it/s]
Adding requests:  68%|   | 2796/4096 [00:06<00:02, 448.28it/s]
Adding requests:  69%|   | 2846/4096 [00:06<00:02, 461.73it/s]
Adding requests:  71%|   | 2893/4096 [00:06<00:02, 453.34it/s]
Adding requests:  72%|  | 2940/4096 [00:06<00:02, 457.47it/s]
Adding requests:  73%|  | 2986/4096 [00:06<00:02, 456.68it/s]
Adding requests:  74%|  | 3035/4096 [00:06<00:02, 465.19it/s]
Adding requests:  75%|  | 3082/4096 [00:06<00:02, 465.93it/s]
Adding requests:  76%|  | 3130/4096 [00:06<00:02, 469.81it/s]
Adding requests:  78%|  | 3179/4096 [00:06<00:01, 475.06it/s]
Adding requests:  79%|  | 3227/4096 [00:07<00:01, 466.95it/s]
Adding requests:  80%|  | 3278/4096 [00:07<00:01, 479.44it/s]
Adding requests:  81%|  | 3326/4096 [00:07<00:01, 477.07it/s]
Adding requests:  82%| | 3375/4096 [00:07<00:01, 480.00it/s]
Adding requests:  84%| | 3424/4096 [00:07<00:01, 479.22it/s]
Adding requests:  85%| | 3472/4096 [00:07<00:01, 472.67it/s]
Adding requests:  86%| | 3522/4096 [00:07<00:01, 477.23it/s]
Adding requests:  87%| | 3570/4096 [00:07<00:01, 475.82it/s]
Adding requests:  88%| | 3618/4096 [00:07<00:01, 475.28it/s]
Adding requests:  90%| | 3666/4096 [00:07<00:00, 473.44it/s]
Adding requests:  91%| | 3715/4096 [00:08<00:00, 477.36it/s]
Adding requests:  92%|| 3763/4096 [00:08<00:00, 473.58it/s]
Adding requests:  93%|| 3811/4096 [00:08<00:00, 452.17it/s]
Adding requests:  94%|| 3862/4096 [00:08<00:00, 467.07it/s]
Adding requests:  95%|| 3910/4096 [00:08<00:00, 470.42it/s]
Adding requests:  97%|| 3960/4096 [00:08<00:00, 477.03it/s]
Adding requests:  98%|| 4008/4096 [00:08<00:00, 467.70it/s]
Adding requests:  99%|| 4055/4096 [00:08<00:00, 466.45it/s]
Adding requests: 100%|| 4096/4096 [00:08<00:00, 463.48it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|         | 226/4096 [00:00<00:06, 639.23it/s, est. speed input: 654661.01 toks/s, output: 639.27 toks/s]
Processed prompts:   7%|         | 290/4096 [00:02<00:42, 88.82it/s, est. speed input: 113875.67 toks/s, output: 111.21 toks/s] 
Processed prompts:   8%|         | 322/4096 [00:03<00:57, 65.28it/s, est. speed input: 88417.42 toks/s, output: 86.34 toks/s]  
Processed prompts:   9%|         | 354/4096 [00:04<01:11, 52.05it/s, est. speed input: 74660.37 toks/s, output: 72.91 toks/s]
Processed prompts:   9%|         | 386/4096 [00:05<01:24, 44.08it/s, est. speed input: 66118.62 toks/s, output: 64.57 toks/s]
Processed prompts:  10%|         | 418/4096 [00:07<01:34, 38.98it/s, est. speed input: 60260.24 toks/s, output: 58.85 toks/s]
Processed prompts:  11%|         | 450/4096 [00:08<01:41, 35.83it/s, est. speed input: 56136.16 toks/s, output: 54.82 toks/s]
Processed prompts:  12%|        | 482/4096 [00:09<01:47, 33.48it/s, est. speed input: 52859.53 toks/s, output: 51.62 toks/s]
Processed prompts:  13%|        | 514/4096 [00:10<01:52, 31.90it/s, est. speed input: 50295.07 toks/s, output: 49.12 toks/s]
Processed prompts:  13%|        | 546/4096 [00:11<01:55, 30.81it/s, est. speed input: 48224.29 toks/s, output: 47.09 toks/s]
Processed prompts:  14%|        | 578/4096 [00:12<01:56, 30.11it/s, est. speed input: 46544.37 toks/s, output: 45.45 toks/s]
Processed prompts:  15%|        | 610/4096 [00:13<01:57, 29.58it/s, est. speed input: 45119.42 toks/s, output: 44.06 toks/s]
Processed prompts:  16%|        | 642/4096 [00:14<01:58, 29.24it/s, est. speed input: 43916.84 toks/s, output: 42.89 toks/s]
Processed prompts:  16%|        | 674/4096 [00:16<01:57, 29.00it/s, est. speed input: 42884.95 toks/s, output: 41.88 toks/s]
Processed prompts:  17%|        | 706/4096 [00:17<01:57, 28.86it/s, est. speed input: 41993.12 toks/s, output: 41.01 toks/s]
Processed prompts:  18%|        | 738/4096 [00:18<01:56, 28.72it/s, est. speed input: 41199.97 toks/s, output: 40.23 toks/s]
Processed prompts:  19%|        | 770/4096 [00:19<01:56, 28.65it/s, est. speed input: 40505.61 toks/s, output: 39.56 toks/s]
Processed prompts:  20%|        | 802/4096 [00:20<01:55, 28.59it/s, est. speed input: 39884.49 toks/s, output: 38.95 toks/s]
Processed prompts:  20%|        | 834/4096 [00:21<01:54, 28.52it/s, est. speed input: 39319.97 toks/s, output: 38.40 toks/s]
Processed prompts:  21%|        | 866/4096 [00:22<01:53, 28.50it/s, est. speed input: 38819.87 toks/s, output: 37.91 toks/s]
Processed prompts:  22%|       | 898/4096 [00:23<01:52, 28.37it/s, est. speed input: 38340.28 toks/s, output: 37.44 toks/s]
Processed prompts:  23%|       | 930/4096 [00:25<01:50, 28.59it/s, est. speed input: 37966.12 toks/s, output: 37.08 toks/s]
Processed prompts:  23%|       | 962/4096 [00:26<01:48, 28.76it/s, est. speed input: 37627.02 toks/s, output: 36.75 toks/s]
Processed prompts:  24%|       | 994/4096 [00:27<01:48, 28.65it/s, est. speed input: 37274.27 toks/s, output: 36.40 toks/s]
Processed prompts:  25%|       | 1026/4096 [00:28<01:47, 28.56it/s, est. speed input: 36946.76 toks/s, output: 36.08 toks/s]
Processed prompts:  26%|       | 1058/4096 [00:29<01:46, 28.53it/s, est. speed input: 36650.17 toks/s, output: 35.79 toks/s]
Processed prompts:  27%|       | 1090/4096 [00:30<01:45, 28.47it/s, est. speed input: 36369.65 toks/s, output: 35.52 toks/s]
Processed prompts:  27%|       | 1122/4096 [00:31<01:44, 28.43it/s, est. speed input: 36107.75 toks/s, output: 35.26 toks/s]
Processed prompts:  28%|       | 1154/4096 [00:32<01:42, 28.63it/s, est. speed input: 35898.17 toks/s, output: 35.06 toks/s]
Processed prompts:  29%|       | 1186/4096 [00:34<01:41, 28.55it/s, est. speed input: 35670.31 toks/s, output: 34.83 toks/s]
Processed prompts:  30%|       | 1218/4096 [00:35<01:40, 28.51it/s, est. speed input: 35460.92 toks/s, output: 34.63 toks/s]
Processed prompts:  31%|       | 1250/4096 [00:36<01:39, 28.68it/s, est. speed input: 35288.26 toks/s, output: 34.46 toks/s]
Processed prompts:  31%|      | 1282/4096 [00:37<01:37, 28.82it/s, est. speed input: 35128.83 toks/s, output: 34.31 toks/s]
Processed prompts:  32%|      | 1314/4096 [00:38<01:37, 28.68it/s, est. speed input: 34949.96 toks/s, output: 34.13 toks/s]
Processed prompts:  33%|      | 1346/4096 [00:39<01:36, 28.59it/s, est. speed input: 34782.71 toks/s, output: 33.97 toks/s]
Processed prompts:  34%|      | 1378/4096 [00:40<01:35, 28.53it/s, est. speed input: 34624.26 toks/s, output: 33.81 toks/s]
Processed prompts:  34%|      | 1410/4096 [00:41<01:34, 28.49it/s, est. speed input: 34474.90 toks/s, output: 33.67 toks/s]
Processed prompts:  35%|      | 1442/4096 [00:43<01:33, 28.44it/s, est. speed input: 34331.72 toks/s, output: 33.53 toks/s]
Processed prompts:  36%|      | 1474/4096 [00:44<01:32, 28.41it/s, est. speed input: 34195.32 toks/s, output: 33.39 toks/s]
Processed prompts:  37%|      | 1506/4096 [00:45<01:31, 28.42it/s, est. speed input: 34069.22 toks/s, output: 33.27 toks/s]
Processed prompts:  38%|      | 1538/4096 [00:46<01:30, 28.41it/s, est. speed input: 33947.89 toks/s, output: 33.15 toks/s]
Processed prompts:  38%|      | 1570/4096 [00:47<01:28, 28.61it/s, est. speed input: 33851.89 toks/s, output: 33.06 toks/s]
Processed prompts:  39%|      | 1602/4096 [00:48<01:27, 28.52it/s, est. speed input: 33738.25 toks/s, output: 32.95 toks/s]
Processed prompts:  40%|      | 1634/4096 [00:49<01:25, 28.71it/s, est. speed input: 33652.98 toks/s, output: 32.86 toks/s]
Processed prompts:  41%|      | 1666/4096 [00:50<01:25, 28.58it/s, est. speed input: 33548.37 toks/s, output: 32.76 toks/s]
Processed prompts:  41%|     | 1698/4096 [00:51<01:24, 28.52it/s, est. speed input: 33451.12 toks/s, output: 32.67 toks/s]
Processed prompts:  42%|     | 1730/4096 [00:53<01:23, 28.45it/s, est. speed input: 33356.03 toks/s, output: 32.57 toks/s]
Processed prompts:  43%|     | 1762/4096 [00:54<01:22, 28.42it/s, est. speed input: 33265.49 toks/s, output: 32.49 toks/s]
Processed prompts:  44%|     | 1794/4096 [00:55<01:21, 28.40it/s, est. speed input: 33179.15 toks/s, output: 32.40 toks/s]
Processed prompts:  45%|     | 1826/4096 [00:56<01:20, 28.36it/s, est. speed input: 33094.89 toks/s, output: 32.32 toks/s]
Processed prompts:  45%|     | 1858/4096 [00:57<01:18, 28.56it/s, est. speed input: 33030.42 toks/s, output: 32.26 toks/s]
Processed prompts:  46%|     | 1890/4096 [00:58<01:17, 28.52it/s, est. speed input: 32954.92 toks/s, output: 32.18 toks/s]
Processed prompts:  47%|     | 1922/4096 [00:59<01:16, 28.46it/s, est. speed input: 32880.48 toks/s, output: 32.11 toks/s]
Processed prompts:  48%|     | 1954/4096 [01:00<01:14, 28.64it/s, est. speed input: 32823.97 toks/s, output: 32.05 toks/s]
Processed prompts:  48%|     | 1986/4096 [01:02<01:12, 29.20it/s, est. speed input: 32799.07 toks/s, output: 32.03 toks/s]
Processed prompts:  49%|     | 2018/4096 [01:03<01:11, 28.93it/s, est. speed input: 32730.98 toks/s, output: 31.96 toks/s]
Processed prompts:  50%|     | 2050/4096 [01:04<01:10, 29.15it/s, est. speed input: 32691.31 toks/s, output: 31.93 toks/s]
Processed prompts:  51%|     | 2082/4096 [01:05<01:09, 29.13it/s, est. speed input: 32642.40 toks/s, output: 31.88 toks/s]
Processed prompts:  52%|    | 2114/4096 [01:06<01:08, 28.90it/s, est. speed input: 32581.36 toks/s, output: 31.82 toks/s]
Processed prompts:  52%|    | 2146/4096 [01:07<01:07, 28.70it/s, est. speed input: 32520.20 toks/s, output: 31.76 toks/s]
Processed prompts:  53%|    | 2178/4096 [01:08<01:05, 29.09it/s, est. speed input: 32492.88 toks/s, output: 31.73 toks/s]
Processed prompts:  54%|    | 2210/4096 [01:09<01:04, 29.40it/s, est. speed input: 32468.38 toks/s, output: 31.71 toks/s]
Processed prompts:  55%|    | 2242/4096 [01:10<01:03, 29.05it/s, est. speed input: 32412.24 toks/s, output: 31.65 toks/s]
Processed prompts:  56%|    | 2274/4096 [01:11<01:02, 29.07it/s, est. speed input: 32372.24 toks/s, output: 31.61 toks/s]
Processed prompts:  56%|    | 2306/4096 [01:13<01:01, 29.05it/s, est. speed input: 32332.22 toks/s, output: 31.57 toks/s]
Processed prompts:  57%|    | 2338/4096 [01:14<01:00, 29.07it/s, est. speed input: 32294.68 toks/s, output: 31.54 toks/s]
Processed prompts:  58%|    | 2370/4096 [01:15<00:58, 29.65it/s, est. speed input: 32288.54 toks/s, output: 31.53 toks/s]
Processed prompts:  59%|    | 2402/4096 [01:16<00:57, 29.49it/s, est. speed input: 32253.25 toks/s, output: 31.50 toks/s]
Processed prompts:  59%|    | 2434/4096 [01:17<00:56, 29.37it/s, est. speed input: 32218.07 toks/s, output: 31.46 toks/s]
Processed prompts:  60%|    | 2466/4096 [01:18<00:55, 29.27it/s, est. speed input: 32183.29 toks/s, output: 31.43 toks/s]
Processed prompts:  61%|    | 2498/4096 [01:19<00:54, 29.22it/s, est. speed input: 32150.17 toks/s, output: 31.40 toks/s]
Processed prompts:  62%|   | 2530/4096 [01:20<00:54, 28.94it/s, est. speed input: 32105.88 toks/s, output: 31.35 toks/s]
Processed prompts:  63%|   | 2562/4096 [01:21<00:52, 28.98it/s, est. speed input: 32074.52 toks/s, output: 31.32 toks/s]
Processed prompts:  63%|   | 2594/4096 [01:22<00:51, 29.04it/s, est. speed input: 32045.62 toks/s, output: 31.29 toks/s]
Processed prompts:  64%|   | 2626/4096 [01:24<00:51, 28.80it/s, est. speed input: 32003.66 toks/s, output: 31.25 toks/s]
Processed prompts:  65%|   | 2658/4096 [01:25<00:50, 28.64it/s, est. speed input: 31963.31 toks/s, output: 31.21 toks/s]
Processed prompts:  66%|   | 2690/4096 [01:26<00:48, 29.07it/s, est. speed input: 31949.27 toks/s, output: 31.20 toks/s]
Processed prompts:  66%|   | 2722/4096 [01:27<00:47, 28.78it/s, est. speed input: 31908.51 toks/s, output: 31.16 toks/s]
Processed prompts:  67%|   | 2754/4096 [01:28<00:46, 28.87it/s, est. speed input: 31882.04 toks/s, output: 31.13 toks/s]
Processed prompts:  68%|   | 2786/4096 [01:29<00:45, 28.72it/s, est. speed input: 31846.31 toks/s, output: 31.10 toks/s]
Processed prompts:  69%|   | 2818/4096 [01:30<00:43, 29.12it/s, est. speed input: 31834.37 toks/s, output: 31.09 toks/s]
Processed prompts:  70%|   | 2850/4096 [01:31<00:42, 29.10it/s, est. speed input: 31809.52 toks/s, output: 31.06 toks/s]
Processed prompts:  70%|   | 2882/4096 [01:32<00:42, 28.86it/s, est. speed input: 31775.27 toks/s, output: 31.03 toks/s]
Processed prompts:  71%|   | 2914/4096 [01:34<00:41, 28.70it/s, est. speed input: 31742.13 toks/s, output: 31.00 toks/s]
Processed prompts:  72%|  | 2946/4096 [01:35<00:39, 28.81it/s, est. speed input: 31719.31 toks/s, output: 30.98 toks/s]
Processed prompts:  73%|  | 2978/4096 [01:36<00:38, 28.67it/s, est. speed input: 31687.84 toks/s, output: 30.95 toks/s]
Processed prompts:  73%|  | 3010/4096 [01:37<00:37, 29.05it/s, est. speed input: 31676.90 toks/s, output: 30.93 toks/s]
Processed prompts:  74%|  | 3042/4096 [01:38<00:36, 29.08it/s, est. speed input: 31656.57 toks/s, output: 30.91 toks/s]
Processed prompts:  75%|  | 3074/4096 [01:39<00:35, 28.87it/s, est. speed input: 31627.27 toks/s, output: 30.89 toks/s]
Processed prompts:  76%|  | 3106/4096 [01:40<00:33, 29.49it/s, est. speed input: 31628.94 toks/s, output: 30.89 toks/s]
Processed prompts:  77%|  | 3138/4096 [01:41<00:32, 29.64it/s, est. speed input: 31619.21 toks/s, output: 30.88 toks/s]
Processed prompts:  77%|  | 3170/4096 [01:42<00:31, 29.25it/s, est. speed input: 31591.38 toks/s, output: 30.85 toks/s]
Processed prompts:  78%|  | 3202/4096 [01:43<00:30, 29.49it/s, est. speed input: 31583.05 toks/s, output: 30.84 toks/s]
Processed prompts:  79%|  | 3234/4096 [01:44<00:29, 29.36it/s, est. speed input: 31563.77 toks/s, output: 30.82 toks/s]
Processed prompts:  80%|  | 3266/4096 [01:46<00:28, 29.07it/s, est. speed input: 31537.64 toks/s, output: 30.80 toks/s]
Processed prompts:  81%|  | 3298/4096 [01:47<00:27, 29.05it/s, est. speed input: 31518.86 toks/s, output: 30.78 toks/s]
Processed prompts:  81%| | 3330/4096 [01:48<00:26, 29.34it/s, est. speed input: 31511.43 toks/s, output: 30.77 toks/s]
Processed prompts:  82%| | 3362/4096 [01:49<00:25, 29.02it/s, est. speed input: 31484.96 toks/s, output: 30.75 toks/s]
Processed prompts:  83%| | 3394/4096 [01:50<00:24, 28.81it/s, est. speed input: 31459.85 toks/s, output: 30.72 toks/s]
Processed prompts:  84%| | 3426/4096 [01:51<00:23, 28.90it/s, est. speed input: 31443.62 toks/s, output: 30.71 toks/s]
Processed prompts:  84%| | 3458/4096 [01:52<00:22, 28.96it/s, est. speed input: 31427.43 toks/s, output: 30.69 toks/s]
Processed prompts:  85%| | 3490/4096 [01:53<00:20, 29.29it/s, est. speed input: 31421.84 toks/s, output: 30.69 toks/s]
Processed prompts:  86%| | 3522/4096 [01:54<00:19, 28.99it/s, est. speed input: 31397.78 toks/s, output: 30.66 toks/s]
Processed prompts:  87%| | 3554/4096 [01:55<00:18, 28.78it/s, est. speed input: 31374.18 toks/s, output: 30.64 toks/s]
Processed prompts:  88%| | 3586/4096 [01:57<00:17, 28.68it/s, est. speed input: 31352.55 toks/s, output: 30.62 toks/s]
Processed prompts:  88%| | 3618/4096 [01:58<00:16, 28.55it/s, est. speed input: 31329.55 toks/s, output: 30.60 toks/s]
Processed prompts:  89%| | 3650/4096 [01:59<00:15, 28.71it/s, est. speed input: 31315.27 toks/s, output: 30.58 toks/s]
Processed prompts:  90%| | 3682/4096 [02:00<00:14, 28.78it/s, est. speed input: 31299.96 toks/s, output: 30.57 toks/s]
Processed prompts:  91%| | 3714/4096 [02:01<00:13, 28.87it/s, est. speed input: 31286.22 toks/s, output: 30.55 toks/s]
Processed prompts:  91%|| 3746/4096 [02:02<00:12, 28.73it/s, est. speed input: 31266.15 toks/s, output: 30.53 toks/s]
Processed prompts:  92%|| 3778/4096 [02:03<00:11, 28.60it/s, est. speed input: 31245.22 toks/s, output: 30.51 toks/s]
Processed prompts:  93%|| 3810/4096 [02:04<00:09, 28.71it/s, est. speed input: 31231.30 toks/s, output: 30.50 toks/s]
Processed prompts:  94%|| 3842/4096 [02:05<00:08, 29.09it/s, est. speed input: 31227.17 toks/s, output: 30.50 toks/s]
Processed prompts:  95%|| 3874/4096 [02:07<00:07, 28.86it/s, est. speed input: 31207.31 toks/s, output: 30.48 toks/s]
Processed prompts:  95%|| 3906/4096 [02:08<00:06, 28.68it/s, est. speed input: 31187.47 toks/s, output: 30.46 toks/s]
Processed prompts:  96%|| 3938/4096 [02:09<00:05, 28.78it/s, est. speed input: 31175.03 toks/s, output: 30.44 toks/s]
Processed prompts:  97%|| 3970/4096 [02:10<00:04, 28.63it/s, est. speed input: 31155.74 toks/s, output: 30.43 toks/s]
Processed prompts:  98%|| 4002/4096 [02:11<00:03, 28.53it/s, est. speed input: 31137.09 toks/s, output: 30.41 toks/s]
Processed prompts:  98%|| 4034/4096 [02:12<00:02, 29.22it/s, est. speed input: 31141.51 toks/s, output: 30.41 toks/s]
Processed prompts:  99%|| 4066/4096 [02:13<00:01, 29.12it/s, est. speed input: 31128.54 toks/s, output: 30.40 toks/s]
Processed prompts: 100%|| 4096/4096 [02:13<00:00, 29.12it/s, est. speed input: 31358.15 toks/s, output: 30.62 toks/s]
Processed prompts: 100%|| 4096/4096 [02:13<00:00, 30.62it/s, est. speed input: 31358.15 toks/s, output: 30.62 toks/s]
[rank0]:[W126 08:36:12.162645304 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 08:36:15
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-1B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:36:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:36:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1083043) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1083043) WARNING 01-26 08:37:07 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 28.51 requests/s, 29220.83 total tokens/s, 28.51 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 08:36:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:36:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:36:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:36:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:36:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:36:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:36:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:36:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:36:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:36:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:36:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:36:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:36:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:36:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:36:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 08:36:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 08:36:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 08:36:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:36:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:36:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:36:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:36:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 08:36:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 08:36:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:36:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:36:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:36:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:36:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1083043) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1083043) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.70s/it]
(EngineCore_DP0 pid=1083043) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:10<00:00, 10.70s/it]
(EngineCore_DP0 pid=1083043) 
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1083043) [2026-01-26 08:36:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1083043) 2026-01-26 08:37:04,958 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1083043) 2026-01-26 08:37:05,203 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 60/8192 [00:00<00:13, 594.46it/s]
Adding requests:   1%|         | 120/8192 [00:00<00:17, 466.47it/s]
Adding requests:   2%|         | 169/8192 [00:00<00:17, 470.31it/s]
Adding requests:   3%|         | 223/8192 [00:00<00:16, 495.17it/s]
Adding requests:   3%|         | 282/8192 [00:00<00:15, 526.20it/s]
Adding requests:   4%|         | 336/8192 [00:00<00:15, 519.63it/s]
Adding requests:   5%|         | 394/8192 [00:00<00:14, 536.82it/s]
Adding requests:   5%|         | 449/8192 [00:00<00:15, 507.68it/s]
Adding requests:   6%|         | 501/8192 [00:00<00:15, 493.99it/s]
Adding requests:   7%|         | 551/8192 [00:01<00:15, 480.15it/s]
Adding requests:   7%|         | 600/8192 [00:01<00:15, 482.26it/s]
Adding requests:   8%|         | 649/8192 [00:01<00:15, 483.59it/s]
Adding requests:   9%|         | 698/8192 [00:01<00:15, 474.70it/s]
Adding requests:   9%|         | 752/8192 [00:01<00:15, 493.00it/s]
Adding requests:  10%|         | 802/8192 [00:01<00:15, 476.21it/s]
Adding requests:  10%|         | 850/8192 [00:01<00:15, 475.39it/s]
Adding requests:  11%|         | 901/8192 [00:01<00:15, 484.97it/s]
Adding requests:  12%|        | 963/8192 [00:01<00:13, 522.75it/s]
Adding requests:  12%|        | 1016/8192 [00:02<00:14, 487.31it/s]
Adding requests:  13%|        | 1066/8192 [00:02<00:14, 478.39it/s]
Adding requests:  14%|        | 1117/8192 [00:02<00:14, 484.91it/s]
Adding requests:  14%|        | 1166/8192 [00:02<00:15, 463.04it/s]
Adding requests:  15%|        | 1224/8192 [00:02<00:14, 493.30it/s]
Adding requests:  16%|        | 1274/8192 [00:02<00:15, 442.82it/s]
Adding requests:  16%|        | 1326/8192 [00:02<00:14, 460.36it/s]
Adding requests:  17%|        | 1374/8192 [00:02<00:14, 455.98it/s]
Adding requests:  17%|        | 1424/8192 [00:02<00:14, 467.74it/s]
Adding requests:  18%|        | 1486/8192 [00:03<00:13, 510.86it/s]
Adding requests:  19%|        | 1538/8192 [00:03<00:13, 486.89it/s]
Adding requests:  19%|        | 1588/8192 [00:03<00:13, 486.28it/s]
Adding requests:  20%|        | 1645/8192 [00:03<00:13, 502.81it/s]
Adding requests:  21%|        | 1696/8192 [00:03<00:13, 470.53it/s]
Adding requests:  21%|       | 1752/8192 [00:03<00:13, 493.73it/s]
Adding requests:  22%|       | 1802/8192 [00:03<00:13, 477.70it/s]
Adding requests:  23%|       | 1851/8192 [00:03<00:13, 475.97it/s]
Adding requests:  23%|       | 1899/8192 [00:03<00:13, 455.95it/s]
Adding requests:  24%|       | 1948/8192 [00:04<00:13, 464.02it/s]
Adding requests:  24%|       | 1995/8192 [00:04<00:14, 424.94it/s]
Adding requests:  25%|       | 2042/8192 [00:04<00:14, 435.21it/s]
Adding requests:  26%|       | 2089/8192 [00:04<00:13, 443.91it/s]
Adding requests:  26%|       | 2144/8192 [00:04<00:12, 472.75it/s]
Adding requests:  27%|       | 2198/8192 [00:04<00:12, 490.73it/s]
Adding requests:  28%|       | 2262/8192 [00:04<00:11, 531.84it/s]
Adding requests:  28%|       | 2332/8192 [00:04<00:10, 579.31it/s]
Adding requests:  29%|       | 2391/8192 [00:04<00:10, 553.72it/s]
Adding requests:  30%|       | 2447/8192 [00:05<00:10, 527.40it/s]
Adding requests:  31%|       | 2501/8192 [00:05<00:11, 512.47it/s]
Adding requests:  31%|       | 2553/8192 [00:05<00:11, 497.35it/s]
Adding requests:  32%|      | 2604/8192 [00:05<00:11, 496.74it/s]
Adding requests:  32%|      | 2654/8192 [00:05<00:11, 486.09it/s]
Adding requests:  33%|      | 2703/8192 [00:05<00:11, 482.47it/s]
Adding requests:  34%|      | 2752/8192 [00:05<00:11, 481.77it/s]
Adding requests:  34%|      | 2801/8192 [00:05<00:11, 483.58it/s]
Adding requests:  35%|      | 2851/8192 [00:05<00:10, 486.31it/s]
Adding requests:  35%|      | 2900/8192 [00:05<00:11, 477.60it/s]
Adding requests:  36%|      | 2948/8192 [00:06<00:11, 469.25it/s]
Adding requests:  37%|      | 3000/8192 [00:06<00:10, 481.10it/s]
Adding requests:  37%|      | 3049/8192 [00:06<00:10, 480.63it/s]
Adding requests:  38%|      | 3098/8192 [00:06<00:10, 472.66it/s]
Adding requests:  38%|      | 3146/8192 [00:06<00:10, 462.26it/s]
Adding requests:  39%|      | 3198/8192 [00:06<00:10, 476.86it/s]
Adding requests:  40%|      | 3246/8192 [00:06<00:10, 466.44it/s]
Adding requests:  40%|      | 3293/8192 [00:06<00:10, 452.26it/s]
Adding requests:  41%|      | 3339/8192 [00:06<00:11, 415.61it/s]
Adding requests:  41%|     | 3389/8192 [00:07<00:11, 435.45it/s]
Adding requests:  42%|     | 3438/8192 [00:07<00:10, 447.60it/s]
Adding requests:  43%|     | 3484/8192 [00:07<00:10, 449.61it/s]
Adding requests:  43%|     | 3533/8192 [00:07<00:10, 458.47it/s]
Adding requests:  44%|     | 3583/8192 [00:07<00:09, 468.20it/s]
Adding requests:  44%|     | 3631/8192 [00:07<00:09, 470.72it/s]
Adding requests:  45%|     | 3680/8192 [00:07<00:09, 474.96it/s]
Adding requests:  46%|     | 3728/8192 [00:07<00:09, 465.05it/s]
Adding requests:  46%|     | 3782/8192 [00:07<00:09, 484.87it/s]
Adding requests:  47%|     | 3831/8192 [00:07<00:09, 478.85it/s]
Adding requests:  47%|     | 3881/8192 [00:08<00:08, 482.41it/s]
Adding requests:  48%|     | 3930/8192 [00:08<00:08, 477.13it/s]
Adding requests:  49%|     | 3983/8192 [00:08<00:08, 490.77it/s]
Adding requests:  49%|     | 4033/8192 [00:08<00:08, 482.04it/s]
Adding requests:  50%|     | 4082/8192 [00:08<00:08, 481.24it/s]
Adding requests:  50%|     | 4134/8192 [00:08<00:08, 489.81it/s]
Adding requests:  51%|     | 4184/8192 [00:08<00:08, 485.25it/s]
Adding requests:  52%|    | 4233/8192 [00:08<00:08, 485.82it/s]
Adding requests:  52%|    | 4282/8192 [00:08<00:08, 477.39it/s]
Adding requests:  53%|    | 4331/8192 [00:08<00:08, 480.58it/s]
Adding requests:  53%|    | 4380/8192 [00:09<00:07, 477.82it/s]
Adding requests:  54%|    | 4428/8192 [00:09<00:07, 477.29it/s]
Adding requests:  55%|    | 4479/8192 [00:09<00:07, 484.85it/s]
Adding requests:  55%|    | 4528/8192 [00:09<00:07, 483.43it/s]
Adding requests:  56%|    | 4577/8192 [00:09<00:07, 484.78it/s]
Adding requests:  56%|    | 4626/8192 [00:09<00:07, 480.80it/s]
Adding requests:  57%|    | 4677/8192 [00:09<00:07, 486.31it/s]
Adding requests:  58%|    | 4726/8192 [00:09<00:07, 453.91it/s]
Adding requests:  58%|    | 4774/8192 [00:09<00:07, 460.56it/s]
Adding requests:  59%|    | 4821/8192 [00:10<00:07, 459.14it/s]
Adding requests:  59%|    | 4869/8192 [00:10<00:07, 461.94it/s]
Adding requests:  60%|    | 4916/8192 [00:10<00:07, 461.18it/s]
Adding requests:  61%|    | 4963/8192 [00:10<00:06, 463.02it/s]
Adding requests:  61%|    | 5010/8192 [00:10<00:06, 462.06it/s]
Adding requests:  62%|   | 5062/8192 [00:10<00:06, 477.37it/s]
Adding requests:  62%|   | 5113/8192 [00:10<00:06, 484.57it/s]
Adding requests:  63%|   | 5162/8192 [00:10<00:06, 472.74it/s]
Adding requests:  64%|   | 5210/8192 [00:10<00:06, 472.06it/s]
Adding requests:  64%|   | 5261/8192 [00:10<00:06, 481.45it/s]
Adding requests:  65%|   | 5310/8192 [00:11<00:06, 465.92it/s]
Adding requests:  65%|   | 5359/8192 [00:11<00:06, 471.81it/s]
Adding requests:  66%|   | 5407/8192 [00:11<00:06, 458.85it/s]
Adding requests:  67%|   | 5457/8192 [00:11<00:05, 470.59it/s]
Adding requests:  67%|   | 5505/8192 [00:11<00:05, 459.32it/s]
Adding requests:  68%|   | 5552/8192 [00:11<00:05, 458.83it/s]
Adding requests:  68%|   | 5601/8192 [00:11<00:05, 467.70it/s]
Adding requests:  69%|   | 5648/8192 [00:11<00:05, 466.08it/s]
Adding requests:  70%|   | 5698/8192 [00:11<00:05, 475.58it/s]
Adding requests:  70%|   | 5746/8192 [00:12<00:05, 462.40it/s]
Adding requests:  71%|   | 5798/8192 [00:12<00:05, 475.50it/s]
Adding requests:  71%|  | 5846/8192 [00:12<00:04, 473.31it/s]
Adding requests:  72%|  | 5896/8192 [00:12<00:04, 480.51it/s]
Adding requests:  73%|  | 5945/8192 [00:12<00:04, 477.50it/s]
Adding requests:  73%|  | 5997/8192 [00:12<00:04, 488.26it/s]
Adding requests:  74%|  | 6046/8192 [00:12<00:04, 488.64it/s]
Adding requests:  74%|  | 6095/8192 [00:12<00:04, 435.59it/s]
Adding requests:  75%|  | 6144/8192 [00:12<00:04, 448.59it/s]
Adding requests:  76%|  | 6192/8192 [00:12<00:04, 456.80it/s]
Adding requests:  76%|  | 6244/8192 [00:13<00:04, 474.64it/s]
Adding requests:  77%|  | 6293/8192 [00:13<00:03, 475.93it/s]
Adding requests:  77%|  | 6342/8192 [00:13<00:03, 478.35it/s]
Adding requests:  78%|  | 6396/8192 [00:13<00:03, 494.22it/s]
Adding requests:  79%|  | 6446/8192 [00:13<00:03, 491.89it/s]
Adding requests:  79%|  | 6496/8192 [00:13<00:03, 482.59it/s]
Adding requests:  80%|  | 6545/8192 [00:13<00:03, 471.60it/s]
Adding requests:  80%|  | 6593/8192 [00:13<00:03, 461.94it/s]
Adding requests:  81%|  | 6640/8192 [00:13<00:03, 459.80it/s]
Adding requests:  82%| | 6689/8192 [00:14<00:03, 467.56it/s]
Adding requests:  82%| | 6739/8192 [00:14<00:03, 475.63it/s]
Adding requests:  83%| | 6789/8192 [00:14<00:02, 481.09it/s]
Adding requests:  83%| | 6838/8192 [00:14<00:02, 483.69it/s]
Adding requests:  84%| | 6887/8192 [00:14<00:02, 482.39it/s]
Adding requests:  85%| | 6942/8192 [00:14<00:02, 498.51it/s]
Adding requests:  85%| | 6993/8192 [00:14<00:02, 497.04it/s]
Adding requests:  86%| | 7043/8192 [00:14<00:02, 490.07it/s]
Adding requests:  87%| | 7093/8192 [00:14<00:02, 477.70it/s]
Adding requests:  87%| | 7145/8192 [00:14<00:02, 489.82it/s]
Adding requests:  88%| | 7195/8192 [00:15<00:02, 488.61it/s]
Adding requests:  88%| | 7244/8192 [00:15<00:01, 486.14it/s]
Adding requests:  89%| | 7294/8192 [00:15<00:01, 488.50it/s]
Adding requests:  90%| | 7347/8192 [00:15<00:01, 497.92it/s]
Adding requests:  90%| | 7399/8192 [00:15<00:01, 501.65it/s]
Adding requests:  91%| | 7450/8192 [00:15<00:01, 459.66it/s]
Adding requests:  92%|| 7498/8192 [00:15<00:01, 464.05it/s]
Adding requests:  92%|| 7545/8192 [00:15<00:01, 460.97it/s]
Adding requests:  93%|| 7592/8192 [00:15<00:01, 460.48it/s]
Adding requests:  93%|| 7642/8192 [00:15<00:01, 471.08it/s]
Adding requests:  94%|| 7691/8192 [00:16<00:01, 473.83it/s]
Adding requests:  95%|| 7743/8192 [00:16<00:00, 486.02it/s]
Adding requests:  95%|| 7792/8192 [00:16<00:00, 480.06it/s]
Adding requests:  96%|| 7843/8192 [00:16<00:00, 486.81it/s]
Adding requests:  96%|| 7893/8192 [00:16<00:00, 488.71it/s]
Adding requests:  97%|| 7943/8192 [00:16<00:00, 489.95it/s]
Adding requests:  98%|| 7993/8192 [00:16<00:00, 487.36it/s]
Adding requests:  98%|| 8042/8192 [00:16<00:00, 483.43it/s]
Adding requests:  99%|| 8094/8192 [00:16<00:00, 492.30it/s]
Adding requests:  99%|| 8144/8192 [00:17<00:00, 487.00it/s]
Adding requests: 100%|| 8192/8192 [00:17<00:00, 478.74it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|         | 386/8192 [00:00<00:17, 450.95it/s, est. speed input: 461781.73 toks/s, output: 450.95 toks/s]
Processed prompts:   5%|         | 450/8192 [00:03<01:05, 117.86it/s, est. speed input: 149012.89 toks/s, output: 145.52 toks/s]
Processed prompts:   6%|         | 514/8192 [00:05<01:49, 70.43it/s, est. speed input: 98601.44 toks/s, output: 96.29 toks/s]   
Processed prompts:   7%|         | 578/8192 [00:07<02:25, 52.28it/s, est. speed input: 77979.43 toks/s, output: 76.15 toks/s]
Processed prompts:   8%|         | 642/8192 [00:09<02:54, 43.26it/s, est. speed input: 66875.73 toks/s, output: 65.31 toks/s]
Processed prompts:   9%|         | 706/8192 [00:12<03:16, 38.04it/s, est. speed input: 59849.95 toks/s, output: 58.45 toks/s]
Processed prompts:   9%|         | 770/8192 [00:14<03:33, 34.79it/s, est. speed input: 55005.44 toks/s, output: 53.72 toks/s]
Processed prompts:  10%|         | 834/8192 [00:16<03:45, 32.70it/s, est. speed input: 51471.00 toks/s, output: 50.26 toks/s]
Processed prompts:  11%|         | 898/8192 [00:18<03:51, 31.45it/s, est. speed input: 48855.10 toks/s, output: 47.71 toks/s]
Processed prompts:  12%|        | 962/8192 [00:21<04:11, 28.78it/s, est. speed input: 45804.19 toks/s, output: 44.73 toks/s]
Processed prompts:  13%|        | 1026/8192 [00:23<04:09, 28.69it/s, est. speed input: 44227.53 toks/s, output: 43.19 toks/s]
Processed prompts:  13%|        | 1090/8192 [00:26<04:08, 28.57it/s, est. speed input: 42902.85 toks/s, output: 41.90 toks/s]
Processed prompts:  14%|        | 1154/8192 [00:28<04:05, 28.65it/s, est. speed input: 41849.72 toks/s, output: 40.87 toks/s]
Processed prompts:  15%|        | 1218/8192 [00:30<04:03, 28.67it/s, est. speed input: 40938.84 toks/s, output: 39.98 toks/s]
Processed prompts:  16%|        | 1282/8192 [00:32<04:01, 28.67it/s, est. speed input: 40147.92 toks/s, output: 39.21 toks/s]
Processed prompts:  16%|        | 1346/8192 [00:34<03:59, 28.55it/s, est. speed input: 39423.23 toks/s, output: 38.50 toks/s]
Processed prompts:  17%|        | 1410/8192 [00:37<03:58, 28.48it/s, est. speed input: 38789.27 toks/s, output: 37.88 toks/s]
Processed prompts:  18%|        | 1474/8192 [00:39<03:55, 28.47it/s, est. speed input: 38238.74 toks/s, output: 37.34 toks/s]
Processed prompts:  19%|        | 1538/8192 [00:41<03:53, 28.54it/s, est. speed input: 37766.72 toks/s, output: 36.88 toks/s]
Processed prompts:  20%|        | 1602/8192 [00:43<03:50, 28.58it/s, est. speed input: 37339.31 toks/s, output: 36.46 toks/s]
Processed prompts:  20%|        | 1666/8192 [00:46<03:48, 28.50it/s, est. speed input: 36930.78 toks/s, output: 36.07 toks/s]
Processed prompts:  21%|        | 1730/8192 [00:48<03:46, 28.48it/s, est. speed input: 36568.13 toks/s, output: 35.71 toks/s]
Processed prompts:  22%|       | 1794/8192 [00:50<03:44, 28.45it/s, est. speed input: 36234.39 toks/s, output: 35.39 toks/s]
Processed prompts:  23%|       | 1858/8192 [00:52<03:42, 28.50it/s, est. speed input: 35941.30 toks/s, output: 35.10 toks/s]
Processed prompts:  23%|       | 1922/8192 [00:55<03:42, 28.16it/s, est. speed input: 35607.77 toks/s, output: 34.77 toks/s]
Processed prompts:  24%|       | 1986/8192 [00:57<03:37, 28.55it/s, est. speed input: 35404.89 toks/s, output: 34.58 toks/s]
Processed prompts:  25%|       | 2050/8192 [00:59<03:32, 28.85it/s, est. speed input: 35219.00 toks/s, output: 34.39 toks/s]
Processed prompts:  26%|       | 2114/8192 [01:01<03:31, 28.69it/s, est. speed input: 34991.56 toks/s, output: 34.17 toks/s]
Processed prompts:  27%|       | 2178/8192 [01:04<03:26, 29.06it/s, est. speed input: 34847.78 toks/s, output: 34.03 toks/s]
Processed prompts:  27%|       | 2242/8192 [01:06<03:25, 28.96it/s, est. speed input: 34665.11 toks/s, output: 33.85 toks/s]
Processed prompts:  28%|       | 2306/8192 [01:08<03:23, 28.98it/s, est. speed input: 34506.43 toks/s, output: 33.70 toks/s]
Processed prompts:  29%|       | 2370/8192 [01:10<03:18, 29.29it/s, est. speed input: 34392.67 toks/s, output: 33.59 toks/s]
Processed prompts:  30%|       | 2434/8192 [01:12<03:16, 29.24it/s, est. speed input: 34255.21 toks/s, output: 33.45 toks/s]
Processed prompts:  30%|       | 2498/8192 [01:14<03:15, 29.07it/s, est. speed input: 34109.62 toks/s, output: 33.31 toks/s]
Processed prompts:  31%|      | 2562/8192 [01:17<03:13, 29.10it/s, est. speed input: 33988.74 toks/s, output: 33.19 toks/s]
Processed prompts:  32%|      | 2626/8192 [01:19<03:12, 28.88it/s, est. speed input: 33848.93 toks/s, output: 33.06 toks/s]
Processed prompts:  33%|      | 2690/8192 [01:21<03:09, 28.97it/s, est. speed input: 33742.60 toks/s, output: 32.95 toks/s]
Processed prompts:  34%|      | 2754/8192 [01:23<03:08, 28.86it/s, est. speed input: 33623.49 toks/s, output: 32.84 toks/s]
Processed prompts:  34%|      | 2818/8192 [01:26<03:04, 29.07it/s, est. speed input: 33539.94 toks/s, output: 32.75 toks/s]
Processed prompts:  35%|      | 2882/8192 [01:28<03:06, 28.51it/s, est. speed input: 33391.14 toks/s, output: 32.61 toks/s]
Processed prompts:  36%|      | 2946/8192 [01:30<03:03, 28.55it/s, est. speed input: 33290.84 toks/s, output: 32.51 toks/s]
Processed prompts:  37%|      | 3010/8192 [01:32<02:59, 28.89it/s, est. speed input: 33224.10 toks/s, output: 32.45 toks/s]
Processed prompts:  38%|      | 3074/8192 [01:34<02:55, 29.12it/s, est. speed input: 33159.81 toks/s, output: 32.38 toks/s]
Processed prompts:  38%|      | 3138/8192 [01:37<02:53, 29.13it/s, est. speed input: 33085.27 toks/s, output: 32.31 toks/s]
Processed prompts:  39%|      | 3202/8192 [01:39<02:50, 29.28it/s, est. speed input: 33025.80 toks/s, output: 32.25 toks/s]
Processed prompts:  40%|      | 3266/8192 [01:41<02:49, 29.09it/s, est. speed input: 32944.58 toks/s, output: 32.17 toks/s]
Processed prompts:  41%|      | 3330/8192 [01:43<02:47, 29.11it/s, est. speed input: 32879.51 toks/s, output: 32.11 toks/s]
Processed prompts:  41%|     | 3394/8192 [01:45<02:45, 28.97it/s, est. speed input: 32804.69 toks/s, output: 32.04 toks/s]
Processed prompts:  42%|     | 3458/8192 [01:48<02:42, 29.18it/s, est. speed input: 32756.37 toks/s, output: 31.99 toks/s]
Processed prompts:  43%|     | 3522/8192 [01:50<02:41, 28.92it/s, est. speed input: 32680.19 toks/s, output: 31.91 toks/s]
Processed prompts:  44%|     | 3586/8192 [01:52<02:40, 28.74it/s, est. speed input: 32606.20 toks/s, output: 31.84 toks/s]
Processed prompts:  45%|     | 3650/8192 [01:54<02:37, 28.86it/s, est. speed input: 32553.57 toks/s, output: 31.79 toks/s]
Processed prompts:  45%|     | 3714/8192 [01:57<02:35, 28.80it/s, est. speed input: 32492.22 toks/s, output: 31.73 toks/s]
Processed prompts:  46%|     | 3778/8192 [01:59<02:34, 28.48it/s, est. speed input: 32413.89 toks/s, output: 31.65 toks/s]
Processed prompts:  47%|     | 3842/8192 [02:01<02:31, 28.67it/s, est. speed input: 32366.96 toks/s, output: 31.61 toks/s]
Processed prompts:  48%|     | 3906/8192 [02:03<02:29, 28.68it/s, est. speed input: 32313.64 toks/s, output: 31.56 toks/s]
Processed prompts:  48%|     | 3970/8192 [02:06<02:27, 28.57it/s, est. speed input: 32254.15 toks/s, output: 31.50 toks/s]
Processed prompts:  49%|     | 4034/8192 [02:08<02:23, 28.89it/s, est. speed input: 32222.23 toks/s, output: 31.47 toks/s]
Processed prompts:  50%|     | 4098/8192 [02:10<02:22, 28.69it/s, est. speed input: 32164.95 toks/s, output: 31.41 toks/s]
Processed prompts:  51%|     | 4162/8192 [02:12<02:18, 29.12it/s, est. speed input: 32144.59 toks/s, output: 31.39 toks/s]
Processed prompts:  52%|    | 4226/8192 [02:14<02:16, 29.13it/s, est. speed input: 32107.04 toks/s, output: 31.35 toks/s]
Processed prompts:  52%|    | 4290/8192 [02:17<02:14, 28.98it/s, est. speed input: 32061.76 toks/s, output: 31.31 toks/s]
Processed prompts:  53%|    | 4354/8192 [02:19<02:13, 28.81it/s, est. speed input: 32013.83 toks/s, output: 31.26 toks/s]
Processed prompts:  54%|    | 4418/8192 [02:21<02:10, 28.92it/s, est. speed input: 31980.83 toks/s, output: 31.23 toks/s]
Processed prompts:  55%|    | 4482/8192 [02:23<02:09, 28.74it/s, est. speed input: 31934.16 toks/s, output: 31.19 toks/s]
Processed prompts:  55%|    | 4546/8192 [02:25<02:05, 28.98it/s, est. speed input: 31909.55 toks/s, output: 31.16 toks/s]
Processed prompts:  56%|    | 4610/8192 [02:28<02:03, 28.89it/s, est. speed input: 31871.02 toks/s, output: 31.12 toks/s]
Processed prompts:  57%|    | 4674/8192 [02:30<02:02, 28.70it/s, est. speed input: 31827.00 toks/s, output: 31.08 toks/s]
Processed prompts:  58%|    | 4738/8192 [02:32<02:00, 28.57it/s, est. speed input: 31784.32 toks/s, output: 31.04 toks/s]
Processed prompts:  59%|    | 4802/8192 [02:34<01:58, 28.61it/s, est. speed input: 31749.80 toks/s, output: 31.01 toks/s]
Processed prompts:  59%|    | 4866/8192 [02:37<01:56, 28.64it/s, est. speed input: 31716.47 toks/s, output: 30.97 toks/s]
Processed prompts:  60%|    | 4930/8192 [02:39<01:53, 28.66it/s, est. speed input: 31684.04 toks/s, output: 30.94 toks/s]
Processed prompts:  61%|    | 4994/8192 [02:41<01:51, 28.80it/s, est. speed input: 31658.95 toks/s, output: 30.92 toks/s]
Processed prompts:  62%|   | 5058/8192 [02:43<01:47, 29.05it/s, est. speed input: 31641.77 toks/s, output: 30.90 toks/s]
Processed prompts:  63%|   | 5122/8192 [02:45<01:46, 28.85it/s, est. speed input: 31606.82 toks/s, output: 30.87 toks/s]
Processed prompts:  63%|   | 5186/8192 [02:48<01:43, 29.07it/s, est. speed input: 31590.32 toks/s, output: 30.85 toks/s]
Processed prompts:  64%|   | 5250/8192 [02:50<01:40, 29.25it/s, est. speed input: 31575.17 toks/s, output: 30.84 toks/s]
Processed prompts:  65%|   | 5314/8192 [02:52<01:37, 29.40it/s, est. speed input: 31561.18 toks/s, output: 30.82 toks/s]
Processed prompts:  66%|   | 5378/8192 [02:54<01:36, 29.16it/s, est. speed input: 31532.18 toks/s, output: 30.79 toks/s]
Processed prompts:  66%|   | 5442/8192 [02:56<01:34, 29.14it/s, est. speed input: 31510.74 toks/s, output: 30.77 toks/s]
Processed prompts:  67%|   | 5506/8192 [02:59<01:32, 28.98it/s, est. speed input: 31483.05 toks/s, output: 30.75 toks/s]
Processed prompts:  68%|   | 5570/8192 [03:01<01:31, 28.81it/s, est. speed input: 31453.37 toks/s, output: 30.72 toks/s]
Processed prompts:  69%|   | 5634/8192 [03:03<01:28, 28.89it/s, est. speed input: 31433.38 toks/s, output: 30.70 toks/s]
Processed prompts:  70%|   | 5698/8192 [03:05<01:27, 28.58it/s, est. speed input: 31397.94 toks/s, output: 30.66 toks/s]
Processed prompts:  70%|   | 5762/8192 [03:08<01:24, 28.62it/s, est. speed input: 31374.27 toks/s, output: 30.64 toks/s]
Processed prompts:  71%|   | 5826/8192 [03:10<01:22, 28.63it/s, est. speed input: 31350.28 toks/s, output: 30.62 toks/s]
Processed prompts:  72%|  | 5890/8192 [03:12<01:20, 28.77it/s, est. speed input: 31332.55 toks/s, output: 30.60 toks/s]
Processed prompts:  73%|  | 5954/8192 [03:14<01:18, 28.63it/s, est. speed input: 31305.31 toks/s, output: 30.57 toks/s]
Processed prompts:  73%|  | 6018/8192 [03:16<01:15, 28.64it/s, est. speed input: 31283.12 toks/s, output: 30.55 toks/s]
Processed prompts:  74%|  | 6082/8192 [03:19<01:13, 28.57it/s, est. speed input: 31258.40 toks/s, output: 30.53 toks/s]
Processed prompts:  75%|  | 6146/8192 [03:21<01:10, 28.86it/s, est. speed input: 31247.62 toks/s, output: 30.52 toks/s]
Processed prompts:  76%|  | 6210/8192 [03:23<01:08, 28.81it/s, est. speed input: 31227.17 toks/s, output: 30.50 toks/s]
Processed prompts:  77%|  | 6274/8192 [03:25<01:06, 28.66it/s, est. speed input: 31202.70 toks/s, output: 30.47 toks/s]
Processed prompts:  77%|  | 6338/8192 [03:28<01:04, 28.78it/s, est. speed input: 31187.33 toks/s, output: 30.46 toks/s]
Processed prompts:  78%|  | 6402/8192 [03:30<01:02, 28.74it/s, est. speed input: 31167.69 toks/s, output: 30.44 toks/s]
Processed prompts:  79%|  | 6466/8192 [03:32<01:00, 28.64it/s, est. speed input: 31145.70 toks/s, output: 30.42 toks/s]
Processed prompts:  80%|  | 6530/8192 [03:34<00:57, 28.80it/s, est. speed input: 31132.73 toks/s, output: 30.40 toks/s]
Processed prompts:  80%|  | 6594/8192 [03:37<00:55, 28.76it/s, est. speed input: 31114.36 toks/s, output: 30.39 toks/s]
Processed prompts:  81%| | 6658/8192 [03:39<00:53, 28.58it/s, est. speed input: 31090.85 toks/s, output: 30.36 toks/s]
Processed prompts:  82%| | 6722/8192 [03:41<00:51, 28.52it/s, est. speed input: 31070.24 toks/s, output: 30.34 toks/s]
Processed prompts:  83%| | 6786/8192 [03:43<00:49, 28.59it/s, est. speed input: 31053.94 toks/s, output: 30.33 toks/s]
Processed prompts:  84%| | 6850/8192 [03:46<00:46, 28.60it/s, est. speed input: 31036.88 toks/s, output: 30.31 toks/s]
Processed prompts:  84%| | 6914/8192 [03:48<00:44, 28.63it/s, est. speed input: 31020.72 toks/s, output: 30.29 toks/s]
Processed prompts:  85%| | 6978/8192 [03:50<00:42, 28.81it/s, est. speed input: 31010.31 toks/s, output: 30.28 toks/s]
Processed prompts:  86%| | 7042/8192 [03:52<00:39, 28.77it/s, est. speed input: 30994.56 toks/s, output: 30.27 toks/s]
Processed prompts:  87%| | 7106/8192 [03:54<00:37, 29.14it/s, est. speed input: 30992.66 toks/s, output: 30.27 toks/s]
Processed prompts:  88%| | 7170/8192 [03:57<00:35, 28.98it/s, est. speed input: 30976.52 toks/s, output: 30.25 toks/s]
Processed prompts:  88%| | 7234/8192 [03:59<00:33, 29.02it/s, est. speed input: 30965.92 toks/s, output: 30.24 toks/s]
Processed prompts:  89%| | 7298/8192 [04:01<00:30, 28.91it/s, est. speed input: 30950.81 toks/s, output: 30.23 toks/s]
Processed prompts:  90%| | 7362/8192 [04:03<00:28, 28.98it/s, est. speed input: 30940.75 toks/s, output: 30.22 toks/s]
Processed prompts:  91%| | 7426/8192 [04:05<00:26, 28.89it/s, est. speed input: 30926.74 toks/s, output: 30.20 toks/s]
Processed prompts:  91%|| 7490/8192 [04:08<00:24, 29.11it/s, est. speed input: 30921.49 toks/s, output: 30.20 toks/s]
Processed prompts:  92%|| 7554/8192 [04:10<00:22, 28.96it/s, est. speed input: 30907.13 toks/s, output: 30.18 toks/s]
Processed prompts:  93%|| 7618/8192 [04:12<00:19, 29.27it/s, est. speed input: 30905.69 toks/s, output: 30.18 toks/s]
Processed prompts:  94%|| 7682/8192 [04:14<00:17, 29.08it/s, est. speed input: 30891.98 toks/s, output: 30.17 toks/s]
Processed prompts:  95%|| 7746/8192 [04:16<00:15, 28.96it/s, est. speed input: 30878.79 toks/s, output: 30.16 toks/s]
Processed prompts:  95%|| 7810/8192 [04:19<00:13, 28.80it/s, est. speed input: 30863.54 toks/s, output: 30.14 toks/s]
Processed prompts:  96%|| 7874/8192 [04:21<00:11, 28.66it/s, est. speed input: 30847.60 toks/s, output: 30.12 toks/s]
Processed prompts:  97%|| 7938/8192 [04:23<00:08, 28.68it/s, est. speed input: 30835.41 toks/s, output: 30.11 toks/s]
Processed prompts:  98%|| 8002/8192 [04:25<00:06, 28.66it/s, est. speed input: 30822.47 toks/s, output: 30.10 toks/s]
Processed prompts:  98%|| 8066/8192 [04:28<00:04, 28.81it/s, est. speed input: 30814.73 toks/s, output: 30.09 toks/s]
Processed prompts:  99%|| 8130/8192 [04:30<00:02, 28.89it/s, est. speed input: 30806.29 toks/s, output: 30.08 toks/s]
Processed prompts: 100%|| 8192/8192 [04:30<00:00, 28.89it/s, est. speed input: 31041.17 toks/s, output: 30.31 toks/s]
Processed prompts: 100%|| 8192/8192 [04:30<00:00, 30.31it/s, est. speed input: 31041.17 toks/s, output: 30.31 toks/s]
[rank0]:[W126 08:41:55.888619587 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 12:52:31
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:52:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:52:35 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1308589) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1308589) WARNING 01-26 12:53:11 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 23.45 requests/s, 12030.04 total tokens/s, 23.45 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 12:52:35] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:52:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:52:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:52:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:52:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:52:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:52:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:52:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:52:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:52:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:52:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:52:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:52:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:52:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:52:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:52:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:52:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:52:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:52:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:52:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:52:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:52:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:52:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:52:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:52:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:52:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:52:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:52:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1308589) [2026-01-26 12:52:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1308589) [2026-01-26 12:52:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1308589) [2026-01-26 12:52:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1308589) [2026-01-26 12:52:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1308589) [2026-01-26 12:52:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1308589) [2026-01-26 12:52:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1308589) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1308589) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.03s/it]
(EngineCore_DP0 pid=1308589) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.03s/it]
(EngineCore_DP0 pid=1308589) 
(EngineCore_DP0 pid=1308589) [2026-01-26 12:53:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1308589) [2026-01-26 12:53:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1308589) [2026-01-26 12:53:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1308589) [2026-01-26 12:53:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1308589) [2026-01-26 12:53:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1308589) [2026-01-26 12:53:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1308589) [2026-01-26 12:53:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1308589) [2026-01-26 12:53:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1308589) 2026-01-26 12:53:10,913 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1308589) 2026-01-26 12:53:10,925 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  92%|| 118/128 [00:00<00:00, 1179.67it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 1185.04it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:06, 18.51it/s, est. speed input: 9479.13 toks/s, output: 18.51 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:05, 21.46it/s, est. speed input: 10781.66 toks/s, output: 21.06 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:05, 22.76it/s, est. speed input: 11345.36 toks/s, output: 22.16 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:05, 23.35it/s, est. speed input: 11617.49 toks/s, output: 22.69 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:04, 23.64it/s, est. speed input: 11769.91 toks/s, output: 22.99 toks/s]
Processed prompts:  13%|        | 17/128 [00:00<00:04, 23.63it/s, est. speed input: 11824.73 toks/s, output: 23.09 toks/s]
Processed prompts:  16%|        | 20/128 [00:00<00:04, 23.75it/s, est. speed input: 11892.38 toks/s, output: 23.23 toks/s]
Processed prompts:  18%|        | 23/128 [00:00<00:04, 24.03it/s, est. speed input: 11982.12 toks/s, output: 23.40 toks/s]
Processed prompts:  20%|        | 26/128 [00:01<00:04, 23.60it/s, est. speed input: 11940.07 toks/s, output: 23.32 toks/s]
Processed prompts:  23%|       | 29/128 [00:01<00:04, 23.78it/s, est. speed input: 11984.82 toks/s, output: 23.41 toks/s]
Processed prompts:  25%|       | 32/128 [00:01<00:04, 23.90it/s, est. speed input: 12021.38 toks/s, output: 23.48 toks/s]
Processed prompts:  27%|       | 35/128 [00:01<00:03, 23.94it/s, est. speed input: 12044.19 toks/s, output: 23.52 toks/s]
Processed prompts:  30%|       | 38/128 [00:01<00:03, 24.17it/s, est. speed input: 12090.38 toks/s, output: 23.61 toks/s]
Processed prompts:  32%|      | 41/128 [00:01<00:03, 24.21it/s, est. speed input: 12115.58 toks/s, output: 23.66 toks/s]
Processed prompts:  34%|      | 44/128 [00:01<00:03, 24.27it/s, est. speed input: 12140.38 toks/s, output: 23.71 toks/s]
Processed prompts:  37%|      | 47/128 [00:01<00:03, 24.27it/s, est. speed input: 12158.05 toks/s, output: 23.75 toks/s]
Processed prompts:  39%|      | 50/128 [00:02<00:03, 23.73it/s, est. speed input: 12119.86 toks/s, output: 23.67 toks/s]
Processed prompts:  41%|     | 53/128 [00:02<00:03, 23.95it/s, est. speed input: 12142.29 toks/s, output: 23.72 toks/s]
Processed prompts:  44%|     | 56/128 [00:02<00:02, 24.19it/s, est. speed input: 12170.58 toks/s, output: 23.77 toks/s]
Processed prompts:  46%|     | 59/128 [00:02<00:02, 24.31it/s, est. speed input: 12191.01 toks/s, output: 23.81 toks/s]
Processed prompts:  48%|     | 62/128 [00:02<00:02, 24.20it/s, est. speed input: 12194.70 toks/s, output: 23.82 toks/s]
Processed prompts:  51%|     | 65/128 [00:02<00:02, 24.00it/s, est. speed input: 12187.79 toks/s, output: 23.80 toks/s]
Processed prompts:  53%|    | 68/128 [00:02<00:02, 23.98it/s, est. speed input: 12191.14 toks/s, output: 23.81 toks/s]
Processed prompts:  55%|    | 71/128 [00:02<00:02, 24.02it/s, est. speed input: 12197.06 toks/s, output: 23.82 toks/s]
Processed prompts:  58%|    | 74/128 [00:03<00:02, 24.13it/s, est. speed input: 12209.13 toks/s, output: 23.85 toks/s]
Processed prompts:  60%|    | 77/128 [00:03<00:02, 23.84it/s, est. speed input: 12195.63 toks/s, output: 23.82 toks/s]
Processed prompts:  62%|   | 80/128 [00:03<00:01, 24.12it/s, est. speed input: 12213.72 toks/s, output: 23.85 toks/s]
Processed prompts:  65%|   | 83/128 [00:03<00:01, 24.22it/s, est. speed input: 12224.41 toks/s, output: 23.88 toks/s]
Processed prompts:  67%|   | 86/128 [00:03<00:01, 24.13it/s, est. speed input: 12225.68 toks/s, output: 23.88 toks/s]
Processed prompts:  70%|   | 89/128 [00:03<00:01, 24.18it/s, est. speed input: 12232.64 toks/s, output: 23.89 toks/s]
Processed prompts:  72%|  | 92/128 [00:03<00:01, 24.20it/s, est. speed input: 12238.31 toks/s, output: 23.90 toks/s]
Processed prompts:  74%|  | 95/128 [00:03<00:01, 24.07it/s, est. speed input: 12236.09 toks/s, output: 23.90 toks/s]
Processed prompts:  77%|  | 98/128 [00:04<00:01, 24.06it/s, est. speed input: 12238.46 toks/s, output: 23.90 toks/s]
Processed prompts:  79%|  | 101/128 [00:04<00:01, 23.64it/s, est. speed input: 12219.52 toks/s, output: 23.87 toks/s]
Processed prompts:  81%| | 104/128 [00:04<00:01, 23.87it/s, est. speed input: 12227.63 toks/s, output: 23.88 toks/s]
Processed prompts:  84%| | 107/128 [00:04<00:00, 24.09it/s, est. speed input: 12237.97 toks/s, output: 23.90 toks/s]
Processed prompts:  86%| | 110/128 [00:04<00:00, 24.18it/s, est. speed input: 12244.45 toks/s, output: 23.91 toks/s]
Processed prompts:  88%| | 113/128 [00:04<00:00, 24.14it/s, est. speed input: 12246.50 toks/s, output: 23.92 toks/s]
Processed prompts:  91%| | 116/128 [00:04<00:00, 24.26it/s, est. speed input: 12254.22 toks/s, output: 23.93 toks/s]
Processed prompts:  93%|| 119/128 [00:04<00:00, 24.23it/s, est. speed input: 12257.29 toks/s, output: 23.94 toks/s]
Processed prompts:  95%|| 122/128 [00:05<00:00, 24.08it/s, est. speed input: 12254.62 toks/s, output: 23.93 toks/s]
Processed prompts:  98%|| 125/128 [00:05<00:00, 23.79it/s, est. speed input: 12244.54 toks/s, output: 23.92 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 24.04it/s, est. speed input: 12253.07 toks/s, output: 23.93 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 24.04it/s, est. speed input: 12253.07 toks/s, output: 23.93 toks/s]
Processed prompts: 100%|| 128/128 [00:05<00:00, 23.93it/s, est. speed input: 12253.07 toks/s, output: 23.93 toks/s]
[rank0]:[W126 12:53:17.543620934 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 12:53:19
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:53:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:53:23 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1309430) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1309430) WARNING 01-26 12:53:57 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.33 requests/s, 12641.91 total tokens/s, 12.33 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 12:53:23] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:53:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:53:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:53:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:53:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:53:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:53:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:53:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:53:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:53:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:53:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:53:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:53:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:53:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:53:26] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:53:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:53:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:53:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:53:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:53:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:53:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:53:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:53:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:53:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:53:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:53:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:53:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:53:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:27] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:27] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:27] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:27] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:27] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1309430) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1309430) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.18s/it]
(EngineCore_DP0 pid=1309430) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.18s/it]
(EngineCore_DP0 pid=1309430) 
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1309430) [2026-01-26 12:53:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1309430) 2026-01-26 12:53:57,261 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1309430) 2026-01-26 12:53:57,272 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  29%|       | 37/128 [00:00<00:00, 363.92it/s]
Adding requests:  66%|   | 85/128 [00:00<00:00, 431.35it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 450.21it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:04, 30.38it/s, est. speed input: 31112.92 toks/s, output: 30.38 toks/s]
Processed prompts:   6%|         | 8/128 [00:00<00:07, 16.67it/s, est. speed input: 18308.55 toks/s, output: 17.88 toks/s]
Processed prompts:   8%|         | 10/128 [00:00<00:07, 15.17it/s, est. speed input: 16855.88 toks/s, output: 16.46 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:08, 14.10it/s, est. speed input: 15900.16 toks/s, output: 15.53 toks/s]
Processed prompts:  11%|         | 14/128 [00:00<00:08, 13.57it/s, est. speed input: 15356.50 toks/s, output: 15.00 toks/s]
Processed prompts:  12%|        | 16/128 [00:01<00:08, 13.30it/s, est. speed input: 15017.28 toks/s, output: 14.67 toks/s]
Processed prompts:  14%|        | 18/128 [00:01<00:08, 13.06it/s, est. speed input: 14740.76 toks/s, output: 14.40 toks/s]
Processed prompts:  16%|        | 20/128 [00:01<00:08, 12.94it/s, est. speed input: 14541.34 toks/s, output: 14.20 toks/s]
Processed prompts:  17%|        | 22/128 [00:01<00:08, 12.80it/s, est. speed input: 14361.16 toks/s, output: 14.02 toks/s]
Processed prompts:  19%|        | 24/128 [00:01<00:08, 12.57it/s, est. speed input: 14169.98 toks/s, output: 13.84 toks/s]
Processed prompts:  20%|        | 26/128 [00:01<00:08, 12.48it/s, est. speed input: 14031.10 toks/s, output: 13.70 toks/s]
Processed prompts:  22%|       | 28/128 [00:02<00:07, 12.55it/s, est. speed input: 13955.10 toks/s, output: 13.63 toks/s]
Processed prompts:  23%|       | 30/128 [00:02<00:07, 12.56it/s, est. speed input: 13878.03 toks/s, output: 13.55 toks/s]
Processed prompts:  25%|       | 32/128 [00:02<00:07, 12.53it/s, est. speed input: 13801.69 toks/s, output: 13.48 toks/s]
Processed prompts:  27%|       | 34/128 [00:02<00:07, 12.50it/s, est. speed input: 13733.51 toks/s, output: 13.41 toks/s]
Processed prompts:  28%|       | 36/128 [00:02<00:07, 12.50it/s, est. speed input: 13677.75 toks/s, output: 13.36 toks/s]
Processed prompts:  30%|       | 38/128 [00:02<00:07, 12.32it/s, est. speed input: 13592.18 toks/s, output: 13.27 toks/s]
Processed prompts:  31%|      | 40/128 [00:03<00:07, 12.37it/s, est. speed input: 13549.47 toks/s, output: 13.23 toks/s]
Processed prompts:  33%|      | 42/128 [00:03<00:06, 12.41it/s, est. speed input: 13512.63 toks/s, output: 13.20 toks/s]
Processed prompts:  34%|      | 44/128 [00:03<00:06, 12.44it/s, est. speed input: 13478.55 toks/s, output: 13.16 toks/s]
Processed prompts:  36%|      | 46/128 [00:03<00:06, 12.55it/s, est. speed input: 13462.47 toks/s, output: 13.15 toks/s]
Processed prompts:  38%|      | 48/128 [00:03<00:06, 12.51it/s, est. speed input: 13429.06 toks/s, output: 13.11 toks/s]
Processed prompts:  39%|      | 50/128 [00:03<00:06, 12.43it/s, est. speed input: 13391.73 toks/s, output: 13.08 toks/s]
Processed prompts:  41%|      | 52/128 [00:03<00:06, 12.43it/s, est. speed input: 13364.27 toks/s, output: 13.05 toks/s]
Processed prompts:  42%|     | 54/128 [00:04<00:05, 12.51it/s, est. speed input: 13351.42 toks/s, output: 13.04 toks/s]
Processed prompts:  44%|     | 56/128 [00:04<00:05, 12.46it/s, est. speed input: 13323.85 toks/s, output: 13.01 toks/s]
Processed prompts:  45%|     | 58/128 [00:04<00:05, 12.46it/s, est. speed input: 13304.49 toks/s, output: 12.99 toks/s]
Processed prompts:  47%|     | 60/128 [00:04<00:05, 12.54it/s, est. speed input: 13295.01 toks/s, output: 12.98 toks/s]
Processed prompts:  48%|     | 62/128 [00:04<00:05, 12.52it/s, est. speed input: 13277.58 toks/s, output: 12.97 toks/s]
Processed prompts:  50%|     | 64/128 [00:04<00:05, 12.38it/s, est. speed input: 13246.72 toks/s, output: 12.94 toks/s]
Processed prompts:  52%|    | 66/128 [00:05<00:04, 12.49it/s, est. speed input: 13240.76 toks/s, output: 12.93 toks/s]
Processed prompts:  53%|    | 68/128 [00:05<00:04, 12.51it/s, est. speed input: 13228.78 toks/s, output: 12.92 toks/s]
Processed prompts:  55%|    | 70/128 [00:05<00:04, 12.42it/s, est. speed input: 13207.85 toks/s, output: 12.90 toks/s]
Processed prompts:  56%|    | 72/128 [00:05<00:04, 12.44it/s, est. speed input: 13195.22 toks/s, output: 12.89 toks/s]
Processed prompts:  58%|    | 74/128 [00:05<00:04, 12.49it/s, est. speed input: 13187.49 toks/s, output: 12.88 toks/s]
Processed prompts:  59%|    | 76/128 [00:05<00:04, 12.36it/s, est. speed input: 13164.11 toks/s, output: 12.86 toks/s]
Processed prompts:  61%|    | 78/128 [00:06<00:04, 12.36it/s, est. speed input: 13150.54 toks/s, output: 12.84 toks/s]
Processed prompts:  62%|   | 80/128 [00:06<00:03, 12.41it/s, est. speed input: 13142.70 toks/s, output: 12.83 toks/s]
Processed prompts:  64%|   | 82/128 [00:06<00:03, 12.49it/s, est. speed input: 13138.55 toks/s, output: 12.83 toks/s]
Processed prompts:  66%|   | 84/128 [00:06<00:03, 12.50it/s, est. speed input: 13130.84 toks/s, output: 12.82 toks/s]
Processed prompts:  67%|   | 86/128 [00:06<00:03, 12.53it/s, est. speed input: 13125.54 toks/s, output: 12.82 toks/s]
Processed prompts:  69%|   | 88/128 [00:06<00:03, 12.53it/s, est. speed input: 13118.26 toks/s, output: 12.81 toks/s]
Processed prompts:  70%|   | 90/128 [00:07<00:03, 12.40it/s, est. speed input: 13101.40 toks/s, output: 12.79 toks/s]
Processed prompts:  72%|  | 92/128 [00:07<00:02, 12.45it/s, est. speed input: 13096.05 toks/s, output: 12.79 toks/s]
Processed prompts:  73%|  | 94/128 [00:07<00:02, 12.45it/s, est. speed input: 13088.61 toks/s, output: 12.78 toks/s]
Processed prompts:  75%|  | 96/128 [00:07<00:02, 12.54it/s, est. speed input: 13087.99 toks/s, output: 12.78 toks/s]
Processed prompts:  77%|  | 98/128 [00:07<00:02, 12.48it/s, est. speed input: 13078.35 toks/s, output: 12.77 toks/s]
Processed prompts:  78%|  | 100/128 [00:07<00:02, 12.42it/s, est. speed input: 13068.18 toks/s, output: 12.76 toks/s]
Processed prompts:  80%|  | 102/128 [00:07<00:02, 12.38it/s, est. speed input: 13057.98 toks/s, output: 12.75 toks/s]
Processed prompts:  81%| | 104/128 [00:08<00:01, 12.41it/s, est. speed input: 13052.66 toks/s, output: 12.75 toks/s]
Processed prompts:  83%| | 106/128 [00:08<00:01, 12.43it/s, est. speed input: 13047.34 toks/s, output: 12.74 toks/s]
Processed prompts:  84%| | 108/128 [00:08<00:01, 12.45it/s, est. speed input: 13042.40 toks/s, output: 12.74 toks/s]
Processed prompts:  86%| | 110/128 [00:08<00:01, 12.56it/s, est. speed input: 13044.21 toks/s, output: 12.74 toks/s]
Processed prompts:  88%| | 112/128 [00:08<00:01, 12.51it/s, est. speed input: 13037.49 toks/s, output: 12.73 toks/s]
Processed prompts:  89%| | 114/128 [00:08<00:01, 12.45it/s, est. speed input: 13029.86 toks/s, output: 12.72 toks/s]
Processed prompts:  91%| | 116/128 [00:09<00:00, 12.30it/s, est. speed input: 13015.31 toks/s, output: 12.71 toks/s]
Processed prompts:  92%|| 118/128 [00:09<00:00, 12.40it/s, est. speed input: 13014.56 toks/s, output: 12.71 toks/s]
Processed prompts:  94%|| 120/128 [00:09<00:00, 12.45it/s, est. speed input: 13011.72 toks/s, output: 12.71 toks/s]
Processed prompts:  95%|| 122/128 [00:09<00:00, 12.44it/s, est. speed input: 13006.67 toks/s, output: 12.70 toks/s]
Processed prompts:  97%|| 124/128 [00:09<00:00, 12.41it/s, est. speed input: 13000.77 toks/s, output: 12.70 toks/s]
Processed prompts:  98%|| 126/128 [00:09<00:00, 12.36it/s, est. speed input: 12992.88 toks/s, output: 12.69 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 12.35it/s, est. speed input: 12987.22 toks/s, output: 12.68 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 12.35it/s, est. speed input: 12987.22 toks/s, output: 12.68 toks/s]
Processed prompts: 100%|| 128/128 [00:10<00:00, 12.68it/s, est. speed input: 12987.22 toks/s, output: 12.68 toks/s]
[rank0]:[W126 12:54:08.702500233 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 12:54:10
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:54:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:54:15 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1310345) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1310345) WARNING 01-26 12:54:49 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 12.33 requests/s, 12641.01 total tokens/s, 12.33 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 12:54:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:54:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:54:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:54:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:54:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:54:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:54:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:54:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:54:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:54:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:54:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:54:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:54:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:54:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:54:18] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:54:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:54:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:54:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:54:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:54:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:54:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:54:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:54:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:54:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:54:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:54:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:54:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:54:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:19] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:19] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:19] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:19] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:19] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1310345) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1310345) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.10s/it]
(EngineCore_DP0 pid=1310345) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.10s/it]
(EngineCore_DP0 pid=1310345) 
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1310345) [2026-01-26 12:54:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1310345) 2026-01-26 12:54:48,904 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1310345) 2026-01-26 12:54:48,916 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  14%|        | 37/256 [00:00<00:00, 362.60it/s]
Adding requests:  34%|      | 86/256 [00:00<00:00, 432.90it/s]
Adding requests:  54%|    | 137/256 [00:00<00:00, 464.96it/s]
Adding requests:  74%|  | 189/256 [00:00<00:00, 484.56it/s]
Adding requests:  94%|| 241/256 [00:00<00:00, 495.66it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 475.08it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:04, 50.88it/s, est. speed input: 52116.12 toks/s, output: 50.89 toks/s]
Processed prompts:   5%|         | 12/256 [00:00<00:13, 18.11it/s, est. speed input: 20530.95 toks/s, output: 20.05 toks/s]
Processed prompts:   6%|         | 15/256 [00:00<00:13, 18.24it/s, est. speed input: 20204.63 toks/s, output: 19.73 toks/s]
Processed prompts:   7%|         | 18/256 [00:01<00:16, 14.26it/s, est. speed input: 17079.08 toks/s, output: 16.68 toks/s]
Processed prompts:   8%|         | 20/256 [00:01<00:17, 13.76it/s, est. speed input: 16480.98 toks/s, output: 16.09 toks/s]
Processed prompts:   9%|         | 22/256 [00:01<00:17, 13.45it/s, est. speed input: 16067.62 toks/s, output: 15.69 toks/s]
Processed prompts:   9%|         | 24/256 [00:01<00:17, 13.20it/s, est. speed input: 15737.01 toks/s, output: 15.37 toks/s]
Processed prompts:  10%|         | 26/256 [00:01<00:17, 12.98it/s, est. speed input: 15454.02 toks/s, output: 15.09 toks/s]
Processed prompts:  11%|         | 28/256 [00:01<00:17, 12.78it/s, est. speed input: 15206.29 toks/s, output: 14.85 toks/s]
Processed prompts:  12%|        | 30/256 [00:02<00:17, 12.69it/s, est. speed input: 15013.78 toks/s, output: 14.66 toks/s]
Processed prompts:  12%|        | 32/256 [00:02<00:17, 12.55it/s, est. speed input: 14827.62 toks/s, output: 14.48 toks/s]
Processed prompts:  13%|        | 34/256 [00:02<00:17, 12.49it/s, est. speed input: 14678.72 toks/s, output: 14.33 toks/s]
Processed prompts:  14%|        | 36/256 [00:02<00:17, 12.43it/s, est. speed input: 14543.91 toks/s, output: 14.20 toks/s]
Processed prompts:  15%|        | 38/256 [00:02<00:17, 12.47it/s, est. speed input: 14445.08 toks/s, output: 14.11 toks/s]
Processed prompts:  16%|        | 40/256 [00:02<00:17, 12.53it/s, est. speed input: 14362.96 toks/s, output: 14.03 toks/s]
Processed prompts:  16%|        | 42/256 [00:03<00:17, 12.49it/s, est. speed input: 14275.03 toks/s, output: 13.94 toks/s]
Processed prompts:  17%|        | 44/256 [00:03<00:16, 12.52it/s, est. speed input: 14205.61 toks/s, output: 13.87 toks/s]
Processed prompts:  18%|        | 46/256 [00:03<00:16, 12.45it/s, est. speed input: 14126.32 toks/s, output: 13.80 toks/s]
Processed prompts:  19%|        | 48/256 [00:03<00:16, 12.47it/s, est. speed input: 14066.46 toks/s, output: 13.74 toks/s]
Processed prompts:  20%|        | 50/256 [00:03<00:16, 12.44it/s, est. speed input: 14003.89 toks/s, output: 13.68 toks/s]
Processed prompts:  20%|        | 52/256 [00:03<00:16, 12.47it/s, est. speed input: 13955.39 toks/s, output: 13.63 toks/s]
Processed prompts:  21%|        | 54/256 [00:03<00:16, 12.54it/s, est. speed input: 13918.37 toks/s, output: 13.59 toks/s]
Processed prompts:  22%|       | 56/256 [00:04<00:15, 12.53it/s, est. speed input: 13875.12 toks/s, output: 13.55 toks/s]
Processed prompts:  23%|       | 58/256 [00:04<00:15, 12.50it/s, est. speed input: 13832.39 toks/s, output: 13.51 toks/s]
Processed prompts:  23%|       | 60/256 [00:04<00:15, 12.40it/s, est. speed input: 13781.34 toks/s, output: 13.46 toks/s]
Processed prompts:  24%|       | 62/256 [00:04<00:15, 12.44it/s, est. speed input: 13749.65 toks/s, output: 13.43 toks/s]
Processed prompts:  25%|       | 64/256 [00:04<00:15, 12.43it/s, est. speed input: 13713.81 toks/s, output: 13.39 toks/s]
Processed prompts:  26%|       | 66/256 [00:04<00:15, 12.46it/s, est. speed input: 13685.35 toks/s, output: 13.36 toks/s]
Processed prompts:  27%|       | 68/256 [00:05<00:15, 12.46it/s, est. speed input: 13656.28 toks/s, output: 13.34 toks/s]
Processed prompts:  27%|       | 70/256 [00:05<00:14, 12.46it/s, est. speed input: 13628.55 toks/s, output: 13.31 toks/s]
Processed prompts:  28%|       | 72/256 [00:05<00:14, 12.33it/s, est. speed input: 13588.44 toks/s, output: 13.27 toks/s]
Processed prompts:  29%|       | 74/256 [00:05<00:14, 12.35it/s, est. speed input: 13562.47 toks/s, output: 13.24 toks/s]
Processed prompts:  30%|       | 76/256 [00:05<00:14, 12.34it/s, est. speed input: 13536.38 toks/s, output: 13.22 toks/s]
Processed prompts:  30%|       | 78/256 [00:05<00:14, 12.39it/s, est. speed input: 13516.02 toks/s, output: 13.20 toks/s]
Processed prompts:  31%|      | 80/256 [00:06<00:14, 12.43it/s, est. speed input: 13498.25 toks/s, output: 13.18 toks/s]
Processed prompts:  32%|      | 82/256 [00:06<00:14, 12.40it/s, est. speed input: 13475.34 toks/s, output: 13.16 toks/s]
Processed prompts:  33%|      | 84/256 [00:06<00:13, 12.41it/s, est. speed input: 13456.78 toks/s, output: 13.14 toks/s]
Processed prompts:  34%|      | 86/256 [00:06<00:13, 12.34it/s, est. speed input: 13431.88 toks/s, output: 13.12 toks/s]
Processed prompts:  34%|      | 88/256 [00:06<00:13, 12.40it/s, est. speed input: 13417.64 toks/s, output: 13.10 toks/s]
Processed prompts:  35%|      | 90/256 [00:06<00:13, 12.40it/s, est. speed input: 13401.00 toks/s, output: 13.09 toks/s]
Processed prompts:  36%|      | 92/256 [00:07<00:13, 12.40it/s, est. speed input: 13385.13 toks/s, output: 13.07 toks/s]
Processed prompts:  37%|      | 94/256 [00:07<00:13, 12.45it/s, est. speed input: 13373.18 toks/s, output: 13.06 toks/s]
Processed prompts:  38%|      | 96/256 [00:07<00:12, 12.45it/s, est. speed input: 13359.53 toks/s, output: 13.05 toks/s]
Processed prompts:  38%|      | 98/256 [00:07<00:12, 12.39it/s, est. speed input: 13341.99 toks/s, output: 13.03 toks/s]
Processed prompts:  39%|      | 100/256 [00:07<00:12, 12.42it/s, est. speed input: 13330.64 toks/s, output: 13.02 toks/s]
Processed prompts:  40%|      | 102/256 [00:07<00:12, 12.45it/s, est. speed input: 13320.28 toks/s, output: 13.01 toks/s]
Processed prompts:  41%|      | 104/256 [00:08<00:12, 12.46it/s, est. speed input: 13309.11 toks/s, output: 13.00 toks/s]
Processed prompts:  41%|     | 106/256 [00:08<00:12, 12.46it/s, est. speed input: 13298.51 toks/s, output: 12.99 toks/s]
Processed prompts:  42%|     | 108/256 [00:08<00:11, 12.48it/s, est. speed input: 13289.58 toks/s, output: 12.98 toks/s]
Processed prompts:  43%|     | 110/256 [00:08<00:11, 12.49it/s, est. speed input: 13280.36 toks/s, output: 12.97 toks/s]
Processed prompts:  44%|     | 112/256 [00:08<00:11, 12.30it/s, est. speed input: 13258.95 toks/s, output: 12.95 toks/s]
Processed prompts:  45%|     | 114/256 [00:08<00:11, 12.32it/s, est. speed input: 13247.69 toks/s, output: 12.94 toks/s]
Processed prompts:  45%|     | 116/256 [00:08<00:11, 12.33it/s, est. speed input: 13237.34 toks/s, output: 12.93 toks/s]
Processed prompts:  46%|     | 118/256 [00:09<00:11, 12.36it/s, est. speed input: 13227.98 toks/s, output: 12.92 toks/s]
Processed prompts:  47%|     | 120/256 [00:09<00:10, 12.42it/s, est. speed input: 13221.80 toks/s, output: 12.91 toks/s]
Processed prompts:  48%|     | 122/256 [00:09<00:10, 12.48it/s, est. speed input: 13216.91 toks/s, output: 12.91 toks/s]
Processed prompts:  48%|     | 124/256 [00:09<00:10, 12.33it/s, est. speed input: 13200.77 toks/s, output: 12.89 toks/s]
Processed prompts:  49%|     | 126/256 [00:09<00:10, 12.32it/s, est. speed input: 13190.41 toks/s, output: 12.88 toks/s]
Processed prompts:  50%|     | 128/256 [00:09<00:10, 12.36it/s, est. speed input: 13183.26 toks/s, output: 12.87 toks/s]
Processed prompts:  51%|     | 130/256 [00:10<00:10, 12.35it/s, est. speed input: 13174.57 toks/s, output: 12.87 toks/s]
Processed prompts:  52%|    | 132/256 [00:10<00:10, 12.37it/s, est. speed input: 13166.97 toks/s, output: 12.86 toks/s]
Processed prompts:  52%|    | 134/256 [00:10<00:09, 12.40it/s, est. speed input: 13161.18 toks/s, output: 12.85 toks/s]
Processed prompts:  53%|    | 136/256 [00:10<00:09, 12.42it/s, est. speed input: 13155.33 toks/s, output: 12.85 toks/s]
Processed prompts:  54%|    | 138/256 [00:10<00:09, 12.34it/s, est. speed input: 13144.22 toks/s, output: 12.84 toks/s]
Processed prompts:  55%|    | 140/256 [00:10<00:09, 12.42it/s, est. speed input: 13140.84 toks/s, output: 12.83 toks/s]
Processed prompts:  55%|    | 142/256 [00:11<00:09, 12.40it/s, est. speed input: 13133.87 toks/s, output: 12.83 toks/s]
Processed prompts:  56%|    | 144/256 [00:11<00:09, 12.40it/s, est. speed input: 13127.52 toks/s, output: 12.82 toks/s]
Processed prompts:  57%|    | 146/256 [00:11<00:08, 12.44it/s, est. speed input: 13123.37 toks/s, output: 12.82 toks/s]
Processed prompts:  58%|    | 148/256 [00:11<00:08, 12.43it/s, est. speed input: 13117.37 toks/s, output: 12.81 toks/s]
Processed prompts:  59%|    | 150/256 [00:11<00:08, 12.39it/s, est. speed input: 13110.13 toks/s, output: 12.80 toks/s]
Processed prompts:  59%|    | 152/256 [00:11<00:08, 12.27it/s, est. speed input: 13098.51 toks/s, output: 12.79 toks/s]
Processed prompts:  60%|    | 154/256 [00:12<00:08, 12.33it/s, est. speed input: 13094.17 toks/s, output: 12.79 toks/s]
Processed prompts:  61%|    | 156/256 [00:12<00:08, 12.36it/s, est. speed input: 13089.54 toks/s, output: 12.78 toks/s]
Processed prompts:  62%|   | 158/256 [00:12<00:07, 12.31it/s, est. speed input: 13081.70 toks/s, output: 12.78 toks/s]
Processed prompts:  62%|   | 160/256 [00:12<00:07, 12.31it/s, est. speed input: 13075.50 toks/s, output: 12.77 toks/s]
Processed prompts:  63%|   | 162/256 [00:12<00:07, 12.33it/s, est. speed input: 13070.46 toks/s, output: 12.76 toks/s]
Processed prompts:  64%|   | 164/256 [00:12<00:07, 12.22it/s, est. speed input: 13059.69 toks/s, output: 12.75 toks/s]
Processed prompts:  65%|   | 166/256 [00:13<00:07, 12.30it/s, est. speed input: 13056.60 toks/s, output: 12.75 toks/s]
Processed prompts:  66%|   | 168/256 [00:13<00:07, 12.35it/s, est. speed input: 13053.02 toks/s, output: 12.75 toks/s]
Processed prompts:  66%|   | 170/256 [00:13<00:06, 12.36it/s, est. speed input: 13048.41 toks/s, output: 12.74 toks/s]
Processed prompts:  67%|   | 172/256 [00:13<00:06, 12.41it/s, est. speed input: 13046.00 toks/s, output: 12.74 toks/s]
Processed prompts:  68%|   | 174/256 [00:13<00:06, 12.40it/s, est. speed input: 13041.57 toks/s, output: 12.74 toks/s]
Processed prompts:  69%|   | 176/256 [00:13<00:06, 12.35it/s, est. speed input: 13035.53 toks/s, output: 12.73 toks/s]
Processed prompts:  70%|   | 178/256 [00:13<00:06, 12.32it/s, est. speed input: 13029.58 toks/s, output: 12.72 toks/s]
Processed prompts:  70%|   | 180/256 [00:14<00:06, 12.38it/s, est. speed input: 13027.20 toks/s, output: 12.72 toks/s]
Processed prompts:  71%|   | 182/256 [00:14<00:05, 12.37it/s, est. speed input: 13022.81 toks/s, output: 12.72 toks/s]
Processed prompts:  72%|  | 184/256 [00:14<00:05, 12.38it/s, est. speed input: 13019.34 toks/s, output: 12.71 toks/s]
Processed prompts:  73%|  | 186/256 [00:14<00:05, 12.35it/s, est. speed input: 13014.39 toks/s, output: 12.71 toks/s]
Processed prompts:  73%|  | 188/256 [00:14<00:05, 12.39it/s, est. speed input: 13011.96 toks/s, output: 12.71 toks/s]
Processed prompts:  74%|  | 190/256 [00:14<00:05, 12.27it/s, est. speed input: 13003.90 toks/s, output: 12.70 toks/s]
Processed prompts:  75%|  | 192/256 [00:15<00:05, 12.37it/s, est. speed input: 13002.75 toks/s, output: 12.70 toks/s]
Processed prompts:  76%|  | 194/256 [00:15<00:05, 12.37it/s, est. speed input: 12999.32 toks/s, output: 12.69 toks/s]
Processed prompts:  77%|  | 196/256 [00:15<00:04, 12.37it/s, est. speed input: 12995.81 toks/s, output: 12.69 toks/s]
Processed prompts:  77%|  | 198/256 [00:15<00:04, 12.43it/s, est. speed input: 12994.67 toks/s, output: 12.69 toks/s]
Processed prompts:  78%|  | 200/256 [00:15<00:04, 12.43it/s, est. speed input: 12991.76 toks/s, output: 12.69 toks/s]
Processed prompts:  79%|  | 202/256 [00:15<00:04, 12.41it/s, est. speed input: 12988.43 toks/s, output: 12.68 toks/s]
Processed prompts:  80%|  | 204/256 [00:16<00:04, 12.29it/s, est. speed input: 12981.27 toks/s, output: 12.68 toks/s]
Processed prompts:  80%|  | 206/256 [00:16<00:04, 12.32it/s, est. speed input: 12978.61 toks/s, output: 12.67 toks/s]
Processed prompts:  81%| | 208/256 [00:16<00:03, 12.38it/s, est. speed input: 12976.84 toks/s, output: 12.67 toks/s]
Processed prompts:  82%| | 210/256 [00:16<00:03, 12.42it/s, est. speed input: 12975.46 toks/s, output: 12.67 toks/s]
Processed prompts:  83%| | 212/256 [00:16<00:03, 12.45it/s, est. speed input: 12974.00 toks/s, output: 12.67 toks/s]
Processed prompts:  84%| | 214/256 [00:16<00:03, 12.43it/s, est. speed input: 12971.22 toks/s, output: 12.67 toks/s]
Processed prompts:  84%| | 216/256 [00:17<00:03, 12.26it/s, est. speed input: 12963.28 toks/s, output: 12.66 toks/s]
Processed prompts:  85%| | 218/256 [00:17<00:03, 12.33it/s, est. speed input: 12961.58 toks/s, output: 12.66 toks/s]
Processed prompts:  86%| | 220/256 [00:17<00:02, 12.36it/s, est. speed input: 12959.39 toks/s, output: 12.66 toks/s]
Processed prompts:  87%| | 222/256 [00:17<00:02, 12.37it/s, est. speed input: 12957.02 toks/s, output: 12.65 toks/s]
Processed prompts:  88%| | 224/256 [00:17<00:02, 12.37it/s, est. speed input: 12954.22 toks/s, output: 12.65 toks/s]
Processed prompts:  88%| | 226/256 [00:17<00:02, 12.47it/s, est. speed input: 12954.90 toks/s, output: 12.65 toks/s]
Processed prompts:  89%| | 228/256 [00:18<00:02, 12.48it/s, est. speed input: 12953.56 toks/s, output: 12.65 toks/s]
Processed prompts:  90%| | 230/256 [00:18<00:02, 12.36it/s, est. speed input: 12948.39 toks/s, output: 12.64 toks/s]
Processed prompts:  91%| | 232/256 [00:18<00:01, 12.37it/s, est. speed input: 12946.16 toks/s, output: 12.64 toks/s]
Processed prompts:  91%|| 234/256 [00:18<00:01, 12.41it/s, est. speed input: 12944.82 toks/s, output: 12.64 toks/s]
Processed prompts:  92%|| 236/256 [00:18<00:01, 12.37it/s, est. speed input: 12941.74 toks/s, output: 12.64 toks/s]
Processed prompts:  93%|| 238/256 [00:18<00:01, 12.39it/s, est. speed input: 12939.79 toks/s, output: 12.64 toks/s]
Processed prompts:  94%|| 240/256 [00:18<00:01, 12.39it/s, est. speed input: 12937.68 toks/s, output: 12.63 toks/s]
Processed prompts:  95%|| 242/256 [00:19<00:01, 12.27it/s, est. speed input: 12932.13 toks/s, output: 12.63 toks/s]
Processed prompts:  95%|| 244/256 [00:19<00:00, 12.27it/s, est. speed input: 12928.99 toks/s, output: 12.63 toks/s]
Processed prompts:  96%|| 246/256 [00:19<00:00, 12.28it/s, est. speed input: 12926.17 toks/s, output: 12.62 toks/s]
Processed prompts:  97%|| 248/256 [00:19<00:00, 12.35it/s, est. speed input: 12925.28 toks/s, output: 12.62 toks/s]
Processed prompts:  98%|| 250/256 [00:19<00:00, 12.35it/s, est. speed input: 12922.98 toks/s, output: 12.62 toks/s]
Processed prompts:  98%|| 252/256 [00:19<00:00, 12.37it/s, est. speed input: 12921.25 toks/s, output: 12.62 toks/s]
Processed prompts:  99%|| 254/256 [00:20<00:00, 12.38it/s, est. speed input: 12919.60 toks/s, output: 12.62 toks/s]
Processed prompts: 100%|| 256/256 [00:20<00:00, 12.38it/s, est. speed input: 12966.01 toks/s, output: 12.66 toks/s]
Processed prompts: 100%|| 256/256 [00:20<00:00, 12.66it/s, est. speed input: 12966.01 toks/s, output: 12.66 toks/s]
[rank0]:[W126 12:55:10.926272593 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 12:55:13
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:55:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:55:18 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1311404) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1311404) WARNING 01-26 12:55:52 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.84 requests/s, 12135.93 total tokens/s, 11.84 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 12:55:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:55:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:55:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:55:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:55:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:55:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:55:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:55:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:55:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:55:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:55:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:55:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:55:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:55:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:55:21] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:55:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:55:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:55:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:55:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:55:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:55:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:55:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:55:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:55:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:55:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:55:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:55:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:55:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1311404) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1311404) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.26s/it]
(EngineCore_DP0 pid=1311404) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.26s/it]
(EngineCore_DP0 pid=1311404) 
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1311404) [2026-01-26 12:55:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1311404) 2026-01-26 12:55:52,009 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1311404) 2026-01-26 12:55:52,020 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   7%|         | 37/512 [00:00<00:01, 361.76it/s]
Adding requests:  16%|        | 83/512 [00:00<00:01, 417.61it/s]
Adding requests:  26%|       | 135/512 [00:00<00:00, 463.74it/s]
Adding requests:  37%|      | 187/512 [00:00<00:00, 485.30it/s]
Adding requests:  47%|     | 242/512 [00:00<00:00, 505.60it/s]
Adding requests:  57%|    | 293/512 [00:00<00:00, 493.69it/s]
Adding requests:  67%|   | 345/512 [00:00<00:00, 500.84it/s]
Adding requests:  78%|  | 398/512 [00:00<00:00, 508.56it/s]
Adding requests:  88%| | 449/512 [00:00<00:00, 506.28it/s]
Adding requests:  98%|| 500/512 [00:01<00:00, 503.32it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 491.52it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 10/512 [00:00<00:06, 74.05it/s, est. speed input: 75840.20 toks/s, output: 74.06 toks/s]
Processed prompts:   4%|         | 18/512 [00:00<00:25, 19.60it/s, est. speed input: 22870.41 toks/s, output: 22.33 toks/s]
Processed prompts:   4%|         | 22/512 [00:01<00:29, 16.71it/s, est. speed input: 19800.09 toks/s, output: 19.34 toks/s]
Processed prompts:   5%|         | 26/512 [00:01<00:32, 15.06it/s, est. speed input: 18108.20 toks/s, output: 17.68 toks/s]
Processed prompts:   6%|         | 30/512 [00:01<00:34, 13.96it/s, est. speed input: 16985.31 toks/s, output: 16.59 toks/s]
Processed prompts:   7%|         | 34/512 [00:02<00:35, 13.35it/s, est. speed input: 16268.11 toks/s, output: 15.89 toks/s]
Processed prompts:   7%|         | 38/512 [00:02<00:36, 12.89it/s, est. speed input: 15715.24 toks/s, output: 15.35 toks/s]
Processed prompts:   8%|         | 42/512 [00:02<00:37, 12.57it/s, est. speed input: 15287.52 toks/s, output: 14.93 toks/s]
Processed prompts:   9%|         | 46/512 [00:03<00:37, 12.36it/s, est. speed input: 14955.96 toks/s, output: 14.61 toks/s]
Processed prompts:  10%|         | 50/512 [00:03<00:37, 12.23it/s, est. speed input: 14693.88 toks/s, output: 14.35 toks/s]
Processed prompts:  11%|         | 54/512 [00:03<00:37, 12.15it/s, est. speed input: 14478.41 toks/s, output: 14.14 toks/s]
Processed prompts:  11%|        | 58/512 [00:04<00:37, 12.10it/s, est. speed input: 14302.63 toks/s, output: 13.97 toks/s]
Processed prompts:  12%|        | 62/512 [00:04<00:37, 12.06it/s, est. speed input: 14149.09 toks/s, output: 13.82 toks/s]
Processed prompts:  13%|        | 66/512 [00:04<00:37, 11.97it/s, est. speed input: 14000.76 toks/s, output: 13.67 toks/s]
Processed prompts:  14%|        | 70/512 [00:05<00:36, 12.00it/s, est. speed input: 13895.19 toks/s, output: 13.57 toks/s]
Processed prompts:  14%|        | 74/512 [00:05<00:36, 12.02it/s, est. speed input: 13802.85 toks/s, output: 13.48 toks/s]
Processed prompts:  15%|        | 78/512 [00:05<00:36, 11.99it/s, est. speed input: 13711.18 toks/s, output: 13.39 toks/s]
Processed prompts:  16%|        | 82/512 [00:06<00:36, 11.94it/s, est. speed input: 13623.34 toks/s, output: 13.30 toks/s]
Processed prompts:  17%|        | 86/512 [00:06<00:35, 11.95it/s, est. speed input: 13552.79 toks/s, output: 13.24 toks/s]
Processed prompts:  18%|        | 90/512 [00:06<00:35, 11.99it/s, est. speed input: 13496.33 toks/s, output: 13.18 toks/s]
Processed prompts:  18%|        | 94/512 [00:07<00:34, 11.98it/s, est. speed input: 13437.41 toks/s, output: 13.12 toks/s]
Processed prompts:  19%|        | 98/512 [00:07<00:34, 11.96it/s, est. speed input: 13381.94 toks/s, output: 13.07 toks/s]
Processed prompts:  20%|        | 102/512 [00:07<00:34, 11.96it/s, est. speed input: 13333.08 toks/s, output: 13.02 toks/s]
Processed prompts:  21%|        | 106/512 [00:08<00:34, 11.92it/s, est. speed input: 13282.60 toks/s, output: 12.97 toks/s]
Processed prompts:  21%|       | 110/512 [00:08<00:33, 11.92it/s, est. speed input: 13239.72 toks/s, output: 12.93 toks/s]
Processed prompts:  22%|       | 114/512 [00:08<00:33, 11.91it/s, est. speed input: 13199.00 toks/s, output: 12.89 toks/s]
Processed prompts:  23%|       | 118/512 [00:09<00:33, 11.89it/s, est. speed input: 13159.71 toks/s, output: 12.85 toks/s]
Processed prompts:  24%|       | 122/512 [00:09<00:32, 11.94it/s, est. speed input: 13130.95 toks/s, output: 12.82 toks/s]
Processed prompts:  25%|       | 126/512 [00:09<00:32, 11.92it/s, est. speed input: 13097.64 toks/s, output: 12.79 toks/s]
Processed prompts:  25%|       | 130/512 [00:10<00:32, 11.88it/s, est. speed input: 13063.49 toks/s, output: 12.76 toks/s]
Processed prompts:  26%|       | 134/512 [00:10<00:31, 11.92it/s, est. speed input: 13039.92 toks/s, output: 12.73 toks/s]
Processed prompts:  27%|       | 138/512 [00:10<00:31, 11.92it/s, est. speed input: 13013.93 toks/s, output: 12.71 toks/s]
Processed prompts:  28%|       | 142/512 [00:11<00:31, 11.92it/s, est. speed input: 12989.97 toks/s, output: 12.69 toks/s]
Processed prompts:  29%|       | 146/512 [00:11<00:30, 11.91it/s, est. speed input: 12965.55 toks/s, output: 12.66 toks/s]
Processed prompts:  29%|       | 150/512 [00:11<00:30, 11.92it/s, est. speed input: 12944.93 toks/s, output: 12.64 toks/s]
Processed prompts:  30%|       | 154/512 [00:12<00:30, 11.89it/s, est. speed input: 12921.99 toks/s, output: 12.62 toks/s]
Processed prompts:  31%|       | 158/512 [00:12<00:29, 11.91it/s, est. speed input: 12904.15 toks/s, output: 12.60 toks/s]
Processed prompts:  32%|      | 162/512 [00:12<00:29, 11.92it/s, est. speed input: 12886.26 toks/s, output: 12.58 toks/s]
Processed prompts:  32%|      | 166/512 [00:13<00:28, 11.94it/s, est. speed input: 12870.98 toks/s, output: 12.57 toks/s]
Processed prompts:  33%|      | 170/512 [00:13<00:28, 11.90it/s, est. speed input: 12851.21 toks/s, output: 12.55 toks/s]
Processed prompts:  34%|      | 174/512 [00:13<00:28, 11.89it/s, est. speed input: 12834.50 toks/s, output: 12.53 toks/s]
Processed prompts:  35%|      | 178/512 [00:14<00:28, 11.90it/s, est. speed input: 12819.61 toks/s, output: 12.52 toks/s]
Processed prompts:  36%|      | 182/512 [00:14<00:27, 11.86it/s, est. speed input: 12801.59 toks/s, output: 12.50 toks/s]
Processed prompts:  36%|      | 186/512 [00:14<00:27, 11.87it/s, est. speed input: 12787.77 toks/s, output: 12.49 toks/s]
Processed prompts:  37%|      | 190/512 [00:15<00:27, 11.88it/s, est. speed input: 12774.53 toks/s, output: 12.48 toks/s]
Processed prompts:  38%|      | 194/512 [00:15<00:26, 11.88it/s, est. speed input: 12761.35 toks/s, output: 12.46 toks/s]
Processed prompts:  39%|      | 198/512 [00:15<00:26, 11.89it/s, est. speed input: 12749.21 toks/s, output: 12.45 toks/s]
Processed prompts:  39%|      | 202/512 [00:16<00:26, 11.91it/s, est. speed input: 12738.73 toks/s, output: 12.44 toks/s]
Processed prompts:  40%|      | 206/512 [00:16<00:25, 11.88it/s, est. speed input: 12725.70 toks/s, output: 12.43 toks/s]
Processed prompts:  41%|      | 210/512 [00:16<00:25, 11.87it/s, est. speed input: 12714.19 toks/s, output: 12.42 toks/s]
Processed prompts:  42%|     | 214/512 [00:17<00:25, 11.91it/s, est. speed input: 12705.64 toks/s, output: 12.41 toks/s]
Processed prompts:  43%|     | 218/512 [00:17<00:24, 11.87it/s, est. speed input: 12693.60 toks/s, output: 12.40 toks/s]
Processed prompts:  43%|     | 222/512 [00:17<00:24, 11.87it/s, est. speed input: 12683.53 toks/s, output: 12.39 toks/s]
Processed prompts:  44%|     | 226/512 [00:18<00:24, 11.87it/s, est. speed input: 12673.87 toks/s, output: 12.38 toks/s]
Processed prompts:  45%|     | 230/512 [00:18<00:23, 11.84it/s, est. speed input: 12662.46 toks/s, output: 12.37 toks/s]
Processed prompts:  46%|     | 234/512 [00:18<00:23, 11.87it/s, est. speed input: 12654.35 toks/s, output: 12.36 toks/s]
Processed prompts:  46%|     | 238/512 [00:19<00:23, 11.89it/s, est. speed input: 12647.33 toks/s, output: 12.35 toks/s]
Processed prompts:  47%|     | 242/512 [00:19<00:22, 11.91it/s, est. speed input: 12640.36 toks/s, output: 12.34 toks/s]
Processed prompts:  48%|     | 246/512 [00:19<00:22, 11.87it/s, est. speed input: 12630.29 toks/s, output: 12.33 toks/s]
Processed prompts:  49%|     | 250/512 [00:20<00:22, 11.89it/s, est. speed input: 12623.46 toks/s, output: 12.33 toks/s]
Processed prompts:  50%|     | 254/512 [00:20<00:21, 11.95it/s, est. speed input: 12619.63 toks/s, output: 12.32 toks/s]
Processed prompts:  50%|     | 258/512 [00:20<00:21, 11.91it/s, est. speed input: 12611.05 toks/s, output: 12.32 toks/s]
Processed prompts:  51%|     | 262/512 [00:21<00:21, 11.89it/s, est. speed input: 12603.43 toks/s, output: 12.31 toks/s]
Processed prompts:  52%|    | 266/512 [00:21<00:20, 11.92it/s, est. speed input: 12598.34 toks/s, output: 12.30 toks/s]
Processed prompts:  53%|    | 270/512 [00:21<00:20, 11.84it/s, est. speed input: 12588.14 toks/s, output: 12.29 toks/s]
Processed prompts:  54%|    | 274/512 [00:22<00:20, 11.88it/s, est. speed input: 12583.04 toks/s, output: 12.29 toks/s]
Processed prompts:  54%|    | 278/512 [00:22<00:19, 11.87it/s, est. speed input: 12576.32 toks/s, output: 12.28 toks/s]
Processed prompts:  55%|    | 282/512 [00:22<00:19, 11.86it/s, est. speed input: 12569.81 toks/s, output: 12.28 toks/s]
Processed prompts:  56%|    | 286/512 [00:23<00:19, 11.87it/s, est. speed input: 12564.14 toks/s, output: 12.27 toks/s]
Processed prompts:  57%|    | 290/512 [00:23<00:18, 11.89it/s, est. speed input: 12559.36 toks/s, output: 12.26 toks/s]
Processed prompts:  57%|    | 294/512 [00:23<00:18, 11.84it/s, est. speed input: 12551.47 toks/s, output: 12.26 toks/s]
Processed prompts:  58%|    | 298/512 [00:24<00:17, 11.90it/s, est. speed input: 12548.61 toks/s, output: 12.25 toks/s]
Processed prompts:  59%|    | 302/512 [00:24<00:17, 11.93it/s, est. speed input: 12544.83 toks/s, output: 12.25 toks/s]
Processed prompts:  60%|    | 306/512 [00:24<00:17, 11.87it/s, est. speed input: 12537.83 toks/s, output: 12.24 toks/s]
Processed prompts:  61%|    | 310/512 [00:25<00:16, 11.90it/s, est. speed input: 12534.01 toks/s, output: 12.24 toks/s]
Processed prompts:  61%|   | 314/512 [00:25<00:16, 11.93it/s, est. speed input: 12530.92 toks/s, output: 12.24 toks/s]
Processed prompts:  62%|   | 318/512 [00:25<00:16, 11.91it/s, est. speed input: 12525.79 toks/s, output: 12.23 toks/s]
Processed prompts:  63%|   | 322/512 [00:26<00:16, 11.85it/s, est. speed input: 12519.19 toks/s, output: 12.23 toks/s]
Processed prompts:  64%|   | 326/512 [00:26<00:15, 11.90it/s, est. speed input: 12516.37 toks/s, output: 12.22 toks/s]
Processed prompts:  64%|   | 330/512 [00:27<00:15, 11.91it/s, est. speed input: 12512.63 toks/s, output: 12.22 toks/s]
Processed prompts:  65%|   | 334/512 [00:27<00:15, 11.85it/s, est. speed input: 12506.10 toks/s, output: 12.21 toks/s]
Processed prompts:  66%|   | 338/512 [00:27<00:14, 11.87it/s, est. speed input: 12502.28 toks/s, output: 12.21 toks/s]
Processed prompts:  67%|   | 342/512 [00:27<00:13, 12.40it/s, est. speed input: 12519.76 toks/s, output: 12.23 toks/s]
Processed prompts:  68%|   | 346/512 [00:28<00:13, 12.24it/s, est. speed input: 12515.48 toks/s, output: 12.22 toks/s]
Processed prompts:  68%|   | 350/512 [00:28<00:13, 12.18it/s, est. speed input: 12513.50 toks/s, output: 12.22 toks/s]
Processed prompts:  69%|   | 354/512 [00:28<00:13, 12.10it/s, est. speed input: 12509.63 toks/s, output: 12.22 toks/s]
Processed prompts:  70%|   | 358/512 [00:29<00:12, 12.01it/s, est. speed input: 12505.07 toks/s, output: 12.21 toks/s]
Processed prompts:  71%|   | 362/512 [00:29<00:12, 11.98it/s, est. speed input: 12501.42 toks/s, output: 12.21 toks/s]
Processed prompts:  71%|  | 366/512 [00:29<00:12, 11.95it/s, est. speed input: 12497.72 toks/s, output: 12.20 toks/s]
Processed prompts:  72%|  | 370/512 [00:30<00:11, 11.90it/s, est. speed input: 12492.83 toks/s, output: 12.20 toks/s]
Processed prompts:  73%|  | 374/512 [00:30<00:11, 11.89it/s, est. speed input: 12489.25 toks/s, output: 12.20 toks/s]
Processed prompts:  74%|  | 378/512 [00:31<00:11, 11.46it/s, est. speed input: 12468.90 toks/s, output: 12.18 toks/s]
Processed prompts:  75%|  | 382/512 [00:31<00:12, 10.35it/s, est. speed input: 12411.27 toks/s, output: 12.12 toks/s]
Processed prompts:  75%|  | 386/512 [00:31<00:11, 10.75it/s, est. speed input: 12408.00 toks/s, output: 12.12 toks/s]
Processed prompts:  76%|  | 390/512 [00:32<00:11, 11.06it/s, est. speed input: 12405.23 toks/s, output: 12.11 toks/s]
Processed prompts:  77%|  | 394/512 [00:32<00:10, 11.24it/s, est. speed input: 12400.48 toks/s, output: 12.11 toks/s]
Processed prompts:  78%|  | 398/512 [00:32<00:09, 11.43it/s, est. speed input: 12398.21 toks/s, output: 12.11 toks/s]
Processed prompts:  79%|  | 402/512 [00:33<00:09, 11.56it/s, est. speed input: 12395.84 toks/s, output: 12.11 toks/s]
Processed prompts:  79%|  | 406/512 [00:33<00:09, 11.63it/s, est. speed input: 12392.68 toks/s, output: 12.10 toks/s]
Processed prompts:  80%|  | 410/512 [00:33<00:08, 11.71it/s, est. speed input: 12390.78 toks/s, output: 12.10 toks/s]
Processed prompts:  81%|  | 414/512 [00:34<00:08, 11.77it/s, est. speed input: 12388.71 toks/s, output: 12.10 toks/s]
Processed prompts:  82%| | 418/512 [00:34<00:07, 11.77it/s, est. speed input: 12385.31 toks/s, output: 12.10 toks/s]
Processed prompts:  82%| | 422/512 [00:34<00:07, 11.84it/s, est. speed input: 12384.50 toks/s, output: 12.09 toks/s]
Processed prompts:  83%| | 426/512 [00:35<00:07, 11.85it/s, est. speed input: 12382.26 toks/s, output: 12.09 toks/s]
Processed prompts:  84%| | 430/512 [00:35<00:06, 11.82it/s, est. speed input: 12379.09 toks/s, output: 12.09 toks/s]
Processed prompts:  85%| | 434/512 [00:35<00:06, 11.81it/s, est. speed input: 12376.27 toks/s, output: 12.09 toks/s]
Processed prompts:  86%| | 438/512 [00:36<00:06, 11.85it/s, est. speed input: 12374.82 toks/s, output: 12.08 toks/s]
Processed prompts:  86%| | 442/512 [00:36<00:05, 11.89it/s, est. speed input: 12373.78 toks/s, output: 12.08 toks/s]
Processed prompts:  87%| | 446/512 [00:36<00:05, 11.84it/s, est. speed input: 12370.37 toks/s, output: 12.08 toks/s]
Processed prompts:  88%| | 450/512 [00:37<00:04, 12.49it/s, est. speed input: 12387.78 toks/s, output: 12.10 toks/s]
Processed prompts:  89%| | 454/512 [00:37<00:04, 12.29it/s, est. speed input: 12385.38 toks/s, output: 12.10 toks/s]
Processed prompts:  89%| | 458/512 [00:37<00:04, 12.11it/s, est. speed input: 12381.84 toks/s, output: 12.09 toks/s]
Processed prompts:  90%| | 462/512 [00:38<00:04, 12.04it/s, est. speed input: 12379.86 toks/s, output: 12.09 toks/s]
Processed prompts:  91%| | 466/512 [00:38<00:03, 12.02it/s, est. speed input: 12378.95 toks/s, output: 12.09 toks/s]
Processed prompts:  92%|| 470/512 [00:38<00:03, 11.93it/s, est. speed input: 12375.66 toks/s, output: 12.09 toks/s]
Processed prompts:  93%|| 474/512 [00:39<00:03, 11.91it/s, est. speed input: 12373.80 toks/s, output: 12.08 toks/s]
Processed prompts:  93%|| 478/512 [00:39<00:02, 11.90it/s, est. speed input: 12371.80 toks/s, output: 12.08 toks/s]
Processed prompts:  94%|| 482/512 [00:39<00:02, 11.85it/s, est. speed input: 12368.89 toks/s, output: 12.08 toks/s]
Processed prompts:  95%|| 486/512 [00:40<00:02, 11.86it/s, est. speed input: 12367.10 toks/s, output: 12.08 toks/s]
Processed prompts:  96%|| 490/512 [00:40<00:01, 11.89it/s, est. speed input: 12366.06 toks/s, output: 12.08 toks/s]
Processed prompts:  96%|| 494/512 [00:40<00:01, 11.83it/s, est. speed input: 12362.82 toks/s, output: 12.07 toks/s]
Processed prompts:  97%|| 498/512 [00:41<00:01, 11.87it/s, est. speed input: 12362.00 toks/s, output: 12.07 toks/s]
Processed prompts:  98%|| 502/512 [00:41<00:00, 11.91it/s, est. speed input: 12361.42 toks/s, output: 12.07 toks/s]
Processed prompts:  99%|| 506/512 [00:41<00:00, 11.91it/s, est. speed input: 12360.07 toks/s, output: 12.07 toks/s]
Processed prompts: 100%|| 510/512 [00:42<00:00, 12.54it/s, est. speed input: 12375.21 toks/s, output: 12.09 toks/s]
Processed prompts: 100%|| 512/512 [00:42<00:00, 12.54it/s, est. speed input: 12423.71 toks/s, output: 12.13 toks/s]
Processed prompts: 100%|| 512/512 [00:42<00:00, 12.13it/s, est. speed input: 12423.71 toks/s, output: 12.13 toks/s]
[rank0]:[W126 12:56:36.558845581 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 12:56:38
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:56:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:56:45 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1312809) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1312809) WARNING 01-26 12:57:20 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.59 requests/s, 11882.06 total tokens/s, 11.59 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 12:56:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:56:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:56:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:56:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:56:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:56:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:56:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:56:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:56:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:56:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:56:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:56:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:56:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:56:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:56:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:56:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:56:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:56:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:56:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:56:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:56:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:56:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:56:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:56:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:56:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:56:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:56:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:56:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1312809) [2026-01-26 12:56:49] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1312809) [2026-01-26 12:56:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1312809) [2026-01-26 12:56:49] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1312809) [2026-01-26 12:56:49] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1312809) [2026-01-26 12:56:49] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1312809) [2026-01-26 12:56:49] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1312809) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1312809) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.07s/it]
(EngineCore_DP0 pid=1312809) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.07s/it]
(EngineCore_DP0 pid=1312809) 
(EngineCore_DP0 pid=1312809) [2026-01-26 12:57:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1312809) [2026-01-26 12:57:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1312809) [2026-01-26 12:57:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1312809) [2026-01-26 12:57:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1312809) [2026-01-26 12:57:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1312809) [2026-01-26 12:57:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1312809) [2026-01-26 12:57:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1312809) [2026-01-26 12:57:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1312809) 2026-01-26 12:57:19,198 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1312809) 2026-01-26 12:57:19,269 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 60/1024 [00:00<00:01, 591.51it/s]
Adding requests:  12%|        | 120/1024 [00:00<00:01, 506.49it/s]
Adding requests:  17%|        | 172/1024 [00:00<00:01, 491.20it/s]
Adding requests:  22%|       | 223/1024 [00:00<00:01, 496.83it/s]
Adding requests:  27%|       | 275/1024 [00:00<00:01, 501.35it/s]
Adding requests:  32%|      | 326/1024 [00:00<00:01, 496.43it/s]
Adding requests:  37%|      | 376/1024 [00:00<00:01, 495.03it/s]
Adding requests:  42%|     | 426/1024 [00:00<00:01, 493.48it/s]
Adding requests:  46%|     | 476/1024 [00:00<00:01, 487.52it/s]
Adding requests:  51%|    | 525/1024 [00:01<00:01, 480.97it/s]
Adding requests:  56%|    | 574/1024 [00:01<00:00, 467.28it/s]
Adding requests:  61%|    | 627/1024 [00:01<00:00, 484.85it/s]
Adding requests:  66%|   | 676/1024 [00:01<00:00, 484.35it/s]
Adding requests:  71%|   | 727/1024 [00:01<00:00, 491.84it/s]
Adding requests:  76%|  | 777/1024 [00:01<00:00, 484.28it/s]
Adding requests:  81%|  | 826/1024 [00:01<00:00, 468.84it/s]
Adding requests:  85%| | 874/1024 [00:01<00:00, 468.51it/s]
Adding requests:  90%| | 924/1024 [00:01<00:00, 475.67it/s]
Adding requests:  95%|| 972/1024 [00:02<00:00, 464.01it/s]
Adding requests: 100%|| 1023/1024 [00:02<00:00, 476.64it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 484.51it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 18/1024 [00:00<00:07, 134.67it/s, est. speed input: 137914.85 toks/s, output: 134.67 toks/s]
Processed prompts:   3%|         | 32/1024 [00:00<00:29, 34.15it/s, est. speed input: 40006.20 toks/s, output: 39.07 toks/s]   
Processed prompts:   4%|         | 39/1024 [00:01<00:47, 20.87it/s, est. speed input: 26601.54 toks/s, output: 25.98 toks/s]
Processed prompts:   4%|         | 44/1024 [00:02<01:06, 14.80it/s, est. speed input: 20560.22 toks/s, output: 20.08 toks/s]
Processed prompts:   5%|         | 50/1024 [00:02<01:18, 12.44it/s, est. speed input: 17781.13 toks/s, output: 17.36 toks/s]
Processed prompts:   6%|         | 58/1024 [00:03<01:19, 12.18it/s, est. speed input: 16672.41 toks/s, output: 16.28 toks/s]
Processed prompts:   6%|         | 66/1024 [00:04<01:19, 12.01it/s, est. speed input: 15909.13 toks/s, output: 15.54 toks/s]
Processed prompts:   7%|         | 74/1024 [00:04<01:19, 11.88it/s, est. speed input: 15347.68 toks/s, output: 14.99 toks/s]
Processed prompts:   8%|         | 82/1024 [00:05<01:19, 11.81it/s, est. speed input: 14934.73 toks/s, output: 14.58 toks/s]
Processed prompts:   9%|         | 90/1024 [00:06<01:19, 11.73it/s, est. speed input: 14593.38 toks/s, output: 14.25 toks/s]
Processed prompts:  10%|         | 98/1024 [00:07<01:19, 11.69it/s, est. speed input: 14325.84 toks/s, output: 13.99 toks/s]
Processed prompts:  10%|         | 106/1024 [00:07<01:18, 11.67it/s, est. speed input: 14110.42 toks/s, output: 13.78 toks/s]
Processed prompts:  11%|         | 114/1024 [00:08<01:18, 11.65it/s, est. speed input: 13927.49 toks/s, output: 13.60 toks/s]
Processed prompts:  12%|        | 122/1024 [00:09<01:17, 11.64it/s, est. speed input: 13772.53 toks/s, output: 13.45 toks/s]
Processed prompts:  13%|        | 130/1024 [00:09<01:16, 11.64it/s, est. speed input: 13641.71 toks/s, output: 13.32 toks/s]
Processed prompts:  13%|        | 138/1024 [00:10<01:16, 11.60it/s, est. speed input: 13518.06 toks/s, output: 13.20 toks/s]
Processed prompts:  14%|        | 146/1024 [00:11<01:15, 11.60it/s, est. speed input: 13416.52 toks/s, output: 13.10 toks/s]
Processed prompts:  15%|        | 154/1024 [00:11<01:14, 11.63it/s, est. speed input: 13334.34 toks/s, output: 13.02 toks/s]
Processed prompts:  16%|        | 162/1024 [00:12<01:14, 11.62it/s, est. speed input: 13253.07 toks/s, output: 12.94 toks/s]
Processed prompts:  17%|        | 170/1024 [00:13<01:13, 11.63it/s, est. speed input: 13185.10 toks/s, output: 12.88 toks/s]
Processed prompts:  17%|        | 178/1024 [00:13<01:12, 11.60it/s, est. speed input: 13116.71 toks/s, output: 12.81 toks/s]
Processed prompts:  18%|        | 186/1024 [00:14<01:12, 11.58it/s, est. speed input: 13054.55 toks/s, output: 12.75 toks/s]
Processed prompts:  19%|        | 194/1024 [00:15<01:11, 11.62it/s, est. speed input: 13006.28 toks/s, output: 12.70 toks/s]
Processed prompts:  20%|        | 202/1024 [00:15<01:10, 11.60it/s, est. speed input: 12956.25 toks/s, output: 12.65 toks/s]
Processed prompts:  21%|        | 210/1024 [00:16<01:10, 11.59it/s, est. speed input: 12909.99 toks/s, output: 12.61 toks/s]
Processed prompts:  21%|       | 218/1024 [00:17<01:09, 11.60it/s, est. speed input: 12870.18 toks/s, output: 12.57 toks/s]
Processed prompts:  22%|       | 226/1024 [00:18<01:08, 11.59it/s, est. speed input: 12830.52 toks/s, output: 12.53 toks/s]
Processed prompts:  23%|       | 234/1024 [00:18<01:08, 11.57it/s, est. speed input: 12792.46 toks/s, output: 12.49 toks/s]
Processed prompts:  24%|       | 242/1024 [00:19<01:07, 11.59it/s, est. speed input: 12761.28 toks/s, output: 12.46 toks/s]
Processed prompts:  24%|       | 250/1024 [00:20<01:06, 11.57it/s, est. speed input: 12728.45 toks/s, output: 12.43 toks/s]
Processed prompts:  25%|       | 258/1024 [00:20<01:06, 11.57it/s, est. speed input: 12699.54 toks/s, output: 12.40 toks/s]
Processed prompts:  26%|       | 266/1024 [00:21<01:05, 11.60it/s, est. speed input: 12675.22 toks/s, output: 12.38 toks/s]
Processed prompts:  27%|       | 274/1024 [00:22<01:04, 11.58it/s, est. speed input: 12648.77 toks/s, output: 12.35 toks/s]
Processed prompts:  28%|       | 282/1024 [00:22<01:04, 11.58it/s, est. speed input: 12624.87 toks/s, output: 12.33 toks/s]
Processed prompts:  28%|       | 290/1024 [00:23<01:03, 11.60it/s, est. speed input: 12603.77 toks/s, output: 12.31 toks/s]
Processed prompts:  29%|       | 298/1024 [00:24<01:02, 11.59it/s, est. speed input: 12582.37 toks/s, output: 12.29 toks/s]
Processed prompts:  30%|       | 306/1024 [00:24<01:01, 11.61it/s, est. speed input: 12564.55 toks/s, output: 12.27 toks/s]
Processed prompts:  31%|       | 314/1024 [00:25<01:01, 11.60it/s, est. speed input: 12545.45 toks/s, output: 12.25 toks/s]
Processed prompts:  31%|      | 322/1024 [00:26<01:00, 11.60it/s, est. speed input: 12527.66 toks/s, output: 12.23 toks/s]
Processed prompts:  32%|      | 330/1024 [00:27<00:59, 11.62it/s, est. speed input: 12512.77 toks/s, output: 12.22 toks/s]
Processed prompts:  33%|      | 338/1024 [00:27<00:57, 11.85it/s, est. speed input: 12517.87 toks/s, output: 12.22 toks/s]
Processed prompts:  34%|      | 346/1024 [00:28<00:57, 11.76it/s, est. speed input: 12501.54 toks/s, output: 12.21 toks/s]
Processed prompts:  35%|      | 354/1024 [00:29<00:57, 11.72it/s, est. speed input: 12487.45 toks/s, output: 12.19 toks/s]
Processed prompts:  35%|      | 362/1024 [00:29<00:56, 11.67it/s, est. speed input: 12472.07 toks/s, output: 12.18 toks/s]
Processed prompts:  36%|      | 370/1024 [00:30<00:56, 11.54it/s, est. speed input: 12450.12 toks/s, output: 12.16 toks/s]
Processed prompts:  37%|      | 378/1024 [00:31<00:57, 11.29it/s, est. speed input: 12415.64 toks/s, output: 12.12 toks/s]
Processed prompts:  38%|      | 386/1024 [00:31<00:56, 11.38it/s, est. speed input: 12403.77 toks/s, output: 12.11 toks/s]
Processed prompts:  38%|      | 394/1024 [00:32<00:55, 11.42it/s, est. speed input: 12390.95 toks/s, output: 12.10 toks/s]
Processed prompts:  39%|      | 402/1024 [00:33<00:54, 11.50it/s, est. speed input: 12381.86 toks/s, output: 12.09 toks/s]
Processed prompts:  40%|      | 410/1024 [00:33<00:53, 11.51it/s, est. speed input: 12370.29 toks/s, output: 12.08 toks/s]
Processed prompts:  41%|      | 418/1024 [00:34<00:52, 11.51it/s, est. speed input: 12358.73 toks/s, output: 12.07 toks/s]
Processed prompts:  42%|     | 426/1024 [00:35<00:51, 11.56it/s, est. speed input: 12350.74 toks/s, output: 12.06 toks/s]
Processed prompts:  42%|     | 434/1024 [00:36<00:51, 11.56it/s, est. speed input: 12340.71 toks/s, output: 12.05 toks/s]
Processed prompts:  43%|     | 442/1024 [00:36<00:50, 11.57it/s, est. speed input: 12331.77 toks/s, output: 12.04 toks/s]
Processed prompts:  44%|     | 450/1024 [00:37<00:48, 11.90it/s, est. speed input: 12344.07 toks/s, output: 12.05 toks/s]
Processed prompts:  45%|     | 458/1024 [00:38<00:48, 11.79it/s, est. speed input: 12334.41 toks/s, output: 12.05 toks/s]
Processed prompts:  46%|     | 466/1024 [00:38<00:47, 11.75it/s, est. speed input: 12327.29 toks/s, output: 12.04 toks/s]
Processed prompts:  46%|     | 474/1024 [00:39<00:47, 11.69it/s, est. speed input: 12318.44 toks/s, output: 12.03 toks/s]
Processed prompts:  47%|     | 482/1024 [00:40<00:46, 11.63it/s, est. speed input: 12309.18 toks/s, output: 12.02 toks/s]
Processed prompts:  48%|     | 490/1024 [00:40<00:45, 11.64it/s, est. speed input: 12303.00 toks/s, output: 12.01 toks/s]
Processed prompts:  49%|     | 498/1024 [00:41<00:45, 11.63it/s, est. speed input: 12296.19 toks/s, output: 12.01 toks/s]
Processed prompts:  49%|     | 506/1024 [00:42<00:44, 11.62it/s, est. speed input: 12289.06 toks/s, output: 12.00 toks/s]
Processed prompts:  50%|     | 514/1024 [00:42<00:43, 11.60it/s, est. speed input: 12281.97 toks/s, output: 11.99 toks/s]
Processed prompts:  51%|     | 522/1024 [00:43<00:43, 11.59it/s, est. speed input: 12274.84 toks/s, output: 11.99 toks/s]
Processed prompts:  52%|    | 530/1024 [00:44<00:42, 11.57it/s, est. speed input: 12267.64 toks/s, output: 11.98 toks/s]
Processed prompts:  53%|    | 538/1024 [00:44<00:41, 11.59it/s, est. speed input: 12261.88 toks/s, output: 11.97 toks/s]
Processed prompts:  53%|    | 546/1024 [00:45<00:41, 11.58it/s, est. speed input: 12255.70 toks/s, output: 11.97 toks/s]
Processed prompts:  54%|    | 554/1024 [00:46<00:40, 11.59it/s, est. speed input: 12250.14 toks/s, output: 11.96 toks/s]
Processed prompts:  55%|    | 562/1024 [00:46<00:39, 11.61it/s, est. speed input: 12245.37 toks/s, output: 11.96 toks/s]
Processed prompts:  56%|    | 570/1024 [00:47<00:39, 11.58it/s, est. speed input: 12238.62 toks/s, output: 11.95 toks/s]
Processed prompts:  56%|    | 578/1024 [00:48<00:38, 11.58it/s, est. speed input: 12233.41 toks/s, output: 11.95 toks/s]
Processed prompts:  57%|    | 586/1024 [00:49<00:37, 11.57it/s, est. speed input: 12227.41 toks/s, output: 11.94 toks/s]
Processed prompts:  58%|    | 594/1024 [00:49<00:37, 11.56it/s, est. speed input: 12221.79 toks/s, output: 11.94 toks/s]
Processed prompts:  59%|    | 602/1024 [00:50<00:36, 11.58it/s, est. speed input: 12217.67 toks/s, output: 11.93 toks/s]
Processed prompts:  60%|    | 610/1024 [00:51<00:35, 11.57it/s, est. speed input: 12212.41 toks/s, output: 11.93 toks/s]
Processed prompts:  60%|    | 618/1024 [00:51<00:35, 11.56it/s, est. speed input: 12206.94 toks/s, output: 11.92 toks/s]
Processed prompts:  61%|    | 626/1024 [00:52<00:34, 11.58it/s, est. speed input: 12203.17 toks/s, output: 11.92 toks/s]
Processed prompts:  62%|   | 634/1024 [00:53<00:33, 11.56it/s, est. speed input: 12197.70 toks/s, output: 11.91 toks/s]
Processed prompts:  63%|   | 642/1024 [00:53<00:33, 11.56it/s, est. speed input: 12192.84 toks/s, output: 11.91 toks/s]
Processed prompts:  63%|   | 650/1024 [00:54<00:32, 11.59it/s, est. speed input: 12189.79 toks/s, output: 11.90 toks/s]
Processed prompts:  64%|   | 658/1024 [00:55<00:31, 11.57it/s, est. speed input: 12185.13 toks/s, output: 11.90 toks/s]
Processed prompts:  65%|   | 666/1024 [00:55<00:30, 11.58it/s, est. speed input: 12181.44 toks/s, output: 11.90 toks/s]
Processed prompts:  66%|   | 674/1024 [00:56<00:30, 11.61it/s, est. speed input: 12178.80 toks/s, output: 11.89 toks/s]
Processed prompts:  67%|   | 682/1024 [00:57<00:29, 11.59it/s, est. speed input: 12174.26 toks/s, output: 11.89 toks/s]
Processed prompts:  67%|   | 690/1024 [00:58<00:28, 11.55it/s, est. speed input: 12169.16 toks/s, output: 11.88 toks/s]
Processed prompts:  68%|   | 698/1024 [00:58<00:28, 11.57it/s, est. speed input: 12166.02 toks/s, output: 11.88 toks/s]
Processed prompts:  69%|   | 706/1024 [00:59<00:27, 11.57it/s, est. speed input: 12162.12 toks/s, output: 11.88 toks/s]
Processed prompts:  70%|   | 714/1024 [01:00<00:26, 11.56it/s, est. speed input: 12158.32 toks/s, output: 11.87 toks/s]
Processed prompts:  71%|   | 722/1024 [01:00<00:26, 11.58it/s, est. speed input: 12155.28 toks/s, output: 11.87 toks/s]
Processed prompts:  71%|  | 730/1024 [01:01<00:25, 11.57it/s, est. speed input: 12151.66 toks/s, output: 11.87 toks/s]
Processed prompts:  72%|  | 738/1024 [01:02<00:24, 11.59it/s, est. speed input: 12148.90 toks/s, output: 11.86 toks/s]
Processed prompts:  73%|  | 746/1024 [01:02<00:24, 11.57it/s, est. speed input: 12145.20 toks/s, output: 11.86 toks/s]
Processed prompts:  74%|  | 754/1024 [01:03<00:23, 11.31it/s, est. speed input: 12131.87 toks/s, output: 11.85 toks/s]
Processed prompts:  74%|  | 762/1024 [01:04<00:23, 11.38it/s, est. speed input: 12128.38 toks/s, output: 11.84 toks/s]
Processed prompts:  75%|  | 770/1024 [01:05<00:22, 11.43it/s, est. speed input: 12125.15 toks/s, output: 11.84 toks/s]
Processed prompts:  76%|  | 778/1024 [01:05<00:21, 11.45it/s, est. speed input: 12121.59 toks/s, output: 11.84 toks/s]
Processed prompts:  77%|  | 786/1024 [01:06<00:20, 11.51it/s, est. speed input: 12119.44 toks/s, output: 11.84 toks/s]
Processed prompts:  78%|  | 794/1024 [01:07<00:19, 11.51it/s, est. speed input: 12116.11 toks/s, output: 11.83 toks/s]
Processed prompts:  78%|  | 802/1024 [01:07<00:19, 11.50it/s, est. speed input: 12112.26 toks/s, output: 11.83 toks/s]
Processed prompts:  79%|  | 810/1024 [01:08<00:18, 11.54it/s, est. speed input: 12110.47 toks/s, output: 11.83 toks/s]
Processed prompts:  80%|  | 818/1024 [01:09<00:17, 11.54it/s, est. speed input: 12107.46 toks/s, output: 11.82 toks/s]
Processed prompts:  81%|  | 826/1024 [01:09<00:17, 11.52it/s, est. speed input: 12103.96 toks/s, output: 11.82 toks/s]
Processed prompts:  81%| | 834/1024 [01:10<00:16, 11.56it/s, est. speed input: 12102.37 toks/s, output: 11.82 toks/s]
Processed prompts:  82%| | 842/1024 [01:11<00:15, 11.55it/s, est. speed input: 12099.37 toks/s, output: 11.82 toks/s]
Processed prompts:  83%| | 850/1024 [01:11<00:15, 11.53it/s, est. speed input: 12096.03 toks/s, output: 11.81 toks/s]
Processed prompts:  84%| | 858/1024 [01:12<00:14, 11.55it/s, est. speed input: 12094.06 toks/s, output: 11.81 toks/s]
Processed prompts:  85%| | 866/1024 [01:13<00:13, 11.56it/s, est. speed input: 12091.72 toks/s, output: 11.81 toks/s]
Processed prompts:  85%| | 874/1024 [01:14<00:12, 11.54it/s, est. speed input: 12088.84 toks/s, output: 11.81 toks/s]
Processed prompts:  86%| | 882/1024 [01:14<00:12, 11.57it/s, est. speed input: 12087.12 toks/s, output: 11.80 toks/s]
Processed prompts:  87%| | 890/1024 [01:15<00:11, 11.55it/s, est. speed input: 12084.34 toks/s, output: 11.80 toks/s]
Processed prompts:  88%| | 898/1024 [01:16<00:10, 11.54it/s, est. speed input: 12081.84 toks/s, output: 11.80 toks/s]
Processed prompts:  88%| | 906/1024 [01:16<00:10, 11.57it/s, est. speed input: 12080.13 toks/s, output: 11.80 toks/s]
Processed prompts:  89%| | 914/1024 [01:17<00:09, 11.58it/s, est. speed input: 12078.42 toks/s, output: 11.80 toks/s]
Processed prompts:  90%| | 922/1024 [01:18<00:08, 11.59it/s, est. speed input: 12076.82 toks/s, output: 11.79 toks/s]
Processed prompts:  91%| | 930/1024 [01:18<00:08, 11.58it/s, est. speed input: 12074.63 toks/s, output: 11.79 toks/s]
Processed prompts:  92%|| 938/1024 [01:19<00:07, 12.07it/s, est. speed input: 12087.04 toks/s, output: 11.80 toks/s]
Processed prompts:  92%|| 946/1024 [01:20<00:06, 11.93it/s, est. speed input: 12085.30 toks/s, output: 11.80 toks/s]
Processed prompts:  93%|| 954/1024 [01:20<00:05, 11.80it/s, est. speed input: 12082.83 toks/s, output: 11.80 toks/s]
Processed prompts:  94%|| 962/1024 [01:21<00:05, 11.73it/s, est. speed input: 12080.67 toks/s, output: 11.80 toks/s]
Processed prompts:  95%|| 970/1024 [01:22<00:04, 11.68it/s, est. speed input: 12078.65 toks/s, output: 11.80 toks/s]
Processed prompts:  96%|| 978/1024 [01:22<00:03, 11.63it/s, est. speed input: 12076.25 toks/s, output: 11.79 toks/s]
Processed prompts:  96%|| 986/1024 [01:23<00:03, 12.07it/s, est. speed input: 12086.97 toks/s, output: 11.80 toks/s]
Processed prompts:  97%|| 994/1024 [01:24<00:02, 11.92it/s, est. speed input: 12085.22 toks/s, output: 11.80 toks/s]
Processed prompts:  98%|| 1002/1024 [01:24<00:01, 11.80it/s, est. speed input: 12083.01 toks/s, output: 11.80 toks/s]
Processed prompts:  99%|| 1010/1024 [01:25<00:01, 11.74it/s, est. speed input: 12081.35 toks/s, output: 11.80 toks/s]
Processed prompts:  99%|| 1018/1024 [01:26<00:00, 12.10it/s, est. speed input: 12090.35 toks/s, output: 11.81 toks/s]
Processed prompts: 100%|| 1024/1024 [01:26<00:00, 12.10it/s, est. speed input: 12161.59 toks/s, output: 11.88 toks/s]
Processed prompts: 100%|| 1024/1024 [01:26<00:00, 11.88it/s, est. speed input: 12161.59 toks/s, output: 11.88 toks/s]
[rank0]:[W126 12:58:49.193138964 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 12:58:51
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 12:59:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 12:59:00 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1314873) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1314873) WARNING 01-26 12:59:37 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.92 requests/s, 12216.22 total tokens/s, 11.92 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 12:59:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:59:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:59:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:59:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:59:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:59:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:59:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:59:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:59:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:59:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:59:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:59:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:59:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:59:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 12:59:03] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 12:59:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 12:59:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 12:59:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:59:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:59:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:59:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:59:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 12:59:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 12:59:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 12:59:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 12:59:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 12:59:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 12:59:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:04] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1314873) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1314873) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.19s/it]
(EngineCore_DP0 pid=1314873) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:23<00:00, 23.19s/it]
(EngineCore_DP0 pid=1314873) 
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:29] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1314873) [2026-01-26 12:59:29] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1314873) 2026-01-26 12:59:35,467 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1314873) 2026-01-26 12:59:35,574 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 55/2048 [00:00<00:03, 549.44it/s]
Adding requests:   5%|         | 110/2048 [00:00<00:03, 493.64it/s]
Adding requests:   8%|         | 162/2048 [00:00<00:03, 503.47it/s]
Adding requests:  10%|         | 214/2048 [00:00<00:03, 507.89it/s]
Adding requests:  13%|        | 269/2048 [00:00<00:03, 522.30it/s]
Adding requests:  16%|        | 322/2048 [00:00<00:03, 516.42it/s]
Adding requests:  18%|        | 375/2048 [00:00<00:03, 520.54it/s]
Adding requests:  21%|        | 428/2048 [00:00<00:03, 521.68it/s]
Adding requests:  23%|       | 481/2048 [00:00<00:03, 519.63it/s]
Adding requests:  26%|       | 534/2048 [00:01<00:02, 505.14it/s]
Adding requests:  29%|       | 587/2048 [00:01<00:02, 512.43it/s]
Adding requests:  31%|       | 639/2048 [00:01<00:02, 513.59it/s]
Adding requests:  34%|      | 692/2048 [00:01<00:02, 517.16it/s]
Adding requests:  36%|      | 745/2048 [00:01<00:02, 519.92it/s]
Adding requests:  39%|      | 798/2048 [00:01<00:02, 485.09it/s]
Adding requests:  41%|     | 848/2048 [00:01<00:02, 487.66it/s]
Adding requests:  44%|     | 898/2048 [00:02<00:06, 187.38it/s]
Adding requests:  46%|     | 950/2048 [00:02<00:04, 231.99it/s]
Adding requests:  49%|     | 1002/2048 [00:02<00:03, 278.42it/s]
Adding requests:  52%|    | 1055/2048 [00:02<00:03, 324.22it/s]
Adding requests:  54%|    | 1106/2048 [00:02<00:02, 363.24it/s]
Adding requests:  56%|    | 1157/2048 [00:02<00:02, 395.08it/s]
Adding requests:  59%|    | 1209/2048 [00:02<00:01, 425.36it/s]
Adding requests:  61%|   | 1259/2048 [00:03<00:01, 437.26it/s]
Adding requests:  64%|   | 1312/2048 [00:03<00:01, 461.85it/s]
Adding requests:  67%|   | 1364/2048 [00:03<00:01, 477.74it/s]
Adding requests:  69%|   | 1415/2048 [00:03<00:01, 483.34it/s]
Adding requests:  72%|  | 1466/2048 [00:03<00:01, 488.46it/s]
Adding requests:  74%|  | 1521/2048 [00:03<00:01, 503.40it/s]
Adding requests:  77%|  | 1575/2048 [00:03<00:00, 510.99it/s]
Adding requests:  80%|  | 1631/2048 [00:03<00:00, 520.79it/s]
Adding requests:  82%| | 1684/2048 [00:03<00:00, 520.70it/s]
Adding requests:  85%| | 1737/2048 [00:03<00:00, 522.32it/s]
Adding requests:  87%| | 1790/2048 [00:04<00:00, 521.85it/s]
Adding requests:  90%| | 1843/2048 [00:04<00:00, 521.83it/s]
Adding requests:  93%|| 1896/2048 [00:04<00:00, 513.50it/s]
Adding requests:  95%|| 1948/2048 [00:04<00:00, 512.03it/s]
Adding requests:  98%|| 2002/2048 [00:04<00:00, 518.67it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 446.41it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 50/2048 [00:00<00:37, 53.54it/s, est. speed input: 54833.64 toks/s, output: 53.55 toks/s]
Processed prompts:   3%|         | 66/2048 [00:02<01:17, 25.65it/s, est. speed input: 29790.02 toks/s, output: 29.09 toks/s]
Processed prompts:   4%|         | 82/2048 [00:03<01:43, 18.94it/s, est. speed input: 23284.24 toks/s, output: 22.74 toks/s]
Processed prompts:   5%|         | 98/2048 [00:04<02:01, 16.06it/s, est. speed input: 20291.43 toks/s, output: 19.82 toks/s]
Processed prompts:   6%|         | 114/2048 [00:06<02:12, 14.55it/s, est. speed input: 18583.93 toks/s, output: 18.15 toks/s]
Processed prompts:   6%|         | 130/2048 [00:07<02:20, 13.65it/s, est. speed input: 17472.53 toks/s, output: 17.06 toks/s]
Processed prompts:   7%|         | 146/2048 [00:08<02:25, 13.08it/s, est. speed input: 16686.61 toks/s, output: 16.30 toks/s]
Processed prompts:   8%|         | 162/2048 [00:10<02:28, 12.72it/s, est. speed input: 16107.26 toks/s, output: 15.73 toks/s]
Processed prompts:   9%|         | 178/2048 [00:11<02:29, 12.48it/s, est. speed input: 15664.72 toks/s, output: 15.30 toks/s]
Processed prompts:   9%|         | 194/2048 [00:12<02:30, 12.31it/s, est. speed input: 15305.84 toks/s, output: 14.95 toks/s]
Processed prompts:  10%|         | 210/2048 [00:14<02:30, 12.21it/s, est. speed input: 15024.76 toks/s, output: 14.67 toks/s]
Processed prompts:  11%|         | 226/2048 [00:15<02:30, 12.11it/s, est. speed input: 14779.48 toks/s, output: 14.43 toks/s]
Processed prompts:  12%|        | 242/2048 [00:16<02:29, 12.06it/s, est. speed input: 14578.29 toks/s, output: 14.24 toks/s]
Processed prompts:  13%|        | 258/2048 [00:18<02:28, 12.02it/s, est. speed input: 14405.34 toks/s, output: 14.07 toks/s]
Processed prompts:  13%|        | 274/2048 [00:19<02:27, 11.99it/s, est. speed input: 14255.73 toks/s, output: 13.92 toks/s]
Processed prompts:  14%|        | 290/2048 [00:21<02:26, 11.97it/s, est. speed input: 14123.70 toks/s, output: 13.79 toks/s]
Processed prompts:  15%|        | 306/2048 [00:22<02:25, 11.97it/s, est. speed input: 14011.86 toks/s, output: 13.68 toks/s]
Processed prompts:  16%|        | 322/2048 [00:23<02:24, 11.96it/s, est. speed input: 13912.36 toks/s, output: 13.59 toks/s]
Processed prompts:  17%|        | 338/2048 [00:25<02:21, 12.07it/s, est. speed input: 13844.43 toks/s, output: 13.52 toks/s]
Processed prompts:  17%|        | 354/2048 [00:26<02:20, 12.02it/s, est. speed input: 13761.27 toks/s, output: 13.44 toks/s]
Processed prompts:  18%|        | 370/2048 [00:27<02:23, 11.73it/s, est. speed input: 13637.17 toks/s, output: 13.32 toks/s]
Processed prompts:  19%|        | 386/2048 [00:29<02:21, 11.78it/s, est. speed input: 13570.51 toks/s, output: 13.25 toks/s]
Processed prompts:  20%|        | 402/2048 [00:30<02:19, 11.81it/s, est. speed input: 13507.93 toks/s, output: 13.19 toks/s]
Processed prompts:  20%|        | 418/2048 [00:31<02:17, 11.85it/s, est. speed input: 13454.02 toks/s, output: 13.14 toks/s]
Processed prompts:  21%|        | 434/2048 [00:33<02:15, 11.87it/s, est. speed input: 13403.60 toks/s, output: 13.09 toks/s]
Processed prompts:  22%|       | 450/2048 [00:34<02:18, 11.51it/s, est. speed input: 13300.28 toks/s, output: 12.99 toks/s]
Processed prompts:  23%|       | 466/2048 [00:35<02:16, 11.63it/s, est. speed input: 13259.79 toks/s, output: 12.95 toks/s]
Processed prompts:  24%|       | 482/2048 [00:37<02:13, 11.72it/s, est. speed input: 13221.93 toks/s, output: 12.91 toks/s]
Processed prompts:  24%|       | 498/2048 [00:38<02:11, 11.77it/s, est. speed input: 13185.84 toks/s, output: 12.88 toks/s]
Processed prompts:  25%|       | 514/2048 [00:40<02:10, 11.80it/s, est. speed input: 13150.67 toks/s, output: 12.84 toks/s]
Processed prompts:  26%|       | 530/2048 [00:41<02:08, 11.84it/s, est. speed input: 13121.30 toks/s, output: 12.81 toks/s]
Processed prompts:  27%|       | 546/2048 [00:42<02:06, 11.86it/s, est. speed input: 13092.00 toks/s, output: 12.79 toks/s]
Processed prompts:  27%|       | 562/2048 [00:44<02:05, 11.87it/s, est. speed input: 13064.04 toks/s, output: 12.76 toks/s]
Processed prompts:  28%|       | 578/2048 [00:45<02:03, 11.89it/s, est. speed input: 13038.61 toks/s, output: 12.73 toks/s]
Processed prompts:  29%|       | 594/2048 [00:46<02:02, 11.89it/s, est. speed input: 13014.37 toks/s, output: 12.71 toks/s]
Processed prompts:  30%|       | 610/2048 [00:48<02:00, 11.90it/s, est. speed input: 12992.23 toks/s, output: 12.69 toks/s]
Processed prompts:  31%|       | 626/2048 [00:49<01:59, 11.89it/s, est. speed input: 12969.31 toks/s, output: 12.67 toks/s]
Processed prompts:  31%|      | 642/2048 [00:50<01:58, 11.89it/s, est. speed input: 12948.40 toks/s, output: 12.64 toks/s]
Processed prompts:  32%|      | 658/2048 [00:52<01:56, 11.89it/s, est. speed input: 12928.64 toks/s, output: 12.63 toks/s]
Processed prompts:  33%|      | 674/2048 [00:53<01:55, 11.91it/s, est. speed input: 12910.96 toks/s, output: 12.61 toks/s]
Processed prompts:  34%|      | 690/2048 [00:54<01:54, 11.89it/s, est. speed input: 12891.97 toks/s, output: 12.59 toks/s]
Processed prompts:  34%|      | 706/2048 [00:56<01:52, 11.90it/s, est. speed input: 12875.19 toks/s, output: 12.57 toks/s]
Processed prompts:  35%|      | 722/2048 [00:57<01:51, 11.90it/s, est. speed input: 12859.37 toks/s, output: 12.56 toks/s]
Processed prompts:  36%|      | 738/2048 [00:58<01:50, 11.89it/s, est. speed input: 12843.50 toks/s, output: 12.54 toks/s]
Processed prompts:  37%|      | 754/2048 [01:00<01:48, 11.89it/s, est. speed input: 12828.03 toks/s, output: 12.53 toks/s]
Processed prompts:  38%|      | 770/2048 [01:01<01:47, 11.89it/s, est. speed input: 12814.25 toks/s, output: 12.51 toks/s]
Processed prompts:  38%|      | 786/2048 [01:02<01:46, 11.90it/s, est. speed input: 12800.93 toks/s, output: 12.50 toks/s]
Processed prompts:  39%|      | 802/2048 [01:04<01:44, 11.88it/s, est. speed input: 12786.54 toks/s, output: 12.49 toks/s]
Processed prompts:  40%|      | 818/2048 [01:05<01:43, 11.89it/s, est. speed input: 12774.34 toks/s, output: 12.47 toks/s]
Processed prompts:  41%|      | 834/2048 [01:06<01:42, 11.88it/s, est. speed input: 12761.57 toks/s, output: 12.46 toks/s]
Processed prompts:  42%|     | 850/2048 [01:08<01:40, 11.89it/s, est. speed input: 12750.56 toks/s, output: 12.45 toks/s]
Processed prompts:  42%|     | 866/2048 [01:09<01:39, 11.88it/s, est. speed input: 12738.65 toks/s, output: 12.44 toks/s]
Processed prompts:  43%|     | 882/2048 [01:10<01:38, 11.89it/s, est. speed input: 12728.50 toks/s, output: 12.43 toks/s]
Processed prompts:  44%|     | 898/2048 [01:12<01:36, 11.89it/s, est. speed input: 12718.11 toks/s, output: 12.42 toks/s]
Processed prompts:  45%|     | 914/2048 [01:13<01:35, 11.89it/s, est. speed input: 12708.30 toks/s, output: 12.41 toks/s]
Processed prompts:  45%|     | 930/2048 [01:14<01:32, 12.09it/s, est. speed input: 12711.10 toks/s, output: 12.41 toks/s]
Processed prompts:  46%|     | 946/2048 [01:16<01:31, 12.04it/s, est. speed input: 12702.19 toks/s, output: 12.40 toks/s]
Processed prompts:  47%|     | 962/2048 [01:17<01:30, 12.00it/s, est. speed input: 12693.59 toks/s, output: 12.40 toks/s]
Processed prompts:  48%|     | 978/2048 [01:18<01:27, 12.18it/s, est. speed input: 12697.35 toks/s, output: 12.40 toks/s]
Processed prompts:  49%|     | 994/2048 [01:20<01:27, 12.08it/s, est. speed input: 12687.69 toks/s, output: 12.39 toks/s]
Processed prompts:  49%|     | 1010/2048 [01:21<01:26, 12.02it/s, est. speed input: 12679.30 toks/s, output: 12.38 toks/s]
Processed prompts:  50%|     | 1026/2048 [01:22<01:25, 11.99it/s, est. speed input: 12671.59 toks/s, output: 12.37 toks/s]
Processed prompts:  51%|     | 1042/2048 [01:24<01:24, 11.96it/s, est. speed input: 12663.76 toks/s, output: 12.37 toks/s]
Processed prompts:  52%|    | 1058/2048 [01:25<01:22, 11.93it/s, est. speed input: 12655.66 toks/s, output: 12.36 toks/s]
Processed prompts:  52%|    | 1074/2048 [01:26<01:21, 11.92it/s, est. speed input: 12648.31 toks/s, output: 12.35 toks/s]
Processed prompts:  53%|    | 1090/2048 [01:28<01:20, 11.91it/s, est. speed input: 12641.15 toks/s, output: 12.34 toks/s]
Processed prompts:  54%|    | 1106/2048 [01:29<01:19, 11.90it/s, est. speed input: 12633.93 toks/s, output: 12.34 toks/s]
Processed prompts:  55%|    | 1122/2048 [01:30<01:17, 11.89it/s, est. speed input: 12626.96 toks/s, output: 12.33 toks/s]
Processed prompts:  56%|    | 1138/2048 [01:32<01:16, 11.91it/s, est. speed input: 12621.02 toks/s, output: 12.33 toks/s]
Processed prompts:  56%|    | 1154/2048 [01:33<01:13, 12.11it/s, est. speed input: 12625.12 toks/s, output: 12.33 toks/s]
Processed prompts:  57%|    | 1170/2048 [01:34<01:12, 12.04it/s, est. speed input: 12618.37 toks/s, output: 12.32 toks/s]
Processed prompts:  58%|    | 1186/2048 [01:36<01:11, 12.01it/s, est. speed input: 12612.89 toks/s, output: 12.32 toks/s]
Processed prompts:  59%|    | 1202/2048 [01:37<01:10, 11.97it/s, est. speed input: 12606.80 toks/s, output: 12.31 toks/s]
Processed prompts:  59%|    | 1218/2048 [01:38<01:09, 11.93it/s, est. speed input: 12600.15 toks/s, output: 12.30 toks/s]
Processed prompts:  60%|    | 1234/2048 [01:40<01:08, 11.91it/s, est. speed input: 12593.99 toks/s, output: 12.30 toks/s]
Processed prompts:  61%|    | 1250/2048 [01:41<01:07, 11.91it/s, est. speed input: 12588.60 toks/s, output: 12.29 toks/s]
Processed prompts:  62%|   | 1266/2048 [01:42<01:04, 12.11it/s, est. speed input: 12592.81 toks/s, output: 12.30 toks/s]
Processed prompts:  63%|   | 1282/2048 [01:44<01:03, 12.06it/s, est. speed input: 12587.92 toks/s, output: 12.29 toks/s]
Processed prompts:  63%|   | 1298/2048 [01:45<01:02, 12.00it/s, est. speed input: 12582.19 toks/s, output: 12.29 toks/s]
Processed prompts:  64%|   | 1314/2048 [01:46<01:01, 11.96it/s, est. speed input: 12577.12 toks/s, output: 12.28 toks/s]
Processed prompts:  65%|   | 1330/2048 [01:48<01:00, 11.95it/s, est. speed input: 12572.48 toks/s, output: 12.28 toks/s]
Processed prompts:  66%|   | 1346/2048 [01:49<00:58, 11.93it/s, est. speed input: 12567.46 toks/s, output: 12.27 toks/s]
Processed prompts:  67%|   | 1362/2048 [01:51<00:57, 11.92it/s, est. speed input: 12562.93 toks/s, output: 12.27 toks/s]
Processed prompts:  67%|   | 1378/2048 [01:52<00:56, 11.93it/s, est. speed input: 12558.94 toks/s, output: 12.26 toks/s]
Processed prompts:  68%|   | 1394/2048 [01:53<00:54, 11.92it/s, est. speed input: 12554.42 toks/s, output: 12.26 toks/s]
Processed prompts:  69%|   | 1410/2048 [01:55<00:53, 11.91it/s, est. speed input: 12550.09 toks/s, output: 12.26 toks/s]
Processed prompts:  70%|   | 1426/2048 [01:56<00:52, 11.90it/s, est. speed input: 12545.40 toks/s, output: 12.25 toks/s]
Processed prompts:  70%|   | 1442/2048 [01:57<00:50, 11.90it/s, est. speed input: 12541.42 toks/s, output: 12.25 toks/s]
Processed prompts:  71%|   | 1458/2048 [01:59<00:49, 11.90it/s, est. speed input: 12537.27 toks/s, output: 12.24 toks/s]
Processed prompts:  72%|  | 1474/2048 [02:00<00:48, 11.88it/s, est. speed input: 12532.79 toks/s, output: 12.24 toks/s]
Processed prompts:  73%|  | 1490/2048 [02:01<00:46, 11.89it/s, est. speed input: 12528.90 toks/s, output: 12.24 toks/s]
Processed prompts:  74%|  | 1506/2048 [02:03<00:45, 11.89it/s, est. speed input: 12525.29 toks/s, output: 12.23 toks/s]
Processed prompts:  74%|  | 1522/2048 [02:04<00:44, 11.89it/s, est. speed input: 12521.46 toks/s, output: 12.23 toks/s]
Processed prompts:  75%|  | 1538/2048 [02:05<00:42, 11.88it/s, est. speed input: 12517.43 toks/s, output: 12.22 toks/s]
Processed prompts:  76%|  | 1554/2048 [02:07<00:41, 11.89it/s, est. speed input: 12514.19 toks/s, output: 12.22 toks/s]
Processed prompts:  77%|  | 1570/2048 [02:08<00:40, 11.90it/s, est. speed input: 12510.95 toks/s, output: 12.22 toks/s]
Processed prompts:  77%|  | 1586/2048 [02:09<00:38, 12.11it/s, est. speed input: 12515.01 toks/s, output: 12.22 toks/s]
Processed prompts:  78%|  | 1602/2048 [02:11<00:37, 12.01it/s, est. speed input: 12510.52 toks/s, output: 12.22 toks/s]
Processed prompts:  79%|  | 1618/2048 [02:12<00:35, 11.98it/s, est. speed input: 12507.39 toks/s, output: 12.21 toks/s]
Processed prompts:  80%|  | 1634/2048 [02:13<00:34, 11.95it/s, est. speed input: 12503.83 toks/s, output: 12.21 toks/s]
Processed prompts:  81%|  | 1650/2048 [02:15<00:33, 11.93it/s, est. speed input: 12500.65 toks/s, output: 12.21 toks/s]
Processed prompts:  81%| | 1666/2048 [02:16<00:32, 11.92it/s, est. speed input: 12497.27 toks/s, output: 12.20 toks/s]
Processed prompts:  82%| | 1682/2048 [02:17<00:30, 11.90it/s, est. speed input: 12493.98 toks/s, output: 12.20 toks/s]
Processed prompts:  83%| | 1698/2048 [02:19<00:29, 11.89it/s, est. speed input: 12490.67 toks/s, output: 12.20 toks/s]
Processed prompts:  84%| | 1714/2048 [02:20<00:28, 11.88it/s, est. speed input: 12487.24 toks/s, output: 12.19 toks/s]
Processed prompts:  84%| | 1730/2048 [02:21<00:26, 11.88it/s, est. speed input: 12484.12 toks/s, output: 12.19 toks/s]
Processed prompts:  85%| | 1746/2048 [02:23<00:25, 11.88it/s, est. speed input: 12481.11 toks/s, output: 12.19 toks/s]
Processed prompts:  86%| | 1762/2048 [02:24<00:24, 11.89it/s, est. speed input: 12478.40 toks/s, output: 12.19 toks/s]
Processed prompts:  87%| | 1778/2048 [02:25<00:22, 11.88it/s, est. speed input: 12475.32 toks/s, output: 12.18 toks/s]
Processed prompts:  88%| | 1794/2048 [02:27<00:21, 11.88it/s, est. speed input: 12472.65 toks/s, output: 12.18 toks/s]
Processed prompts:  88%| | 1810/2048 [02:28<00:20, 11.89it/s, est. speed input: 12470.11 toks/s, output: 12.18 toks/s]
Processed prompts:  89%| | 1826/2048 [02:29<00:18, 11.91it/s, est. speed input: 12467.93 toks/s, output: 12.18 toks/s]
Processed prompts:  90%| | 1842/2048 [02:31<00:17, 11.89it/s, est. speed input: 12464.89 toks/s, output: 12.17 toks/s]
Processed prompts:  91%| | 1858/2048 [02:32<00:15, 11.88it/s, est. speed input: 12462.10 toks/s, output: 12.17 toks/s]
Processed prompts:  92%|| 1874/2048 [02:33<00:14, 12.10it/s, est. speed input: 12466.18 toks/s, output: 12.17 toks/s]
Processed prompts:  92%|| 1890/2048 [02:35<00:13, 12.04it/s, est. speed input: 12463.87 toks/s, output: 12.17 toks/s]
Processed prompts:  93%|| 1906/2048 [02:36<00:11, 11.98it/s, est. speed input: 12460.90 toks/s, output: 12.17 toks/s]
Processed prompts:  94%|| 1922/2048 [02:37<00:10, 11.97it/s, est. speed input: 12458.84 toks/s, output: 12.17 toks/s]
Processed prompts:  95%|| 1938/2048 [02:39<00:09, 11.94it/s, est. speed input: 12456.29 toks/s, output: 12.16 toks/s]
Processed prompts:  95%|| 1954/2048 [02:40<00:07, 12.14it/s, est. speed input: 12460.13 toks/s, output: 12.17 toks/s]
Processed prompts:  96%|| 1970/2048 [02:41<00:06, 12.05it/s, est. speed input: 12457.33 toks/s, output: 12.17 toks/s]
Processed prompts:  97%|| 1986/2048 [02:43<00:05, 12.01it/s, est. speed input: 12455.19 toks/s, output: 12.16 toks/s]
Processed prompts:  98%|| 2002/2048 [02:44<00:03, 11.98it/s, est. speed input: 12453.11 toks/s, output: 12.16 toks/s]
Processed prompts:  99%|| 2018/2048 [02:45<00:02, 11.95it/s, est. speed input: 12450.69 toks/s, output: 12.16 toks/s]
Processed prompts:  99%|| 2034/2048 [02:47<00:01, 12.11it/s, est. speed input: 12453.46 toks/s, output: 12.16 toks/s]
Processed prompts: 100%|| 2048/2048 [02:47<00:00, 12.11it/s, est. speed input: 12539.17 toks/s, output: 12.25 toks/s]
Processed prompts: 100%|| 2048/2048 [02:47<00:00, 12.25it/s, est. speed input: 12539.17 toks/s, output: 12.25 toks/s]
[rank0]:[W126 13:02:29.848061463 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 13:02:31
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:02:47 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 13:02:47 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1318165) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1318165) WARNING 01-26 13:03:28 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.49 requests/s, 11780.76 total tokens/s, 11.49 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 13:02:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:02:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:02:47] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:02:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:02:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:02:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:02:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:02:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:02:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:02:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:02:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:02:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:02:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:02:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:02:50] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:02:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:02:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:02:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:02:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:02:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:02:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:02:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:02:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:02:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:02:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:02:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:02:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:02:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1318165) [2026-01-26 13:02:51] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1318165) [2026-01-26 13:02:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1318165) [2026-01-26 13:02:51] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1318165) [2026-01-26 13:02:51] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1318165) [2026-01-26 13:02:51] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1318165) [2026-01-26 13:02:51] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1318165) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1318165) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:22<00:00, 22.97s/it]
(EngineCore_DP0 pid=1318165) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:22<00:00, 22.97s/it]
(EngineCore_DP0 pid=1318165) 
(EngineCore_DP0 pid=1318165) [2026-01-26 13:03:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1318165) [2026-01-26 13:03:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1318165) [2026-01-26 13:03:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1318165) [2026-01-26 13:03:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1318165) [2026-01-26 13:03:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1318165) [2026-01-26 13:03:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1318165) [2026-01-26 13:03:15] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1318165) [2026-01-26 13:03:15] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1318165) 2026-01-26 13:03:22,938 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1318165) 2026-01-26 13:03:23,822 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|         | 58/4096 [00:00<00:07, 576.62it/s]
Adding requests:   3%|         | 116/4096 [00:00<00:07, 527.38it/s]
Adding requests:   4%|         | 170/4096 [00:00<00:07, 507.07it/s]
Adding requests:   5%|         | 221/4096 [00:00<00:07, 503.14it/s]
Adding requests:   7%|         | 276/4096 [00:00<00:07, 517.35it/s]
Adding requests:   8%|         | 328/4096 [00:00<00:07, 514.17it/s]
Adding requests:   9%|         | 381/4096 [00:00<00:07, 514.84it/s]
Adding requests:  11%|         | 433/4096 [00:00<00:07, 493.55it/s]
Adding requests:  12%|        | 483/4096 [00:00<00:07, 494.77it/s]
Adding requests:  13%|        | 533/4096 [00:01<00:07, 491.12it/s]
Adding requests:  14%|        | 586/4096 [00:01<00:07, 500.33it/s]
Adding requests:  16%|        | 639/4096 [00:01<00:06, 507.76it/s]
Adding requests:  17%|        | 693/4096 [00:01<00:06, 516.21it/s]
Adding requests:  18%|        | 745/4096 [00:01<00:06, 506.57it/s]
Adding requests:  19%|        | 796/4096 [00:01<00:06, 506.97it/s]
Adding requests:  21%|        | 847/4096 [00:01<00:06, 497.48it/s]
Adding requests:  22%|       | 898/4096 [00:01<00:06, 499.40it/s]
Adding requests:  23%|       | 949/4096 [00:01<00:06, 500.00it/s]
Adding requests:  24%|       | 1000/4096 [00:01<00:06, 496.98it/s]
Adding requests:  26%|       | 1051/4096 [00:02<00:06, 499.99it/s]
Adding requests:  27%|       | 1102/4096 [00:02<00:06, 491.20it/s]
Adding requests:  28%|       | 1152/4096 [00:02<00:06, 487.49it/s]
Adding requests:  29%|       | 1201/4096 [00:02<00:06, 479.80it/s]
Adding requests:  31%|       | 1252/4096 [00:02<00:05, 487.05it/s]
Adding requests:  32%|      | 1303/4096 [00:02<00:05, 492.57it/s]
Adding requests:  33%|      | 1356/4096 [00:02<00:05, 503.10it/s]
Adding requests:  34%|      | 1409/4096 [00:02<00:05, 510.12it/s]
Adding requests:  36%|      | 1461/4096 [00:02<00:05, 507.64it/s]
Adding requests:  37%|      | 1512/4096 [00:03<00:05, 508.26it/s]
Adding requests:  38%|      | 1566/4096 [00:03<00:04, 515.34it/s]
Adding requests:  40%|      | 1619/4096 [00:03<00:04, 516.85it/s]
Adding requests:  41%|      | 1671/4096 [00:03<00:04, 511.01it/s]
Adding requests:  42%|     | 1723/4096 [00:03<00:04, 506.57it/s]
Adding requests:  43%|     | 1776/4096 [00:03<00:04, 511.50it/s]
Adding requests:  45%|     | 1828/4096 [00:03<00:04, 512.04it/s]
Adding requests:  46%|     | 1880/4096 [00:03<00:04, 512.47it/s]
Adding requests:  47%|     | 1933/4096 [00:03<00:04, 515.53it/s]
Adding requests:  48%|     | 1985/4096 [00:03<00:04, 513.67it/s]
Adding requests:  50%|     | 2039/4096 [00:04<00:03, 519.76it/s]
Adding requests:  51%|     | 2093/4096 [00:04<00:03, 522.02it/s]
Adding requests:  52%|    | 2146/4096 [00:04<00:03, 518.50it/s]
Adding requests:  54%|    | 2198/4096 [00:04<00:03, 513.27it/s]
Adding requests:  55%|    | 2251/4096 [00:04<00:03, 516.92it/s]
Adding requests:  56%|    | 2303/4096 [00:04<00:03, 515.35it/s]
Adding requests:  57%|    | 2355/4096 [00:04<00:03, 508.02it/s]
Adding requests:  59%|    | 2407/4096 [00:04<00:03, 509.57it/s]
Adding requests:  60%|    | 2458/4096 [00:04<00:03, 484.33it/s]
Adding requests:  61%|   | 2511/4096 [00:04<00:03, 495.59it/s]
Adding requests:  63%|   | 2564/4096 [00:05<00:03, 502.18it/s]
Adding requests:  64%|   | 2616/4096 [00:05<00:02, 505.49it/s]
Adding requests:  65%|   | 2669/4096 [00:05<00:02, 511.87it/s]
Adding requests:  66%|   | 2721/4096 [00:05<00:02, 508.05it/s]
Adding requests:  68%|   | 2772/4096 [00:05<00:02, 502.38it/s]
Adding requests:  69%|   | 2823/4096 [00:05<00:02, 492.79it/s]
Adding requests:  70%|   | 2874/4096 [00:05<00:02, 497.45it/s]
Adding requests:  71%|  | 2924/4096 [00:05<00:02, 495.01it/s]
Adding requests:  73%|  | 2975/4096 [00:05<00:02, 498.80it/s]
Adding requests:  74%|  | 3025/4096 [00:05<00:02, 492.51it/s]
Adding requests:  75%|  | 3075/4096 [00:06<00:02, 490.13it/s]
Adding requests:  76%|  | 3126/4096 [00:06<00:01, 495.42it/s]
Adding requests:  78%|  | 3178/4096 [00:06<00:01, 502.48it/s]
Adding requests:  79%|  | 3229/4096 [00:06<00:01, 503.75it/s]
Adding requests:  80%|  | 3283/4096 [00:06<00:01, 512.79it/s]
Adding requests:  81%| | 3335/4096 [00:06<00:01, 511.64it/s]
Adding requests:  83%| | 3387/4096 [00:06<00:01, 503.28it/s]
Adding requests:  84%| | 3438/4096 [00:06<00:01, 504.71it/s]
Adding requests:  85%| | 3489/4096 [00:06<00:01, 498.34it/s]
Adding requests:  86%| | 3541/4096 [00:07<00:01, 503.91it/s]
Adding requests:  88%| | 3592/4096 [00:07<00:01, 502.64it/s]
Adding requests:  89%| | 3643/4096 [00:07<00:00, 504.29it/s]
Adding requests:  90%| | 3695/4096 [00:07<00:00, 508.73it/s]
Adding requests:  91%|| 3747/4096 [00:07<00:00, 511.22it/s]
Adding requests:  93%|| 3799/4096 [00:07<00:00, 488.12it/s]
Adding requests:  94%|| 3849/4096 [00:07<00:00, 487.45it/s]
Adding requests:  95%|| 3902/4096 [00:07<00:00, 498.66it/s]
Adding requests:  97%|| 3954/4096 [00:07<00:00, 503.89it/s]
Adding requests:  98%|| 4007/4096 [00:07<00:00, 511.00it/s]
Adding requests:  99%|| 4059/4096 [00:08<00:00, 505.28it/s]
Adding requests: 100%|| 4096/4096 [00:08<00:00, 504.35it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 66/4096 [00:00<00:07, 562.93it/s, est. speed input: 576618.26 toks/s, output: 563.00 toks/s]
Processed prompts:   3%|         | 123/4096 [00:02<01:46, 37.19it/s, est. speed input: 44818.72 toks/s, output: 43.77 toks/s]  
Processed prompts:   4%|         | 148/4096 [00:05<03:08, 20.99it/s, est. speed input: 27547.95 toks/s, output: 26.90 toks/s]
Processed prompts:   4%|         | 162/4096 [00:08<04:44, 13.83it/s, est. speed input: 20247.36 toks/s, output: 19.77 toks/s]
Processed prompts:   5%|         | 194/4096 [00:10<04:58, 13.07it/s, est. speed input: 18252.54 toks/s, output: 17.82 toks/s]
Processed prompts:   6%|         | 226/4096 [00:13<05:06, 12.64it/s, est. speed input: 17044.53 toks/s, output: 16.65 toks/s]
Processed prompts:   6%|         | 258/4096 [00:16<05:10, 12.38it/s, est. speed input: 16233.59 toks/s, output: 15.85 toks/s]
Processed prompts:   7%|         | 290/4096 [00:18<05:11, 12.21it/s, est. speed input: 15653.73 toks/s, output: 15.29 toks/s]
Processed prompts:   8%|         | 322/4096 [00:21<05:09, 12.19it/s, est. speed input: 15260.04 toks/s, output: 14.90 toks/s]
Processed prompts:   9%|         | 354/4096 [00:25<05:51, 10.64it/s, est. speed input: 14231.53 toks/s, output: 13.90 toks/s]
Processed prompts:   9%|         | 386/4096 [00:28<05:49, 10.60it/s, est. speed input: 13863.33 toks/s, output: 13.54 toks/s]
Processed prompts:  10%|         | 418/4096 [00:31<05:35, 10.96it/s, est. speed input: 13714.21 toks/s, output: 13.39 toks/s]
Processed prompts:  11%|         | 450/4096 [00:33<05:22, 11.29it/s, est. speed input: 13615.22 toks/s, output: 13.30 toks/s]
Processed prompts:  12%|        | 482/4096 [00:36<05:15, 11.45it/s, est. speed input: 13503.26 toks/s, output: 13.19 toks/s]
Processed prompts:  13%|        | 514/4096 [00:39<05:09, 11.57it/s, est. speed input: 13409.48 toks/s, output: 13.10 toks/s]
Processed prompts:  13%|        | 546/4096 [00:41<05:04, 11.65it/s, est. speed input: 13326.90 toks/s, output: 13.01 toks/s]
Processed prompts:  14%|        | 578/4096 [00:44<05:00, 11.71it/s, est. speed input: 13256.03 toks/s, output: 12.95 toks/s]
Processed prompts:  15%|        | 610/4096 [00:47<04:56, 11.75it/s, est. speed input: 13191.01 toks/s, output: 12.88 toks/s]
Processed prompts:  16%|        | 642/4096 [00:50<04:53, 11.78it/s, est. speed input: 13134.65 toks/s, output: 12.83 toks/s]
Processed prompts:  16%|        | 674/4096 [00:52<04:49, 11.80it/s, est. speed input: 13082.98 toks/s, output: 12.78 toks/s]
Processed prompts:  17%|        | 706/4096 [00:55<04:46, 11.82it/s, est. speed input: 13036.80 toks/s, output: 12.73 toks/s]
Processed prompts:  18%|        | 738/4096 [00:58<04:44, 11.82it/s, est. speed input: 12993.74 toks/s, output: 12.69 toks/s]
Processed prompts:  19%|        | 770/4096 [01:01<05:15, 10.55it/s, est. speed input: 12726.38 toks/s, output: 12.43 toks/s]
Processed prompts:  20%|        | 802/4096 [01:04<05:02, 10.90it/s, est. speed input: 12701.07 toks/s, output: 12.40 toks/s]
Processed prompts:  20%|        | 834/4096 [01:07<04:52, 11.16it/s, est. speed input: 12677.39 toks/s, output: 12.38 toks/s]
Processed prompts:  21%|        | 866/4096 [01:10<04:44, 11.36it/s, est. speed input: 12655.72 toks/s, output: 12.36 toks/s]
Processed prompts:  22%|       | 898/4096 [01:12<04:38, 11.49it/s, est. speed input: 12635.18 toks/s, output: 12.34 toks/s]
Processed prompts:  23%|       | 930/4096 [01:15<04:30, 11.69it/s, est. speed input: 12629.05 toks/s, output: 12.33 toks/s]
Processed prompts:  23%|       | 962/4096 [01:18<04:25, 11.82it/s, est. speed input: 12622.19 toks/s, output: 12.33 toks/s]
Processed prompts:  24%|       | 994/4096 [01:20<04:22, 11.83it/s, est. speed input: 12606.14 toks/s, output: 12.31 toks/s]
Processed prompts:  25%|       | 1026/4096 [01:23<04:19, 11.83it/s, est. speed input: 12589.75 toks/s, output: 12.29 toks/s]
Processed prompts:  26%|       | 1058/4096 [01:26<04:16, 11.83it/s, est. speed input: 12574.99 toks/s, output: 12.28 toks/s]
Processed prompts:  27%|       | 1090/4096 [01:28<04:14, 11.82it/s, est. speed input: 12560.51 toks/s, output: 12.27 toks/s]
Processed prompts:  27%|       | 1122/4096 [01:31<04:11, 11.83it/s, est. speed input: 12547.90 toks/s, output: 12.25 toks/s]
Processed prompts:  28%|       | 1154/4096 [01:35<04:44, 10.35it/s, est. speed input: 12365.99 toks/s, output: 12.08 toks/s]
Processed prompts:  29%|       | 1186/4096 [01:38<04:30, 10.75it/s, est. speed input: 12358.80 toks/s, output: 12.07 toks/s]
Processed prompts:  30%|       | 1218/4096 [01:40<04:20, 11.06it/s, est. speed input: 12352.73 toks/s, output: 12.06 toks/s]
Processed prompts:  31%|       | 1250/4096 [01:43<04:10, 11.36it/s, est. speed input: 12355.01 toks/s, output: 12.07 toks/s]
Processed prompts:  31%|      | 1282/4096 [01:46<04:04, 11.50it/s, est. speed input: 12349.29 toks/s, output: 12.06 toks/s]
Processed prompts:  32%|      | 1314/4096 [01:49<03:59, 11.60it/s, est. speed input: 12343.50 toks/s, output: 12.05 toks/s]
Processed prompts:  33%|      | 1346/4096 [01:51<03:55, 11.68it/s, est. speed input: 12338.51 toks/s, output: 12.05 toks/s]
Processed prompts:  34%|      | 1378/4096 [01:54<03:51, 11.72it/s, est. speed input: 12332.89 toks/s, output: 12.04 toks/s]
Processed prompts:  34%|      | 1410/4096 [01:57<03:48, 11.75it/s, est. speed input: 12327.59 toks/s, output: 12.04 toks/s]
Processed prompts:  35%|      | 1442/4096 [01:59<03:45, 11.78it/s, est. speed input: 12323.04 toks/s, output: 12.03 toks/s]
Processed prompts:  36%|      | 1474/4096 [02:02<03:42, 11.79it/s, est. speed input: 12318.49 toks/s, output: 12.03 toks/s]
Processed prompts:  37%|      | 1506/4096 [02:05<03:39, 11.81it/s, est. speed input: 12314.48 toks/s, output: 12.03 toks/s]
Processed prompts:  38%|      | 1538/4096 [02:09<04:02, 10.55it/s, est. speed input: 12206.63 toks/s, output: 11.92 toks/s]
Processed prompts:  38%|      | 1570/4096 [02:11<03:49, 10.98it/s, est. speed input: 12211.54 toks/s, output: 11.93 toks/s]
Processed prompts:  39%|      | 1602/4096 [02:14<03:42, 11.23it/s, est. speed input: 12209.72 toks/s, output: 11.92 toks/s]
Processed prompts:  40%|      | 1634/4096 [02:17<03:35, 11.41it/s, est. speed input: 12208.19 toks/s, output: 11.92 toks/s]
Processed prompts:  41%|      | 1666/4096 [02:19<03:30, 11.53it/s, est. speed input: 12206.36 toks/s, output: 11.92 toks/s]
Processed prompts:  41%|     | 1698/4096 [02:22<03:26, 11.62it/s, est. speed input: 12204.94 toks/s, output: 11.92 toks/s]
Processed prompts:  42%|     | 1730/4096 [02:25<03:22, 11.68it/s, est. speed input: 12203.13 toks/s, output: 11.92 toks/s]
Processed prompts:  43%|     | 1762/4096 [02:27<03:19, 11.73it/s, est. speed input: 12201.49 toks/s, output: 11.92 toks/s]
Processed prompts:  44%|     | 1794/4096 [02:30<03:15, 11.76it/s, est. speed input: 12200.20 toks/s, output: 11.91 toks/s]
Processed prompts:  45%|     | 1826/4096 [02:33<03:12, 11.79it/s, est. speed input: 12198.92 toks/s, output: 11.91 toks/s]
Processed prompts:  45%|     | 1858/4096 [02:35<03:08, 11.90it/s, est. speed input: 12203.32 toks/s, output: 11.92 toks/s]
Processed prompts:  46%|     | 1890/4096 [02:38<03:05, 11.88it/s, est. speed input: 12201.99 toks/s, output: 11.92 toks/s]
Processed prompts:  47%|     | 1922/4096 [02:41<03:03, 11.85it/s, est. speed input: 12199.37 toks/s, output: 11.91 toks/s]
Processed prompts:  48%|     | 1954/4096 [02:45<03:24, 10.46it/s, est. speed input: 12109.87 toks/s, output: 11.83 toks/s]
Processed prompts:  48%|     | 1986/4096 [02:47<03:14, 10.84it/s, est. speed input: 12110.15 toks/s, output: 11.83 toks/s]
Processed prompts:  49%|     | 2018/4096 [02:50<03:06, 11.11it/s, est. speed input: 12110.00 toks/s, output: 11.83 toks/s]
Processed prompts:  50%|     | 2050/4096 [02:53<03:00, 11.33it/s, est. speed input: 12110.45 toks/s, output: 11.83 toks/s]
Processed prompts:  51%|     | 2082/4096 [02:56<02:55, 11.48it/s, est. speed input: 12111.00 toks/s, output: 11.83 toks/s]
Processed prompts:  52%|    | 2114/4096 [02:58<02:51, 11.58it/s, est. speed input: 12111.00 toks/s, output: 11.83 toks/s]
Processed prompts:  52%|    | 2146/4096 [03:01<02:47, 11.66it/s, est. speed input: 12111.32 toks/s, output: 11.83 toks/s]
Processed prompts:  53%|    | 2178/4096 [03:04<02:43, 11.72it/s, est. speed input: 12111.58 toks/s, output: 11.83 toks/s]
Processed prompts:  54%|    | 2210/4096 [03:06<02:37, 11.96it/s, est. speed input: 12122.05 toks/s, output: 11.84 toks/s]
Processed prompts:  55%|    | 2242/4096 [03:09<02:35, 11.92it/s, est. speed input: 12121.74 toks/s, output: 11.84 toks/s]
Processed prompts:  56%|    | 2274/4096 [03:12<02:31, 11.99it/s, est. speed input: 12126.44 toks/s, output: 11.84 toks/s]
Processed prompts:  56%|    | 2306/4096 [03:14<02:29, 11.94it/s, est. speed input: 12126.14 toks/s, output: 11.84 toks/s]
Processed prompts:  57%|    | 2338/4096 [03:18<02:47, 10.48it/s, est. speed input: 12051.46 toks/s, output: 11.77 toks/s]
Processed prompts:  58%|    | 2370/4096 [03:21<02:36, 11.04it/s, est. speed input: 12062.24 toks/s, output: 11.78 toks/s]
Processed prompts:  59%|    | 2402/4096 [03:23<02:30, 11.27it/s, est. speed input: 12063.23 toks/s, output: 11.78 toks/s]
Processed prompts:  59%|    | 2434/4096 [03:26<02:25, 11.43it/s, est. speed input: 12063.85 toks/s, output: 11.78 toks/s]
Processed prompts:  60%|    | 2466/4096 [03:29<02:21, 11.55it/s, est. speed input: 12064.72 toks/s, output: 11.78 toks/s]
Processed prompts:  61%|    | 2498/4096 [03:31<02:16, 11.72it/s, est. speed input: 12069.28 toks/s, output: 11.79 toks/s]
Processed prompts:  62%|   | 2530/4096 [03:34<02:13, 11.76it/s, est. speed input: 12070.19 toks/s, output: 11.79 toks/s]
Processed prompts:  63%|   | 2562/4096 [03:37<02:09, 11.88it/s, est. speed input: 12074.70 toks/s, output: 11.79 toks/s]
Processed prompts:  63%|   | 2594/4096 [03:39<02:06, 11.87it/s, est. speed input: 12075.56 toks/s, output: 11.79 toks/s]
Processed prompts:  64%|   | 2626/4096 [03:42<02:03, 11.86it/s, est. speed input: 12076.19 toks/s, output: 11.79 toks/s]
Processed prompts:  65%|   | 2658/4096 [03:45<02:01, 11.85it/s, est. speed input: 12076.54 toks/s, output: 11.79 toks/s]
Processed prompts:  66%|   | 2690/4096 [03:48<01:58, 11.85it/s, est. speed input: 12077.05 toks/s, output: 11.79 toks/s]
Processed prompts:  66%|   | 2722/4096 [03:51<02:09, 10.61it/s, est. speed input: 12022.84 toks/s, output: 11.74 toks/s]
Processed prompts:  67%|   | 2754/4096 [03:54<02:02, 10.95it/s, est. speed input: 12024.30 toks/s, output: 11.74 toks/s]
Processed prompts:  68%|   | 2786/4096 [03:57<01:56, 11.20it/s, est. speed input: 12025.14 toks/s, output: 11.74 toks/s]
Processed prompts:  69%|   | 2818/4096 [03:59<01:52, 11.39it/s, est. speed input: 12026.35 toks/s, output: 11.74 toks/s]
Processed prompts:  70%|   | 2850/4096 [04:02<01:48, 11.51it/s, est. speed input: 12027.25 toks/s, output: 11.75 toks/s]
Processed prompts:  70%|   | 2882/4096 [04:05<01:44, 11.61it/s, est. speed input: 12028.36 toks/s, output: 11.75 toks/s]
Processed prompts:  71%|   | 2914/4096 [04:08<01:41, 11.68it/s, est. speed input: 12029.50 toks/s, output: 11.75 toks/s]
Processed prompts:  72%|  | 2946/4096 [04:10<01:38, 11.73it/s, est. speed input: 12030.73 toks/s, output: 11.75 toks/s]
Processed prompts:  73%|  | 2978/4096 [04:13<01:35, 11.76it/s, est. speed input: 12031.62 toks/s, output: 11.75 toks/s]
Processed prompts:  73%|  | 3010/4096 [04:16<01:32, 11.78it/s, est. speed input: 12032.49 toks/s, output: 11.75 toks/s]
Processed prompts:  74%|  | 3042/4096 [04:18<01:29, 11.80it/s, est. speed input: 12033.58 toks/s, output: 11.75 toks/s]
Processed prompts:  75%|  | 3074/4096 [04:21<01:26, 11.81it/s, est. speed input: 12034.28 toks/s, output: 11.75 toks/s]
Processed prompts:  76%|  | 3106/4096 [04:24<01:25, 11.63it/s, est. speed input: 12028.62 toks/s, output: 11.75 toks/s]
Processed prompts:  77%|  | 3138/4096 [04:28<01:31, 10.44it/s, est. speed input: 11980.51 toks/s, output: 11.70 toks/s]
Processed prompts:  77%|  | 3170/4096 [04:30<01:25, 10.83it/s, est. speed input: 11982.10 toks/s, output: 11.70 toks/s]
Processed prompts:  78%|  | 3202/4096 [04:33<01:20, 11.12it/s, est. speed input: 11983.68 toks/s, output: 11.70 toks/s]
Processed prompts:  79%|  | 3234/4096 [04:36<01:16, 11.32it/s, est. speed input: 11984.97 toks/s, output: 11.70 toks/s]
Processed prompts:  80%|  | 3266/4096 [04:39<01:12, 11.48it/s, est. speed input: 11986.42 toks/s, output: 11.71 toks/s]
Processed prompts:  81%|  | 3298/4096 [04:41<01:08, 11.58it/s, est. speed input: 11987.65 toks/s, output: 11.71 toks/s]
Processed prompts:  81%| | 3330/4096 [04:44<01:05, 11.66it/s, est. speed input: 11989.09 toks/s, output: 11.71 toks/s]
Processed prompts:  82%| | 3362/4096 [04:47<01:02, 11.71it/s, est. speed input: 11990.15 toks/s, output: 11.71 toks/s]
Processed prompts:  83%| | 3394/4096 [04:49<00:59, 11.75it/s, est. speed input: 11991.38 toks/s, output: 11.71 toks/s]
Processed prompts:  84%| | 3426/4096 [04:52<00:56, 11.77it/s, est. speed input: 11992.49 toks/s, output: 11.71 toks/s]
Processed prompts:  84%| | 3458/4096 [04:55<00:54, 11.79it/s, est. speed input: 11993.63 toks/s, output: 11.71 toks/s]
Processed prompts:  85%| | 3490/4096 [04:57<00:50, 12.03it/s, est. speed input: 12001.51 toks/s, output: 11.72 toks/s]
Processed prompts:  86%| | 3522/4096 [05:01<00:53, 10.71it/s, est. speed input: 11960.92 toks/s, output: 11.68 toks/s]
Processed prompts:  87%| | 3554/4096 [05:04<00:49, 11.02it/s, est. speed input: 11962.18 toks/s, output: 11.68 toks/s]
Processed prompts:  88%| | 3586/4096 [05:06<00:45, 11.26it/s, est. speed input: 11963.70 toks/s, output: 11.68 toks/s]
Processed prompts:  88%| | 3618/4096 [05:09<00:41, 11.42it/s, est. speed input: 11964.91 toks/s, output: 11.68 toks/s]
Processed prompts:  89%| | 3650/4096 [05:12<00:38, 11.55it/s, est. speed input: 11966.37 toks/s, output: 11.69 toks/s]
Processed prompts:  90%| | 3682/4096 [05:15<00:35, 11.64it/s, est. speed input: 11967.84 toks/s, output: 11.69 toks/s]
Processed prompts:  91%| | 3714/4096 [05:17<00:32, 11.78it/s, est. speed input: 11971.66 toks/s, output: 11.69 toks/s]
Processed prompts:  91%|| 3746/4096 [05:20<00:29, 11.80it/s, est. speed input: 11972.96 toks/s, output: 11.69 toks/s]
Processed prompts:  92%|| 3778/4096 [05:23<00:26, 11.80it/s, est. speed input: 11974.00 toks/s, output: 11.69 toks/s]
Processed prompts:  93%|| 3810/4096 [05:25<00:24, 11.82it/s, est. speed input: 11975.32 toks/s, output: 11.69 toks/s]
Processed prompts:  94%|| 3842/4096 [05:28<00:21, 11.91it/s, est. speed input: 11978.99 toks/s, output: 11.70 toks/s]
Processed prompts:  95%|| 3874/4096 [05:31<00:18, 11.89it/s, est. speed input: 11980.22 toks/s, output: 11.70 toks/s]
Processed prompts:  95%|| 3906/4096 [05:34<00:17, 10.63it/s, est. speed input: 11943.83 toks/s, output: 11.66 toks/s]
Processed prompts:  96%|| 3938/4096 [05:37<00:14, 10.97it/s, est. speed input: 11945.22 toks/s, output: 11.67 toks/s]
Processed prompts:  97%|| 3970/4096 [05:40<00:11, 11.22it/s, est. speed input: 11946.66 toks/s, output: 11.67 toks/s]
Processed prompts:  98%|| 4002/4096 [05:42<00:08, 11.40it/s, est. speed input: 11948.08 toks/s, output: 11.67 toks/s]
Processed prompts:  98%|| 4034/4096 [05:45<00:05, 11.61it/s, est. speed input: 11951.74 toks/s, output: 11.67 toks/s]
Processed prompts:  99%|| 4066/4096 [05:48<00:02, 11.77it/s, est. speed input: 11955.59 toks/s, output: 11.68 toks/s]
Processed prompts: 100%|| 4096/4096 [05:48<00:00, 11.77it/s, est. speed input: 12043.79 toks/s, output: 11.76 toks/s]
Processed prompts: 100%|| 4096/4096 [05:48<00:00, 11.76it/s, est. speed input: 12043.79 toks/s, output: 11.76 toks/s]
[rank0]:[W126 13:09:25.767699195 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 13:09:27
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Llama3.2-3B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:09:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 13:09:55 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1324248) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1324248) WARNING 01-26 13:10:40 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.97 requests/s, 12269.08 total tokens/s, 11.97 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-26 13:09:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:09:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:09:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:09:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:09:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:09:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:09:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:09:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:09:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:09:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:09:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:09:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:09:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:09:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:09:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 13:09:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 13:09:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 13:09:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:09:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:09:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:09:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:09:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 13:09:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 13:09:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:09:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:09:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:09:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:09:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1324248) [2026-01-26 13:09:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1324248) [2026-01-26 13:09:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1324248) [2026-01-26 13:09:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1324248) [2026-01-26 13:09:59] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1324248) [2026-01-26 13:09:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1324248) [2026-01-26 13:09:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1324248) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1324248) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.07s/it]
(EngineCore_DP0 pid=1324248) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:24<00:00, 24.07s/it]
(EngineCore_DP0 pid=1324248) 
(EngineCore_DP0 pid=1324248) [2026-01-26 13:10:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1324248) [2026-01-26 13:10:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1324248) [2026-01-26 13:10:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1324248) [2026-01-26 13:10:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1324248) [2026-01-26 13:10:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1324248) [2026-01-26 13:10:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1324248) [2026-01-26 13:10:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1324248) [2026-01-26 13:10:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1324248) 2026-01-26 13:10:34,779 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1324248) 2026-01-26 13:10:35,101 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   1%|          | 57/8192 [00:00<00:14, 565.77it/s]
Adding requests:   1%|         | 114/8192 [00:00<00:20, 403.26it/s]
Adding requests:   2%|         | 171/8192 [00:00<00:17, 463.89it/s]
Adding requests:   3%|         | 231/8192 [00:00<00:15, 509.72it/s]
Adding requests:   4%|         | 288/8192 [00:00<00:14, 528.60it/s]
Adding requests:   4%|         | 343/8192 [00:00<00:15, 509.29it/s]
Adding requests:   5%|         | 396/8192 [00:00<00:15, 493.32it/s]
Adding requests:   5%|         | 447/8192 [00:00<00:15, 486.23it/s]
Adding requests:   6%|         | 499/8192 [00:01<00:15, 493.86it/s]
Adding requests:   7%|         | 549/8192 [00:01<00:15, 489.21it/s]
Adding requests:   7%|         | 599/8192 [00:01<00:15, 483.05it/s]
Adding requests:   8%|         | 654/8192 [00:01<00:15, 501.69it/s]
Adding requests:   9%|         | 718/8192 [00:01<00:13, 540.19it/s]
Adding requests:   9%|         | 773/8192 [00:01<00:14, 520.37it/s]
Adding requests:  10%|         | 826/8192 [00:01<00:15, 490.51it/s]
Adding requests:  11%|         | 884/8192 [00:01<00:14, 514.28it/s]
Adding requests:  11%|        | 937/8192 [00:01<00:14, 515.52it/s]
Adding requests:  12%|        | 989/8192 [00:01<00:14, 496.41it/s]
Adding requests:  13%|        | 1039/8192 [00:02<00:14, 493.75it/s]
Adding requests:  13%|        | 1097/8192 [00:02<00:13, 516.02it/s]
Adding requests:  14%|        | 1149/8192 [00:02<00:14, 486.11it/s]
Adding requests:  15%|        | 1199/8192 [00:02<00:14, 486.79it/s]
Adding requests:  15%|        | 1257/8192 [00:02<00:13, 511.78it/s]
Adding requests:  16%|        | 1309/8192 [00:02<00:14, 479.87it/s]
Adding requests:  17%|        | 1358/8192 [00:02<00:14, 478.80it/s]
Adding requests:  17%|        | 1418/8192 [00:02<00:13, 509.45it/s]
Adding requests:  18%|        | 1470/8192 [00:02<00:13, 498.14it/s]
Adding requests:  19%|        | 1521/8192 [00:03<00:13, 493.61it/s]
Adding requests:  19%|        | 1574/8192 [00:03<00:13, 502.87it/s]
Adding requests:  20%|        | 1627/8192 [00:03<00:12, 509.93it/s]
Adding requests:  20%|        | 1679/8192 [00:03<00:12, 509.50it/s]
Adding requests:  21%|        | 1734/8192 [00:03<00:12, 518.73it/s]
Adding requests:  22%|       | 1786/8192 [00:03<00:12, 510.44it/s]
Adding requests:  22%|       | 1838/8192 [00:03<00:12, 512.12it/s]
Adding requests:  23%|       | 1890/8192 [00:03<00:12, 496.04it/s]
Adding requests:  24%|       | 1940/8192 [00:03<00:12, 488.71it/s]
Adding requests:  24%|       | 1991/8192 [00:03<00:12, 494.31it/s]
Adding requests:  25%|       | 2041/8192 [00:04<00:12, 494.54it/s]
Adding requests:  26%|       | 2091/8192 [00:04<00:12, 494.59it/s]
Adding requests:  26%|       | 2141/8192 [00:04<00:12, 488.52it/s]
Adding requests:  27%|       | 2191/8192 [00:04<00:12, 490.16it/s]
Adding requests:  27%|       | 2243/8192 [00:04<00:11, 497.94it/s]
Adding requests:  28%|       | 2298/8192 [00:04<00:11, 513.01it/s]
Adding requests:  29%|       | 2350/8192 [00:04<00:11, 498.58it/s]
Adding requests:  29%|       | 2400/8192 [00:04<00:11, 494.41it/s]
Adding requests:  30%|       | 2452/8192 [00:04<00:11, 500.91it/s]
Adding requests:  31%|       | 2503/8192 [00:05<00:11, 498.08it/s]
Adding requests:  31%|       | 2555/8192 [00:05<00:11, 502.86it/s]
Adding requests:  32%|      | 2606/8192 [00:05<00:11, 498.36it/s]
Adding requests:  32%|      | 2660/8192 [00:05<00:10, 509.40it/s]
Adding requests:  33%|      | 2711/8192 [00:05<00:10, 503.93it/s]
Adding requests:  34%|      | 2763/8192 [00:05<00:10, 506.52it/s]
Adding requests:  34%|      | 2814/8192 [00:05<00:10, 501.34it/s]
Adding requests:  35%|      | 2869/8192 [00:05<00:10, 514.61it/s]
Adding requests:  36%|      | 2921/8192 [00:05<00:10, 511.26it/s]
Adding requests:  36%|      | 2973/8192 [00:05<00:10, 513.75it/s]
Adding requests:  37%|      | 3025/8192 [00:06<00:10, 511.00it/s]
Adding requests:  38%|      | 3077/8192 [00:06<00:10, 507.57it/s]
Adding requests:  38%|      | 3131/8192 [00:06<00:09, 516.44it/s]
Adding requests:  39%|      | 3183/8192 [00:06<00:09, 514.95it/s]
Adding requests:  39%|      | 3235/8192 [00:06<00:09, 496.83it/s]
Adding requests:  40%|      | 3285/8192 [00:06<00:09, 494.67it/s]
Adding requests:  41%|      | 3337/8192 [00:06<00:09, 500.14it/s]
Adding requests:  41%|     | 3388/8192 [00:06<00:09, 493.14it/s]
Adding requests:  42%|     | 3439/8192 [00:06<00:09, 496.54it/s]
Adding requests:  43%|     | 3489/8192 [00:06<00:09, 492.75it/s]
Adding requests:  43%|     | 3540/8192 [00:07<00:09, 496.39it/s]
Adding requests:  44%|     | 3592/8192 [00:07<00:09, 500.81it/s]
Adding requests:  44%|     | 3645/8192 [00:07<00:08, 508.81it/s]
Adding requests:  45%|     | 3697/8192 [00:07<00:08, 512.00it/s]
Adding requests:  46%|     | 3751/8192 [00:07<00:08, 518.61it/s]
Adding requests:  46%|     | 3804/8192 [00:07<00:08, 520.90it/s]
Adding requests:  47%|     | 3857/8192 [00:07<00:08, 520.52it/s]
Adding requests:  48%|     | 3910/8192 [00:07<00:08, 522.70it/s]
Adding requests:  48%|     | 3963/8192 [00:07<00:08, 518.87it/s]
Adding requests:  49%|     | 4017/8192 [00:07<00:07, 521.88it/s]
Adding requests:  50%|     | 4070/8192 [00:08<00:08, 502.41it/s]
Adding requests:  50%|     | 4121/8192 [00:08<00:08, 500.39it/s]
Adding requests:  51%|     | 4172/8192 [00:08<00:08, 498.24it/s]
Adding requests:  52%|    | 4225/8192 [00:08<00:07, 506.51it/s]
Adding requests:  52%|    | 4278/8192 [00:08<00:07, 508.88it/s]
Adding requests:  53%|    | 4332/8192 [00:08<00:07, 517.83it/s]
Adding requests:  54%|    | 4385/8192 [00:08<00:07, 520.85it/s]
Adding requests:  54%|    | 4440/8192 [00:08<00:07, 528.80it/s]
Adding requests:  55%|    | 4493/8192 [00:08<00:07, 521.54it/s]
Adding requests:  55%|    | 4546/8192 [00:09<00:07, 517.19it/s]
Adding requests:  56%|    | 4598/8192 [00:09<00:07, 512.27it/s]
Adding requests:  57%|    | 4650/8192 [00:09<00:07, 497.62it/s]
Adding requests:  57%|    | 4702/8192 [00:09<00:06, 503.56it/s]
Adding requests:  58%|    | 4753/8192 [00:09<00:06, 503.54it/s]
Adding requests:  59%|    | 4808/8192 [00:09<00:06, 512.80it/s]
Adding requests:  59%|    | 4860/8192 [00:09<00:06, 510.64it/s]
Adding requests:  60%|    | 4912/8192 [00:09<00:06, 505.43it/s]
Adding requests:  61%|    | 4963/8192 [00:09<00:06, 500.80it/s]
Adding requests:  61%|   | 5019/8192 [00:09<00:06, 517.83it/s]
Adding requests:  62%|   | 5071/8192 [00:10<00:06, 512.83it/s]
Adding requests:  63%|   | 5126/8192 [00:10<00:05, 521.37it/s]
Adding requests:  63%|   | 5179/8192 [00:10<00:05, 521.93it/s]
Adding requests:  64%|   | 5232/8192 [00:10<00:05, 516.21it/s]
Adding requests:  65%|   | 5286/8192 [00:10<00:05, 516.49it/s]
Adding requests:  65%|   | 5338/8192 [00:10<00:05, 513.90it/s]
Adding requests:  66%|   | 5392/8192 [00:10<00:05, 520.65it/s]
Adding requests:  66%|   | 5445/8192 [00:10<00:05, 507.71it/s]
Adding requests:  67%|   | 5497/8192 [00:10<00:05, 509.75it/s]
Adding requests:  68%|   | 5549/8192 [00:10<00:05, 500.13it/s]
Adding requests:  68%|   | 5604/8192 [00:11<00:05, 512.62it/s]
Adding requests:  69%|   | 5656/8192 [00:11<00:05, 506.26it/s]
Adding requests:  70%|   | 5710/8192 [00:11<00:04, 514.31it/s]
Adding requests:  70%|   | 5763/8192 [00:11<00:04, 517.70it/s]
Adding requests:  71%|   | 5815/8192 [00:11<00:04, 513.25it/s]
Adding requests:  72%|  | 5870/8192 [00:11<00:04, 522.96it/s]
Adding requests:  72%|  | 5923/8192 [00:11<00:04, 507.88it/s]
Adding requests:  73%|  | 5975/8192 [00:11<00:04, 470.06it/s]
Adding requests:  74%|  | 6023/8192 [00:11<00:04, 470.59it/s]
Adding requests:  74%|  | 6077/8192 [00:12<00:04, 489.32it/s]
Adding requests:  75%|  | 6127/8192 [00:12<00:04, 476.36it/s]
Adding requests:  75%|  | 6180/8192 [00:12<00:04, 489.82it/s]
Adding requests:  76%|  | 6231/8192 [00:12<00:03, 495.61it/s]
Adding requests:  77%|  | 6287/8192 [00:12<00:03, 512.83it/s]
Adding requests:  77%|  | 6339/8192 [00:12<00:03, 514.87it/s]
Adding requests:  78%|  | 6396/8192 [00:12<00:03, 527.41it/s]
Adding requests:  79%|  | 6450/8192 [00:12<00:03, 529.76it/s]
Adding requests:  79%|  | 6504/8192 [00:12<00:03, 531.96it/s]
Adding requests:  80%|  | 6561/8192 [00:12<00:03, 541.37it/s]
Adding requests:  81%|  | 6616/8192 [00:13<00:02, 528.37it/s]
Adding requests:  81%| | 6672/8192 [00:13<00:02, 534.58it/s]
Adding requests:  82%| | 6726/8192 [00:13<00:02, 529.79it/s]
Adding requests:  83%| | 6780/8192 [00:13<00:02, 525.43it/s]
Adding requests:  83%| | 6833/8192 [00:13<00:02, 525.62it/s]
Adding requests:  84%| | 6886/8192 [00:13<00:02, 523.54it/s]
Adding requests:  85%| | 6941/8192 [00:13<00:02, 531.00it/s]
Adding requests:  85%| | 6995/8192 [00:13<00:02, 533.04it/s]
Adding requests:  86%| | 7049/8192 [00:13<00:02, 526.33it/s]
Adding requests:  87%| | 7106/8192 [00:14<00:02, 538.63it/s]
Adding requests:  87%| | 7160/8192 [00:14<00:01, 530.40it/s]
Adding requests:  88%| | 7214/8192 [00:14<00:01, 522.95it/s]
Adding requests:  89%| | 7267/8192 [00:14<00:01, 524.25it/s]
Adding requests:  89%| | 7320/8192 [00:14<00:01, 519.02it/s]
Adding requests:  90%| | 7372/8192 [00:14<00:01, 491.29it/s]
Adding requests:  91%| | 7427/8192 [00:14<00:01, 507.65it/s]
Adding requests:  91%|| 7480/8192 [00:14<00:01, 513.15it/s]
Adding requests:  92%|| 7534/8192 [00:14<00:01, 520.37it/s]
Adding requests:  93%|| 7587/8192 [00:14<00:01, 517.91it/s]
Adding requests:  93%|| 7640/8192 [00:15<00:01, 519.81it/s]
Adding requests:  94%|| 7693/8192 [00:15<00:00, 519.31it/s]
Adding requests:  95%|| 7745/8192 [00:15<00:00, 516.31it/s]
Adding requests:  95%|| 7798/8192 [00:15<00:00, 520.20it/s]
Adding requests:  96%|| 7851/8192 [00:15<00:00, 522.98it/s]
Adding requests:  96%|| 7904/8192 [00:15<00:00, 520.46it/s]
Adding requests:  97%|| 7959/8192 [00:15<00:00, 528.56it/s]
Adding requests:  98%|| 8012/8192 [00:15<00:00, 527.84it/s]
Adding requests:  98%|| 8067/8192 [00:15<00:00, 533.61it/s]
Adding requests:  99%|| 8121/8192 [00:15<00:00, 519.10it/s]
Adding requests: 100%|| 8176/8192 [00:16<00:00, 526.67it/s]
Adding requests: 100%|| 8192/8192 [00:16<00:00, 508.89it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 130/8192 [00:01<01:24, 95.12it/s, est. speed input: 97403.02 toks/s, output: 95.12 toks/s]
Processed prompts:   2%|         | 194/8192 [00:06<05:25, 24.60it/s, est. speed input: 29602.18 toks/s, output: 28.91 toks/s]
Processed prompts:   3%|         | 258/8192 [00:12<07:28, 17.68it/s, est. speed input: 21912.00 toks/s, output: 21.40 toks/s]
Processed prompts:   4%|         | 322/8192 [00:17<08:35, 15.27it/s, est. speed input: 19028.21 toks/s, output: 18.58 toks/s]
Processed prompts:   5%|         | 386/8192 [00:22<09:18, 13.99it/s, est. speed input: 17429.44 toks/s, output: 17.02 toks/s]
Processed prompts:   5%|         | 450/8192 [00:27<09:40, 13.33it/s, est. speed input: 16481.70 toks/s, output: 16.10 toks/s]
Processed prompts:   6%|         | 514/8192 [00:33<09:57, 12.86it/s, est. speed input: 15797.26 toks/s, output: 15.43 toks/s]
Processed prompts:   7%|         | 578/8192 [00:38<10:06, 12.56it/s, est. speed input: 15301.02 toks/s, output: 14.94 toks/s]
Processed prompts:   8%|         | 642/8192 [00:44<10:10, 12.36it/s, est. speed input: 14925.84 toks/s, output: 14.58 toks/s]
Processed prompts:   9%|         | 706/8192 [00:49<10:12, 12.22it/s, est. speed input: 14629.97 toks/s, output: 14.29 toks/s]
Processed prompts:   9%|         | 770/8192 [00:54<10:12, 12.13it/s, est. speed input: 14392.26 toks/s, output: 14.05 toks/s]
Processed prompts:  10%|         | 834/8192 [01:00<10:09, 12.07it/s, est. speed input: 14198.48 toks/s, output: 13.87 toks/s]
Processed prompts:  11%|         | 898/8192 [01:05<10:03, 12.10it/s, est. speed input: 14058.04 toks/s, output: 13.73 toks/s]
Processed prompts:  12%|        | 962/8192 [01:10<09:56, 12.12it/s, est. speed input: 13939.45 toks/s, output: 13.61 toks/s]
Processed prompts:  13%|        | 1026/8192 [01:16<09:54, 12.06it/s, est. speed input: 13817.34 toks/s, output: 13.49 toks/s]
Processed prompts:  13%|        | 1090/8192 [01:21<09:50, 12.02it/s, est. speed input: 13712.44 toks/s, output: 13.39 toks/s]
Processed prompts:  14%|        | 1154/8192 [01:26<09:43, 12.06it/s, est. speed input: 13635.95 toks/s, output: 13.32 toks/s]
Processed prompts:  15%|        | 1218/8192 [01:31<09:36, 12.09it/s, est. speed input: 13567.15 toks/s, output: 13.25 toks/s]
Processed prompts:  16%|        | 1282/8192 [01:37<09:33, 12.05it/s, est. speed input: 13493.98 toks/s, output: 13.18 toks/s]
Processed prompts:  16%|        | 1346/8192 [01:42<09:29, 12.02it/s, est. speed input: 13427.98 toks/s, output: 13.11 toks/s]
Processed prompts:  17%|        | 1410/8192 [01:48<09:25, 11.99it/s, est. speed input: 13368.01 toks/s, output: 13.05 toks/s]
Processed prompts:  18%|        | 1474/8192 [01:53<09:20, 11.98it/s, est. speed input: 13313.97 toks/s, output: 13.00 toks/s]
Processed prompts:  19%|        | 1538/8192 [01:58<09:13, 12.03it/s, est. speed input: 13275.13 toks/s, output: 12.96 toks/s]
Processed prompts:  20%|        | 1602/8192 [02:04<09:09, 12.00it/s, est. speed input: 13229.20 toks/s, output: 12.92 toks/s]
Processed prompts:  20%|        | 1666/8192 [02:09<09:05, 11.97it/s, est. speed input: 13186.77 toks/s, output: 12.88 toks/s]
Processed prompts:  21%|        | 1730/8192 [02:14<09:00, 11.96it/s, est. speed input: 13148.05 toks/s, output: 12.84 toks/s]
Processed prompts:  22%|       | 1794/8192 [02:20<08:55, 11.95it/s, est. speed input: 13112.24 toks/s, output: 12.80 toks/s]
Processed prompts:  23%|       | 1858/8192 [02:25<08:47, 12.01it/s, est. speed input: 13088.43 toks/s, output: 12.78 toks/s]
Processed prompts:  23%|       | 1922/8192 [02:30<08:40, 12.05it/s, est. speed input: 13065.36 toks/s, output: 12.76 toks/s]
Processed prompts:  24%|       | 1986/8192 [02:36<08:36, 12.01it/s, est. speed input: 13036.19 toks/s, output: 12.73 toks/s]
Processed prompts:  25%|       | 2050/8192 [02:41<08:32, 11.99it/s, est. speed input: 13008.50 toks/s, output: 12.70 toks/s]
Processed prompts:  26%|       | 2114/8192 [02:46<08:27, 11.96it/s, est. speed input: 12982.59 toks/s, output: 12.68 toks/s]
Processed prompts:  27%|       | 2178/8192 [02:51<08:18, 12.06it/s, est. speed input: 12970.64 toks/s, output: 12.67 toks/s]
Processed prompts:  27%|       | 2242/8192 [02:57<08:12, 12.09it/s, est. speed input: 12954.74 toks/s, output: 12.65 toks/s]
Processed prompts:  28%|       | 2306/8192 [03:02<08:06, 12.11it/s, est. speed input: 12939.96 toks/s, output: 12.64 toks/s]
Processed prompts:  29%|       | 2370/8192 [03:07<07:58, 12.16it/s, est. speed input: 12929.78 toks/s, output: 12.63 toks/s]
Processed prompts:  30%|       | 2434/8192 [03:13<07:56, 12.09it/s, est. speed input: 12909.70 toks/s, output: 12.61 toks/s]
Processed prompts:  30%|       | 2498/8192 [03:18<07:50, 12.10it/s, est. speed input: 12896.80 toks/s, output: 12.59 toks/s]
Processed prompts:  31%|      | 2562/8192 [03:23<07:44, 12.12it/s, est. speed input: 12885.15 toks/s, output: 12.58 toks/s]
Processed prompts:  32%|      | 2626/8192 [03:28<07:41, 12.06it/s, est. speed input: 12867.67 toks/s, output: 12.57 toks/s]
Processed prompts:  33%|      | 2690/8192 [03:34<07:37, 12.01it/s, est. speed input: 12851.05 toks/s, output: 12.55 toks/s]
Processed prompts:  34%|      | 2754/8192 [03:39<07:33, 11.99it/s, est. speed input: 12835.26 toks/s, output: 12.53 toks/s]
Processed prompts:  34%|      | 2818/8192 [03:45<07:29, 11.97it/s, est. speed input: 12820.24 toks/s, output: 12.52 toks/s]
Processed prompts:  35%|      | 2882/8192 [03:50<07:24, 11.95it/s, est. speed input: 12805.99 toks/s, output: 12.51 toks/s]
Processed prompts:  36%|      | 2946/8192 [03:55<07:19, 11.94it/s, est. speed input: 12792.26 toks/s, output: 12.49 toks/s]
Processed prompts:  37%|      | 3010/8192 [04:01<07:14, 11.94it/s, est. speed input: 12779.23 toks/s, output: 12.48 toks/s]
Processed prompts:  38%|      | 3074/8192 [04:06<07:08, 11.93it/s, est. speed input: 12766.93 toks/s, output: 12.47 toks/s]
Processed prompts:  38%|      | 3138/8192 [04:11<07:01, 11.99it/s, est. speed input: 12759.67 toks/s, output: 12.46 toks/s]
Processed prompts:  39%|      | 3202/8192 [04:17<06:57, 11.97it/s, est. speed input: 12747.85 toks/s, output: 12.45 toks/s]
Processed prompts:  40%|      | 3266/8192 [04:22<06:52, 11.95it/s, est. speed input: 12736.88 toks/s, output: 12.44 toks/s]
Processed prompts:  41%|      | 3330/8192 [04:27<06:47, 11.94it/s, est. speed input: 12726.12 toks/s, output: 12.43 toks/s]
Processed prompts:  41%|     | 3394/8192 [04:33<06:41, 11.94it/s, est. speed input: 12715.92 toks/s, output: 12.42 toks/s]
Processed prompts:  42%|     | 3458/8192 [04:38<06:33, 12.04it/s, est. speed input: 12713.58 toks/s, output: 12.42 toks/s]
Processed prompts:  43%|     | 3522/8192 [04:43<06:28, 12.01it/s, est. speed input: 12704.30 toks/s, output: 12.41 toks/s]
Processed prompts:  44%|     | 3586/8192 [04:49<06:24, 11.98it/s, est. speed input: 12694.90 toks/s, output: 12.40 toks/s]
Processed prompts:  45%|     | 3650/8192 [04:54<06:19, 11.96it/s, est. speed input: 12685.62 toks/s, output: 12.39 toks/s]
Processed prompts:  45%|     | 3714/8192 [04:59<06:12, 12.01it/s, est. speed input: 12681.12 toks/s, output: 12.38 toks/s]
Processed prompts:  46%|     | 3778/8192 [05:05<06:08, 11.98it/s, est. speed input: 12672.74 toks/s, output: 12.38 toks/s]
Processed prompts:  47%|     | 3842/8192 [05:10<06:03, 11.96it/s, est. speed input: 12664.29 toks/s, output: 12.37 toks/s]
Processed prompts:  48%|     | 3906/8192 [05:16<05:58, 11.94it/s, est. speed input: 12656.38 toks/s, output: 12.36 toks/s]
Processed prompts:  48%|     | 3970/8192 [05:21<05:53, 11.94it/s, est. speed input: 12648.90 toks/s, output: 12.35 toks/s]
Processed prompts:  49%|     | 4034/8192 [05:26<05:46, 11.99it/s, est. speed input: 12645.21 toks/s, output: 12.35 toks/s]
Processed prompts:  50%|     | 4098/8192 [05:32<05:41, 11.97it/s, est. speed input: 12638.14 toks/s, output: 12.34 toks/s]
Processed prompts:  51%|     | 4162/8192 [05:37<05:37, 11.95it/s, est. speed input: 12631.05 toks/s, output: 12.34 toks/s]
Processed prompts:  52%|    | 4226/8192 [05:42<05:29, 12.05it/s, est. speed input: 12630.48 toks/s, output: 12.33 toks/s]
Processed prompts:  52%|    | 4290/8192 [05:47<05:23, 12.08it/s, est. speed input: 12627.37 toks/s, output: 12.33 toks/s]
Processed prompts:  53%|    | 4354/8192 [05:53<05:18, 12.04it/s, est. speed input: 12621.30 toks/s, output: 12.33 toks/s]
Processed prompts:  54%|    | 4418/8192 [05:58<05:14, 12.00it/s, est. speed input: 12615.18 toks/s, output: 12.32 toks/s]
Processed prompts:  55%|    | 4482/8192 [06:03<05:09, 11.98it/s, est. speed input: 12609.13 toks/s, output: 12.31 toks/s]
Processed prompts:  55%|    | 4546/8192 [06:09<05:04, 11.96it/s, est. speed input: 12603.06 toks/s, output: 12.31 toks/s]
Processed prompts:  56%|    | 4610/8192 [06:14<04:59, 11.94it/s, est. speed input: 12597.32 toks/s, output: 12.30 toks/s]
Processed prompts:  57%|    | 4674/8192 [06:20<04:54, 11.93it/s, est. speed input: 12591.66 toks/s, output: 12.30 toks/s]
Processed prompts:  58%|    | 4738/8192 [06:25<04:47, 12.00it/s, est. speed input: 12589.45 toks/s, output: 12.29 toks/s]
Processed prompts:  59%|    | 4802/8192 [06:30<04:41, 12.04it/s, est. speed input: 12587.28 toks/s, output: 12.29 toks/s]
Processed prompts:  59%|    | 4866/8192 [06:36<04:37, 11.99it/s, est. speed input: 12581.78 toks/s, output: 12.29 toks/s]
Processed prompts:  60%|    | 4930/8192 [06:41<04:32, 11.97it/s, est. speed input: 12576.63 toks/s, output: 12.28 toks/s]
Processed prompts:  61%|    | 4994/8192 [06:46<04:25, 12.06it/s, est. speed input: 12576.76 toks/s, output: 12.28 toks/s]
Processed prompts:  62%|   | 5058/8192 [06:51<04:20, 12.02it/s, est. speed input: 12571.78 toks/s, output: 12.28 toks/s]
Processed prompts:  63%|   | 5122/8192 [06:57<04:16, 11.99it/s, est. speed input: 12566.99 toks/s, output: 12.27 toks/s]
Processed prompts:  63%|   | 5186/8192 [07:02<04:09, 12.03it/s, est. speed input: 12565.13 toks/s, output: 12.27 toks/s]
Processed prompts:  64%|   | 5250/8192 [07:07<04:05, 12.00it/s, est. speed input: 12560.80 toks/s, output: 12.27 toks/s]
Processed prompts:  65%|   | 5314/8192 [07:13<03:59, 12.04it/s, est. speed input: 12559.04 toks/s, output: 12.26 toks/s]
Processed prompts:  66%|   | 5378/8192 [07:18<03:53, 12.06it/s, est. speed input: 12557.30 toks/s, output: 12.26 toks/s]
Processed prompts:  66%|   | 5442/8192 [07:23<03:48, 12.02it/s, est. speed input: 12552.95 toks/s, output: 12.26 toks/s]
Processed prompts:  67%|   | 5506/8192 [07:29<03:42, 12.05it/s, est. speed input: 12551.54 toks/s, output: 12.26 toks/s]
Processed prompts:  68%|   | 5570/8192 [07:34<03:38, 12.01it/s, est. speed input: 12547.44 toks/s, output: 12.25 toks/s]
Processed prompts:  69%|   | 5634/8192 [07:39<03:32, 12.05it/s, est. speed input: 12545.94 toks/s, output: 12.25 toks/s]
Processed prompts:  70%|   | 5698/8192 [07:45<03:27, 12.01it/s, est. speed input: 12542.05 toks/s, output: 12.25 toks/s]
Processed prompts:  70%|   | 5762/8192 [07:50<03:22, 11.98it/s, est. speed input: 12538.08 toks/s, output: 12.24 toks/s]
Processed prompts:  71%|   | 5826/8192 [07:55<03:17, 11.96it/s, est. speed input: 12534.25 toks/s, output: 12.24 toks/s]
Processed prompts:  72%|  | 5890/8192 [08:01<03:12, 11.94it/s, est. speed input: 12530.30 toks/s, output: 12.24 toks/s]
Processed prompts:  73%|  | 5954/8192 [08:06<03:07, 11.93it/s, est. speed input: 12526.58 toks/s, output: 12.23 toks/s]
Processed prompts:  73%|  | 6018/8192 [08:12<03:02, 11.93it/s, est. speed input: 12523.15 toks/s, output: 12.23 toks/s]
Processed prompts:  74%|  | 6082/8192 [08:17<02:56, 11.92it/s, est. speed input: 12519.63 toks/s, output: 12.23 toks/s]
Processed prompts:  75%|  | 6146/8192 [08:22<02:51, 11.92it/s, est. speed input: 12516.03 toks/s, output: 12.22 toks/s]
Processed prompts:  76%|  | 6210/8192 [08:28<02:46, 11.91it/s, est. speed input: 12512.61 toks/s, output: 12.22 toks/s]
Processed prompts:  77%|  | 6274/8192 [08:33<02:41, 11.91it/s, est. speed input: 12509.28 toks/s, output: 12.22 toks/s]
Processed prompts:  77%|  | 6338/8192 [08:38<02:35, 11.91it/s, est. speed input: 12506.08 toks/s, output: 12.21 toks/s]
Processed prompts:  78%|  | 6402/8192 [08:44<02:30, 11.91it/s, est. speed input: 12502.79 toks/s, output: 12.21 toks/s]
Processed prompts:  79%|  | 6466/8192 [08:49<02:24, 11.91it/s, est. speed input: 12499.85 toks/s, output: 12.21 toks/s]
Processed prompts:  80%|  | 6530/8192 [08:55<02:19, 11.91it/s, est. speed input: 12496.85 toks/s, output: 12.20 toks/s]
Processed prompts:  80%|  | 6594/8192 [09:00<02:13, 11.98it/s, est. speed input: 12496.06 toks/s, output: 12.20 toks/s]
Processed prompts:  81%| | 6658/8192 [09:05<02:07, 12.02it/s, est. speed input: 12495.36 toks/s, output: 12.20 toks/s]
Processed prompts:  82%| | 6722/8192 [09:10<02:02, 11.99it/s, est. speed input: 12492.61 toks/s, output: 12.20 toks/s]
Processed prompts:  83%| | 6786/8192 [09:16<01:57, 11.97it/s, est. speed input: 12489.79 toks/s, output: 12.20 toks/s]
Processed prompts:  84%| | 6850/8192 [09:21<01:52, 11.95it/s, est. speed input: 12486.93 toks/s, output: 12.19 toks/s]
Processed prompts:  84%| | 6914/8192 [09:27<01:47, 11.94it/s, est. speed input: 12484.22 toks/s, output: 12.19 toks/s]
Processed prompts:  85%| | 6978/8192 [09:32<01:41, 11.93it/s, est. speed input: 12481.53 toks/s, output: 12.19 toks/s]
Processed prompts:  86%| | 7042/8192 [09:37<01:36, 11.92it/s, est. speed input: 12478.77 toks/s, output: 12.19 toks/s]
Processed prompts:  87%| | 7106/8192 [09:43<01:30, 11.99it/s, est. speed input: 12478.43 toks/s, output: 12.19 toks/s]
Processed prompts:  88%| | 7170/8192 [09:48<01:25, 11.96it/s, est. speed input: 12475.72 toks/s, output: 12.18 toks/s]
Processed prompts:  88%| | 7234/8192 [09:53<01:19, 12.01it/s, est. speed input: 12475.21 toks/s, output: 12.18 toks/s]
Processed prompts:  89%| | 7298/8192 [09:59<01:14, 11.98it/s, est. speed input: 12472.62 toks/s, output: 12.18 toks/s]
Processed prompts:  90%| | 7362/8192 [10:04<01:09, 11.96it/s, est. speed input: 12470.16 toks/s, output: 12.18 toks/s]
Processed prompts:  91%| | 7426/8192 [10:09<01:03, 12.00it/s, est. speed input: 12469.59 toks/s, output: 12.18 toks/s]
Processed prompts:  91%|| 7490/8192 [10:15<00:58, 11.98it/s, est. speed input: 12467.44 toks/s, output: 12.18 toks/s]
Processed prompts:  92%|| 7554/8192 [10:20<00:52, 12.08it/s, est. speed input: 12468.50 toks/s, output: 12.18 toks/s]
Processed prompts:  93%|| 7618/8192 [10:25<00:47, 12.03it/s, est. speed input: 12466.23 toks/s, output: 12.17 toks/s]
Processed prompts:  94%|| 7682/8192 [10:31<00:42, 12.06it/s, est. speed input: 12465.81 toks/s, output: 12.17 toks/s]
Processed prompts:  95%|| 7746/8192 [10:36<00:37, 12.01it/s, est. speed input: 12463.43 toks/s, output: 12.17 toks/s]
Processed prompts:  95%|| 7810/8192 [10:41<00:31, 11.98it/s, est. speed input: 12461.31 toks/s, output: 12.17 toks/s]
Processed prompts:  96%|| 7874/8192 [10:47<00:26, 11.96it/s, est. speed input: 12459.12 toks/s, output: 12.17 toks/s]
Processed prompts:  97%|| 7938/8192 [10:52<00:21, 12.01it/s, est. speed input: 12458.75 toks/s, output: 12.17 toks/s]
Processed prompts:  98%|| 8002/8192 [10:57<00:15, 11.98it/s, est. speed input: 12456.69 toks/s, output: 12.16 toks/s]
Processed prompts:  98%|| 8066/8192 [11:03<00:10, 12.03it/s, est. speed input: 12456.43 toks/s, output: 12.16 toks/s]
Processed prompts:  99%|| 8130/8192 [11:08<00:05, 12.10it/s, est. speed input: 12457.43 toks/s, output: 12.17 toks/s]
Processed prompts: 100%|| 8192/8192 [11:08<00:00, 12.10it/s, est. speed input: 12552.42 toks/s, output: 12.26 toks/s]
Processed prompts: 100%|| 8192/8192 [11:08<00:00, 12.26it/s, est. speed input: 12552.42 toks/s, output: 12.26 toks/s]
[rank0]:[W126 13:22:05.117879982 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 19:16:11
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:16:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:16:15 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1640888) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1640888) WARNING 01-26 19:17:30 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 11.07 requests/s, 5679.84 total tokens/s, 11.07 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 19:16:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:16:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:16:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:16:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:16:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:16:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:16:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:16:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:16:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:16:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:16:19] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:16:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:16:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:16:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:16:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:16:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:16:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1640888) [2026-01-26 19:16:19] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1640888) [2026-01-26 19:16:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1640888) [2026-01-26 19:16:19] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1640888) [2026-01-26 19:16:19] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1640888) [2026-01-26 19:16:19] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1640888) [2026-01-26 19:16:19] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1640888) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1640888) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.56s/it]
(EngineCore_DP0 pid=1640888) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.99s/it]
(EngineCore_DP0 pid=1640888) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.47s/it]
(EngineCore_DP0 pid=1640888) 
(EngineCore_DP0 pid=1640888) [2026-01-26 19:17:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1640888) [2026-01-26 19:17:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1640888) [2026-01-26 19:17:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1640888) [2026-01-26 19:17:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1640888) [2026-01-26 19:17:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1640888) [2026-01-26 19:17:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1640888) [2026-01-26 19:17:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1640888) [2026-01-26 19:17:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1640888) 2026-01-26 19:17:29,484 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1640888) 2026-01-26 19:17:29,539 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  14%|        | 18/128 [00:00<00:00, 178.25it/s]
Adding requests:  72%|  | 92/128 [00:00<00:00, 505.12it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 537.33it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:17,  7.31it/s, est. speed input: 3741.95 toks/s, output: 7.31 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:12, 10.12it/s, est. speed input: 4991.02 toks/s, output: 9.75 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:11, 10.78it/s, est. speed input: 5312.89 toks/s, output: 10.38 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:10, 11.03it/s, est. speed input: 5451.92 toks/s, output: 10.65 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:10, 11.19it/s, est. speed input: 5538.27 toks/s, output: 10.82 toks/s]
Processed prompts:   9%|         | 11/128 [00:01<00:10, 11.22it/s, est. speed input: 5580.00 toks/s, output: 10.90 toks/s]
Processed prompts:  10%|         | 13/128 [00:01<00:10, 11.29it/s, est. speed input: 5619.84 toks/s, output: 10.98 toks/s]
Processed prompts:  12%|        | 15/128 [00:01<00:09, 11.41it/s, est. speed input: 5664.63 toks/s, output: 11.06 toks/s]
Processed prompts:  13%|        | 17/128 [00:01<00:09, 11.39it/s, est. speed input: 5682.07 toks/s, output: 11.10 toks/s]
Processed prompts:  15%|        | 19/128 [00:01<00:09, 11.42it/s, est. speed input: 5701.54 toks/s, output: 11.14 toks/s]
Processed prompts:  16%|        | 21/128 [00:01<00:09, 11.44it/s, est. speed input: 5718.63 toks/s, output: 11.17 toks/s]
Processed prompts:  18%|        | 23/128 [00:02<00:09, 11.31it/s, est. speed input: 5712.17 toks/s, output: 11.16 toks/s]
Processed prompts:  20%|        | 25/128 [00:02<00:09, 11.38it/s, est. speed input: 5726.81 toks/s, output: 11.19 toks/s]
Processed prompts:  21%|        | 27/128 [00:02<00:08, 11.39it/s, est. speed input: 5735.81 toks/s, output: 11.20 toks/s]
Processed prompts:  23%|       | 29/128 [00:02<00:08, 11.46it/s, est. speed input: 5750.29 toks/s, output: 11.23 toks/s]
Processed prompts:  24%|       | 31/128 [00:02<00:08, 11.49it/s, est. speed input: 5760.29 toks/s, output: 11.25 toks/s]
Processed prompts:  26%|       | 33/128 [00:02<00:08, 11.49it/s, est. speed input: 5767.87 toks/s, output: 11.27 toks/s]
Processed prompts:  27%|       | 35/128 [00:03<00:08, 11.38it/s, est. speed input: 5764.01 toks/s, output: 11.26 toks/s]
Processed prompts:  29%|       | 37/128 [00:03<00:07, 11.44it/s, est. speed input: 5772.38 toks/s, output: 11.27 toks/s]
Processed prompts:  30%|       | 39/128 [00:03<00:07, 11.48it/s, est. speed input: 5780.14 toks/s, output: 11.29 toks/s]
Processed prompts:  32%|      | 41/128 [00:03<00:07, 11.46it/s, est. speed input: 5783.26 toks/s, output: 11.30 toks/s]
Processed prompts:  34%|      | 43/128 [00:03<00:07, 11.46it/s, est. speed input: 5787.01 toks/s, output: 11.30 toks/s]
Processed prompts:  35%|      | 45/128 [00:03<00:07, 11.45it/s, est. speed input: 5789.91 toks/s, output: 11.31 toks/s]
Processed prompts:  37%|      | 47/128 [00:04<00:07, 11.32it/s, est. speed input: 5783.45 toks/s, output: 11.30 toks/s]
Processed prompts:  38%|      | 49/128 [00:04<00:06, 11.38it/s, est. speed input: 5787.92 toks/s, output: 11.30 toks/s]
Processed prompts:  40%|      | 51/128 [00:04<00:06, 11.42it/s, est. speed input: 5792.32 toks/s, output: 11.31 toks/s]
Processed prompts:  41%|     | 53/128 [00:04<00:06, 11.43it/s, est. speed input: 5795.18 toks/s, output: 11.32 toks/s]
Processed prompts:  43%|     | 55/128 [00:04<00:06, 11.47it/s, est. speed input: 5799.66 toks/s, output: 11.33 toks/s]
Processed prompts:  45%|     | 57/128 [00:05<00:06, 11.46it/s, est. speed input: 5801.51 toks/s, output: 11.33 toks/s]
Processed prompts:  46%|     | 59/128 [00:05<00:06, 11.36it/s, est. speed input: 5798.09 toks/s, output: 11.32 toks/s]
Processed prompts:  48%|     | 61/128 [00:05<00:05, 11.42it/s, est. speed input: 5802.20 toks/s, output: 11.33 toks/s]
Processed prompts:  49%|     | 63/128 [00:05<00:05, 11.44it/s, est. speed input: 5804.58 toks/s, output: 11.34 toks/s]
Processed prompts:  51%|     | 65/128 [00:05<00:05, 11.43it/s, est. speed input: 5805.53 toks/s, output: 11.34 toks/s]
Processed prompts:  52%|    | 67/128 [00:05<00:05, 11.50it/s, est. speed input: 5810.55 toks/s, output: 11.35 toks/s]
Processed prompts:  54%|    | 69/128 [00:06<00:05, 11.50it/s, est. speed input: 5812.58 toks/s, output: 11.35 toks/s]
Processed prompts:  55%|    | 71/128 [00:06<00:05, 11.34it/s, est. speed input: 5807.07 toks/s, output: 11.34 toks/s]
Processed prompts:  57%|    | 73/128 [00:06<00:04, 11.42it/s, est. speed input: 5810.72 toks/s, output: 11.35 toks/s]
Processed prompts:  59%|    | 75/128 [00:06<00:04, 11.41it/s, est. speed input: 5811.31 toks/s, output: 11.35 toks/s]
Processed prompts:  60%|    | 77/128 [00:06<00:04, 11.41it/s, est. speed input: 5812.31 toks/s, output: 11.35 toks/s]
Processed prompts:  62%|   | 79/128 [00:06<00:04, 11.43it/s, est. speed input: 5813.70 toks/s, output: 11.35 toks/s]
Processed prompts:  63%|   | 81/128 [00:07<00:04, 11.46it/s, est. speed input: 5816.08 toks/s, output: 11.36 toks/s]
Processed prompts:  65%|   | 83/128 [00:07<00:03, 11.37it/s, est. speed input: 5813.36 toks/s, output: 11.35 toks/s]
Processed prompts:  66%|   | 85/128 [00:07<00:03, 11.40it/s, est. speed input: 5815.03 toks/s, output: 11.36 toks/s]
Processed prompts:  68%|   | 87/128 [00:07<00:03, 11.41it/s, est. speed input: 5815.67 toks/s, output: 11.36 toks/s]
Processed prompts:  70%|   | 89/128 [00:07<00:03, 11.43it/s, est. speed input: 5817.22 toks/s, output: 11.36 toks/s]
Processed prompts:  71%|   | 91/128 [00:08<00:03, 11.50it/s, est. speed input: 5820.49 toks/s, output: 11.37 toks/s]
Processed prompts:  73%|  | 93/128 [00:08<00:03, 11.47it/s, est. speed input: 5821.02 toks/s, output: 11.37 toks/s]
Processed prompts:  74%|  | 95/128 [00:08<00:02, 11.39it/s, est. speed input: 5819.17 toks/s, output: 11.37 toks/s]
Processed prompts:  76%|  | 97/128 [00:08<00:02, 11.36it/s, est. speed input: 5818.52 toks/s, output: 11.36 toks/s]
Processed prompts:  77%|  | 99/128 [00:08<00:02, 11.50it/s, est. speed input: 5822.96 toks/s, output: 11.37 toks/s]
Processed prompts:  79%|  | 101/128 [00:08<00:02, 11.48it/s, est. speed input: 5823.84 toks/s, output: 11.37 toks/s]
Processed prompts:  80%|  | 103/128 [00:09<00:02, 11.45it/s, est. speed input: 5823.64 toks/s, output: 11.37 toks/s]
Processed prompts:  82%| | 105/128 [00:09<00:02, 11.48it/s, est. speed input: 5825.35 toks/s, output: 11.38 toks/s]
Processed prompts:  84%| | 107/128 [00:09<00:01, 11.39it/s, est. speed input: 5823.55 toks/s, output: 11.37 toks/s]
Processed prompts:  85%| | 109/128 [00:09<00:01, 11.44it/s, est. speed input: 5825.10 toks/s, output: 11.38 toks/s]
Processed prompts:  87%| | 111/128 [00:09<00:01, 11.44it/s, est. speed input: 5825.75 toks/s, output: 11.38 toks/s]
Processed prompts:  88%| | 113/128 [00:09<00:01, 11.44it/s, est. speed input: 5826.34 toks/s, output: 11.38 toks/s]
Processed prompts:  90%| | 115/128 [00:10<00:01, 11.37it/s, est. speed input: 5824.85 toks/s, output: 11.38 toks/s]
Processed prompts:  91%|| 117/128 [00:10<00:00, 11.38it/s, est. speed input: 5825.11 toks/s, output: 11.38 toks/s]
Processed prompts:  93%|| 119/128 [00:10<00:00, 11.34it/s, est. speed input: 5823.95 toks/s, output: 11.37 toks/s]
Processed prompts:  95%|| 121/128 [00:10<00:00, 11.31it/s, est. speed input: 5822.79 toks/s, output: 11.37 toks/s]
Processed prompts:  96%|| 123/128 [00:10<00:00, 11.40it/s, est. speed input: 5824.78 toks/s, output: 11.38 toks/s]
Processed prompts:  98%|| 125/128 [00:10<00:00, 11.38it/s, est. speed input: 5824.31 toks/s, output: 11.38 toks/s]
Processed prompts:  99%|| 127/128 [00:11<00:00, 11.36it/s, est. speed input: 5823.89 toks/s, output: 11.37 toks/s]
Processed prompts: 100%|| 128/128 [00:11<00:00, 11.36it/s, est. speed input: 5817.67 toks/s, output: 11.36 toks/s]
Processed prompts: 100%|| 128/128 [00:11<00:00, 11.36it/s, est. speed input: 5817.67 toks/s, output: 11.36 toks/s]
[rank0]:[W126 19:17:42.602630569 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 19:17:48
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:17:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:17:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1642494) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1642494) WARNING 01-26 19:19:12 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.84 requests/s, 5983.65 total tokens/s, 5.84 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 19:17:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:17:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:17:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:17:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:17:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:17:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:17:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:17:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:17:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:17:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:17:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:17:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:17:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:17:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:17:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:17:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:17:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1642494) [2026-01-26 19:18:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1642494) [2026-01-26 19:18:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1642494) [2026-01-26 19:18:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1642494) [2026-01-26 19:18:00] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1642494) [2026-01-26 19:18:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1642494) [2026-01-26 19:18:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1642494) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1642494) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.90s/it]
(EngineCore_DP0 pid=1642494) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.81s/it]
(EngineCore_DP0 pid=1642494) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.38s/it]
(EngineCore_DP0 pid=1642494) 
(EngineCore_DP0 pid=1642494) [2026-01-26 19:19:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1642494) [2026-01-26 19:19:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1642494) [2026-01-26 19:19:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1642494) [2026-01-26 19:19:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1642494) [2026-01-26 19:19:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1642494) [2026-01-26 19:19:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1642494) [2026-01-26 19:19:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1642494) [2026-01-26 19:19:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1642494) 2026-01-26 19:19:11,275 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1642494) 2026-01-26 19:19:11,319 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  38%|      | 48/128 [00:00<00:00, 478.87it/s]
Adding requests:  75%|  | 96/128 [00:00<00:00, 438.54it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 436.30it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 2/128 [00:00<00:08, 14.95it/s, est. speed input: 15305.66 toks/s, output: 14.95 toks/s]
Processed prompts:   3%|         | 4/128 [00:00<00:15,  7.83it/s, est. speed input: 8633.04 toks/s, output: 8.43 toks/s]  
Processed prompts:   4%|         | 5/128 [00:00<00:17,  7.12it/s, est. speed input: 7935.44 toks/s, output: 7.75 toks/s]
Processed prompts:   5%|         | 6/128 [00:00<00:18,  6.75it/s, est. speed input: 7571.75 toks/s, output: 7.39 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:18,  6.43it/s, est. speed input: 7282.78 toks/s, output: 7.11 toks/s]
Processed prompts:   6%|         | 8/128 [00:01<00:19,  6.24it/s, est. speed input: 7086.14 toks/s, output: 6.92 toks/s]
Processed prompts:   7%|         | 9/128 [00:01<00:19,  6.12it/s, est. speed input: 6948.95 toks/s, output: 6.79 toks/s]
Processed prompts:   8%|         | 10/128 [00:01<00:19,  6.05it/s, est. speed input: 6844.64 toks/s, output: 6.68 toks/s]
Processed prompts:   9%|         | 11/128 [00:01<00:19,  5.99it/s, est. speed input: 6758.13 toks/s, output: 6.60 toks/s]
Processed prompts:   9%|         | 12/128 [00:01<00:19,  6.00it/s, est. speed input: 6703.57 toks/s, output: 6.55 toks/s]
Processed prompts:  10%|         | 13/128 [00:02<00:19,  5.92it/s, est. speed input: 6632.57 toks/s, output: 6.48 toks/s]
Processed prompts:  11%|         | 14/128 [00:02<00:19,  5.90it/s, est. speed input: 6581.45 toks/s, output: 6.43 toks/s]
Processed prompts:  12%|        | 15/128 [00:02<00:19,  5.90it/s, est. speed input: 6543.49 toks/s, output: 6.39 toks/s]
Processed prompts:  12%|        | 16/128 [00:02<00:18,  5.90it/s, est. speed input: 6508.87 toks/s, output: 6.36 toks/s]
Processed prompts:  13%|        | 17/128 [00:02<00:18,  5.92it/s, est. speed input: 6484.44 toks/s, output: 6.33 toks/s]
Processed prompts:  14%|        | 18/128 [00:02<00:18,  5.93it/s, est. speed input: 6461.70 toks/s, output: 6.31 toks/s]
Processed prompts:  15%|        | 19/128 [00:03<00:18,  5.88it/s, est. speed input: 6428.72 toks/s, output: 6.28 toks/s]
Processed prompts:  16%|        | 20/128 [00:03<00:18,  5.87it/s, est. speed input: 6405.83 toks/s, output: 6.26 toks/s]
Processed prompts:  16%|        | 21/128 [00:03<00:18,  5.90it/s, est. speed input: 6390.60 toks/s, output: 6.24 toks/s]
Processed prompts:  17%|        | 22/128 [00:03<00:17,  5.90it/s, est. speed input: 6374.57 toks/s, output: 6.23 toks/s]
Processed prompts:  18%|        | 23/128 [00:03<00:17,  5.91it/s, est. speed input: 6361.48 toks/s, output: 6.21 toks/s]
Processed prompts:  19%|        | 24/128 [00:03<00:17,  5.91it/s, est. speed input: 6347.88 toks/s, output: 6.20 toks/s]
Processed prompts:  20%|        | 25/128 [00:04<00:17,  5.88it/s, est. speed input: 6331.16 toks/s, output: 6.18 toks/s]
Processed prompts:  20%|        | 26/128 [00:04<00:17,  5.86it/s, est. speed input: 6316.00 toks/s, output: 6.17 toks/s]
Processed prompts:  21%|        | 27/128 [00:04<00:17,  5.89it/s, est. speed input: 6307.72 toks/s, output: 6.16 toks/s]
Processed prompts:  22%|       | 28/128 [00:04<00:16,  5.88it/s, est. speed input: 6296.60 toks/s, output: 6.15 toks/s]
Processed prompts:  23%|       | 29/128 [00:04<00:16,  5.90it/s, est. speed input: 6288.51 toks/s, output: 6.14 toks/s]
Processed prompts:  23%|       | 30/128 [00:04<00:16,  5.88it/s, est. speed input: 6277.81 toks/s, output: 6.13 toks/s]
Processed prompts:  24%|       | 31/128 [00:05<00:16,  5.91it/s, est. speed input: 6272.80 toks/s, output: 6.13 toks/s]
Processed prompts:  25%|       | 32/128 [00:05<00:16,  5.84it/s, est. speed input: 6257.85 toks/s, output: 6.11 toks/s]
Processed prompts:  26%|       | 33/128 [00:05<00:16,  5.85it/s, est. speed input: 6250.02 toks/s, output: 6.10 toks/s]
Processed prompts:  27%|       | 34/128 [00:05<00:16,  5.87it/s, est. speed input: 6243.78 toks/s, output: 6.10 toks/s]
Processed prompts:  27%|       | 35/128 [00:05<00:15,  5.88it/s, est. speed input: 6238.71 toks/s, output: 6.09 toks/s]
Processed prompts:  28%|       | 36/128 [00:05<00:15,  5.90it/s, est. speed input: 6233.67 toks/s, output: 6.09 toks/s]
Processed prompts:  29%|       | 37/128 [00:06<00:15,  5.89it/s, est. speed input: 6227.58 toks/s, output: 6.08 toks/s]
Processed prompts:  30%|       | 38/128 [00:06<00:15,  5.84it/s, est. speed input: 6217.35 toks/s, output: 6.07 toks/s]
Processed prompts:  30%|       | 39/128 [00:06<00:15,  5.88it/s, est. speed input: 6214.82 toks/s, output: 6.07 toks/s]
Processed prompts:  31%|      | 40/128 [00:06<00:14,  5.88it/s, est. speed input: 6210.27 toks/s, output: 6.06 toks/s]
Processed prompts:  32%|      | 41/128 [00:06<00:14,  5.92it/s, est. speed input: 6208.72 toks/s, output: 6.06 toks/s]
Processed prompts:  33%|      | 42/128 [00:06<00:14,  5.91it/s, est. speed input: 6204.59 toks/s, output: 6.06 toks/s]
Processed prompts:  34%|      | 43/128 [00:07<00:14,  5.92it/s, est. speed input: 6201.48 toks/s, output: 6.06 toks/s]
Processed prompts:  34%|      | 44/128 [00:07<00:14,  5.85it/s, est. speed input: 6192.67 toks/s, output: 6.05 toks/s]
Processed prompts:  35%|      | 45/128 [00:07<00:14,  5.87it/s, est. speed input: 6189.82 toks/s, output: 6.04 toks/s]
Processed prompts:  36%|      | 46/128 [00:07<00:13,  5.88it/s, est. speed input: 6186.67 toks/s, output: 6.04 toks/s]
Processed prompts:  37%|      | 47/128 [00:07<00:13,  5.89it/s, est. speed input: 6183.72 toks/s, output: 6.04 toks/s]
Processed prompts:  38%|      | 48/128 [00:07<00:13,  5.89it/s, est. speed input: 6180.28 toks/s, output: 6.04 toks/s]
Processed prompts:  38%|      | 49/128 [00:08<00:13,  5.90it/s, est. speed input: 6177.97 toks/s, output: 6.03 toks/s]
Processed prompts:  39%|      | 50/128 [00:08<00:13,  5.84it/s, est. speed input: 6170.54 toks/s, output: 6.03 toks/s]
Processed prompts:  40%|      | 51/128 [00:08<00:13,  5.86it/s, est. speed input: 6168.37 toks/s, output: 6.02 toks/s]
Processed prompts:  41%|      | 52/128 [00:08<00:12,  5.88it/s, est. speed input: 6166.20 toks/s, output: 6.02 toks/s]
Processed prompts:  41%|     | 53/128 [00:08<00:12,  5.87it/s, est. speed input: 6162.74 toks/s, output: 6.02 toks/s]
Processed prompts:  42%|     | 54/128 [00:08<00:12,  5.86it/s, est. speed input: 6159.55 toks/s, output: 6.02 toks/s]
Processed prompts:  43%|     | 55/128 [00:09<00:12,  5.88it/s, est. speed input: 6157.80 toks/s, output: 6.01 toks/s]
Processed prompts:  44%|     | 56/128 [00:09<00:12,  5.90it/s, est. speed input: 6156.80 toks/s, output: 6.01 toks/s]
Processed prompts:  45%|     | 57/128 [00:09<00:12,  5.84it/s, est. speed input: 6150.86 toks/s, output: 6.01 toks/s]
Processed prompts:  45%|     | 58/128 [00:09<00:11,  5.84it/s, est. speed input: 6147.52 toks/s, output: 6.00 toks/s]
Processed prompts:  46%|     | 59/128 [00:09<00:11,  5.85it/s, est. speed input: 6145.35 toks/s, output: 6.00 toks/s]
Processed prompts:  47%|     | 60/128 [00:09<00:11,  5.88it/s, est. speed input: 6144.37 toks/s, output: 6.00 toks/s]
Processed prompts:  48%|     | 61/128 [00:10<00:11,  5.86it/s, est. speed input: 6141.23 toks/s, output: 6.00 toks/s]
Processed prompts:  48%|     | 62/128 [00:10<00:11,  5.89it/s, est. speed input: 6140.80 toks/s, output: 6.00 toks/s]
Processed prompts:  49%|     | 63/128 [00:10<00:11,  5.83it/s, est. speed input: 6135.80 toks/s, output: 5.99 toks/s]
Processed prompts:  50%|     | 64/128 [00:10<00:10,  5.85it/s, est. speed input: 6133.88 toks/s, output: 5.99 toks/s]
Processed prompts:  51%|     | 65/128 [00:10<00:10,  5.88it/s, est. speed input: 6133.17 toks/s, output: 5.99 toks/s]
Processed prompts:  52%|    | 66/128 [00:11<00:10,  5.90it/s, est. speed input: 6132.83 toks/s, output: 5.99 toks/s]
Processed prompts:  52%|    | 67/128 [00:11<00:10,  5.89it/s, est. speed input: 6130.86 toks/s, output: 5.99 toks/s]
Processed prompts:  53%|    | 68/128 [00:11<00:10,  5.89it/s, est. speed input: 6129.24 toks/s, output: 5.99 toks/s]
Processed prompts:  54%|    | 69/128 [00:11<00:10,  5.84it/s, est. speed input: 6125.27 toks/s, output: 5.98 toks/s]
Processed prompts:  55%|    | 70/128 [00:11<00:09,  5.83it/s, est. speed input: 6122.60 toks/s, output: 5.98 toks/s]
Processed prompts:  55%|    | 71/128 [00:11<00:09,  5.84it/s, est. speed input: 6121.16 toks/s, output: 5.98 toks/s]
Processed prompts:  56%|    | 72/128 [00:12<00:09,  5.85it/s, est. speed input: 6119.72 toks/s, output: 5.98 toks/s]
Processed prompts:  57%|    | 73/128 [00:12<00:09,  5.85it/s, est. speed input: 6117.75 toks/s, output: 5.97 toks/s]
Processed prompts:  58%|    | 74/128 [00:12<00:09,  5.86it/s, est. speed input: 6116.55 toks/s, output: 5.97 toks/s]
Processed prompts:  59%|    | 75/128 [00:12<00:09,  5.83it/s, est. speed input: 6113.42 toks/s, output: 5.97 toks/s]
Processed prompts:  59%|    | 76/128 [00:12<00:08,  5.83it/s, est. speed input: 6111.42 toks/s, output: 5.97 toks/s]
Processed prompts:  60%|    | 77/128 [00:12<00:08,  5.84it/s, est. speed input: 6110.02 toks/s, output: 5.97 toks/s]
Processed prompts:  61%|    | 78/128 [00:13<00:08,  5.86it/s, est. speed input: 6109.37 toks/s, output: 5.97 toks/s]
Processed prompts:  62%|   | 79/128 [00:13<00:08,  5.86it/s, est. speed input: 6108.12 toks/s, output: 5.96 toks/s]
Processed prompts:  62%|   | 80/128 [00:13<00:08,  5.85it/s, est. speed input: 6106.05 toks/s, output: 5.96 toks/s]
Processed prompts:  63%|   | 81/128 [00:13<00:08,  5.83it/s, est. speed input: 6103.61 toks/s, output: 5.96 toks/s]
Processed prompts:  64%|   | 82/128 [00:13<00:07,  5.82it/s, est. speed input: 6101.62 toks/s, output: 5.96 toks/s]
Processed prompts:  65%|   | 83/128 [00:13<00:07,  5.81it/s, est. speed input: 6099.58 toks/s, output: 5.96 toks/s]
Processed prompts:  66%|   | 84/128 [00:14<00:07,  5.83it/s, est. speed input: 6098.62 toks/s, output: 5.96 toks/s]
Processed prompts:  66%|   | 85/128 [00:14<00:07,  5.86it/s, est. speed input: 6098.12 toks/s, output: 5.96 toks/s]
Processed prompts:  67%|   | 86/128 [00:14<00:07,  5.87it/s, est. speed input: 6097.41 toks/s, output: 5.95 toks/s]
Processed prompts:  68%|   | 87/128 [00:14<00:06,  5.86it/s, est. speed input: 6096.18 toks/s, output: 5.95 toks/s]
Processed prompts:  69%|   | 88/128 [00:14<00:06,  5.81it/s, est. speed input: 6093.07 toks/s, output: 5.95 toks/s]
Processed prompts:  70%|   | 89/128 [00:14<00:06,  5.83it/s, est. speed input: 6092.12 toks/s, output: 5.95 toks/s]
Processed prompts:  70%|   | 90/128 [00:15<00:06,  5.85it/s, est. speed input: 6091.35 toks/s, output: 5.95 toks/s]
Processed prompts:  71%|   | 91/128 [00:15<00:06,  5.84it/s, est. speed input: 6090.14 toks/s, output: 5.95 toks/s]
Processed prompts:  72%|  | 92/128 [00:15<00:06,  5.85it/s, est. speed input: 6089.26 toks/s, output: 5.95 toks/s]
Processed prompts:  73%|  | 93/128 [00:15<00:05,  5.87it/s, est. speed input: 6088.74 toks/s, output: 5.95 toks/s]
Processed prompts:  73%|  | 94/128 [00:15<00:05,  5.81it/s, est. speed input: 6085.67 toks/s, output: 5.94 toks/s]
Processed prompts:  74%|  | 95/128 [00:15<00:05,  5.84it/s, est. speed input: 6085.44 toks/s, output: 5.94 toks/s]
Processed prompts:  75%|  | 96/128 [00:16<00:05,  5.85it/s, est. speed input: 6084.71 toks/s, output: 5.94 toks/s]
Processed prompts:  76%|  | 97/128 [00:16<00:05,  5.84it/s, est. speed input: 6083.38 toks/s, output: 5.94 toks/s]
Processed prompts:  77%|  | 98/128 [00:16<00:05,  5.85it/s, est. speed input: 6082.63 toks/s, output: 5.94 toks/s]
Processed prompts:  77%|  | 99/128 [00:16<00:04,  5.85it/s, est. speed input: 6081.66 toks/s, output: 5.94 toks/s]
Processed prompts:  78%|  | 100/128 [00:16<00:04,  5.82it/s, est. speed input: 6079.84 toks/s, output: 5.94 toks/s]
Processed prompts:  79%|  | 101/128 [00:17<00:04,  5.84it/s, est. speed input: 6079.29 toks/s, output: 5.94 toks/s]
Processed prompts:  80%|  | 102/128 [00:17<00:04,  5.83it/s, est. speed input: 6078.01 toks/s, output: 5.94 toks/s]
Processed prompts:  80%|  | 103/128 [00:17<00:04,  5.85it/s, est. speed input: 6077.41 toks/s, output: 5.93 toks/s]
Processed prompts:  81%| | 104/128 [00:17<00:04,  5.88it/s, est. speed input: 6077.58 toks/s, output: 5.94 toks/s]
Processed prompts:  82%| | 105/128 [00:17<00:03,  5.85it/s, est. speed input: 6076.17 toks/s, output: 5.93 toks/s]
Processed prompts:  83%| | 106/128 [00:17<00:03,  5.80it/s, est. speed input: 6073.65 toks/s, output: 5.93 toks/s]
Processed prompts:  84%| | 107/128 [00:18<00:03,  5.83it/s, est. speed input: 6073.39 toks/s, output: 5.93 toks/s]
Processed prompts:  84%| | 108/128 [00:18<00:03,  5.84it/s, est. speed input: 6072.84 toks/s, output: 5.93 toks/s]
Processed prompts:  85%| | 109/128 [00:18<00:03,  5.89it/s, est. speed input: 6073.44 toks/s, output: 5.93 toks/s]
Processed prompts:  86%| | 110/128 [00:18<00:03,  5.89it/s, est. speed input: 6072.96 toks/s, output: 5.93 toks/s]
Processed prompts:  87%| | 111/128 [00:18<00:02,  5.88it/s, est. speed input: 6072.29 toks/s, output: 5.93 toks/s]
Processed prompts:  88%| | 112/128 [00:18<00:02,  5.88it/s, est. speed input: 6071.98 toks/s, output: 5.93 toks/s]
Processed prompts:  88%| | 113/128 [00:19<00:02,  5.83it/s, est. speed input: 6069.89 toks/s, output: 5.93 toks/s]
Processed prompts:  89%| | 114/128 [00:19<00:02,  5.82it/s, est. speed input: 6068.55 toks/s, output: 5.93 toks/s]
Processed prompts:  90%| | 115/128 [00:19<00:02,  5.82it/s, est. speed input: 6067.81 toks/s, output: 5.93 toks/s]
Processed prompts:  91%| | 116/128 [00:19<00:02,  5.82it/s, est. speed input: 6066.88 toks/s, output: 5.92 toks/s]
Processed prompts:  91%|| 117/128 [00:19<00:01,  5.84it/s, est. speed input: 6066.63 toks/s, output: 5.92 toks/s]
Processed prompts:  92%|| 118/128 [00:19<00:01,  5.85it/s, est. speed input: 6066.15 toks/s, output: 5.92 toks/s]
Processed prompts:  93%|| 119/128 [00:20<00:01,  5.81it/s, est. speed input: 6064.24 toks/s, output: 5.92 toks/s]
Processed prompts:  94%|| 120/128 [00:20<00:01,  5.82it/s, est. speed input: 6063.48 toks/s, output: 5.92 toks/s]
Processed prompts:  95%|| 121/128 [00:20<00:01,  5.83it/s, est. speed input: 6062.84 toks/s, output: 5.92 toks/s]
Processed prompts:  95%|| 122/128 [00:20<00:01,  5.85it/s, est. speed input: 6062.75 toks/s, output: 5.92 toks/s]
Processed prompts:  96%|| 123/128 [00:20<00:00,  5.86it/s, est. speed input: 6062.52 toks/s, output: 5.92 toks/s]
Processed prompts:  97%|| 124/128 [00:20<00:00,  5.86it/s, est. speed input: 6062.07 toks/s, output: 5.92 toks/s]
Processed prompts:  98%|| 125/128 [00:21<00:00,  5.84it/s, est. speed input: 6060.93 toks/s, output: 5.92 toks/s]
Processed prompts:  98%|| 126/128 [00:21<00:00,  5.84it/s, est. speed input: 6060.35 toks/s, output: 5.92 toks/s]
Processed prompts:  99%|| 127/128 [00:21<00:00,  5.85it/s, est. speed input: 6059.93 toks/s, output: 5.92 toks/s]
Processed prompts: 100%|| 128/128 [00:21<00:00,  5.84it/s, est. speed input: 6059.19 toks/s, output: 5.92 toks/s]
Processed prompts: 100%|| 128/128 [00:21<00:00,  5.84it/s, est. speed input: 6059.19 toks/s, output: 5.92 toks/s]
Processed prompts: 100%|| 128/128 [00:21<00:00,  5.92it/s, est. speed input: 6059.19 toks/s, output: 5.92 toks/s]
[rank0]:[W126 19:19:34.344539713 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 19:19:36
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:19:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:19:40 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1644138) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1644138) WARNING 01-26 19:20:55 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.82 requests/s, 5962.32 total tokens/s, 5.82 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 19:19:40] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:19:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:19:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:19:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:19:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:19:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:19:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:19:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:19:44] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:19:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:19:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:19:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:19:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:19:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:19:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:19:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:19:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1644138) [2026-01-26 19:19:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1644138) [2026-01-26 19:19:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1644138) [2026-01-26 19:19:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1644138) [2026-01-26 19:19:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1644138) [2026-01-26 19:19:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1644138) [2026-01-26 19:19:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1644138) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1644138) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.09s/it]
(EngineCore_DP0 pid=1644138) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 31.49s/it]
(EngineCore_DP0 pid=1644138) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:01<00:00, 30.98s/it]
(EngineCore_DP0 pid=1644138) 
(EngineCore_DP0 pid=1644138) [2026-01-26 19:20:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1644138) [2026-01-26 19:20:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1644138) [2026-01-26 19:20:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1644138) [2026-01-26 19:20:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1644138) [2026-01-26 19:20:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1644138) [2026-01-26 19:20:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1644138) [2026-01-26 19:20:48] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1644138) [2026-01-26 19:20:48] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1644138) 2026-01-26 19:20:54,681 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1644138) 2026-01-26 19:20:54,743 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  16%|        | 41/256 [00:00<00:00, 405.28it/s]
Adding requests:  32%|      | 82/256 [00:00<00:00, 402.00it/s]
Adding requests:  48%|     | 123/256 [00:00<00:00, 395.74it/s]
Adding requests:  65%|   | 167/256 [00:00<00:00, 406.99it/s]
Adding requests:  81%| | 208/256 [00:00<00:00, 401.64it/s]
Adding requests:  98%|| 250/256 [00:00<00:00, 407.47it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 403.53it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 2/256 [00:00<00:33,  7.48it/s, est. speed input: 7662.16 toks/s, output: 7.48 toks/s]
Processed prompts:   2%|         | 4/256 [00:00<00:40,  6.18it/s, est. speed input: 6493.75 toks/s, output: 6.34 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:41,  6.06it/s, est. speed input: 6343.27 toks/s, output: 6.19 toks/s]
Processed prompts:   3%|         | 8/256 [00:01<00:41,  5.96it/s, est. speed input: 6239.98 toks/s, output: 6.09 toks/s]
Processed prompts:   4%|         | 10/256 [00:01<00:41,  5.95it/s, est. speed input: 6208.50 toks/s, output: 6.06 toks/s]
Processed prompts:   5%|         | 12/256 [00:01<00:41,  5.93it/s, est. speed input: 6179.51 toks/s, output: 6.03 toks/s]
Processed prompts:   5%|         | 14/256 [00:02<00:40,  5.92it/s, est. speed input: 6156.49 toks/s, output: 6.01 toks/s]
Processed prompts:   6%|         | 16/256 [00:02<00:40,  5.94it/s, est. speed input: 6153.94 toks/s, output: 6.01 toks/s]
Processed prompts:   7%|         | 18/256 [00:02<00:40,  5.94it/s, est. speed input: 6145.69 toks/s, output: 6.00 toks/s]
Processed prompts:   8%|         | 20/256 [00:03<00:40,  5.90it/s, est. speed input: 6125.10 toks/s, output: 5.98 toks/s]
Processed prompts:   9%|         | 22/256 [00:03<00:39,  5.90it/s, est. speed input: 6118.30 toks/s, output: 5.97 toks/s]
Processed prompts:   9%|         | 24/256 [00:04<00:39,  5.90it/s, est. speed input: 6112.03 toks/s, output: 5.97 toks/s]
Processed prompts:  10%|         | 26/256 [00:04<00:39,  5.88it/s, est. speed input: 6100.77 toks/s, output: 5.96 toks/s]
Processed prompts:  11%|         | 28/256 [00:04<00:38,  5.90it/s, est. speed input: 6099.02 toks/s, output: 5.96 toks/s]
Processed prompts:  12%|        | 30/256 [00:05<00:38,  5.89it/s, est. speed input: 6093.77 toks/s, output: 5.95 toks/s]
Processed prompts:  12%|        | 32/256 [00:05<00:37,  5.92it/s, est. speed input: 6095.17 toks/s, output: 5.95 toks/s]
Processed prompts:  13%|        | 34/256 [00:05<00:37,  5.89it/s, est. speed input: 6086.80 toks/s, output: 5.94 toks/s]
Processed prompts:  14%|        | 36/256 [00:06<00:37,  5.89it/s, est. speed input: 6084.63 toks/s, output: 5.94 toks/s]
Processed prompts:  15%|        | 38/256 [00:06<00:36,  5.91it/s, est. speed input: 6085.54 toks/s, output: 5.94 toks/s]
Processed prompts:  16%|        | 40/256 [00:06<00:36,  5.88it/s, est. speed input: 6078.61 toks/s, output: 5.94 toks/s]
Processed prompts:  16%|        | 42/256 [00:07<00:36,  5.88it/s, est. speed input: 6075.96 toks/s, output: 5.93 toks/s]
Processed prompts:  17%|        | 44/256 [00:07<00:35,  5.91it/s, est. speed input: 6077.60 toks/s, output: 5.94 toks/s]
Processed prompts:  18%|        | 46/256 [00:07<00:35,  5.86it/s, est. speed input: 6069.63 toks/s, output: 5.93 toks/s]
Processed prompts:  19%|        | 48/256 [00:08<00:35,  5.88it/s, est. speed input: 6069.75 toks/s, output: 5.93 toks/s]
Processed prompts:  20%|        | 50/256 [00:08<00:34,  5.90it/s, est. speed input: 6070.22 toks/s, output: 5.93 toks/s]
Processed prompts:  20%|        | 52/256 [00:08<00:34,  5.87it/s, est. speed input: 6064.76 toks/s, output: 5.92 toks/s]
Processed prompts:  21%|        | 54/256 [00:09<00:34,  5.88it/s, est. speed input: 6064.68 toks/s, output: 5.92 toks/s]
Processed prompts:  22%|       | 56/256 [00:09<00:33,  5.89it/s, est. speed input: 6063.67 toks/s, output: 5.92 toks/s]
Processed prompts:  23%|       | 58/256 [00:09<00:33,  5.87it/s, est. speed input: 6060.93 toks/s, output: 5.92 toks/s]
Processed prompts:  23%|       | 60/256 [00:10<00:33,  5.89it/s, est. speed input: 6061.40 toks/s, output: 5.92 toks/s]
Processed prompts:  24%|       | 62/256 [00:10<00:32,  5.90it/s, est. speed input: 6061.67 toks/s, output: 5.92 toks/s]
Processed prompts:  25%|       | 64/256 [00:10<00:32,  5.90it/s, est. speed input: 6060.51 toks/s, output: 5.92 toks/s]
Processed prompts:  26%|       | 66/256 [00:11<00:32,  5.91it/s, est. speed input: 6060.73 toks/s, output: 5.92 toks/s]
Processed prompts:  27%|       | 68/256 [00:11<00:31,  5.90it/s, est. speed input: 6059.54 toks/s, output: 5.92 toks/s]
Processed prompts:  27%|       | 70/256 [00:11<00:31,  5.87it/s, est. speed input: 6055.77 toks/s, output: 5.91 toks/s]
Processed prompts:  28%|       | 72/256 [00:12<00:31,  5.88it/s, est. speed input: 6055.62 toks/s, output: 5.91 toks/s]
Processed prompts:  29%|       | 74/256 [00:12<00:30,  5.90it/s, est. speed input: 6056.24 toks/s, output: 5.91 toks/s]
Processed prompts:  30%|       | 76/256 [00:12<00:30,  5.88it/s, est. speed input: 6053.98 toks/s, output: 5.91 toks/s]
Processed prompts:  30%|       | 78/256 [00:13<00:30,  5.87it/s, est. speed input: 6052.87 toks/s, output: 5.91 toks/s]
Processed prompts:  31%|      | 80/256 [00:13<00:29,  5.89it/s, est. speed input: 6053.16 toks/s, output: 5.91 toks/s]
Processed prompts:  32%|      | 82/256 [00:13<00:29,  5.90it/s, est. speed input: 6053.18 toks/s, output: 5.91 toks/s]
Processed prompts:  33%|      | 84/256 [00:14<00:29,  5.87it/s, est. speed input: 6050.89 toks/s, output: 5.91 toks/s]
Processed prompts:  34%|      | 86/256 [00:14<00:28,  5.88it/s, est. speed input: 6050.55 toks/s, output: 5.91 toks/s]
Processed prompts:  34%|      | 88/256 [00:14<00:28,  5.89it/s, est. speed input: 6050.95 toks/s, output: 5.91 toks/s]
Processed prompts:  35%|      | 90/256 [00:15<00:28,  5.87it/s, est. speed input: 6048.53 toks/s, output: 5.91 toks/s]
Processed prompts:  36%|      | 92/256 [00:15<00:27,  5.87it/s, est. speed input: 6047.71 toks/s, output: 5.91 toks/s]
Processed prompts:  37%|      | 94/256 [00:15<00:27,  5.88it/s, est. speed input: 6047.55 toks/s, output: 5.91 toks/s]
Processed prompts:  38%|      | 96/256 [00:16<00:27,  5.86it/s, est. speed input: 6045.60 toks/s, output: 5.90 toks/s]
Processed prompts:  38%|      | 98/256 [00:16<00:26,  5.86it/s, est. speed input: 6045.10 toks/s, output: 5.90 toks/s]
Processed prompts:  39%|      | 100/256 [00:16<00:26,  5.88it/s, est. speed input: 6045.03 toks/s, output: 5.90 toks/s]
Processed prompts:  40%|      | 102/256 [00:17<00:26,  5.85it/s, est. speed input: 6043.07 toks/s, output: 5.90 toks/s]
Processed prompts:  41%|      | 104/256 [00:17<00:25,  5.87it/s, est. speed input: 6043.34 toks/s, output: 5.90 toks/s]
Processed prompts:  41%|     | 106/256 [00:17<00:25,  5.88it/s, est. speed input: 6043.17 toks/s, output: 5.90 toks/s]
Processed prompts:  42%|     | 108/256 [00:18<00:25,  5.86it/s, est. speed input: 6041.59 toks/s, output: 5.90 toks/s]
Processed prompts:  43%|     | 110/256 [00:18<00:24,  5.87it/s, est. speed input: 6041.19 toks/s, output: 5.90 toks/s]
Processed prompts:  44%|     | 112/256 [00:18<00:24,  5.87it/s, est. speed input: 6041.11 toks/s, output: 5.90 toks/s]
Processed prompts:  45%|     | 114/256 [00:19<00:24,  5.85it/s, est. speed input: 6039.35 toks/s, output: 5.90 toks/s]
Processed prompts:  45%|     | 116/256 [00:19<00:23,  5.86it/s, est. speed input: 6039.08 toks/s, output: 5.90 toks/s]
Processed prompts:  46%|     | 118/256 [00:20<00:23,  5.87it/s, est. speed input: 6039.08 toks/s, output: 5.90 toks/s]
Processed prompts:  47%|     | 120/256 [00:20<00:23,  5.86it/s, est. speed input: 6037.69 toks/s, output: 5.90 toks/s]
Processed prompts:  48%|     | 122/256 [00:20<00:22,  5.86it/s, est. speed input: 6037.47 toks/s, output: 5.90 toks/s]
Processed prompts:  48%|     | 124/256 [00:21<00:22,  5.89it/s, est. speed input: 6038.14 toks/s, output: 5.90 toks/s]
Processed prompts:  49%|     | 126/256 [00:21<00:22,  5.87it/s, est. speed input: 6037.08 toks/s, output: 5.90 toks/s]
Processed prompts:  50%|     | 128/256 [00:21<00:21,  5.88it/s, est. speed input: 6037.15 toks/s, output: 5.90 toks/s]
Processed prompts:  51%|     | 130/256 [00:22<00:21,  5.87it/s, est. speed input: 6036.39 toks/s, output: 5.89 toks/s]
Processed prompts:  52%|    | 132/256 [00:22<00:21,  5.87it/s, est. speed input: 6036.02 toks/s, output: 5.89 toks/s]
Processed prompts:  52%|    | 134/256 [00:22<00:20,  5.89it/s, est. speed input: 6036.42 toks/s, output: 5.89 toks/s]
Processed prompts:  53%|    | 136/256 [00:23<00:20,  5.89it/s, est. speed input: 6036.65 toks/s, output: 5.90 toks/s]
Processed prompts:  54%|    | 138/256 [00:23<00:19,  5.90it/s, est. speed input: 6036.99 toks/s, output: 5.90 toks/s]
Processed prompts:  55%|    | 140/256 [00:23<00:19,  5.87it/s, est. speed input: 6035.47 toks/s, output: 5.89 toks/s]
Processed prompts:  55%|    | 142/256 [00:24<00:19,  5.89it/s, est. speed input: 6036.10 toks/s, output: 5.89 toks/s]
Processed prompts:  56%|    | 144/256 [00:24<00:19,  5.88it/s, est. speed input: 6035.53 toks/s, output: 5.89 toks/s]
Processed prompts:  57%|    | 146/256 [00:24<00:18,  5.87it/s, est. speed input: 6034.87 toks/s, output: 5.89 toks/s]
Processed prompts:  58%|    | 148/256 [00:25<00:18,  5.88it/s, est. speed input: 6035.16 toks/s, output: 5.89 toks/s]
Processed prompts:  59%|    | 150/256 [00:25<00:18,  5.88it/s, est. speed input: 6035.06 toks/s, output: 5.89 toks/s]
Processed prompts:  59%|    | 152/256 [00:25<00:17,  5.88it/s, est. speed input: 6034.55 toks/s, output: 5.89 toks/s]
Processed prompts:  60%|    | 154/256 [00:26<00:17,  5.88it/s, est. speed input: 6034.71 toks/s, output: 5.89 toks/s]
Processed prompts:  61%|    | 156/256 [00:26<00:16,  5.88it/s, est. speed input: 6034.51 toks/s, output: 5.89 toks/s]
Processed prompts:  62%|   | 158/256 [00:26<00:16,  5.87it/s, est. speed input: 6033.62 toks/s, output: 5.89 toks/s]
Processed prompts:  62%|   | 160/256 [00:27<00:16,  5.87it/s, est. speed input: 6033.44 toks/s, output: 5.89 toks/s]
Processed prompts:  63%|   | 162/256 [00:27<00:16,  5.87it/s, est. speed input: 6033.17 toks/s, output: 5.89 toks/s]
Processed prompts:  64%|   | 164/256 [00:27<00:15,  5.86it/s, est. speed input: 6032.55 toks/s, output: 5.89 toks/s]
Processed prompts:  65%|   | 166/256 [00:28<00:15,  5.86it/s, est. speed input: 6032.10 toks/s, output: 5.89 toks/s]
Processed prompts:  66%|   | 168/256 [00:28<00:15,  5.86it/s, est. speed input: 6031.87 toks/s, output: 5.89 toks/s]
Processed prompts:  66%|   | 170/256 [00:28<00:14,  5.85it/s, est. speed input: 6030.89 toks/s, output: 5.89 toks/s]
Processed prompts:  67%|   | 172/256 [00:29<00:14,  5.87it/s, est. speed input: 6031.23 toks/s, output: 5.89 toks/s]
Processed prompts:  68%|   | 174/256 [00:29<00:13,  5.88it/s, est. speed input: 6031.27 toks/s, output: 5.89 toks/s]
Processed prompts:  69%|   | 176/256 [00:29<00:13,  5.85it/s, est. speed input: 6030.00 toks/s, output: 5.89 toks/s]
Processed prompts:  70%|   | 178/256 [00:30<00:13,  5.86it/s, est. speed input: 6030.08 toks/s, output: 5.89 toks/s]
Processed prompts:  70%|   | 180/256 [00:30<00:12,  5.87it/s, est. speed input: 6029.98 toks/s, output: 5.89 toks/s]
Processed prompts:  71%|   | 182/256 [00:30<00:12,  5.85it/s, est. speed input: 6028.98 toks/s, output: 5.89 toks/s]
Processed prompts:  72%|  | 184/256 [00:31<00:12,  5.87it/s, est. speed input: 6029.23 toks/s, output: 5.89 toks/s]
Processed prompts:  73%|  | 186/256 [00:31<00:11,  5.87it/s, est. speed input: 6029.03 toks/s, output: 5.89 toks/s]
Processed prompts:  73%|  | 188/256 [00:31<00:11,  5.87it/s, est. speed input: 6028.73 toks/s, output: 5.89 toks/s]
Processed prompts:  74%|  | 190/256 [00:32<00:11,  5.86it/s, est. speed input: 6028.21 toks/s, output: 5.89 toks/s]
Processed prompts:  75%|  | 192/256 [00:32<00:10,  5.87it/s, est. speed input: 6028.23 toks/s, output: 5.89 toks/s]
Processed prompts:  76%|  | 194/256 [00:33<00:11,  5.37it/s, est. speed input: 6008.80 toks/s, output: 5.87 toks/s]
Processed prompts:  77%|  | 196/256 [00:33<00:10,  5.49it/s, est. speed input: 6008.13 toks/s, output: 5.87 toks/s]
Processed prompts:  77%|  | 198/256 [00:33<00:10,  5.60it/s, est. speed input: 6008.13 toks/s, output: 5.87 toks/s]
Processed prompts:  78%|  | 200/256 [00:34<00:09,  5.66it/s, est. speed input: 6007.56 toks/s, output: 5.87 toks/s]
Processed prompts:  79%|  | 202/256 [00:34<00:08,  6.42it/s, est. speed input: 6029.73 toks/s, output: 5.89 toks/s]
Processed prompts:  80%|  | 204/256 [00:34<00:08,  6.24it/s, est. speed input: 6029.46 toks/s, output: 5.89 toks/s]
Processed prompts:  80%|  | 206/256 [00:34<00:08,  6.12it/s, est. speed input: 6029.25 toks/s, output: 5.89 toks/s]
Processed prompts:  81%| | 208/256 [00:35<00:07,  6.01it/s, est. speed input: 6028.09 toks/s, output: 5.89 toks/s]
Processed prompts:  82%| | 210/256 [00:35<00:07,  5.98it/s, est. speed input: 6028.25 toks/s, output: 5.89 toks/s]
Processed prompts:  83%| | 212/256 [00:36<00:07,  5.96it/s, est. speed input: 6028.34 toks/s, output: 5.89 toks/s]
Processed prompts:  84%| | 214/256 [00:36<00:07,  5.92it/s, est. speed input: 6027.84 toks/s, output: 5.89 toks/s]
Processed prompts:  84%| | 216/256 [00:36<00:06,  5.90it/s, est. speed input: 6027.53 toks/s, output: 5.89 toks/s]
Processed prompts:  85%| | 218/256 [00:37<00:06,  5.91it/s, est. speed input: 6027.88 toks/s, output: 5.89 toks/s]
Processed prompts:  86%| | 220/256 [00:37<00:06,  5.87it/s, est. speed input: 6027.09 toks/s, output: 5.89 toks/s]
Processed prompts:  87%| | 222/256 [00:37<00:05,  5.88it/s, est. speed input: 6027.23 toks/s, output: 5.89 toks/s]
Processed prompts:  88%| | 224/256 [00:38<00:05,  5.88it/s, est. speed input: 6027.15 toks/s, output: 5.89 toks/s]
Processed prompts:  88%| | 226/256 [00:38<00:05,  5.87it/s, est. speed input: 6026.84 toks/s, output: 5.89 toks/s]
Processed prompts:  89%| | 228/256 [00:38<00:04,  5.89it/s, est. speed input: 6027.12 toks/s, output: 5.89 toks/s]
Processed prompts:  90%| | 230/256 [00:39<00:04,  5.88it/s, est. speed input: 6026.81 toks/s, output: 5.89 toks/s]
Processed prompts:  91%| | 232/256 [00:39<00:04,  5.85it/s, est. speed input: 6026.03 toks/s, output: 5.88 toks/s]
Processed prompts:  91%|| 234/256 [00:39<00:03,  5.86it/s, est. speed input: 6025.84 toks/s, output: 5.88 toks/s]
Processed prompts:  92%|| 236/256 [00:40<00:03,  5.86it/s, est. speed input: 6025.74 toks/s, output: 5.88 toks/s]
Processed prompts:  93%|| 238/256 [00:40<00:03,  5.85it/s, est. speed input: 6025.21 toks/s, output: 5.88 toks/s]
Processed prompts:  94%|| 240/256 [00:40<00:02,  5.86it/s, est. speed input: 6025.14 toks/s, output: 5.88 toks/s]
Processed prompts:  95%|| 242/256 [00:41<00:02,  5.88it/s, est. speed input: 6025.47 toks/s, output: 5.88 toks/s]
Processed prompts:  95%|| 244/256 [00:41<00:02,  5.88it/s, est. speed input: 6025.42 toks/s, output: 5.88 toks/s]
Processed prompts:  96%|| 246/256 [00:41<00:01,  5.86it/s, est. speed input: 6024.95 toks/s, output: 5.88 toks/s]
Processed prompts:  97%|| 248/256 [00:42<00:01,  5.86it/s, est. speed input: 6024.69 toks/s, output: 5.88 toks/s]
Processed prompts:  98%|| 250/256 [00:42<00:01,  5.86it/s, est. speed input: 6024.63 toks/s, output: 5.88 toks/s]
Processed prompts:  98%|| 252/256 [00:42<00:00,  5.84it/s, est. speed input: 6023.80 toks/s, output: 5.88 toks/s]
Processed prompts:  99%|| 254/256 [00:43<00:00,  5.86it/s, est. speed input: 6023.89 toks/s, output: 5.88 toks/s]
Processed prompts: 100%|| 256/256 [00:43<00:00,  6.89it/s, est. speed input: 6047.40 toks/s, output: 5.91 toks/s]
Processed prompts: 100%|| 256/256 [00:43<00:00,  6.89it/s, est. speed input: 6047.40 toks/s, output: 5.91 toks/s]
Processed prompts: 100%|| 256/256 [00:43<00:00,  5.91it/s, est. speed input: 6047.40 toks/s, output: 5.91 toks/s]
[rank0]:[W126 19:21:40.301962314 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 19:21:43
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:21:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:21:50 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1646107) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1646107) WARNING 01-26 19:23:06 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.70 requests/s, 5845.99 total tokens/s, 5.70 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 19:21:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:21:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:21:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:21:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:21:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:21:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:21:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:21:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:21:53] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:21:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:21:53] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:21:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:21:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:21:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:21:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:21:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:21:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1646107) [2026-01-26 19:21:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1646107) [2026-01-26 19:21:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1646107) [2026-01-26 19:21:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1646107) [2026-01-26 19:21:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1646107) [2026-01-26 19:21:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1646107) [2026-01-26 19:21:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1646107) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1646107) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.68s/it]
(EngineCore_DP0 pid=1646107) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:03<00:00, 32.03s/it]
(EngineCore_DP0 pid=1646107) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:03<00:00, 31.53s/it]
(EngineCore_DP0 pid=1646107) 
(EngineCore_DP0 pid=1646107) [2026-01-26 19:22:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1646107) [2026-01-26 19:22:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1646107) [2026-01-26 19:22:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1646107) [2026-01-26 19:22:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1646107) [2026-01-26 19:22:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1646107) [2026-01-26 19:22:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1646107) [2026-01-26 19:22:58] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1646107) [2026-01-26 19:22:58] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1646107) 2026-01-26 19:23:05,257 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1646107) 2026-01-26 19:23:05,361 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   6%|         | 33/512 [00:00<00:01, 328.22it/s]
Adding requests:  15%|        | 75/512 [00:00<00:01, 378.52it/s]
Adding requests:  22%|       | 114/512 [00:00<00:01, 380.75it/s]
Adding requests:  30%|       | 153/512 [00:00<00:00, 378.32it/s]
Adding requests:  38%|      | 195/512 [00:00<00:00, 392.47it/s]
Adding requests:  46%|     | 238/512 [00:00<00:00, 403.35it/s]
Adding requests:  55%|    | 281/512 [00:00<00:00, 409.97it/s]
Adding requests:  63%|   | 325/512 [00:00<00:00, 417.27it/s]
Adding requests:  73%|  | 373/512 [00:00<00:00, 434.91it/s]
Adding requests:  82%| | 419/512 [00:01<00:00, 439.48it/s]
Adding requests:  90%| | 463/512 [00:01<00:00, 433.42it/s]
Adding requests:  99%|| 508/512 [00:01<00:00, 437.34it/s]
Adding requests: 100%|| 512/512 [00:01<00:00, 415.37it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 6/512 [00:00<00:40, 12.54it/s, est. speed input: 12837.12 toks/s, output: 12.54 toks/s]
Processed prompts:   2%|         | 10/512 [00:01<01:03,  7.93it/s, est. speed input: 8694.88 toks/s, output: 8.49 toks/s] 
Processed prompts:   3%|         | 14/512 [00:01<01:12,  6.85it/s, est. speed input: 7643.33 toks/s, output: 7.46 toks/s]
Processed prompts:   4%|         | 18/512 [00:02<01:17,  6.39it/s, est. speed input: 7159.31 toks/s, output: 6.99 toks/s]
Processed prompts:   4%|         | 22/512 [00:03<01:19,  6.13it/s, est. speed input: 6876.09 toks/s, output: 6.71 toks/s]
Processed prompts:   5%|         | 26/512 [00:03<01:20,  6.00it/s, est. speed input: 6703.54 toks/s, output: 6.55 toks/s]
Processed prompts:   6%|         | 30/512 [00:04<01:21,  5.90it/s, est. speed input: 6572.50 toks/s, output: 6.42 toks/s]
Processed prompts:   7%|         | 34/512 [00:05<01:21,  5.83it/s, est. speed input: 6474.37 toks/s, output: 6.32 toks/s]
Processed prompts:   7%|         | 38/512 [00:06<01:21,  5.80it/s, est. speed input: 6406.92 toks/s, output: 6.26 toks/s]
Processed prompts:   8%|         | 42/512 [00:06<01:21,  5.77it/s, est. speed input: 6345.83 toks/s, output: 6.20 toks/s]
Processed prompts:   9%|         | 46/512 [00:07<01:21,  5.75it/s, est. speed input: 6298.14 toks/s, output: 6.15 toks/s]
Processed prompts:  10%|         | 50/512 [00:08<01:20,  5.75it/s, est. speed input: 6263.53 toks/s, output: 6.12 toks/s]
Processed prompts:  11%|         | 54/512 [00:08<01:19,  5.73it/s, est. speed input: 6229.02 toks/s, output: 6.08 toks/s]
Processed prompts:  11%|        | 58/512 [00:09<01:19,  5.72it/s, est. speed input: 6198.86 toks/s, output: 6.05 toks/s]
Processed prompts:  12%|        | 62/512 [00:10<01:18,  5.72it/s, est. speed input: 6176.36 toks/s, output: 6.03 toks/s]
Processed prompts:  13%|        | 66/512 [00:10<01:18,  5.71it/s, est. speed input: 6153.20 toks/s, output: 6.01 toks/s]
Processed prompts:  14%|        | 70/512 [00:11<01:17,  5.71it/s, est. speed input: 6134.99 toks/s, output: 5.99 toks/s]
Processed prompts:  14%|        | 74/512 [00:12<01:16,  5.71it/s, est. speed input: 6119.37 toks/s, output: 5.98 toks/s]
Processed prompts:  15%|        | 78/512 [00:13<01:15,  5.71it/s, est. speed input: 6105.15 toks/s, output: 5.96 toks/s]
Processed prompts:  16%|        | 82/512 [00:13<01:15,  5.71it/s, est. speed input: 6091.85 toks/s, output: 5.95 toks/s]
Processed prompts:  17%|        | 86/512 [00:14<01:14,  5.69it/s, est. speed input: 6077.11 toks/s, output: 5.93 toks/s]
Processed prompts:  18%|        | 90/512 [00:15<01:14,  5.69it/s, est. speed input: 6064.77 toks/s, output: 5.92 toks/s]
Processed prompts:  18%|        | 94/512 [00:15<01:13,  5.69it/s, est. speed input: 6054.65 toks/s, output: 5.91 toks/s]
Processed prompts:  19%|        | 98/512 [00:16<01:12,  5.69it/s, est. speed input: 6045.23 toks/s, output: 5.90 toks/s]
Processed prompts:  20%|        | 102/512 [00:17<01:12,  5.68it/s, est. speed input: 6034.98 toks/s, output: 5.89 toks/s]
Processed prompts:  21%|        | 106/512 [00:18<01:11,  5.69it/s, est. speed input: 6027.82 toks/s, output: 5.89 toks/s]
Processed prompts:  21%|       | 110/512 [00:18<01:10,  5.69it/s, est. speed input: 6019.59 toks/s, output: 5.88 toks/s]
Processed prompts:  22%|       | 114/512 [00:19<01:10,  5.68it/s, est. speed input: 6011.61 toks/s, output: 5.87 toks/s]
Processed prompts:  23%|       | 118/512 [00:20<01:09,  5.70it/s, est. speed input: 6006.72 toks/s, output: 5.87 toks/s]
Processed prompts:  24%|       | 122/512 [00:20<01:08,  5.69it/s, est. speed input: 5999.90 toks/s, output: 5.86 toks/s]
Processed prompts:  25%|       | 126/512 [00:21<01:07,  5.68it/s, est. speed input: 5993.69 toks/s, output: 5.85 toks/s]
Processed prompts:  25%|       | 130/512 [00:22<01:07,  5.69it/s, est. speed input: 5988.75 toks/s, output: 5.85 toks/s]
Processed prompts:  26%|       | 134/512 [00:22<01:06,  5.68it/s, est. speed input: 5982.75 toks/s, output: 5.84 toks/s]
Processed prompts:  27%|       | 138/512 [00:23<01:05,  5.68it/s, est. speed input: 5977.40 toks/s, output: 5.84 toks/s]
Processed prompts:  28%|       | 142/512 [00:24<01:05,  5.68it/s, est. speed input: 5973.39 toks/s, output: 5.83 toks/s]
Processed prompts:  29%|       | 146/512 [00:25<01:04,  5.67it/s, est. speed input: 5968.09 toks/s, output: 5.83 toks/s]
Processed prompts:  29%|       | 150/512 [00:25<01:03,  5.68it/s, est. speed input: 5964.32 toks/s, output: 5.82 toks/s]
Processed prompts:  30%|       | 154/512 [00:26<01:02,  5.69it/s, est. speed input: 5961.42 toks/s, output: 5.82 toks/s]
Processed prompts:  31%|       | 158/512 [00:27<01:02,  5.70it/s, est. speed input: 5958.57 toks/s, output: 5.82 toks/s]
Processed prompts:  32%|      | 162/512 [00:27<01:01,  5.69it/s, est. speed input: 5955.14 toks/s, output: 5.82 toks/s]
Processed prompts:  32%|      | 166/512 [00:28<01:00,  5.69it/s, est. speed input: 5951.84 toks/s, output: 5.81 toks/s]
Processed prompts:  33%|      | 170/512 [00:29<01:00,  5.69it/s, est. speed input: 5948.65 toks/s, output: 5.81 toks/s]
Processed prompts:  34%|      | 174/512 [00:29<00:59,  5.69it/s, est. speed input: 5945.54 toks/s, output: 5.81 toks/s]
Processed prompts:  35%|      | 178/512 [00:30<00:58,  5.70it/s, est. speed input: 5943.45 toks/s, output: 5.80 toks/s]
Processed prompts:  36%|      | 182/512 [00:31<00:58,  5.69it/s, est. speed input: 5940.34 toks/s, output: 5.80 toks/s]
Processed prompts:  36%|      | 186/512 [00:32<00:57,  5.68it/s, est. speed input: 5937.26 toks/s, output: 5.80 toks/s]
Processed prompts:  37%|      | 190/512 [00:32<00:56,  5.69it/s, est. speed input: 5935.09 toks/s, output: 5.80 toks/s]
Processed prompts:  38%|      | 194/512 [00:33<00:55,  5.69it/s, est. speed input: 5933.29 toks/s, output: 5.79 toks/s]
Processed prompts:  39%|      | 198/512 [00:34<00:55,  5.68it/s, est. speed input: 5930.15 toks/s, output: 5.79 toks/s]
Processed prompts:  39%|      | 202/512 [00:34<00:51,  6.06it/s, est. speed input: 5953.03 toks/s, output: 5.81 toks/s]
Processed prompts:  40%|      | 206/512 [00:35<00:51,  5.94it/s, est. speed input: 5950.55 toks/s, output: 5.81 toks/s]
Processed prompts:  41%|      | 210/512 [00:36<00:51,  5.87it/s, est. speed input: 5948.10 toks/s, output: 5.81 toks/s]
Processed prompts:  42%|     | 214/512 [00:36<00:51,  5.80it/s, est. speed input: 5944.93 toks/s, output: 5.81 toks/s]
Processed prompts:  43%|     | 218/512 [00:37<00:50,  5.76it/s, est. speed input: 5942.69 toks/s, output: 5.80 toks/s]
Processed prompts:  43%|     | 222/512 [00:38<00:50,  5.74it/s, est. speed input: 5940.72 toks/s, output: 5.80 toks/s]
Processed prompts:  44%|     | 226/512 [00:38<00:49,  5.73it/s, est. speed input: 5938.52 toks/s, output: 5.80 toks/s]
Processed prompts:  45%|     | 230/512 [00:39<00:49,  5.71it/s, est. speed input: 5936.23 toks/s, output: 5.80 toks/s]
Processed prompts:  46%|     | 234/512 [00:40<00:48,  5.71it/s, est. speed input: 5934.74 toks/s, output: 5.80 toks/s]
Processed prompts:  46%|     | 238/512 [00:41<00:48,  5.69it/s, est. speed input: 5932.02 toks/s, output: 5.79 toks/s]
Processed prompts:  47%|     | 242/512 [00:41<00:47,  5.68it/s, est. speed input: 5929.51 toks/s, output: 5.79 toks/s]
Processed prompts:  48%|     | 246/512 [00:42<00:46,  5.68it/s, est. speed input: 5927.95 toks/s, output: 5.79 toks/s]
Processed prompts:  49%|     | 250/512 [00:43<00:46,  5.68it/s, est. speed input: 5925.79 toks/s, output: 5.79 toks/s]
Processed prompts:  50%|     | 254/512 [00:43<00:45,  5.68it/s, est. speed input: 5923.97 toks/s, output: 5.79 toks/s]
Processed prompts:  50%|     | 258/512 [00:44<00:44,  5.69it/s, est. speed input: 5922.73 toks/s, output: 5.78 toks/s]
Processed prompts:  51%|     | 262/512 [00:45<00:44,  5.68it/s, est. speed input: 5920.58 toks/s, output: 5.78 toks/s]
Processed prompts:  52%|    | 266/512 [00:46<00:43,  5.67it/s, est. speed input: 5918.90 toks/s, output: 5.78 toks/s]
Processed prompts:  53%|    | 270/512 [00:46<00:42,  5.68it/s, est. speed input: 5917.73 toks/s, output: 5.78 toks/s]
Processed prompts:  54%|    | 274/512 [00:47<00:41,  5.67it/s, est. speed input: 5915.81 toks/s, output: 5.78 toks/s]
Processed prompts:  54%|    | 278/512 [00:48<00:41,  5.67it/s, est. speed input: 5914.02 toks/s, output: 5.78 toks/s]
Processed prompts:  55%|    | 282/512 [00:48<00:40,  5.67it/s, est. speed input: 5912.68 toks/s, output: 5.77 toks/s]
Processed prompts:  56%|    | 286/512 [00:49<00:39,  5.67it/s, est. speed input: 5911.06 toks/s, output: 5.77 toks/s]
Processed prompts:  57%|    | 290/512 [00:50<00:39,  5.67it/s, est. speed input: 5909.50 toks/s, output: 5.77 toks/s]
Processed prompts:  57%|    | 294/512 [00:50<00:38,  5.68it/s, est. speed input: 5908.46 toks/s, output: 5.77 toks/s]
Processed prompts:  58%|    | 298/512 [00:51<00:37,  5.67it/s, est. speed input: 5906.98 toks/s, output: 5.77 toks/s]
Processed prompts:  59%|    | 302/512 [00:52<00:37,  5.67it/s, est. speed input: 5905.48 toks/s, output: 5.77 toks/s]
Processed prompts:  60%|    | 306/512 [00:52<00:33,  6.13it/s, est. speed input: 5923.70 toks/s, output: 5.78 toks/s]
Processed prompts:  61%|    | 310/512 [00:53<00:33,  5.98it/s, est. speed input: 5922.01 toks/s, output: 5.78 toks/s]
Processed prompts:  61%|   | 314/512 [00:54<00:33,  5.89it/s, est. speed input: 5920.92 toks/s, output: 5.78 toks/s]
Processed prompts:  62%|   | 318/512 [00:55<00:33,  5.82it/s, est. speed input: 5919.49 toks/s, output: 5.78 toks/s]
Processed prompts:  63%|   | 322/512 [00:55<00:32,  5.78it/s, est. speed input: 5918.01 toks/s, output: 5.78 toks/s]
Processed prompts:  64%|   | 326/512 [00:56<00:32,  5.75it/s, est. speed input: 5916.84 toks/s, output: 5.78 toks/s]
Processed prompts:  64%|   | 330/512 [00:57<00:31,  5.73it/s, est. speed input: 5915.51 toks/s, output: 5.78 toks/s]
Processed prompts:  65%|   | 334/512 [00:57<00:31,  5.70it/s, est. speed input: 5913.97 toks/s, output: 5.78 toks/s]
Processed prompts:  66%|   | 338/512 [00:58<00:30,  5.70it/s, est. speed input: 5913.03 toks/s, output: 5.77 toks/s]
Processed prompts:  67%|   | 342/512 [00:59<00:29,  5.69it/s, est. speed input: 5911.68 toks/s, output: 5.77 toks/s]
Processed prompts:  68%|   | 346/512 [00:59<00:29,  5.68it/s, est. speed input: 5910.29 toks/s, output: 5.77 toks/s]
Processed prompts:  68%|   | 350/512 [01:00<00:28,  5.68it/s, est. speed input: 5909.13 toks/s, output: 5.77 toks/s]
Processed prompts:  69%|   | 354/512 [01:01<00:27,  5.67it/s, est. speed input: 5907.87 toks/s, output: 5.77 toks/s]
Processed prompts:  70%|   | 358/512 [01:02<00:27,  5.67it/s, est. speed input: 5906.66 toks/s, output: 5.77 toks/s]
Processed prompts:  71%|   | 362/512 [01:02<00:26,  5.68it/s, est. speed input: 5905.88 toks/s, output: 5.77 toks/s]
Processed prompts:  71%|  | 366/512 [01:03<00:25,  5.67it/s, est. speed input: 5904.45 toks/s, output: 5.77 toks/s]
Processed prompts:  72%|  | 370/512 [01:04<00:25,  5.66it/s, est. speed input: 5903.09 toks/s, output: 5.76 toks/s]
Processed prompts:  73%|  | 374/512 [01:04<00:24,  5.68it/s, est. speed input: 5902.54 toks/s, output: 5.76 toks/s]
Processed prompts:  74%|  | 378/512 [01:05<00:23,  5.68it/s, est. speed input: 5901.50 toks/s, output: 5.76 toks/s]
Processed prompts:  75%|  | 382/512 [01:06<00:22,  5.67it/s, est. speed input: 5900.18 toks/s, output: 5.76 toks/s]
Processed prompts:  75%|  | 386/512 [01:06<00:22,  5.68it/s, est. speed input: 5899.56 toks/s, output: 5.76 toks/s]
Processed prompts:  76%|  | 390/512 [01:07<00:21,  5.68it/s, est. speed input: 5898.69 toks/s, output: 5.76 toks/s]
Processed prompts:  77%|  | 394/512 [01:08<00:20,  5.67it/s, est. speed input: 5897.51 toks/s, output: 5.76 toks/s]
Processed prompts:  78%|  | 398/512 [01:09<00:20,  5.68it/s, est. speed input: 5897.06 toks/s, output: 5.76 toks/s]
Processed prompts:  79%|  | 402/512 [01:09<00:19,  5.67it/s, est. speed input: 5895.99 toks/s, output: 5.76 toks/s]
Processed prompts:  79%|  | 406/512 [01:10<00:18,  5.66it/s, est. speed input: 5894.78 toks/s, output: 5.76 toks/s]
Processed prompts:  80%|  | 410/512 [01:11<00:18,  5.67it/s, est. speed input: 5893.92 toks/s, output: 5.76 toks/s]
Processed prompts:  81%|  | 414/512 [01:11<00:17,  5.67it/s, est. speed input: 5893.09 toks/s, output: 5.75 toks/s]
Processed prompts:  82%| | 418/512 [01:12<00:16,  5.66it/s, est. speed input: 5892.06 toks/s, output: 5.75 toks/s]
Processed prompts:  82%| | 422/512 [01:13<00:15,  5.67it/s, est. speed input: 5891.24 toks/s, output: 5.75 toks/s]
Processed prompts:  83%| | 426/512 [01:14<00:15,  5.67it/s, est. speed input: 5890.41 toks/s, output: 5.75 toks/s]
Processed prompts:  84%| | 430/512 [01:14<00:14,  5.66it/s, est. speed input: 5889.42 toks/s, output: 5.75 toks/s]
Processed prompts:  85%| | 434/512 [01:15<00:12,  6.11it/s, est. speed input: 5902.09 toks/s, output: 5.76 toks/s]
Processed prompts:  86%| | 438/512 [01:16<00:12,  5.97it/s, est. speed input: 5901.24 toks/s, output: 5.76 toks/s]
Processed prompts:  86%| | 442/512 [01:16<00:11,  5.88it/s, est. speed input: 5900.43 toks/s, output: 5.76 toks/s]
Processed prompts:  87%| | 446/512 [01:17<00:11,  5.81it/s, est. speed input: 5899.42 toks/s, output: 5.76 toks/s]
Processed prompts:  88%| | 450/512 [01:18<00:10,  5.76it/s, est. speed input: 5898.41 toks/s, output: 5.76 toks/s]
Processed prompts:  89%| | 454/512 [01:18<00:10,  5.74it/s, est. speed input: 5897.72 toks/s, output: 5.76 toks/s]
Processed prompts:  89%| | 458/512 [01:19<00:09,  5.71it/s, est. speed input: 5896.78 toks/s, output: 5.76 toks/s]
Processed prompts:  90%| | 462/512 [01:20<00:08,  5.69it/s, est. speed input: 5895.76 toks/s, output: 5.76 toks/s]
Processed prompts:  91%| | 466/512 [01:20<00:08,  5.69it/s, est. speed input: 5895.16 toks/s, output: 5.76 toks/s]
Processed prompts:  92%|| 470/512 [01:21<00:07,  5.68it/s, est. speed input: 5894.11 toks/s, output: 5.76 toks/s]
Processed prompts:  93%|| 474/512 [01:22<00:06,  5.67it/s, est. speed input: 5893.10 toks/s, output: 5.75 toks/s]
Processed prompts:  93%|| 478/512 [01:23<00:05,  5.68it/s, est. speed input: 5892.76 toks/s, output: 5.75 toks/s]
Processed prompts:  94%|| 482/512 [01:23<00:05,  5.67it/s, est. speed input: 5891.87 toks/s, output: 5.75 toks/s]
Processed prompts:  95%|| 486/512 [01:24<00:04,  5.66it/s, est. speed input: 5890.90 toks/s, output: 5.75 toks/s]
Processed prompts:  96%|| 490/512 [01:25<00:03,  5.67it/s, est. speed input: 5890.43 toks/s, output: 5.75 toks/s]
Processed prompts:  96%|| 494/512 [01:25<00:03,  5.67it/s, est. speed input: 5889.72 toks/s, output: 5.75 toks/s]
Processed prompts:  97%|| 498/512 [01:26<00:02,  5.67it/s, est. speed input: 5888.97 toks/s, output: 5.75 toks/s]
Processed prompts:  98%|| 502/512 [01:27<00:01,  5.68it/s, est. speed input: 5888.61 toks/s, output: 5.75 toks/s]
Processed prompts:  99%|| 506/512 [01:28<00:01,  5.68it/s, est. speed input: 5887.91 toks/s, output: 5.75 toks/s]
Processed prompts: 100%|| 510/512 [01:28<00:00,  6.12it/s, est. speed input: 5898.58 toks/s, output: 5.76 toks/s]
Processed prompts: 100%|| 512/512 [01:28<00:00,  6.12it/s, est. speed input: 5921.70 toks/s, output: 5.78 toks/s]
Processed prompts: 100%|| 512/512 [01:28<00:00,  5.78it/s, est. speed input: 5921.70 toks/s, output: 5.78 toks/s]
[rank0]:[W126 19:24:36.751983373 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 19:24:38
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:24:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:24:46 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1648735) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1648735) WARNING 01-26 19:26:03 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.85 requests/s, 5999.45 total tokens/s, 5.85 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 19:24:46] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:24:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:24:46] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:24:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:24:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:24:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:24:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:24:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:24:49] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:24:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:24:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:24:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:24:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:24:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:24:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:24:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:24:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1648735) [2026-01-26 19:24:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1648735) [2026-01-26 19:24:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1648735) [2026-01-26 19:24:50] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1648735) [2026-01-26 19:24:50] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1648735) [2026-01-26 19:24:50] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1648735) [2026-01-26 19:24:50] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1648735) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1648735) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.00s/it]
(EngineCore_DP0 pid=1648735) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.65s/it]
(EngineCore_DP0 pid=1648735) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.10s/it]
(EngineCore_DP0 pid=1648735) 
(EngineCore_DP0 pid=1648735) [2026-01-26 19:25:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1648735) [2026-01-26 19:25:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1648735) [2026-01-26 19:25:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1648735) [2026-01-26 19:25:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1648735) [2026-01-26 19:25:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1648735) [2026-01-26 19:25:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1648735) [2026-01-26 19:25:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1648735) [2026-01-26 19:25:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1648735) 2026-01-26 19:26:01,138 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1648735) 2026-01-26 19:26:01,453 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|         | 32/1024 [00:00<00:03, 319.76it/s]
Adding requests:   7%|         | 67/1024 [00:00<00:02, 332.63it/s]
Adding requests:  11%|         | 108/1024 [00:00<00:02, 365.46it/s]
Adding requests:  14%|        | 146/1024 [00:00<00:02, 367.62it/s]
Adding requests:  18%|        | 188/1024 [00:00<00:02, 383.39it/s]
Adding requests:  23%|       | 231/1024 [00:00<00:01, 398.88it/s]
Adding requests:  27%|       | 272/1024 [00:00<00:01, 398.78it/s]
Adding requests:  31%|       | 319/1024 [00:00<00:01, 419.51it/s]
Adding requests:  35%|      | 362/1024 [00:00<00:01, 422.14it/s]
Adding requests:  40%|      | 407/1024 [00:01<00:01, 426.48it/s]
Adding requests:  44%|     | 450/1024 [00:01<00:01, 414.24it/s]
Adding requests:  48%|     | 496/1024 [00:01<00:01, 426.52it/s]
Adding requests:  53%|    | 541/1024 [00:01<00:01, 431.42it/s]
Adding requests:  57%|    | 585/1024 [00:01<00:01, 426.62it/s]
Adding requests:  62%|   | 630/1024 [00:01<00:00, 431.86it/s]
Adding requests:  66%|   | 674/1024 [00:01<00:00, 403.26it/s]
Adding requests:  70%|   | 715/1024 [00:01<00:00, 404.24it/s]
Adding requests:  74%|  | 756/1024 [00:01<00:00, 396.64it/s]
Adding requests:  78%|  | 800/1024 [00:01<00:00, 408.46it/s]
Adding requests:  82%| | 842/1024 [00:02<00:00, 405.88it/s]
Adding requests:  86%| | 885/1024 [00:02<00:00, 410.78it/s]
Adding requests:  91%| | 927/1024 [00:02<00:00, 411.84it/s]
Adding requests:  95%|| 970/1024 [00:02<00:00, 417.04it/s]
Adding requests:  99%|| 1012/1024 [00:02<00:00, 416.19it/s]
Adding requests: 100%|| 1024/1024 [00:02<00:00, 407.89it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 10/1024 [00:00<00:48, 20.96it/s, est. speed input: 21466.87 toks/s, output: 20.96 toks/s]
Processed prompts:   2%|         | 18/1024 [00:01<01:53,  8.89it/s, est. speed input: 10069.19 toks/s, output: 9.83 toks/s] 
Processed prompts:   3%|         | 26/1024 [00:03<02:16,  7.29it/s, est. speed input: 8357.05 toks/s, output: 8.16 toks/s] 
Processed prompts:   3%|         | 34/1024 [00:04<02:27,  6.70it/s, est. speed input: 7675.85 toks/s, output: 7.50 toks/s]
Processed prompts:   4%|         | 42/1024 [00:05<02:33,  6.40it/s, est. speed input: 7302.24 toks/s, output: 7.13 toks/s]
Processed prompts:   5%|         | 50/1024 [00:07<02:36,  6.23it/s, est. speed input: 7071.42 toks/s, output: 6.91 toks/s]
Processed prompts:   6%|         | 58/1024 [00:08<02:37,  6.12it/s, est. speed input: 6909.01 toks/s, output: 6.75 toks/s]
Processed prompts:   6%|         | 66/1024 [00:09<02:38,  6.05it/s, est. speed input: 6790.97 toks/s, output: 6.63 toks/s]
Processed prompts:   7%|         | 74/1024 [00:11<02:38,  6.01it/s, est. speed input: 6703.15 toks/s, output: 6.55 toks/s]
Processed prompts:   8%|         | 82/1024 [00:12<02:37,  5.97it/s, est. speed input: 6630.92 toks/s, output: 6.48 toks/s]
Processed prompts:   9%|         | 90/1024 [00:14<02:36,  5.95it/s, est. speed input: 6575.24 toks/s, output: 6.42 toks/s]
Processed prompts:  10%|         | 98/1024 [00:15<02:35,  5.94it/s, est. speed input: 6529.16 toks/s, output: 6.38 toks/s]
Processed prompts:  10%|         | 106/1024 [00:16<02:34,  5.93it/s, est. speed input: 6489.57 toks/s, output: 6.34 toks/s]
Processed prompts:  11%|         | 114/1024 [00:18<02:33,  5.92it/s, est. speed input: 6455.24 toks/s, output: 6.30 toks/s]
Processed prompts:  12%|        | 122/1024 [00:19<02:32,  5.91it/s, est. speed input: 6426.75 toks/s, output: 6.28 toks/s]
Processed prompts:  13%|        | 130/1024 [00:20<02:31,  5.91it/s, est. speed input: 6401.89 toks/s, output: 6.25 toks/s]
Processed prompts:  13%|        | 138/1024 [00:22<02:30,  5.91it/s, est. speed input: 6379.58 toks/s, output: 6.23 toks/s]
Processed prompts:  14%|        | 146/1024 [00:23<02:28,  5.90it/s, est. speed input: 6358.83 toks/s, output: 6.21 toks/s]
Processed prompts:  15%|        | 154/1024 [00:24<02:27,  5.90it/s, est. speed input: 6341.66 toks/s, output: 6.19 toks/s]
Processed prompts:  16%|        | 162/1024 [00:26<02:26,  5.90it/s, est. speed input: 6326.37 toks/s, output: 6.18 toks/s]
Processed prompts:  17%|        | 170/1024 [00:27<02:24,  5.90it/s, est. speed input: 6311.68 toks/s, output: 6.16 toks/s]
Processed prompts:  17%|        | 178/1024 [00:28<02:23,  5.89it/s, est. speed input: 6298.57 toks/s, output: 6.15 toks/s]
Processed prompts:  18%|        | 186/1024 [00:30<02:31,  5.54it/s, est. speed input: 6227.79 toks/s, output: 6.08 toks/s]
Processed prompts:  19%|        | 194/1024 [00:31<02:27,  5.64it/s, est. speed input: 6218.36 toks/s, output: 6.07 toks/s]
Processed prompts:  20%|        | 202/1024 [00:33<02:20,  5.87it/s, est. speed input: 6234.24 toks/s, output: 6.09 toks/s]
Processed prompts:  21%|        | 210/1024 [00:34<02:18,  5.88it/s, est. speed input: 6226.74 toks/s, output: 6.08 toks/s]
Processed prompts:  21%|       | 218/1024 [00:35<02:17,  5.88it/s, est. speed input: 6218.96 toks/s, output: 6.07 toks/s]
Processed prompts:  22%|       | 226/1024 [00:37<02:15,  5.88it/s, est. speed input: 6212.00 toks/s, output: 6.07 toks/s]
Processed prompts:  23%|       | 234/1024 [00:38<02:14,  5.88it/s, est. speed input: 6205.08 toks/s, output: 6.06 toks/s]
Processed prompts:  24%|       | 242/1024 [00:39<02:12,  5.88it/s, est. speed input: 6199.14 toks/s, output: 6.05 toks/s]
Processed prompts:  24%|       | 250/1024 [00:41<02:11,  5.88it/s, est. speed input: 6193.09 toks/s, output: 6.05 toks/s]
Processed prompts:  25%|       | 258/1024 [00:42<02:10,  5.87it/s, est. speed input: 6186.79 toks/s, output: 6.04 toks/s]
Processed prompts:  26%|       | 266/1024 [00:44<02:08,  5.88it/s, est. speed input: 6181.94 toks/s, output: 6.04 toks/s]
Processed prompts:  27%|       | 274/1024 [00:45<02:07,  5.88it/s, est. speed input: 6177.34 toks/s, output: 6.03 toks/s]
Processed prompts:  28%|       | 282/1024 [00:46<02:06,  5.87it/s, est. speed input: 6171.79 toks/s, output: 6.03 toks/s]
Processed prompts:  28%|       | 290/1024 [00:48<02:04,  5.87it/s, est. speed input: 6167.65 toks/s, output: 6.02 toks/s]
Processed prompts:  29%|       | 298/1024 [00:49<02:03,  5.87it/s, est. speed input: 6163.26 toks/s, output: 6.02 toks/s]
Processed prompts:  30%|       | 306/1024 [00:50<01:58,  6.07it/s, est. speed input: 6176.92 toks/s, output: 6.03 toks/s]
Processed prompts:  31%|       | 314/1024 [00:52<01:58,  6.00it/s, est. speed input: 6172.26 toks/s, output: 6.03 toks/s]
Processed prompts:  31%|      | 322/1024 [00:53<01:57,  5.96it/s, est. speed input: 6168.21 toks/s, output: 6.02 toks/s]
Processed prompts:  32%|      | 330/1024 [00:54<01:56,  5.94it/s, est. speed input: 6164.40 toks/s, output: 6.02 toks/s]
Processed prompts:  33%|      | 338/1024 [00:56<01:55,  5.92it/s, est. speed input: 6160.59 toks/s, output: 6.02 toks/s]
Processed prompts:  34%|      | 346/1024 [00:57<01:54,  5.90it/s, est. speed input: 6156.68 toks/s, output: 6.01 toks/s]
Processed prompts:  35%|      | 354/1024 [00:58<01:53,  5.89it/s, est. speed input: 6153.06 toks/s, output: 6.01 toks/s]
Processed prompts:  35%|      | 362/1024 [01:00<01:52,  5.88it/s, est. speed input: 6149.85 toks/s, output: 6.01 toks/s]
Processed prompts:  36%|      | 370/1024 [01:01<01:51,  5.87it/s, est. speed input: 6146.56 toks/s, output: 6.00 toks/s]
Processed prompts:  37%|      | 378/1024 [01:03<01:53,  5.67it/s, est. speed input: 6128.12 toks/s, output: 5.98 toks/s]
Processed prompts:  38%|      | 386/1024 [01:04<01:51,  5.73it/s, est. speed input: 6125.77 toks/s, output: 5.98 toks/s]
Processed prompts:  38%|      | 394/1024 [01:05<01:49,  5.77it/s, est. speed input: 6122.88 toks/s, output: 5.98 toks/s]
Processed prompts:  39%|      | 402/1024 [01:07<01:47,  5.80it/s, est. speed input: 6120.60 toks/s, output: 5.98 toks/s]
Processed prompts:  40%|      | 410/1024 [01:08<01:45,  5.82it/s, est. speed input: 6118.57 toks/s, output: 5.98 toks/s]
Processed prompts:  41%|      | 418/1024 [01:09<01:43,  5.83it/s, est. speed input: 6116.30 toks/s, output: 5.97 toks/s]
Processed prompts:  42%|     | 426/1024 [01:11<01:42,  5.84it/s, est. speed input: 6113.94 toks/s, output: 5.97 toks/s]
Processed prompts:  42%|     | 434/1024 [01:12<01:37,  6.04it/s, est. speed input: 6124.15 toks/s, output: 5.98 toks/s]
Processed prompts:  43%|     | 442/1024 [01:13<01:37,  5.98it/s, est. speed input: 6121.74 toks/s, output: 5.98 toks/s]
Processed prompts:  44%|     | 450/1024 [01:15<01:36,  5.95it/s, est. speed input: 6119.59 toks/s, output: 5.98 toks/s]
Processed prompts:  45%|     | 458/1024 [01:16<01:35,  5.92it/s, est. speed input: 6117.18 toks/s, output: 5.97 toks/s]
Processed prompts:  46%|     | 466/1024 [01:18<01:34,  5.90it/s, est. speed input: 6115.44 toks/s, output: 5.97 toks/s]
Processed prompts:  46%|     | 474/1024 [01:19<01:33,  5.89it/s, est. speed input: 6113.69 toks/s, output: 5.97 toks/s]
Processed prompts:  47%|     | 482/1024 [01:20<01:32,  5.89it/s, est. speed input: 6111.91 toks/s, output: 5.97 toks/s]
Processed prompts:  48%|     | 490/1024 [01:22<01:30,  5.88it/s, est. speed input: 6110.04 toks/s, output: 5.97 toks/s]
Processed prompts:  49%|     | 498/1024 [01:23<01:29,  5.88it/s, est. speed input: 6108.48 toks/s, output: 5.97 toks/s]
Processed prompts:  49%|     | 506/1024 [01:24<01:28,  5.87it/s, est. speed input: 6106.73 toks/s, output: 5.96 toks/s]
Processed prompts:  50%|     | 514/1024 [01:26<01:26,  5.86it/s, est. speed input: 6104.81 toks/s, output: 5.96 toks/s]
Processed prompts:  51%|     | 522/1024 [01:27<01:25,  5.87it/s, est. speed input: 6103.45 toks/s, output: 5.96 toks/s]
Processed prompts:  52%|    | 530/1024 [01:28<01:24,  5.87it/s, est. speed input: 6101.94 toks/s, output: 5.96 toks/s]
Processed prompts:  53%|    | 538/1024 [01:30<01:22,  5.87it/s, est. speed input: 6100.47 toks/s, output: 5.96 toks/s]
Processed prompts:  53%|    | 546/1024 [01:31<01:21,  5.86it/s, est. speed input: 6098.69 toks/s, output: 5.96 toks/s]
Processed prompts:  54%|    | 554/1024 [01:33<01:20,  5.86it/s, est. speed input: 6097.37 toks/s, output: 5.95 toks/s]
Processed prompts:  55%|    | 562/1024 [01:34<01:18,  5.86it/s, est. speed input: 6095.97 toks/s, output: 5.95 toks/s]
Processed prompts:  56%|    | 570/1024 [01:35<01:19,  5.68it/s, est. speed input: 6085.18 toks/s, output: 5.94 toks/s]
Processed prompts:  56%|    | 578/1024 [01:37<01:17,  5.73it/s, est. speed input: 6084.17 toks/s, output: 5.94 toks/s]
Processed prompts:  57%|    | 586/1024 [01:38<01:15,  5.76it/s, est. speed input: 6082.70 toks/s, output: 5.94 toks/s]
Processed prompts:  58%|    | 594/1024 [01:40<01:14,  5.79it/s, est. speed input: 6081.33 toks/s, output: 5.94 toks/s]
Processed prompts:  59%|    | 602/1024 [01:41<01:12,  5.81it/s, est. speed input: 6080.21 toks/s, output: 5.94 toks/s]
Processed prompts:  60%|    | 610/1024 [01:42<01:11,  5.83it/s, est. speed input: 6079.37 toks/s, output: 5.94 toks/s]
Processed prompts:  60%|    | 618/1024 [01:44<01:09,  5.84it/s, est. speed input: 6078.56 toks/s, output: 5.94 toks/s]
Processed prompts:  61%|    | 626/1024 [01:45<01:08,  5.84it/s, est. speed input: 6077.21 toks/s, output: 5.93 toks/s]
Processed prompts:  62%|   | 634/1024 [01:46<01:06,  5.85it/s, est. speed input: 6076.34 toks/s, output: 5.93 toks/s]
Processed prompts:  63%|   | 642/1024 [01:48<01:05,  5.85it/s, est. speed input: 6075.24 toks/s, output: 5.93 toks/s]
Processed prompts:  63%|   | 650/1024 [01:49<01:03,  5.85it/s, est. speed input: 6074.34 toks/s, output: 5.93 toks/s]
Processed prompts:  64%|   | 658/1024 [01:50<01:02,  5.86it/s, est. speed input: 6073.46 toks/s, output: 5.93 toks/s]
Processed prompts:  65%|   | 666/1024 [01:52<01:01,  5.85it/s, est. speed input: 6072.49 toks/s, output: 5.93 toks/s]
Processed prompts:  66%|   | 674/1024 [01:53<00:59,  5.86it/s, est. speed input: 6071.67 toks/s, output: 5.93 toks/s]
Processed prompts:  67%|   | 682/1024 [01:55<00:58,  5.85it/s, est. speed input: 6070.61 toks/s, output: 5.93 toks/s]
Processed prompts:  67%|   | 690/1024 [01:56<00:57,  5.86it/s, est. speed input: 6069.82 toks/s, output: 5.93 toks/s]
Processed prompts:  68%|   | 698/1024 [01:57<00:55,  5.86it/s, est. speed input: 6069.06 toks/s, output: 5.93 toks/s]
Processed prompts:  69%|   | 706/1024 [01:59<00:54,  5.86it/s, est. speed input: 6068.17 toks/s, output: 5.93 toks/s]
Processed prompts:  70%|   | 714/1024 [02:00<00:52,  5.86it/s, est. speed input: 6067.50 toks/s, output: 5.93 toks/s]
Processed prompts:  71%|   | 722/1024 [02:01<00:51,  5.86it/s, est. speed input: 6066.60 toks/s, output: 5.92 toks/s]
Processed prompts:  71%|  | 730/1024 [02:03<00:50,  5.86it/s, est. speed input: 6065.86 toks/s, output: 5.92 toks/s]
Processed prompts:  72%|  | 738/1024 [02:04<00:48,  5.86it/s, est. speed input: 6065.18 toks/s, output: 5.92 toks/s]
Processed prompts:  73%|  | 746/1024 [02:05<00:47,  5.85it/s, est. speed input: 6064.20 toks/s, output: 5.92 toks/s]
Processed prompts:  74%|  | 754/1024 [02:07<00:46,  5.86it/s, est. speed input: 6063.58 toks/s, output: 5.92 toks/s]
Processed prompts:  74%|  | 762/1024 [02:08<00:46,  5.69it/s, est. speed input: 6056.56 toks/s, output: 5.91 toks/s]
Processed prompts:  75%|  | 770/1024 [02:10<00:44,  5.74it/s, est. speed input: 6055.95 toks/s, output: 5.91 toks/s]
Processed prompts:  76%|  | 778/1024 [02:11<00:42,  5.78it/s, est. speed input: 6055.61 toks/s, output: 5.91 toks/s]
Processed prompts:  77%|  | 786/1024 [02:12<00:39,  5.99it/s, est. speed input: 6061.48 toks/s, output: 5.92 toks/s]
Processed prompts:  78%|  | 794/1024 [02:14<00:38,  5.94it/s, est. speed input: 6060.64 toks/s, output: 5.92 toks/s]
Processed prompts:  78%|  | 802/1024 [02:15<00:37,  5.92it/s, est. speed input: 6060.27 toks/s, output: 5.92 toks/s]
Processed prompts:  79%|  | 810/1024 [02:16<00:36,  5.90it/s, est. speed input: 6059.67 toks/s, output: 5.92 toks/s]
Processed prompts:  80%|  | 818/1024 [02:18<00:35,  5.89it/s, est. speed input: 6058.89 toks/s, output: 5.92 toks/s]
Processed prompts:  81%|  | 826/1024 [02:19<00:33,  5.88it/s, est. speed input: 6058.36 toks/s, output: 5.92 toks/s]
Processed prompts:  81%| | 834/1024 [02:20<00:32,  5.87it/s, est. speed input: 6057.79 toks/s, output: 5.92 toks/s]
Processed prompts:  82%| | 842/1024 [02:22<00:30,  5.87it/s, est. speed input: 6057.35 toks/s, output: 5.92 toks/s]
Processed prompts:  83%| | 850/1024 [02:23<00:29,  5.86it/s, est. speed input: 6056.57 toks/s, output: 5.91 toks/s]
Processed prompts:  84%| | 858/1024 [02:25<00:28,  5.86it/s, est. speed input: 6055.98 toks/s, output: 5.91 toks/s]
Processed prompts:  85%| | 866/1024 [02:26<00:26,  5.86it/s, est. speed input: 6055.46 toks/s, output: 5.91 toks/s]
Processed prompts:  85%| | 874/1024 [02:27<00:25,  5.86it/s, est. speed input: 6054.83 toks/s, output: 5.91 toks/s]
Processed prompts:  86%| | 882/1024 [02:29<00:24,  5.86it/s, est. speed input: 6054.40 toks/s, output: 5.91 toks/s]
Processed prompts:  87%| | 890/1024 [02:30<00:22,  5.86it/s, est. speed input: 6053.90 toks/s, output: 5.91 toks/s]
Processed prompts:  88%| | 898/1024 [02:31<00:21,  5.86it/s, est. speed input: 6053.45 toks/s, output: 5.91 toks/s]
Processed prompts:  88%| | 906/1024 [02:33<00:20,  5.85it/s, est. speed input: 6052.76 toks/s, output: 5.91 toks/s]
Processed prompts:  89%| | 914/1024 [02:34<00:18,  5.85it/s, est. speed input: 6052.22 toks/s, output: 5.91 toks/s]
Processed prompts:  90%| | 922/1024 [02:36<00:17,  5.86it/s, est. speed input: 6051.79 toks/s, output: 5.91 toks/s]
Processed prompts:  91%| | 930/1024 [02:37<00:16,  5.85it/s, est. speed input: 6051.13 toks/s, output: 5.91 toks/s]
Processed prompts:  92%|| 938/1024 [02:38<00:14,  5.85it/s, est. speed input: 6050.67 toks/s, output: 5.91 toks/s]
Processed prompts:  92%|| 946/1024 [02:40<00:13,  5.85it/s, est. speed input: 6050.21 toks/s, output: 5.91 toks/s]
Processed prompts:  93%|| 954/1024 [02:41<00:12,  5.65it/s, est. speed input: 6043.50 toks/s, output: 5.90 toks/s]
Processed prompts:  94%|| 962/1024 [02:43<00:10,  5.71it/s, est. speed input: 6043.14 toks/s, output: 5.90 toks/s]
Processed prompts:  95%|| 970/1024 [02:44<00:09,  5.75it/s, est. speed input: 6042.66 toks/s, output: 5.90 toks/s]
Processed prompts:  96%|| 978/1024 [02:45<00:07,  5.78it/s, est. speed input: 6042.26 toks/s, output: 5.90 toks/s]
Processed prompts:  96%|| 986/1024 [02:47<00:06,  5.80it/s, est. speed input: 6041.70 toks/s, output: 5.90 toks/s]
Processed prompts:  97%|| 994/1024 [02:48<00:05,  5.81it/s, est. speed input: 6041.32 toks/s, output: 5.90 toks/s]
Processed prompts:  98%|| 1002/1024 [02:49<00:03,  5.83it/s, est. speed input: 6040.97 toks/s, output: 5.90 toks/s]
Processed prompts:  99%|| 1010/1024 [02:51<00:02,  5.83it/s, est. speed input: 6040.40 toks/s, output: 5.90 toks/s]
Processed prompts:  99%|| 1018/1024 [02:52<00:00,  6.03it/s, est. speed input: 6045.29 toks/s, output: 5.90 toks/s]
Processed prompts: 100%|| 1024/1024 [02:52<00:00,  6.03it/s, est. speed input: 6080.91 toks/s, output: 5.94 toks/s]
Processed prompts: 100%|| 1024/1024 [02:52<00:00,  5.94it/s, est. speed input: 6080.91 toks/s, output: 5.94 toks/s]
[rank0]:[W126 19:28:59.314844423 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 19:29:01
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:29:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:29:14 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1652606) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1652606) WARNING 01-26 19:30:36 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.86 requests/s, 6008.47 total tokens/s, 5.86 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 19:29:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:29:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:29:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:29:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:29:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:29:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:29:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:29:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:29:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:29:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:29:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:29:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:29:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:29:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:29:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:29:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:29:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1652606) [2026-01-26 19:29:19] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1652606) [2026-01-26 19:29:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1652606) [2026-01-26 19:29:19] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1652606) [2026-01-26 19:29:19] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1652606) [2026-01-26 19:29:19] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1652606) [2026-01-26 19:29:19] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1652606) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1652606) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:29<00:29, 29.31s/it]
(EngineCore_DP0 pid=1652606) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.51s/it]
(EngineCore_DP0 pid=1652606) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:04<00:00, 32.03s/it]
(EngineCore_DP0 pid=1652606) 
(EngineCore_DP0 pid=1652606) [2026-01-26 19:30:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1652606) [2026-01-26 19:30:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1652606) [2026-01-26 19:30:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1652606) [2026-01-26 19:30:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1652606) [2026-01-26 19:30:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1652606) [2026-01-26 19:30:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1652606) [2026-01-26 19:30:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1652606) [2026-01-26 19:30:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1652606) 2026-01-26 19:30:32,487 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1652606) 2026-01-26 19:30:33,067 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   2%|         | 48/2048 [00:00<00:04, 471.63it/s]
Adding requests:   5%|         | 96/2048 [00:00<00:05, 365.68it/s]
Adding requests:   7%|         | 138/2048 [00:00<00:04, 384.71it/s]
Adding requests:   9%|         | 178/2048 [00:00<00:04, 387.75it/s]
Adding requests:  11%|         | 223/2048 [00:00<00:04, 408.35it/s]
Adding requests:  13%|        | 265/2048 [00:00<00:04, 411.29it/s]
Adding requests:  15%|        | 308/2048 [00:00<00:04, 415.71it/s]
Adding requests:  17%|        | 354/2048 [00:00<00:03, 427.19it/s]
Adding requests:  20%|        | 400/2048 [00:00<00:03, 434.79it/s]
Adding requests:  22%|       | 444/2048 [00:01<00:03, 435.59it/s]
Adding requests:  24%|       | 492/2048 [00:01<00:03, 446.56it/s]
Adding requests:  26%|       | 540/2048 [00:01<00:03, 456.16it/s]
Adding requests:  29%|       | 586/2048 [00:01<00:03, 445.79it/s]
Adding requests:  31%|       | 631/2048 [00:01<00:03, 446.45it/s]
Adding requests:  33%|      | 676/2048 [00:01<00:03, 434.55it/s]
Adding requests:  35%|      | 720/2048 [00:01<00:03, 429.44it/s]
Adding requests:  37%|      | 764/2048 [00:01<00:03, 427.43it/s]
Adding requests:  40%|      | 809/2048 [00:01<00:02, 432.14it/s]
Adding requests:  42%|     | 854/2048 [00:01<00:02, 436.80it/s]
Adding requests:  44%|     | 898/2048 [00:02<00:02, 430.83it/s]
Adding requests:  46%|     | 942/2048 [00:02<00:02, 425.40it/s]
Adding requests:  48%|     | 985/2048 [00:02<00:07, 147.52it/s]
Adding requests:  50%|     | 1025/2048 [00:03<00:05, 178.80it/s]
Adding requests:  52%|    | 1065/2048 [00:03<00:04, 212.01it/s]
Adding requests:  54%|    | 1108/2048 [00:03<00:03, 250.32it/s]
Adding requests:  56%|    | 1152/2048 [00:03<00:03, 288.52it/s]
Adding requests:  58%|    | 1196/2048 [00:03<00:02, 321.51it/s]
Adding requests:  61%|    | 1241/2048 [00:03<00:02, 352.54it/s]
Adding requests:  63%|   | 1283/2048 [00:03<00:02, 362.09it/s]
Adding requests:  65%|   | 1325/2048 [00:03<00:01, 375.15it/s]
Adding requests:  67%|   | 1368/2048 [00:03<00:01, 390.10it/s]
Adding requests:  69%|   | 1412/2048 [00:03<00:01, 400.55it/s]
Adding requests:  71%|   | 1456/2048 [00:04<00:01, 410.15it/s]
Adding requests:  73%|  | 1501/2048 [00:04<00:01, 420.29it/s]
Adding requests:  75%|  | 1545/2048 [00:04<00:01, 422.65it/s]
Adding requests:  78%|  | 1588/2048 [00:04<00:01, 422.64it/s]
Adding requests:  80%|  | 1631/2048 [00:04<00:00, 422.24it/s]
Adding requests:  82%| | 1674/2048 [00:04<00:00, 415.56it/s]
Adding requests:  84%| | 1718/2048 [00:04<00:00, 420.72it/s]
Adding requests:  86%| | 1763/2048 [00:04<00:00, 427.14it/s]
Adding requests:  88%| | 1806/2048 [00:04<00:00, 425.39it/s]
Adding requests:  90%| | 1849/2048 [00:05<00:00, 416.45it/s]
Adding requests:  92%|| 1894/2048 [00:05<00:00, 424.90it/s]
Adding requests:  95%|| 1939/2048 [00:05<00:00, 431.09it/s]
Adding requests:  97%|| 1984/2048 [00:05<00:00, 434.14it/s]
Adding requests:  99%|| 2028/2048 [00:05<00:00, 429.31it/s]
Adding requests: 100%|| 2048/2048 [00:05<00:00, 374.71it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 18/2048 [00:00<00:34, 59.14it/s, est. speed input: 60573.21 toks/s, output: 59.15 toks/s]
Processed prompts:   2%|         | 34/2048 [00:03<03:26,  9.75it/s, est. speed input: 11510.76 toks/s, output: 11.24 toks/s]
Processed prompts:   2%|         | 50/2048 [00:05<04:24,  7.54it/s, est. speed input: 8906.56 toks/s, output: 8.70 toks/s]  
Processed prompts:   3%|         | 66/2048 [00:08<04:51,  6.79it/s, est. speed input: 7974.51 toks/s, output: 7.79 toks/s]
Processed prompts:   4%|         | 82/2048 [00:11<05:05,  6.43it/s, est. speed input: 7496.27 toks/s, output: 7.32 toks/s]
Processed prompts:   5%|         | 98/2048 [00:13<05:13,  6.22it/s, est. speed input: 7202.34 toks/s, output: 7.03 toks/s]
Processed prompts:   6%|         | 114/2048 [00:16<05:17,  6.10it/s, est. speed input: 7003.59 toks/s, output: 6.84 toks/s]
Processed prompts:   6%|         | 130/2048 [00:19<05:18,  6.02it/s, est. speed input: 6861.07 toks/s, output: 6.70 toks/s]
Processed prompts:   7%|         | 146/2048 [00:22<05:18,  5.96it/s, est. speed input: 6753.67 toks/s, output: 6.60 toks/s]
Processed prompts:   8%|         | 162/2048 [00:24<05:18,  5.93it/s, est. speed input: 6668.99 toks/s, output: 6.51 toks/s]
Processed prompts:   9%|         | 178/2048 [00:27<05:17,  5.90it/s, est. speed input: 6600.12 toks/s, output: 6.45 toks/s]
Processed prompts:   9%|         | 194/2048 [00:30<05:09,  5.99it/s, est. speed input: 6580.53 toks/s, output: 6.43 toks/s]
Processed prompts:  10%|         | 210/2048 [00:32<05:09,  5.94it/s, est. speed input: 6528.83 toks/s, output: 6.38 toks/s]
Processed prompts:  11%|         | 226/2048 [00:35<05:08,  5.91it/s, est. speed input: 6486.65 toks/s, output: 6.33 toks/s]
Processed prompts:  12%|        | 242/2048 [00:38<05:07,  5.88it/s, est. speed input: 6448.94 toks/s, output: 6.30 toks/s]
Processed prompts:  13%|        | 258/2048 [00:41<05:05,  5.86it/s, est. speed input: 6416.20 toks/s, output: 6.27 toks/s]
Processed prompts:  13%|        | 274/2048 [00:43<05:03,  5.85it/s, est. speed input: 6388.65 toks/s, output: 6.24 toks/s]
Processed prompts:  14%|        | 290/2048 [00:46<05:00,  5.84it/s, est. speed input: 6363.46 toks/s, output: 6.21 toks/s]
Processed prompts:  15%|        | 306/2048 [00:49<04:52,  5.96it/s, est. speed input: 6365.30 toks/s, output: 6.22 toks/s]
Processed prompts:  16%|        | 322/2048 [00:51<04:51,  5.91it/s, est. speed input: 6343.16 toks/s, output: 6.19 toks/s]
Processed prompts:  17%|        | 338/2048 [00:54<04:50,  5.89it/s, est. speed input: 6324.43 toks/s, output: 6.18 toks/s]
Processed prompts:  17%|        | 354/2048 [00:57<04:48,  5.87it/s, est. speed input: 6307.02 toks/s, output: 6.16 toks/s]
Processed prompts:  18%|        | 370/2048 [01:00<04:46,  5.86it/s, est. speed input: 6291.51 toks/s, output: 6.14 toks/s]
Processed prompts:  19%|        | 386/2048 [01:02<04:44,  5.84it/s, est. speed input: 6276.86 toks/s, output: 6.13 toks/s]
Processed prompts:  20%|        | 402/2048 [01:05<04:42,  5.83it/s, est. speed input: 6263.17 toks/s, output: 6.12 toks/s]
Processed prompts:  20%|        | 418/2048 [01:08<04:39,  5.83it/s, est. speed input: 6251.30 toks/s, output: 6.10 toks/s]
Processed prompts:  21%|        | 434/2048 [01:11<04:31,  5.95it/s, est. speed input: 6255.96 toks/s, output: 6.11 toks/s]
Processed prompts:  22%|       | 450/2048 [01:13<04:30,  5.91it/s, est. speed input: 6245.11 toks/s, output: 6.10 toks/s]
Processed prompts:  23%|       | 466/2048 [01:16<04:29,  5.88it/s, est. speed input: 6234.50 toks/s, output: 6.09 toks/s]
Processed prompts:  24%|       | 482/2048 [01:19<04:27,  5.86it/s, est. speed input: 6224.79 toks/s, output: 6.08 toks/s]
Processed prompts:  24%|       | 498/2048 [01:22<04:25,  5.84it/s, est. speed input: 6215.43 toks/s, output: 6.07 toks/s]
Processed prompts:  25%|       | 514/2048 [01:24<04:22,  5.84it/s, est. speed input: 6207.07 toks/s, output: 6.06 toks/s]
Processed prompts:  26%|       | 530/2048 [01:27<04:20,  5.83it/s, est. speed input: 6199.33 toks/s, output: 6.05 toks/s]
Processed prompts:  27%|       | 546/2048 [01:30<04:17,  5.83it/s, est. speed input: 6191.85 toks/s, output: 6.05 toks/s]
Processed prompts:  27%|       | 562/2048 [01:33<04:15,  5.82it/s, est. speed input: 6184.98 toks/s, output: 6.04 toks/s]
Processed prompts:  28%|       | 578/2048 [01:35<04:12,  5.82it/s, est. speed input: 6178.12 toks/s, output: 6.03 toks/s]
Processed prompts:  29%|       | 594/2048 [01:38<04:09,  5.82it/s, est. speed input: 6171.89 toks/s, output: 6.03 toks/s]
Processed prompts:  30%|       | 610/2048 [01:41<04:07,  5.82it/s, est. speed input: 6166.00 toks/s, output: 6.02 toks/s]
Processed prompts:  31%|       | 626/2048 [01:44<04:04,  5.82it/s, est. speed input: 6160.36 toks/s, output: 6.02 toks/s]
Processed prompts:  31%|      | 642/2048 [01:46<04:01,  5.82it/s, est. speed input: 6155.17 toks/s, output: 6.01 toks/s]
Processed prompts:  32%|      | 658/2048 [01:49<03:59,  5.82it/s, est. speed input: 6150.01 toks/s, output: 6.01 toks/s]
Processed prompts:  33%|      | 674/2048 [01:52<03:56,  5.82it/s, est. speed input: 6145.38 toks/s, output: 6.00 toks/s]
Processed prompts:  34%|      | 690/2048 [01:55<03:53,  5.82it/s, est. speed input: 6140.75 toks/s, output: 6.00 toks/s]
Processed prompts:  34%|      | 706/2048 [01:57<03:50,  5.81it/s, est. speed input: 6136.11 toks/s, output: 5.99 toks/s]
Processed prompts:  35%|      | 722/2048 [02:00<03:48,  5.81it/s, est. speed input: 6131.80 toks/s, output: 5.99 toks/s]
Processed prompts:  36%|      | 738/2048 [02:03<03:45,  5.81it/s, est. speed input: 6127.44 toks/s, output: 5.98 toks/s]
Processed prompts:  37%|      | 754/2048 [02:06<03:42,  5.80it/s, est. speed input: 6123.20 toks/s, output: 5.98 toks/s]
Processed prompts:  38%|      | 770/2048 [02:08<03:40,  5.80it/s, est. speed input: 6119.25 toks/s, output: 5.98 toks/s]
Processed prompts:  38%|      | 786/2048 [02:11<03:33,  5.92it/s, est. speed input: 6124.24 toks/s, output: 5.98 toks/s]
Processed prompts:  39%|      | 802/2048 [02:14<03:31,  5.89it/s, est. speed input: 6120.52 toks/s, output: 5.98 toks/s]
Processed prompts:  40%|      | 818/2048 [02:16<03:29,  5.86it/s, est. speed input: 6116.94 toks/s, output: 5.97 toks/s]
Processed prompts:  41%|      | 834/2048 [02:19<03:27,  5.85it/s, est. speed input: 6113.62 toks/s, output: 5.97 toks/s]
Processed prompts:  42%|     | 850/2048 [02:22<03:25,  5.83it/s, est. speed input: 6110.27 toks/s, output: 5.97 toks/s]
Processed prompts:  42%|     | 866/2048 [02:25<03:22,  5.83it/s, est. speed input: 6107.21 toks/s, output: 5.96 toks/s]
Processed prompts:  43%|     | 882/2048 [02:27<03:20,  5.82it/s, est. speed input: 6104.31 toks/s, output: 5.96 toks/s]
Processed prompts:  44%|     | 898/2048 [02:30<03:17,  5.82it/s, est. speed input: 6101.52 toks/s, output: 5.96 toks/s]
Processed prompts:  45%|     | 914/2048 [02:33<03:15,  5.82it/s, est. speed input: 6098.75 toks/s, output: 5.96 toks/s]
Processed prompts:  45%|     | 930/2048 [02:36<03:12,  5.81it/s, est. speed input: 6096.07 toks/s, output: 5.95 toks/s]
Processed prompts:  46%|     | 946/2048 [02:38<03:09,  5.81it/s, est. speed input: 6093.59 toks/s, output: 5.95 toks/s]
Processed prompts:  47%|     | 962/2048 [02:41<03:07,  5.80it/s, est. speed input: 6090.69 toks/s, output: 5.95 toks/s]
Processed prompts:  48%|     | 978/2048 [02:44<03:04,  5.81it/s, est. speed input: 6088.45 toks/s, output: 5.95 toks/s]
Processed prompts:  49%|     | 994/2048 [02:47<03:01,  5.81it/s, est. speed input: 6086.13 toks/s, output: 5.94 toks/s]
Processed prompts:  49%|     | 1010/2048 [02:50<02:58,  5.80it/s, est. speed input: 6083.68 toks/s, output: 5.94 toks/s]
Processed prompts:  50%|     | 1026/2048 [02:52<02:56,  5.81it/s, est. speed input: 6081.57 toks/s, output: 5.94 toks/s]
Processed prompts:  51%|     | 1042/2048 [02:55<02:53,  5.80it/s, est. speed input: 6079.29 toks/s, output: 5.94 toks/s]
Processed prompts:  52%|    | 1058/2048 [02:58<02:50,  5.81it/s, est. speed input: 6077.51 toks/s, output: 5.94 toks/s]
Processed prompts:  52%|    | 1074/2048 [03:01<02:47,  5.81it/s, est. speed input: 6075.42 toks/s, output: 5.93 toks/s]
Processed prompts:  53%|    | 1090/2048 [03:03<02:44,  5.81it/s, est. speed input: 6073.55 toks/s, output: 5.93 toks/s]
Processed prompts:  54%|    | 1106/2048 [03:06<02:42,  5.81it/s, est. speed input: 6071.66 toks/s, output: 5.93 toks/s]
Processed prompts:  55%|    | 1122/2048 [03:09<02:39,  5.81it/s, est. speed input: 6069.72 toks/s, output: 5.93 toks/s]
Processed prompts:  56%|    | 1138/2048 [03:12<02:36,  5.81it/s, est. speed input: 6068.06 toks/s, output: 5.93 toks/s]
Processed prompts:  56%|    | 1154/2048 [03:14<02:34,  5.80it/s, est. speed input: 6066.18 toks/s, output: 5.92 toks/s]
Processed prompts:  57%|    | 1170/2048 [03:17<02:31,  5.80it/s, est. speed input: 6064.48 toks/s, output: 5.92 toks/s]
Processed prompts:  58%|    | 1186/2048 [03:20<02:28,  5.80it/s, est. speed input: 6062.75 toks/s, output: 5.92 toks/s]
Processed prompts:  59%|    | 1202/2048 [03:22<02:22,  5.93it/s, est. speed input: 6066.78 toks/s, output: 5.92 toks/s]
Processed prompts:  59%|    | 1218/2048 [03:25<02:20,  5.89it/s, est. speed input: 6065.12 toks/s, output: 5.92 toks/s]
Processed prompts:  60%|    | 1234/2048 [03:28<02:15,  5.99it/s, est. speed input: 6069.03 toks/s, output: 5.93 toks/s]
Processed prompts:  61%|    | 1250/2048 [03:30<02:14,  5.93it/s, est. speed input: 6067.37 toks/s, output: 5.93 toks/s]
Processed prompts:  62%|   | 1266/2048 [03:33<02:12,  5.89it/s, est. speed input: 6065.88 toks/s, output: 5.92 toks/s]
Processed prompts:  63%|   | 1282/2048 [03:36<02:10,  5.87it/s, est. speed input: 6064.42 toks/s, output: 5.92 toks/s]
Processed prompts:  63%|   | 1298/2048 [03:39<02:08,  5.85it/s, est. speed input: 6062.91 toks/s, output: 5.92 toks/s]
Processed prompts:  64%|   | 1314/2048 [03:41<02:05,  5.84it/s, est. speed input: 6061.58 toks/s, output: 5.92 toks/s]
Processed prompts:  65%|   | 1330/2048 [03:44<02:00,  5.95it/s, est. speed input: 6064.96 toks/s, output: 5.92 toks/s]
Processed prompts:  66%|   | 1346/2048 [03:47<01:58,  5.90it/s, est. speed input: 6063.57 toks/s, output: 5.92 toks/s]
Processed prompts:  67%|   | 1362/2048 [03:50<01:56,  5.87it/s, est. speed input: 6062.12 toks/s, output: 5.92 toks/s]
Processed prompts:  67%|   | 1378/2048 [03:52<01:54,  5.86it/s, est. speed input: 6060.89 toks/s, output: 5.92 toks/s]
Processed prompts:  68%|   | 1394/2048 [03:55<01:51,  5.84it/s, est. speed input: 6059.46 toks/s, output: 5.92 toks/s]
Processed prompts:  69%|   | 1410/2048 [03:58<01:49,  5.83it/s, est. speed input: 6058.10 toks/s, output: 5.92 toks/s]
Processed prompts:  70%|   | 1426/2048 [04:01<01:46,  5.82it/s, est. speed input: 6056.87 toks/s, output: 5.91 toks/s]
Processed prompts:  70%|   | 1442/2048 [04:03<01:42,  5.94it/s, est. speed input: 6060.27 toks/s, output: 5.92 toks/s]
Processed prompts:  71%|   | 1458/2048 [04:06<01:37,  6.02it/s, est. speed input: 6063.51 toks/s, output: 5.92 toks/s]
Processed prompts:  72%|  | 1474/2048 [04:08<01:36,  5.95it/s, est. speed input: 6062.12 toks/s, output: 5.92 toks/s]
Processed prompts:  73%|  | 1490/2048 [04:11<01:34,  5.91it/s, est. speed input: 6060.89 toks/s, output: 5.92 toks/s]
Processed prompts:  74%|  | 1506/2048 [04:14<01:32,  5.87it/s, est. speed input: 6059.47 toks/s, output: 5.92 toks/s]
Processed prompts:  74%|  | 1522/2048 [04:17<01:28,  5.98it/s, est. speed input: 6062.65 toks/s, output: 5.92 toks/s]
Processed prompts:  75%|  | 1538/2048 [04:19<01:26,  5.92it/s, est. speed input: 6061.25 toks/s, output: 5.92 toks/s]
Processed prompts:  76%|  | 1554/2048 [04:22<01:22,  6.00it/s, est. speed input: 6064.19 toks/s, output: 5.92 toks/s]
Processed prompts:  77%|  | 1570/2048 [04:25<01:20,  5.94it/s, est. speed input: 6062.82 toks/s, output: 5.92 toks/s]
Processed prompts:  77%|  | 1586/2048 [04:27<01:18,  5.90it/s, est. speed input: 6061.60 toks/s, output: 5.92 toks/s]
Processed prompts:  78%|  | 1602/2048 [04:30<01:16,  5.87it/s, est. speed input: 6060.26 toks/s, output: 5.92 toks/s]
Processed prompts:  79%|  | 1618/2048 [04:33<01:12,  5.97it/s, est. speed input: 6063.25 toks/s, output: 5.92 toks/s]
Processed prompts:  80%|  | 1634/2048 [04:36<01:10,  5.91it/s, est. speed input: 6061.86 toks/s, output: 5.92 toks/s]
Processed prompts:  81%|  | 1650/2048 [04:38<01:07,  5.88it/s, est. speed input: 6060.64 toks/s, output: 5.92 toks/s]
Processed prompts:  81%| | 1666/2048 [04:41<01:05,  5.86it/s, est. speed input: 6059.52 toks/s, output: 5.92 toks/s]
Processed prompts:  82%| | 1682/2048 [04:44<01:02,  5.84it/s, est. speed input: 6058.24 toks/s, output: 5.92 toks/s]
Processed prompts:  83%| | 1698/2048 [04:47<01:00,  5.83it/s, est. speed input: 6057.20 toks/s, output: 5.92 toks/s]
Processed prompts:  84%| | 1714/2048 [04:49<00:57,  5.82it/s, est. speed input: 6055.97 toks/s, output: 5.91 toks/s]
Processed prompts:  84%| | 1730/2048 [04:52<00:53,  5.93it/s, est. speed input: 6058.67 toks/s, output: 5.92 toks/s]
Processed prompts:  85%| | 1746/2048 [04:54<00:49,  6.11it/s, est. speed input: 6064.26 toks/s, output: 5.92 toks/s]
Processed prompts:  86%| | 1762/2048 [04:57<00:47,  6.02it/s, est. speed input: 6063.13 toks/s, output: 5.92 toks/s]
Processed prompts:  87%| | 1778/2048 [05:00<00:45,  5.95it/s, est. speed input: 6061.99 toks/s, output: 5.92 toks/s]
Processed prompts:  88%| | 1794/2048 [05:03<00:43,  5.90it/s, est. speed input: 6060.86 toks/s, output: 5.92 toks/s]
Processed prompts:  88%| | 1810/2048 [05:05<00:40,  5.87it/s, est. speed input: 6059.75 toks/s, output: 5.92 toks/s]
Processed prompts:  89%| | 1826/2048 [05:08<00:37,  5.85it/s, est. speed input: 6058.64 toks/s, output: 5.92 toks/s]
Processed prompts:  90%| | 1842/2048 [05:11<00:35,  5.83it/s, est. speed input: 6057.60 toks/s, output: 5.92 toks/s]
Processed prompts:  91%| | 1858/2048 [05:14<00:32,  5.82it/s, est. speed input: 6056.45 toks/s, output: 5.91 toks/s]
Processed prompts:  92%|| 1874/2048 [05:16<00:29,  5.81it/s, est. speed input: 6055.36 toks/s, output: 5.91 toks/s]
Processed prompts:  92%|| 1890/2048 [05:19<00:26,  5.93it/s, est. speed input: 6057.85 toks/s, output: 5.92 toks/s]
Processed prompts:  93%|| 1906/2048 [05:22<00:24,  5.89it/s, est. speed input: 6056.86 toks/s, output: 5.91 toks/s]
Processed prompts:  94%|| 1922/2048 [05:24<00:21,  5.86it/s, est. speed input: 6055.81 toks/s, output: 5.91 toks/s]
Processed prompts:  95%|| 1938/2048 [05:27<00:18,  5.84it/s, est. speed input: 6054.82 toks/s, output: 5.91 toks/s]
Processed prompts:  95%|| 1954/2048 [05:30<00:16,  5.83it/s, est. speed input: 6053.85 toks/s, output: 5.91 toks/s]
Processed prompts:  96%|| 1970/2048 [05:33<00:13,  5.82it/s, est. speed input: 6052.94 toks/s, output: 5.91 toks/s]
Processed prompts:  97%|| 1986/2048 [05:35<00:10,  5.94it/s, est. speed input: 6055.43 toks/s, output: 5.91 toks/s]
Processed prompts:  98%|| 2002/2048 [05:38<00:07,  5.90it/s, est. speed input: 6054.47 toks/s, output: 5.91 toks/s]
Processed prompts:  99%|| 2018/2048 [05:41<00:05,  5.87it/s, est. speed input: 6053.68 toks/s, output: 5.91 toks/s]
Processed prompts:  99%|| 2034/2048 [05:43<00:02,  5.98it/s, est. speed input: 6056.34 toks/s, output: 5.91 toks/s]
Processed prompts: 100%|| 2048/2048 [05:43<00:00,  5.98it/s, est. speed input: 6098.02 toks/s, output: 5.96 toks/s]
Processed prompts: 100%|| 2048/2048 [05:43<00:00,  5.96it/s, est. speed input: 6098.02 toks/s, output: 5.96 toks/s]
[rank0]:[W126 19:36:26.183409365 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 19:36:28
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:36:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:36:48 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1659109) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1659109) WARNING 01-26 19:38:18 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 5.84 requests/s, 5989.39 total tokens/s, 5.84 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 19:36:48] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:36:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:36:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:36:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:36:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:36:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:36:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:36:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:36:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:36:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:36:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:36:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:36:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:36:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:36:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:36:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:36:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1659109) [2026-01-26 19:36:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1659109) [2026-01-26 19:36:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1659109) [2026-01-26 19:36:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1659109) [2026-01-26 19:36:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1659109) [2026-01-26 19:36:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1659109) [2026-01-26 19:36:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1659109) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1659109) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:27<00:27, 27.92s/it]
(EngineCore_DP0 pid=1659109) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.80s/it]
(EngineCore_DP0 pid=1659109) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:00<00:00, 30.36s/it]
(EngineCore_DP0 pid=1659109) 
(EngineCore_DP0 pid=1659109) [2026-01-26 19:37:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1659109) [2026-01-26 19:37:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1659109) [2026-01-26 19:37:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1659109) [2026-01-26 19:37:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1659109) [2026-01-26 19:37:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1659109) [2026-01-26 19:37:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1659109) [2026-01-26 19:37:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1659109) [2026-01-26 19:37:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1659109) 2026-01-26 19:38:05,755 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1659109) 2026-01-26 19:38:06,940 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/4096 [00:00<15:04,  4.52it/s]
Adding requests:   0%|          | 3/4096 [00:00<06:32, 10.42it/s]
Adding requests:   0%|          | 5/4096 [00:00<04:57, 13.73it/s]
Adding requests:   0%|          | 9/4096 [00:00<03:08, 21.64it/s]
Adding requests:   0%|          | 17/4096 [00:00<01:46, 38.40it/s]
Adding requests:   1%|          | 31/4096 [00:00<00:59, 68.72it/s]
Adding requests:   1%|          | 49/4096 [00:00<00:40, 101.03it/s]
Adding requests:   2%|         | 79/4096 [00:00<00:25, 158.51it/s]
Adding requests:   3%|         | 111/4096 [00:01<00:19, 206.23it/s]
Adding requests:   4%|         | 149/4096 [00:01<00:15, 256.38it/s]
Adding requests:   4%|         | 183/4096 [00:01<00:13, 281.07it/s]
Adding requests:   6%|         | 226/4096 [00:01<00:11, 324.49it/s]
Adding requests:   7%|         | 271/4096 [00:01<00:10, 360.68it/s]
Adding requests:   8%|         | 308/4096 [00:01<00:10, 361.59it/s]
Adding requests:   9%|         | 353/4096 [00:01<00:09, 385.76it/s]
Adding requests:  10%|         | 392/4096 [00:01<00:09, 376.29it/s]
Adding requests:  11%|         | 440/4096 [00:01<00:08, 406.58it/s]
Adding requests:  12%|        | 483/4096 [00:01<00:08, 410.19it/s]
Adding requests:  13%|        | 535/4096 [00:02<00:08, 442.41it/s]
Adding requests:  14%|        | 580/4096 [00:02<00:08, 437.14it/s]
Adding requests:  15%|        | 626/4096 [00:02<00:07, 442.12it/s]
Adding requests:  16%|        | 671/4096 [00:02<00:07, 432.59it/s]
Adding requests:  18%|        | 718/4096 [00:02<00:07, 442.86it/s]
Adding requests:  19%|        | 763/4096 [00:02<00:07, 427.10it/s]
Adding requests:  20%|        | 806/4096 [00:02<00:07, 423.12it/s]
Adding requests:  21%|        | 851/4096 [00:02<00:07, 429.67it/s]
Adding requests:  22%|       | 896/4096 [00:02<00:07, 434.74it/s]
Adding requests:  23%|       | 940/4096 [00:03<00:07, 428.00it/s]
Adding requests:  24%|       | 983/4096 [00:03<00:07, 419.56it/s]
Adding requests:  25%|       | 1029/4096 [00:03<00:07, 431.13it/s]
Adding requests:  26%|       | 1073/4096 [00:03<00:07, 420.01it/s]
Adding requests:  27%|       | 1118/4096 [00:03<00:06, 427.87it/s]
Adding requests:  28%|       | 1161/4096 [00:03<00:06, 420.75it/s]
Adding requests:  29%|       | 1205/4096 [00:03<00:06, 424.76it/s]
Adding requests:  30%|       | 1248/4096 [00:03<00:06, 421.11it/s]
Adding requests:  32%|      | 1291/4096 [00:03<00:07, 391.05it/s]
Adding requests:  32%|      | 1331/4096 [00:03<00:07, 387.16it/s]
Adding requests:  33%|      | 1371/4096 [00:04<00:07, 385.27it/s]
Adding requests:  35%|      | 1416/4096 [00:04<00:06, 401.49it/s]
Adding requests:  36%|      | 1459/4096 [00:04<00:06, 408.29it/s]
Adding requests:  37%|      | 1510/4096 [00:04<00:05, 435.06it/s]
Adding requests:  38%|      | 1554/4096 [00:04<00:06, 420.59it/s]
Adding requests:  39%|      | 1599/4096 [00:04<00:05, 427.42it/s]
Adding requests:  40%|      | 1642/4096 [00:04<00:05, 413.29it/s]
Adding requests:  41%|      | 1685/4096 [00:04<00:05, 417.41it/s]
Adding requests:  42%|     | 1727/4096 [00:04<00:05, 417.07it/s]
Adding requests:  43%|     | 1774/4096 [00:05<00:05, 430.94it/s]
Adding requests:  44%|     | 1818/4096 [00:05<00:05, 415.39it/s]
Adding requests:  45%|     | 1860/4096 [00:05<00:05, 413.76it/s]
Adding requests:  46%|     | 1903/4096 [00:05<00:05, 417.04it/s]
Adding requests:  48%|     | 1948/4096 [00:05<00:05, 425.53it/s]
Adding requests:  49%|     | 1994/4096 [00:05<00:04, 433.67it/s]
Adding requests:  50%|     | 2038/4096 [00:05<00:04, 426.75it/s]
Adding requests:  51%|     | 2081/4096 [00:05<00:04, 419.51it/s]
Adding requests:  52%|    | 2124/4096 [00:05<00:05, 392.63it/s]
Adding requests:  53%|    | 2164/4096 [00:06<00:05, 369.93it/s]
Adding requests:  54%|    | 2202/4096 [00:06<00:05, 350.99it/s]
Adding requests:  55%|    | 2238/4096 [00:06<00:05, 346.95it/s]
Adding requests:  56%|    | 2281/4096 [00:06<00:04, 367.61it/s]
Adding requests:  57%|    | 2323/4096 [00:06<00:04, 381.32it/s]
Adding requests:  58%|    | 2372/4096 [00:06<00:04, 411.82it/s]
Adding requests:  59%|    | 2414/4096 [00:06<00:04, 413.14it/s]
Adding requests:  60%|    | 2458/4096 [00:06<00:03, 418.83it/s]
Adding requests:  61%|    | 2501/4096 [00:06<00:03, 406.61it/s]
Adding requests:  62%|   | 2546/4096 [00:06<00:03, 418.49it/s]
Adding requests:  63%|   | 2589/4096 [00:07<00:03, 405.59it/s]
Adding requests:  64%|   | 2635/4096 [00:07<00:03, 418.44it/s]
Adding requests:  65%|   | 2678/4096 [00:07<00:03, 416.81it/s]
Adding requests:  66%|   | 2722/4096 [00:07<00:03, 420.73it/s]
Adding requests:  68%|   | 2765/4096 [00:07<00:03, 419.15it/s]
Adding requests:  69%|   | 2812/4096 [00:07<00:02, 432.04it/s]
Adding requests:  70%|   | 2857/4096 [00:07<00:02, 436.51it/s]
Adding requests:  71%|   | 2903/4096 [00:07<00:02, 441.49it/s]
Adding requests:  72%|  | 2948/4096 [00:07<00:02, 439.75it/s]
Adding requests:  73%|  | 2996/4096 [00:08<00:02, 447.89it/s]
Adding requests:  74%|  | 3043/4096 [00:08<00:02, 451.47it/s]
Adding requests:  75%|  | 3089/4096 [00:08<00:02, 451.92it/s]
Adding requests:  77%|  | 3137/4096 [00:08<00:02, 458.00it/s]
Adding requests:  78%|  | 3183/4096 [00:08<00:02, 446.59it/s]
Adding requests:  79%|  | 3233/4096 [00:08<00:01, 461.75it/s]
Adding requests:  80%|  | 3280/4096 [00:08<00:01, 438.94it/s]
Adding requests:  81%|  | 3327/4096 [00:08<00:01, 446.16it/s]
Adding requests:  82%| | 3372/4096 [00:08<00:01, 432.81it/s]
Adding requests:  83%| | 3418/4096 [00:08<00:01, 438.02it/s]
Adding requests:  85%| | 3462/4096 [00:09<00:01, 431.95it/s]
Adding requests:  86%| | 3507/4096 [00:09<00:01, 435.93it/s]
Adding requests:  87%| | 3552/4096 [00:09<00:01, 438.17it/s]
Adding requests:  88%| | 3596/4096 [00:09<00:01, 436.49it/s]
Adding requests:  89%| | 3640/4096 [00:09<00:01, 434.67it/s]
Adding requests:  90%| | 3684/4096 [00:09<00:00, 430.97it/s]
Adding requests:  91%| | 3728/4096 [00:09<00:00, 428.95it/s]
Adding requests:  92%|| 3771/4096 [00:09<00:00, 422.63it/s]
Adding requests:  93%|| 3814/4096 [00:09<00:00, 417.31it/s]
Adding requests:  94%|| 3856/4096 [00:09<00:00, 407.58it/s]
Adding requests:  95%|| 3902/4096 [00:10<00:00, 420.45it/s]
Adding requests:  96%|| 3945/4096 [00:10<00:00, 381.38it/s]
Adding requests:  97%|| 3988/4096 [00:10<00:00, 392.30it/s]
Adding requests:  98%|| 4030/4096 [00:10<00:00, 398.23it/s]
Adding requests:  99%|| 4073/4096 [00:10<00:00, 404.93it/s]
Adding requests: 100%|| 4096/4096 [00:10<00:00, 386.64it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 39/4096 [00:01<03:02, 22.27it/s, est. speed input: 22801.83 toks/s, output: 22.27 toks/s]
Processed prompts:   2%|         | 71/4096 [00:07<07:32,  8.90it/s, est. speed input: 10116.44 toks/s, output: 9.88 toks/s] 
Processed prompts:   3%|         | 103/4096 [00:12<09:16,  7.17it/s, est. speed input: 8258.03 toks/s, output: 8.06 toks/s]
Processed prompts:   3%|         | 135/4096 [00:18<09:59,  6.61it/s, est. speed input: 7583.63 toks/s, output: 7.41 toks/s]
Processed prompts:   4%|         | 167/4096 [00:23<10:21,  6.32it/s, est. speed input: 7216.62 toks/s, output: 7.05 toks/s]
Processed prompts:   5%|         | 199/4096 [00:29<10:27,  6.21it/s, est. speed input: 7020.78 toks/s, output: 6.86 toks/s]
Processed prompts:   6%|         | 231/4096 [00:34<10:35,  6.08it/s, est. speed input: 6854.31 toks/s, output: 6.69 toks/s]
Processed prompts:   6%|         | 263/4096 [00:39<10:38,  6.00it/s, est. speed input: 6733.38 toks/s, output: 6.58 toks/s]
Processed prompts:   7%|         | 295/4096 [00:45<10:38,  5.95it/s, est. speed input: 6643.40 toks/s, output: 6.49 toks/s]
Processed prompts:   8%|         | 327/4096 [00:50<10:37,  5.92it/s, est. speed input: 6571.76 toks/s, output: 6.42 toks/s]
Processed prompts:   9%|         | 359/4096 [00:56<10:34,  5.89it/s, est. speed input: 6512.61 toks/s, output: 6.36 toks/s]
Processed prompts:  10%|         | 391/4096 [01:01<10:30,  5.87it/s, est. speed input: 6465.61 toks/s, output: 6.31 toks/s]
Processed prompts:  10%|         | 423/4096 [01:07<10:21,  5.91it/s, est. speed input: 6440.31 toks/s, output: 6.29 toks/s]
Processed prompts:  11%|         | 455/4096 [01:12<10:18,  5.88it/s, est. speed input: 6403.99 toks/s, output: 6.25 toks/s]
Processed prompts:  12%|        | 487/4096 [01:18<10:25,  5.77it/s, est. speed input: 6347.93 toks/s, output: 6.20 toks/s]
Processed prompts:  13%|        | 519/4096 [01:24<10:18,  5.78it/s, est. speed input: 6323.00 toks/s, output: 6.17 toks/s]
Processed prompts:  13%|        | 551/4096 [01:29<10:11,  5.80it/s, est. speed input: 6301.32 toks/s, output: 6.15 toks/s]
Processed prompts:  14%|        | 583/4096 [01:35<10:05,  5.81it/s, est. speed input: 6281.78 toks/s, output: 6.13 toks/s]
Processed prompts:  15%|        | 615/4096 [01:40<09:58,  5.81it/s, est. speed input: 6264.94 toks/s, output: 6.12 toks/s]
Processed prompts:  16%|        | 647/4096 [01:46<09:52,  5.82it/s, est. speed input: 6249.71 toks/s, output: 6.10 toks/s]
Processed prompts:  17%|        | 679/4096 [01:51<09:51,  5.78it/s, est. speed input: 6228.22 toks/s, output: 6.08 toks/s]
Processed prompts:  17%|        | 711/4096 [01:57<09:44,  5.79it/s, est. speed input: 6216.09 toks/s, output: 6.07 toks/s]
Processed prompts:  18%|        | 743/4096 [02:02<09:37,  5.80it/s, est. speed input: 6205.07 toks/s, output: 6.06 toks/s]
Processed prompts:  19%|        | 775/4096 [02:07<09:26,  5.86it/s, est. speed input: 6201.91 toks/s, output: 6.06 toks/s]
Processed prompts:  20%|        | 807/4096 [02:13<09:22,  5.85it/s, est. speed input: 6192.07 toks/s, output: 6.05 toks/s]
Processed prompts:  20%|        | 839/4096 [02:18<09:17,  5.84it/s, est. speed input: 6182.65 toks/s, output: 6.04 toks/s]
Processed prompts:  21%|       | 871/4096 [02:24<09:17,  5.79it/s, est. speed input: 6168.24 toks/s, output: 6.02 toks/s]
Processed prompts:  22%|       | 903/4096 [02:30<09:10,  5.80it/s, est. speed input: 6160.69 toks/s, output: 6.02 toks/s]
Processed prompts:  23%|       | 935/4096 [02:35<09:04,  5.80it/s, est. speed input: 6153.57 toks/s, output: 6.01 toks/s]
Processed prompts:  24%|       | 967/4096 [02:41<08:58,  5.81it/s, est. speed input: 6147.01 toks/s, output: 6.00 toks/s]
Processed prompts:  24%|       | 999/4096 [02:46<08:52,  5.82it/s, est. speed input: 6141.10 toks/s, output: 6.00 toks/s]
Processed prompts:  25%|       | 1031/4096 [02:52<08:47,  5.82it/s, est. speed input: 6135.22 toks/s, output: 5.99 toks/s]
Processed prompts:  26%|       | 1063/4096 [02:57<08:45,  5.77it/s, est. speed input: 6124.66 toks/s, output: 5.98 toks/s]
Processed prompts:  27%|       | 1095/4096 [03:03<08:38,  5.78it/s, est. speed input: 6119.68 toks/s, output: 5.98 toks/s]
Processed prompts:  28%|       | 1127/4096 [03:08<08:32,  5.79it/s, est. speed input: 6114.89 toks/s, output: 5.97 toks/s]
Processed prompts:  28%|       | 1159/4096 [03:14<08:26,  5.80it/s, est. speed input: 6110.60 toks/s, output: 5.97 toks/s]
Processed prompts:  29%|       | 1191/4096 [03:19<08:16,  5.86it/s, est. speed input: 6111.13 toks/s, output: 5.97 toks/s]
Processed prompts:  30%|       | 1223/4096 [03:24<08:07,  5.90it/s, est. speed input: 6111.71 toks/s, output: 5.97 toks/s]
Processed prompts:  31%|       | 1255/4096 [03:30<08:07,  5.83it/s, est. speed input: 6103.60 toks/s, output: 5.96 toks/s]
Processed prompts:  31%|      | 1287/4096 [03:36<08:02,  5.83it/s, est. speed input: 6099.94 toks/s, output: 5.96 toks/s]
Processed prompts:  32%|      | 1319/4096 [03:41<07:52,  5.87it/s, est. speed input: 6100.85 toks/s, output: 5.96 toks/s]
Processed prompts:  33%|      | 1351/4096 [03:46<07:48,  5.86it/s, est. speed input: 6097.35 toks/s, output: 5.95 toks/s]
Processed prompts:  34%|      | 1383/4096 [03:52<07:43,  5.85it/s, est. speed input: 6094.18 toks/s, output: 5.95 toks/s]
Processed prompts:  35%|      | 1415/4096 [03:57<07:35,  5.89it/s, est. speed input: 6095.09 toks/s, output: 5.95 toks/s]
Processed prompts:  35%|      | 1447/4096 [04:03<07:31,  5.87it/s, est. speed input: 6092.35 toks/s, output: 5.95 toks/s]
Processed prompts:  36%|      | 1479/4096 [04:08<07:26,  5.86it/s, est. speed input: 6089.36 toks/s, output: 5.95 toks/s]
Processed prompts:  37%|      | 1511/4096 [04:14<07:18,  5.90it/s, est. speed input: 6090.27 toks/s, output: 5.95 toks/s]
Processed prompts:  38%|      | 1543/4096 [04:19<07:11,  5.91it/s, est. speed input: 6090.51 toks/s, output: 5.95 toks/s]
Processed prompts:  38%|      | 1575/4096 [04:24<07:08,  5.88it/s, est. speed input: 6087.51 toks/s, output: 5.94 toks/s]
Processed prompts:  39%|      | 1607/4096 [04:30<07:01,  5.91it/s, est. speed input: 6088.11 toks/s, output: 5.95 toks/s]
Processed prompts:  40%|      | 1639/4096 [04:35<06:57,  5.88it/s, est. speed input: 6085.50 toks/s, output: 5.94 toks/s]
Processed prompts:  41%|      | 1671/4096 [04:41<06:53,  5.86it/s, est. speed input: 6083.10 toks/s, output: 5.94 toks/s]
Processed prompts:  42%|     | 1703/4096 [04:46<06:49,  5.85it/s, est. speed input: 6080.75 toks/s, output: 5.94 toks/s]
Processed prompts:  42%|     | 1735/4096 [04:51<06:33,  6.00it/s, est. speed input: 6088.77 toks/s, output: 5.95 toks/s]
Processed prompts:  43%|     | 1767/4096 [04:57<06:42,  5.79it/s, est. speed input: 6076.25 toks/s, output: 5.93 toks/s]
Processed prompts:  44%|     | 1799/4096 [05:03<06:36,  5.80it/s, est. speed input: 6074.09 toks/s, output: 5.93 toks/s]
Processed prompts:  45%|     | 1831/4096 [05:08<06:30,  5.80it/s, est. speed input: 6071.91 toks/s, output: 5.93 toks/s]
Processed prompts:  45%|     | 1863/4096 [05:14<06:21,  5.85it/s, est. speed input: 6072.84 toks/s, output: 5.93 toks/s]
Processed prompts:  46%|     | 1895/4096 [05:19<06:16,  5.84it/s, est. speed input: 6070.72 toks/s, output: 5.93 toks/s]
Processed prompts:  47%|     | 1927/4096 [05:25<06:21,  5.68it/s, est. speed input: 6059.66 toks/s, output: 5.92 toks/s]
Processed prompts:  48%|     | 1959/4096 [05:30<06:10,  5.77it/s, est. speed input: 6061.02 toks/s, output: 5.92 toks/s]
Processed prompts:  49%|     | 1991/4096 [05:36<06:03,  5.79it/s, est. speed input: 6059.29 toks/s, output: 5.92 toks/s]
Processed prompts:  49%|     | 2023/4096 [05:41<05:57,  5.80it/s, est. speed input: 6057.65 toks/s, output: 5.92 toks/s]
Processed prompts:  50%|     | 2055/4096 [05:47<05:48,  5.85it/s, est. speed input: 6058.72 toks/s, output: 5.92 toks/s]
Processed prompts:  51%|     | 2087/4096 [05:52<05:44,  5.84it/s, est. speed input: 6057.05 toks/s, output: 5.92 toks/s]
Processed prompts:  52%|    | 2119/4096 [05:58<05:45,  5.72it/s, est. speed input: 6049.43 toks/s, output: 5.91 toks/s]
Processed prompts:  53%|    | 2151/4096 [06:04<05:38,  5.75it/s, est. speed input: 6048.00 toks/s, output: 5.91 toks/s]
Processed prompts:  53%|    | 2183/4096 [06:09<05:29,  5.81it/s, est. speed input: 6049.00 toks/s, output: 5.91 toks/s]
Processed prompts:  54%|    | 2215/4096 [06:15<05:23,  5.81it/s, est. speed input: 6047.38 toks/s, output: 5.91 toks/s]
Processed prompts:  55%|    | 2247/4096 [06:20<05:18,  5.81it/s, est. speed input: 6045.99 toks/s, output: 5.90 toks/s]
Processed prompts:  56%|    | 2279/4096 [06:26<05:12,  5.81it/s, est. speed input: 6044.59 toks/s, output: 5.90 toks/s]
Processed prompts:  56%|    | 2311/4096 [06:31<05:07,  5.81it/s, est. speed input: 6043.24 toks/s, output: 5.90 toks/s]
Processed prompts:  57%|    | 2343/4096 [06:36<04:59,  5.86it/s, est. speed input: 6044.39 toks/s, output: 5.90 toks/s]
Processed prompts:  58%|    | 2375/4096 [06:42<04:54,  5.84it/s, est. speed input: 6043.06 toks/s, output: 5.90 toks/s]
Processed prompts:  59%|    | 2407/4096 [06:47<04:49,  5.83it/s, est. speed input: 6041.65 toks/s, output: 5.90 toks/s]
Processed prompts:  60%|    | 2439/4096 [06:53<04:44,  5.82it/s, est. speed input: 6040.40 toks/s, output: 5.90 toks/s]
Processed prompts:  60%|    | 2471/4096 [06:58<04:39,  5.82it/s, est. speed input: 6039.18 toks/s, output: 5.90 toks/s]
Processed prompts:  61%|    | 2503/4096 [07:04<04:33,  5.82it/s, est. speed input: 6037.97 toks/s, output: 5.90 toks/s]
Processed prompts:  62%|   | 2535/4096 [07:09<04:26,  5.86it/s, est. speed input: 6038.92 toks/s, output: 5.90 toks/s]
Processed prompts:  63%|   | 2567/4096 [07:15<04:21,  5.84it/s, est. speed input: 6037.65 toks/s, output: 5.90 toks/s]
Processed prompts:  63%|   | 2599/4096 [07:20<04:14,  5.88it/s, est. speed input: 6038.60 toks/s, output: 5.90 toks/s]
Processed prompts:  64%|   | 2631/4096 [07:26<04:07,  5.91it/s, est. speed input: 6039.55 toks/s, output: 5.90 toks/s]
Processed prompts:  65%|   | 2663/4096 [07:31<04:03,  5.88it/s, est. speed input: 6038.31 toks/s, output: 5.90 toks/s]
Processed prompts:  66%|   | 2695/4096 [07:37<03:59,  5.85it/s, est. speed input: 6037.01 toks/s, output: 5.90 toks/s]
Processed prompts:  67%|   | 2727/4096 [07:42<03:52,  5.89it/s, est. speed input: 6037.88 toks/s, output: 5.90 toks/s]
Processed prompts:  67%|   | 2759/4096 [07:48<03:48,  5.86it/s, est. speed input: 6036.56 toks/s, output: 5.90 toks/s]
Processed prompts:  68%|   | 2791/4096 [07:53<03:43,  5.84it/s, est. speed input: 6035.52 toks/s, output: 5.89 toks/s]
Processed prompts:  69%|   | 2823/4096 [07:59<03:38,  5.82it/s, est. speed input: 6034.19 toks/s, output: 5.89 toks/s]
Processed prompts:  70%|   | 2855/4096 [08:04<03:33,  5.82it/s, est. speed input: 6033.15 toks/s, output: 5.89 toks/s]
Processed prompts:  70%|   | 2887/4096 [08:09<03:25,  5.89it/s, est. speed input: 6035.13 toks/s, output: 5.89 toks/s]
Processed prompts:  71%|  | 2919/4096 [08:15<03:18,  5.92it/s, est. speed input: 6036.05 toks/s, output: 5.89 toks/s]
Processed prompts:  72%|  | 2951/4096 [08:20<03:14,  5.89it/s, est. speed input: 6035.15 toks/s, output: 5.89 toks/s]
Processed prompts:  73%|  | 2983/4096 [08:26<03:08,  5.92it/s, est. speed input: 6036.17 toks/s, output: 5.89 toks/s]
Processed prompts:  74%|  | 3015/4096 [08:31<03:03,  5.88it/s, est. speed input: 6035.12 toks/s, output: 5.89 toks/s]
Processed prompts:  74%|  | 3047/4096 [08:37<02:59,  5.86it/s, est. speed input: 6034.08 toks/s, output: 5.89 toks/s]
Processed prompts:  75%|  | 3079/4096 [08:42<02:54,  5.84it/s, est. speed input: 6033.07 toks/s, output: 5.89 toks/s]
Processed prompts:  76%|  | 3111/4096 [08:48<02:49,  5.83it/s, est. speed input: 6032.12 toks/s, output: 5.89 toks/s]
Processed prompts:  77%|  | 3143/4096 [08:53<02:44,  5.81it/s, est. speed input: 6030.80 toks/s, output: 5.89 toks/s]
Processed prompts:  78%|  | 3175/4096 [08:59<02:37,  5.86it/s, est. speed input: 6031.61 toks/s, output: 5.89 toks/s]
Processed prompts:  78%|  | 3207/4096 [09:04<02:32,  5.84it/s, est. speed input: 6030.75 toks/s, output: 5.89 toks/s]
Processed prompts:  79%|  | 3239/4096 [09:10<02:26,  5.83it/s, est. speed input: 6029.89 toks/s, output: 5.89 toks/s]
Processed prompts:  80%|  | 3271/4096 [09:15<02:21,  5.82it/s, est. speed input: 6029.07 toks/s, output: 5.89 toks/s]
Processed prompts:  81%|  | 3303/4096 [09:21<02:16,  5.82it/s, est. speed input: 6028.40 toks/s, output: 5.89 toks/s]
Processed prompts:  81%| | 3335/4096 [09:26<02:10,  5.82it/s, est. speed input: 6027.78 toks/s, output: 5.89 toks/s]
Processed prompts:  82%| | 3367/4096 [09:32<02:05,  5.82it/s, est. speed input: 6027.16 toks/s, output: 5.89 toks/s]
Processed prompts:  83%| | 3399/4096 [09:37<01:58,  5.87it/s, est. speed input: 6028.18 toks/s, output: 5.89 toks/s]
Processed prompts:  84%| | 3431/4096 [09:42<01:53,  5.86it/s, est. speed input: 6027.59 toks/s, output: 5.89 toks/s]
Processed prompts:  85%| | 3463/4096 [09:48<01:48,  5.85it/s, est. speed input: 6026.93 toks/s, output: 5.89 toks/s]
Processed prompts:  85%| | 3495/4096 [09:53<01:42,  5.84it/s, est. speed input: 6026.30 toks/s, output: 5.89 toks/s]
Processed prompts:  86%| | 3527/4096 [09:59<01:37,  5.84it/s, est. speed input: 6025.78 toks/s, output: 5.88 toks/s]
Processed prompts:  87%| | 3559/4096 [10:04<01:31,  5.88it/s, est. speed input: 6026.80 toks/s, output: 5.89 toks/s]
Processed prompts:  88%| | 3591/4096 [10:10<01:26,  5.87it/s, est. speed input: 6026.30 toks/s, output: 5.89 toks/s]
Processed prompts:  88%| | 3623/4096 [10:15<01:20,  5.91it/s, est. speed input: 6027.42 toks/s, output: 5.89 toks/s]
Processed prompts:  89%| | 3655/4096 [10:20<01:14,  5.89it/s, est. speed input: 6026.96 toks/s, output: 5.89 toks/s]
Processed prompts:  90%| | 3687/4096 [10:26<01:08,  5.95it/s, est. speed input: 6028.79 toks/s, output: 5.89 toks/s]
Processed prompts:  91%| | 3719/4096 [10:31<01:03,  5.91it/s, est. speed input: 6028.32 toks/s, output: 5.89 toks/s]
Processed prompts:  92%|| 3751/4096 [10:37<00:58,  5.89it/s, est. speed input: 6027.74 toks/s, output: 5.89 toks/s]
Processed prompts:  92%|| 3783/4096 [10:42<00:53,  5.87it/s, est. speed input: 6027.27 toks/s, output: 5.89 toks/s]
Processed prompts:  93%|| 3815/4096 [10:48<00:47,  5.86it/s, est. speed input: 6026.77 toks/s, output: 5.89 toks/s]
Processed prompts:  94%|| 3847/4096 [10:53<00:42,  5.85it/s, est. speed input: 6026.32 toks/s, output: 5.89 toks/s]
Processed prompts:  95%|| 3879/4096 [10:59<00:37,  5.85it/s, est. speed input: 6025.96 toks/s, output: 5.88 toks/s]
Processed prompts:  95%|| 3911/4096 [11:04<00:31,  5.90it/s, est. speed input: 6026.99 toks/s, output: 5.89 toks/s]
Processed prompts:  96%|| 3943/4096 [11:09<00:25,  5.93it/s, est. speed input: 6027.93 toks/s, output: 5.89 toks/s]
Processed prompts:  97%|| 3975/4096 [11:15<00:20,  5.90it/s, est. speed input: 6027.46 toks/s, output: 5.89 toks/s]
Processed prompts:  98%|| 4007/4096 [11:20<00:15,  5.93it/s, est. speed input: 6028.44 toks/s, output: 5.89 toks/s]
Processed prompts:  99%|| 4039/4096 [11:25<00:09,  5.95it/s, est. speed input: 6029.40 toks/s, output: 5.89 toks/s]
Processed prompts:  99%|| 4071/4096 [11:30<00:03,  6.29it/s, est. speed input: 6038.31 toks/s, output: 5.90 toks/s]
Processed prompts: 100%|| 4096/4096 [11:30<00:00,  6.29it/s, est. speed input: 6075.39 toks/s, output: 5.93 toks/s]
Processed prompts: 100%|| 4096/4096 [11:30<00:00,  5.93it/s, est. speed input: 6075.39 toks/s, output: 5.93 toks/s]
[rank0]:[W126 19:50:06.694487318 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 19:50:11
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:50:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 19:50:43 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=1671147) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return self._linear_fn(
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 243, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]     out = torch.zeros(M_padded, K_out_padded, dtype=torch.float8_e4m3fn, device=x.device)
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866] torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866] Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1671147) ERROR 01-26 19:51:53 [core.py:866] 

STDERR:
[2026-01-26 19:50:43] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:50:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:50:43] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:50:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:50:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:50:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:50:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:50:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:50:47] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-26 19:50:47] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:50:47] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:47] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:47] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:47] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:47] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:47] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 19:50:47] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 19:50:47] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:50:47] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:50:47] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:50:47] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:50:47] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1671147) [2026-01-26 19:50:48] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1671147) [2026-01-26 19:50:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=1671147) [2026-01-26 19:50:48] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1671147) [2026-01-26 19:50:48] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1671147) [2026-01-26 19:50:48] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1671147) [2026-01-26 19:50:48] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1671147) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1671147) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:28<00:28, 28.81s/it]
(EngineCore_DP0 pid=1671147) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.90s/it]
(EngineCore_DP0 pid=1671147) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [01:02<00:00, 31.44s/it]
(EngineCore_DP0 pid=1671147) 
(EngineCore_DP0 pid=1671147) [2026-01-26 19:51:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1671147) [2026-01-26 19:51:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1671147) [2026-01-26 19:51:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1671147) [2026-01-26 19:51:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1671147) [2026-01-26 19:51:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1671147) [2026-01-26 19:51:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1671147) [2026-01-26 19:51:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1671147) [2026-01-26 19:51:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1671147) Process EngineCore_DP0:
(EngineCore_DP0 pid=1671147) Traceback (most recent call last):
(EngineCore_DP0 pid=1671147)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1671147)     self.run()
(EngineCore_DP0 pid=1671147)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1671147)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1671147)     raise e
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1671147)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1671147)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1671147)     super().__init__(
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=1671147)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=1671147)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=1671147)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=1671147)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=1671147)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=1671147)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=1671147)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=1671147)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1671147)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=1671147)     self.model_runner.profile_run()
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=1671147)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=1671147)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=1671147)     return func(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=1671147)     outputs = self.model(
(EngineCore_DP0 pid=1671147)               ^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1671147)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1671147)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=1671147)     hidden_states = self.model(
(EngineCore_DP0 pid=1671147)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/compilation/decorators.py", line 372, in __call__
(EngineCore_DP0 pid=1671147)     return self.forward(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 442, in forward
(EngineCore_DP0 pid=1671147)     hidden_states, residual = layer(positions, hidden_states, residual)
(EngineCore_DP0 pid=1671147)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1671147)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1671147)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 303, in forward
(EngineCore_DP0 pid=1671147)     hidden_states = self.mlp(hidden_states)
(EngineCore_DP0 pid=1671147)                     ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1671147)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1671147)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 108, in forward
(EngineCore_DP0 pid=1671147)     x, _ = self.down_proj(x)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=1671147)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=1671147)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 1405, in forward
(EngineCore_DP0 pid=1671147)     output_parallel = self.quant_method.apply(self, input_parallel, bias_)
(EngineCore_DP0 pid=1671147)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 957, in apply
(EngineCore_DP0 pid=1671147)     return scheme.apply_weights(layer, x, bias=bias)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 685, in apply_weights
(EngineCore_DP0 pid=1671147)     return self.slidesparse_fp8_linear.apply(
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 471, in apply
(EngineCore_DP0 pid=1671147)     return self._linear_fn(
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_FP8.py", line 256, in cuSPARSELt_FP8_linear
(EngineCore_DP0 pid=1671147)     qinput, scale_a_pad = quant_slide_fp8_kernel(input, model_name, L)
(EngineCore_DP0 pid=1671147)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/slidesparse/core/kernels.py", line 309, in quant_slide_fp8_kernel
(EngineCore_DP0 pid=1671147)     return torch.ops.slidesparse.quant_slide_fp8(input, model_name, L)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 1255, in __call__
(EngineCore_DP0 pid=1671147)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=1671147)     return fn(input, L)
(EngineCore_DP0 pid=1671147)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/GB10_cc121_py312_cu129_aarch64/quant_slide_tuned_Qwen2.5-7B.py", line 243, in quant_slide_fp8_triton
(EngineCore_DP0 pid=1671147)     out = torch.zeros(M_padded, K_out_padded, dtype=torch.float8_e4m3fn, device=x.device)
(EngineCore_DP0 pid=1671147)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1671147) torch.AcceleratorError: CUDA error: an illegal memory access was encountered
(EngineCore_DP0 pid=1671147) Search for `cudaErrorIllegalAddress' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.
(EngineCore_DP0 pid=1671147) CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
(EngineCore_DP0 pid=1671147) For debugging consider passing CUDA_LAUNCH_BLOCKING=1
(EngineCore_DP0 pid=1671147) Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
(EngineCore_DP0 pid=1671147) 
[rank0]:[W126 19:51:54.237458237 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-27 11:32:47
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 11:32:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 11:32:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2563604) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2563604) WARNING 01-27 11:35:14 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 6.40 requests/s, 3281.06 total tokens/s, 6.40 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-27 11:32:54] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:32:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:32:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:32:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:32:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:32:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:32:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:32:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 11:32:58] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:32:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:32:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:32:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:32:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:32:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:32:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:32:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:32:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2563604) [2026-01-27 11:32:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2563604) [2026-01-27 11:32:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2563604) [2026-01-27 11:32:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2563604) [2026-01-27 11:32:59] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2563604) [2026-01-27 11:32:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2563604) [2026-01-27 11:32:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2563604) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2563604) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.60s/it]
(EngineCore_DP0 pid=2563604) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:47<00:52, 26.39s/it]
(EngineCore_DP0 pid=2563604) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:18<00:28, 28.50s/it]
(EngineCore_DP0 pid=2563604) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 33.37s/it]
(EngineCore_DP0 pid=2563604) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [01:59<00:00, 29.82s/it]
(EngineCore_DP0 pid=2563604) 
(EngineCore_DP0 pid=2563604) [2026-01-27 11:35:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2563604) [2026-01-27 11:35:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=2563604) [2026-01-27 11:35:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2563604) [2026-01-27 11:35:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=2563604) [2026-01-27 11:35:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2563604) [2026-01-27 11:35:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=2563604) [2026-01-27 11:35:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2563604) [2026-01-27 11:35:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=2563604) 2026-01-27 11:35:09,290 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2563604) 2026-01-27 11:35:09,551 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:00<01:27,  1.45it/s]
Adding requests:   2%|         | 2/128 [00:00<00:51,  2.45it/s]
Adding requests:   2%|         | 3/128 [00:01<00:35,  3.53it/s]
Adding requests:   4%|         | 5/128 [00:01<00:21,  5.82it/s]
Adding requests:   5%|         | 7/128 [00:01<00:15,  8.02it/s]
Adding requests:   8%|         | 10/128 [00:01<00:09, 12.24it/s]
Adding requests:  10%|         | 13/128 [00:01<00:07, 15.29it/s]
Adding requests:  14%|        | 18/128 [00:01<00:04, 22.91it/s]
Adding requests:  20%|        | 25/128 [00:01<00:03, 32.94it/s]
Adding requests:  30%|       | 38/128 [00:01<00:01, 57.16it/s]
Adding requests:  58%|    | 74/128 [00:02<00:00, 136.36it/s]
Adding requests:  96%|| 123/128 [00:02<00:00, 232.47it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 60.51it/s] 

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:02, 58.36it/s, est. speed input: 29884.64 toks/s, output: 58.36 toks/s]
Processed prompts:  12%|        | 15/128 [00:01<00:09, 12.38it/s, est. speed input: 7387.12 toks/s, output: 14.43 toks/s]
Processed prompts:  14%|        | 18/128 [00:01<00:10, 10.15it/s, est. speed input: 6195.03 toks/s, output: 12.10 toks/s]
Processed prompts:  16%|        | 20/128 [00:01<00:11,  9.25it/s, est. speed input: 5745.95 toks/s, output: 11.22 toks/s]
Processed prompts:  17%|        | 22/128 [00:02<00:12,  8.55it/s, est. speed input: 5417.88 toks/s, output: 10.58 toks/s]
Processed prompts:  19%|        | 24/128 [00:02<00:12,  8.00it/s, est. speed input: 5163.43 toks/s, output: 10.08 toks/s]
Processed prompts:  20%|        | 25/128 [00:02<00:13,  7.80it/s, est. speed input: 5066.04 toks/s, output: 9.89 toks/s] 
Processed prompts:  20%|        | 26/128 [00:02<00:13,  7.60it/s, est. speed input: 4976.93 toks/s, output: 9.72 toks/s]
Processed prompts:  21%|        | 27/128 [00:02<00:13,  7.40it/s, est. speed input: 4894.09 toks/s, output: 9.56 toks/s]
Processed prompts:  22%|       | 28/128 [00:02<00:13,  7.26it/s, est. speed input: 4824.72 toks/s, output: 9.42 toks/s]
Processed prompts:  23%|       | 29/128 [00:03<00:13,  7.14it/s, est. speed input: 4760.73 toks/s, output: 9.30 toks/s]
Processed prompts:  23%|       | 30/128 [00:03<00:13,  7.04it/s, est. speed input: 4702.14 toks/s, output: 9.18 toks/s]
Processed prompts:  24%|       | 31/128 [00:03<00:14,  6.91it/s, est. speed input: 4642.62 toks/s, output: 9.07 toks/s]
Processed prompts:  25%|       | 32/128 [00:03<00:13,  6.87it/s, est. speed input: 4593.63 toks/s, output: 8.97 toks/s]
Processed prompts:  26%|       | 33/128 [00:03<00:13,  6.84it/s, est. speed input: 4548.81 toks/s, output: 8.88 toks/s]
Processed prompts:  27%|       | 34/128 [00:03<00:13,  6.85it/s, est. speed input: 4510.28 toks/s, output: 8.81 toks/s]
Processed prompts:  27%|       | 35/128 [00:04<00:13,  6.81it/s, est. speed input: 4470.11 toks/s, output: 8.73 toks/s]
Processed prompts:  28%|       | 36/128 [00:04<00:13,  6.79it/s, est. speed input: 4434.20 toks/s, output: 8.66 toks/s]
Processed prompts:  29%|       | 37/128 [00:04<00:13,  6.80it/s, est. speed input: 4401.63 toks/s, output: 8.60 toks/s]
Processed prompts:  30%|       | 38/128 [00:04<00:13,  6.72it/s, est. speed input: 4365.38 toks/s, output: 8.53 toks/s]
Processed prompts:  30%|       | 39/128 [00:04<00:13,  6.72it/s, est. speed input: 4335.91 toks/s, output: 8.47 toks/s]
Processed prompts:  31%|      | 40/128 [00:04<00:13,  6.76it/s, est. speed input: 4310.12 toks/s, output: 8.42 toks/s]
Processed prompts:  32%|      | 41/128 [00:04<00:12,  6.77it/s, est. speed input: 4285.48 toks/s, output: 8.37 toks/s]
Processed prompts:  33%|      | 42/128 [00:05<00:12,  6.77it/s, est. speed input: 4261.62 toks/s, output: 8.32 toks/s]
Processed prompts:  34%|      | 43/128 [00:05<00:12,  6.77it/s, est. speed input: 4238.85 toks/s, output: 8.28 toks/s]
Processed prompts:  34%|      | 44/128 [00:05<00:12,  6.78it/s, est. speed input: 4218.30 toks/s, output: 8.24 toks/s]
Processed prompts:  35%|      | 45/128 [00:05<00:12,  6.70it/s, est. speed input: 4193.78 toks/s, output: 8.19 toks/s]
Processed prompts:  36%|      | 46/128 [00:05<00:12,  6.70it/s, est. speed input: 4173.63 toks/s, output: 8.15 toks/s]
Processed prompts:  37%|      | 47/128 [00:05<00:12,  6.74it/s, est. speed input: 4156.44 toks/s, output: 8.12 toks/s]
Processed prompts:  38%|      | 48/128 [00:05<00:11,  6.78it/s, est. speed input: 4140.85 toks/s, output: 8.09 toks/s]
Processed prompts:  38%|      | 49/128 [00:06<00:11,  6.75it/s, est. speed input: 4123.25 toks/s, output: 8.05 toks/s]
Processed prompts:  39%|      | 50/128 [00:06<00:11,  6.75it/s, est. speed input: 4107.55 toks/s, output: 8.02 toks/s]
Processed prompts:  40%|      | 51/128 [00:06<00:11,  6.75it/s, est. speed input: 4092.11 toks/s, output: 7.99 toks/s]
Processed prompts:  41%|      | 52/128 [00:06<00:11,  6.68it/s, est. speed input: 4074.62 toks/s, output: 7.96 toks/s]
Processed prompts:  41%|     | 53/128 [00:06<00:11,  6.70it/s, est. speed input: 4060.60 toks/s, output: 7.93 toks/s]
Processed prompts:  42%|     | 54/128 [00:06<00:10,  6.74it/s, est. speed input: 4048.78 toks/s, output: 7.91 toks/s]
Processed prompts:  43%|     | 55/128 [00:06<00:10,  6.75it/s, est. speed input: 4036.29 toks/s, output: 7.88 toks/s]
Processed prompts:  44%|     | 56/128 [00:07<00:10,  6.75it/s, est. speed input: 4024.30 toks/s, output: 7.86 toks/s]
Processed prompts:  45%|     | 57/128 [00:07<00:10,  6.75it/s, est. speed input: 4012.77 toks/s, output: 7.84 toks/s]
Processed prompts:  45%|     | 58/128 [00:07<00:10,  6.77it/s, est. speed input: 4002.57 toks/s, output: 7.82 toks/s]
Processed prompts:  46%|     | 59/128 [00:07<00:10,  6.69it/s, est. speed input: 3988.78 toks/s, output: 7.79 toks/s]
Processed prompts:  47%|     | 60/128 [00:07<00:10,  6.71it/s, est. speed input: 3978.72 toks/s, output: 7.77 toks/s]
Processed prompts:  48%|     | 61/128 [00:07<00:09,  6.73it/s, est. speed input: 3969.07 toks/s, output: 7.75 toks/s]
Processed prompts:  48%|     | 62/128 [00:08<00:09,  6.73it/s, est. speed input: 3959.42 toks/s, output: 7.73 toks/s]
Processed prompts:  49%|     | 63/128 [00:08<00:09,  6.72it/s, est. speed input: 3949.80 toks/s, output: 7.71 toks/s]
Processed prompts:  50%|     | 64/128 [00:08<00:09,  6.71it/s, est. speed input: 3940.27 toks/s, output: 7.70 toks/s]
Processed prompts:  51%|     | 65/128 [00:08<00:09,  6.60it/s, est. speed input: 3927.73 toks/s, output: 7.67 toks/s]
Processed prompts:  52%|    | 66/128 [00:08<00:09,  6.71it/s, est. speed input: 3921.86 toks/s, output: 7.66 toks/s]
Processed prompts:  52%|    | 67/128 [00:08<00:09,  6.75it/s, est. speed input: 3914.70 toks/s, output: 7.65 toks/s]
Processed prompts:  53%|    | 68/128 [00:08<00:08,  6.76it/s, est. speed input: 3907.55 toks/s, output: 7.63 toks/s]
Processed prompts:  54%|    | 69/128 [00:09<00:08,  6.74it/s, est. speed input: 3899.62 toks/s, output: 7.62 toks/s]
Processed prompts:  55%|    | 70/128 [00:09<00:08,  6.72it/s, est. speed input: 3891.82 toks/s, output: 7.60 toks/s]
Processed prompts:  55%|    | 71/128 [00:09<00:08,  6.76it/s, est. speed input: 3885.69 toks/s, output: 7.59 toks/s]
Processed prompts:  56%|    | 72/128 [00:09<00:08,  6.79it/s, est. speed input: 3880.13 toks/s, output: 7.58 toks/s]
Processed prompts:  57%|    | 73/128 [00:09<00:08,  6.72it/s, est. speed input: 3871.75 toks/s, output: 7.56 toks/s]
Processed prompts:  58%|    | 74/128 [00:09<00:08,  6.72it/s, est. speed input: 3865.22 toks/s, output: 7.55 toks/s]
Processed prompts:  59%|    | 75/128 [00:09<00:07,  6.74it/s, est. speed input: 3859.45 toks/s, output: 7.54 toks/s]
Processed prompts:  59%|    | 76/128 [00:10<00:07,  6.74it/s, est. speed input: 3853.37 toks/s, output: 7.53 toks/s]
Processed prompts:  60%|    | 77/128 [00:10<00:07,  6.76it/s, est. speed input: 3848.25 toks/s, output: 7.52 toks/s]
Processed prompts:  61%|    | 78/128 [00:10<00:07,  6.75it/s, est. speed input: 3842.37 toks/s, output: 7.50 toks/s]
Processed prompts:  62%|   | 79/128 [00:10<00:07,  6.77it/s, est. speed input: 3837.43 toks/s, output: 7.49 toks/s]
Processed prompts:  62%|   | 80/128 [00:10<00:07,  6.74it/s, est. speed input: 3831.59 toks/s, output: 7.48 toks/s]
Processed prompts:  63%|   | 81/128 [00:10<00:07,  6.69it/s, est. speed input: 3824.98 toks/s, output: 7.47 toks/s]
Processed prompts:  64%|   | 82/128 [00:10<00:06,  6.72it/s, est. speed input: 3820.41 toks/s, output: 7.46 toks/s]
Processed prompts:  65%|   | 83/128 [00:11<00:06,  6.73it/s, est. speed input: 3815.52 toks/s, output: 7.45 toks/s]
Processed prompts:  66%|   | 84/128 [00:11<00:06,  6.75it/s, est. speed input: 3811.15 toks/s, output: 7.44 toks/s]
Processed prompts:  66%|   | 85/128 [00:11<00:06,  6.81it/s, est. speed input: 3808.01 toks/s, output: 7.44 toks/s]
Processed prompts:  67%|   | 86/128 [00:11<00:06,  6.77it/s, est. speed input: 3803.09 toks/s, output: 7.43 toks/s]
Processed prompts:  68%|   | 87/128 [00:11<00:06,  6.78it/s, est. speed input: 3799.08 toks/s, output: 7.42 toks/s]
Processed prompts:  69%|   | 88/128 [00:11<00:05,  6.72it/s, est. speed input: 3793.57 toks/s, output: 7.41 toks/s]
Processed prompts:  70%|   | 89/128 [00:12<00:05,  6.74it/s, est. speed input: 3789.60 toks/s, output: 7.40 toks/s]
Processed prompts:  70%|   | 90/128 [00:12<00:05,  6.74it/s, est. speed input: 3785.41 toks/s, output: 7.39 toks/s]
Processed prompts:  71%|   | 91/128 [00:12<00:05,  6.72it/s, est. speed input: 3781.05 toks/s, output: 7.38 toks/s]
Processed prompts:  72%|  | 92/128 [00:12<00:05,  6.73it/s, est. speed input: 3777.21 toks/s, output: 7.38 toks/s]
Processed prompts:  73%|  | 93/128 [00:12<00:05,  6.72it/s, est. speed input: 3773.15 toks/s, output: 7.37 toks/s]
Processed prompts:  73%|  | 94/128 [00:12<00:05,  6.76it/s, est. speed input: 3770.12 toks/s, output: 7.36 toks/s]
Processed prompts:  74%|  | 95/128 [00:12<00:04,  6.68it/s, est. speed input: 3764.80 toks/s, output: 7.35 toks/s]
Processed prompts:  75%|  | 96/128 [00:13<00:04,  6.71it/s, est. speed input: 3761.44 toks/s, output: 7.35 toks/s]
Processed prompts:  76%|  | 97/128 [00:13<00:04,  6.72it/s, est. speed input: 3758.12 toks/s, output: 7.34 toks/s]
Processed prompts:  77%|  | 98/128 [00:13<00:04,  6.74it/s, est. speed input: 3754.99 toks/s, output: 7.33 toks/s]
Processed prompts:  77%|  | 99/128 [00:13<00:04,  6.76it/s, est. speed input: 3752.00 toks/s, output: 7.33 toks/s]
Processed prompts:  78%|  | 100/128 [00:13<00:04,  6.74it/s, est. speed input: 3748.46 toks/s, output: 7.32 toks/s]
Processed prompts:  79%|  | 101/128 [00:13<00:04,  6.75it/s, est. speed input: 3745.44 toks/s, output: 7.32 toks/s]
Processed prompts:  80%|  | 102/128 [00:13<00:03,  6.65it/s, est. speed input: 3740.46 toks/s, output: 7.31 toks/s]
Processed prompts:  80%|  | 103/128 [00:14<00:03,  6.68it/s, est. speed input: 3737.49 toks/s, output: 7.30 toks/s]
Processed prompts:  81%| | 104/128 [00:14<00:03,  6.72it/s, est. speed input: 3734.85 toks/s, output: 7.29 toks/s]
Processed prompts:  82%| | 105/128 [00:14<00:03,  6.76it/s, est. speed input: 3732.58 toks/s, output: 7.29 toks/s]
Processed prompts:  83%| | 106/128 [00:14<00:03,  6.74it/s, est. speed input: 3729.52 toks/s, output: 7.28 toks/s]
Processed prompts:  84%| | 107/128 [00:14<00:03,  6.77it/s, est. speed input: 3727.23 toks/s, output: 7.28 toks/s]
Processed prompts:  84%| | 108/128 [00:14<00:02,  6.77it/s, est. speed input: 3724.60 toks/s, output: 7.27 toks/s]
Processed prompts:  85%| | 109/128 [00:15<00:02,  6.69it/s, est. speed input: 3720.53 toks/s, output: 7.27 toks/s]
Processed prompts:  86%| | 110/128 [00:15<00:02,  6.70it/s, est. speed input: 3717.89 toks/s, output: 7.26 toks/s]
Processed prompts:  87%| | 111/128 [00:15<00:02,  6.77it/s, est. speed input: 3716.26 toks/s, output: 7.26 toks/s]
Processed prompts:  88%| | 112/128 [00:15<00:02,  6.79it/s, est. speed input: 3714.30 toks/s, output: 7.25 toks/s]
Processed prompts:  88%| | 113/128 [00:15<00:02,  6.77it/s, est. speed input: 3711.61 toks/s, output: 7.25 toks/s]
Processed prompts:  89%| | 114/128 [00:15<00:02,  6.77it/s, est. speed input: 3709.31 toks/s, output: 7.24 toks/s]
Processed prompts:  90%| | 115/128 [00:15<00:01,  6.79it/s, est. speed input: 3707.40 toks/s, output: 7.24 toks/s]
Processed prompts:  91%| | 116/128 [00:16<00:01,  6.69it/s, est. speed input: 3703.68 toks/s, output: 7.23 toks/s]
Processed prompts:  91%|| 117/128 [00:16<00:01,  6.70it/s, est. speed input: 3701.21 toks/s, output: 7.23 toks/s]
Processed prompts:  92%|| 118/128 [00:16<00:01,  6.71it/s, est. speed input: 3698.91 toks/s, output: 7.22 toks/s]
Processed prompts:  93%|| 119/128 [00:16<00:01,  6.75it/s, est. speed input: 3697.15 toks/s, output: 7.22 toks/s]
Processed prompts:  94%|| 120/128 [00:16<00:01,  6.76it/s, est. speed input: 3695.26 toks/s, output: 7.22 toks/s]
Processed prompts:  95%|| 121/128 [00:16<00:01,  6.77it/s, est. speed input: 3693.27 toks/s, output: 7.21 toks/s]
Processed prompts:  95%|| 122/128 [00:16<00:00,  6.79it/s, est. speed input: 3691.66 toks/s, output: 7.21 toks/s]
Processed prompts:  96%|| 123/128 [00:17<00:00,  6.72it/s, est. speed input: 3688.66 toks/s, output: 7.20 toks/s]
Processed prompts:  97%|| 124/128 [00:17<00:00,  6.72it/s, est. speed input: 3686.59 toks/s, output: 7.20 toks/s]
Processed prompts:  98%|| 125/128 [00:17<00:00,  6.75it/s, est. speed input: 3684.85 toks/s, output: 7.20 toks/s]
Processed prompts:  98%|| 126/128 [00:17<00:00,  6.74it/s, est. speed input: 3682.86 toks/s, output: 7.19 toks/s]
Processed prompts:  99%|| 127/128 [00:17<00:00,  6.73it/s, est. speed input: 3680.75 toks/s, output: 7.19 toks/s]
Processed prompts: 100%|| 128/128 [00:17<00:00,  6.72it/s, est. speed input: 3678.67 toks/s, output: 7.18 toks/s]
Processed prompts: 100%|| 128/128 [00:17<00:00,  6.72it/s, est. speed input: 3678.67 toks/s, output: 7.18 toks/s]
Processed prompts: 100%|| 128/128 [00:17<00:00,  7.18it/s, est. speed input: 3678.67 toks/s, output: 7.18 toks/s]
[rank0]:[W127 11:35:35.891952433 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-27 11:35:49
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 11:35:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 11:35:57 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2566308) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2566308) WARNING 01-27 11:38:15 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.16 requests/s, 3240.49 total tokens/s, 3.16 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-27 11:35:57] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:35:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:35:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:35:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:35:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:35:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:35:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:35:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:35:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:35:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:35:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:35:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:35:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:35:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 11:36:00] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:36:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:36:00] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:36:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:36:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:36:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:36:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:36:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:36:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:36:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:36:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:36:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:36:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:36:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2566308) [2026-01-27 11:36:01] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2566308) [2026-01-27 11:36:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2566308) [2026-01-27 11:36:01] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2566308) [2026-01-27 11:36:01] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2566308) [2026-01-27 11:36:01] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2566308) [2026-01-27 11:36:01] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2566308) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2566308) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.48s/it]
(EngineCore_DP0 pid=2566308) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:53, 26.98s/it]
(EngineCore_DP0 pid=2566308) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:19<00:28, 28.88s/it]
(EngineCore_DP0 pid=2566308) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 33.61s/it]
(EngineCore_DP0 pid=2566308) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 30.10s/it]
(EngineCore_DP0 pid=2566308) 
(EngineCore_DP0 pid=2566308) [2026-01-27 11:38:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2566308) [2026-01-27 11:38:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=2566308) [2026-01-27 11:38:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2566308) [2026-01-27 11:38:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=2566308) [2026-01-27 11:38:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2566308) [2026-01-27 11:38:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=2566308) [2026-01-27 11:38:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2566308) [2026-01-27 11:38:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=2566308) 2026-01-27 11:38:12,772 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2566308) 2026-01-27 11:38:13,018 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   1%|          | 1/128 [00:01<02:07,  1.01s/it]
Adding requests:   2%|         | 2/128 [00:01<01:09,  1.81it/s]
Adding requests:   2%|         | 3/128 [00:01<00:45,  2.77it/s]
Adding requests:   3%|         | 4/128 [00:01<00:32,  3.82it/s]
Adding requests:   5%|         | 6/128 [00:01<00:20,  6.10it/s]
Adding requests:   6%|         | 8/128 [00:01<00:14,  8.41it/s]
Adding requests:   9%|         | 11/128 [00:01<00:09, 12.54it/s]
Adding requests:  11%|         | 14/128 [00:01<00:07, 15.98it/s]
Adding requests:  19%|        | 24/128 [00:02<00:02, 35.46it/s]
Adding requests:  30%|       | 38/128 [00:02<00:01, 60.60it/s]
Adding requests:  41%|     | 53/128 [00:02<00:00, 82.24it/s]
Adding requests:  55%|    | 71/128 [00:02<00:00, 107.87it/s]
Adding requests:  77%|  | 99/128 [00:02<00:00, 154.65it/s]
Adding requests: 100%|| 128/128 [00:02<00:00, 49.35it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:08, 14.57it/s, est. speed input: 14915.74 toks/s, output: 14.57 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:18,  6.52it/s, est. speed input: 7570.30 toks/s, output: 7.39 toks/s]  
Processed prompts:   6%|         | 8/128 [00:01<00:22,  5.40it/s, est. speed input: 6533.60 toks/s, output: 6.38 toks/s]
Processed prompts:   7%|         | 9/128 [00:01<00:25,  4.75it/s, est. speed input: 5943.55 toks/s, output: 5.80 toks/s]
Processed prompts:   8%|         | 10/128 [00:01<00:27,  4.30it/s, est. speed input: 5532.43 toks/s, output: 5.40 toks/s]
Processed prompts:   9%|         | 11/128 [00:02<00:29,  4.00it/s, est. speed input: 5234.79 toks/s, output: 5.11 toks/s]
Processed prompts:   9%|         | 12/128 [00:02<00:30,  3.77it/s, est. speed input: 5000.02 toks/s, output: 4.88 toks/s]
Processed prompts:  10%|         | 13/128 [00:02<00:31,  3.63it/s, est. speed input: 4822.49 toks/s, output: 4.71 toks/s]
Processed prompts:  11%|         | 14/128 [00:03<00:32,  3.55it/s, est. speed input: 4687.78 toks/s, output: 4.58 toks/s]
Processed prompts:  12%|        | 15/128 [00:03<00:32,  3.45it/s, est. speed input: 4562.47 toks/s, output: 4.46 toks/s]
Processed prompts:  12%|        | 16/128 [00:03<00:32,  3.41it/s, est. speed input: 4465.10 toks/s, output: 4.36 toks/s]
Processed prompts:  13%|        | 17/128 [00:03<00:32,  3.39it/s, est. speed input: 4386.59 toks/s, output: 4.28 toks/s]
Processed prompts:  14%|        | 18/128 [00:04<00:32,  3.38it/s, est. speed input: 4320.89 toks/s, output: 4.22 toks/s]
Processed prompts:  15%|        | 19/128 [00:04<00:32,  3.35it/s, est. speed input: 4255.35 toks/s, output: 4.16 toks/s]
Processed prompts:  16%|        | 20/128 [00:04<00:32,  3.34it/s, est. speed input: 4202.50 toks/s, output: 4.10 toks/s]
Processed prompts:  16%|        | 21/128 [00:05<00:32,  3.33it/s, est. speed input: 4155.14 toks/s, output: 4.06 toks/s]
Processed prompts:  17%|        | 22/128 [00:05<00:32,  3.30it/s, est. speed input: 4106.95 toks/s, output: 4.01 toks/s]
Processed prompts:  18%|        | 23/128 [00:05<00:31,  3.31it/s, est. speed input: 4070.36 toks/s, output: 3.97 toks/s]
Processed prompts:  19%|        | 24/128 [00:06<00:31,  3.31it/s, est. speed input: 4038.10 toks/s, output: 3.94 toks/s]
Processed prompts:  20%|        | 25/128 [00:06<00:31,  3.32it/s, est. speed input: 4008.91 toks/s, output: 3.91 toks/s]
Processed prompts:  20%|        | 26/128 [00:06<00:30,  3.30it/s, est. speed input: 3978.46 toks/s, output: 3.89 toks/s]
Processed prompts:  21%|        | 27/128 [00:06<00:30,  3.30it/s, est. speed input: 3951.31 toks/s, output: 3.86 toks/s]
Processed prompts:  22%|       | 28/128 [00:07<00:30,  3.30it/s, est. speed input: 3927.59 toks/s, output: 3.84 toks/s]
Processed prompts:  23%|       | 29/128 [00:07<00:30,  3.28it/s, est. speed input: 3903.45 toks/s, output: 3.81 toks/s]
Processed prompts:  23%|       | 30/128 [00:07<00:29,  3.30it/s, est. speed input: 3884.72 toks/s, output: 3.79 toks/s]
Processed prompts:  24%|       | 31/128 [00:08<00:29,  3.30it/s, est. speed input: 3866.74 toks/s, output: 3.78 toks/s]
Processed prompts:  25%|       | 32/128 [00:08<00:29,  3.30it/s, est. speed input: 3849.33 toks/s, output: 3.76 toks/s]
Processed prompts:  26%|       | 33/128 [00:08<00:28,  3.29it/s, est. speed input: 3831.57 toks/s, output: 3.74 toks/s]
Processed prompts:  27%|       | 34/128 [00:09<00:28,  3.29it/s, est. speed input: 3816.42 toks/s, output: 3.73 toks/s]
Processed prompts:  27%|       | 35/128 [00:09<00:28,  3.29it/s, est. speed input: 3802.02 toks/s, output: 3.71 toks/s]
Processed prompts:  28%|       | 36/128 [00:09<00:28,  3.28it/s, est. speed input: 3786.98 toks/s, output: 3.70 toks/s]
Processed prompts:  29%|       | 37/128 [00:10<00:27,  3.30it/s, est. speed input: 3776.70 toks/s, output: 3.69 toks/s]
Processed prompts:  30%|       | 38/128 [00:10<00:27,  3.30it/s, est. speed input: 3764.67 toks/s, output: 3.68 toks/s]
Processed prompts:  30%|       | 39/128 [00:10<00:27,  3.29it/s, est. speed input: 3752.22 toks/s, output: 3.66 toks/s]
Processed prompts:  31%|      | 40/128 [00:10<00:26,  3.29it/s, est. speed input: 3741.92 toks/s, output: 3.65 toks/s]
Processed prompts:  32%|      | 41/128 [00:11<00:26,  3.29it/s, est. speed input: 3732.27 toks/s, output: 3.64 toks/s]
Processed prompts:  33%|      | 42/128 [00:11<00:26,  3.30it/s, est. speed input: 3723.45 toks/s, output: 3.64 toks/s]
Processed prompts:  34%|      | 43/128 [00:11<00:25,  3.29it/s, est. speed input: 3713.63 toks/s, output: 3.63 toks/s]
Processed prompts:  34%|      | 44/128 [00:12<00:25,  3.29it/s, est. speed input: 3704.70 toks/s, output: 3.62 toks/s]
Processed prompts:  35%|      | 45/128 [00:12<00:25,  3.29it/s, est. speed input: 3696.67 toks/s, output: 3.61 toks/s]
Processed prompts:  36%|      | 46/128 [00:12<00:24,  3.29it/s, est. speed input: 3688.52 toks/s, output: 3.60 toks/s]
Processed prompts:  37%|      | 47/128 [00:13<00:24,  3.29it/s, est. speed input: 3681.23 toks/s, output: 3.59 toks/s]
Processed prompts:  38%|      | 48/128 [00:13<00:24,  3.29it/s, est. speed input: 3674.49 toks/s, output: 3.59 toks/s]
Processed prompts:  38%|      | 49/128 [00:13<00:24,  3.29it/s, est. speed input: 3667.40 toks/s, output: 3.58 toks/s]
Processed prompts:  39%|      | 50/128 [00:13<00:23,  3.27it/s, est. speed input: 3659.72 toks/s, output: 3.57 toks/s]
Processed prompts:  40%|      | 51/128 [00:14<00:23,  3.30it/s, est. speed input: 3655.10 toks/s, output: 3.57 toks/s]
Processed prompts:  41%|      | 52/128 [00:14<00:23,  3.30it/s, est. speed input: 3649.62 toks/s, output: 3.56 toks/s]
Processed prompts:  41%|     | 53/128 [00:14<00:22,  3.30it/s, est. speed input: 3644.08 toks/s, output: 3.56 toks/s]
Processed prompts:  42%|     | 54/128 [00:15<00:22,  3.29it/s, est. speed input: 3638.18 toks/s, output: 3.55 toks/s]
Processed prompts:  43%|     | 55/128 [00:15<00:22,  3.29it/s, est. speed input: 3632.74 toks/s, output: 3.55 toks/s]
Processed prompts:  44%|     | 56/128 [00:15<00:21,  3.30it/s, est. speed input: 3628.66 toks/s, output: 3.54 toks/s]
Processed prompts:  45%|     | 57/128 [00:16<00:21,  3.29it/s, est. speed input: 3623.42 toks/s, output: 3.54 toks/s]
Processed prompts:  45%|     | 58/128 [00:16<00:21,  3.30it/s, est. speed input: 3619.04 toks/s, output: 3.53 toks/s]
Processed prompts:  46%|     | 59/128 [00:16<00:20,  3.29it/s, est. speed input: 3614.33 toks/s, output: 3.53 toks/s]
Processed prompts:  47%|     | 60/128 [00:17<00:20,  3.28it/s, est. speed input: 3608.95 toks/s, output: 3.52 toks/s]
Processed prompts:  48%|     | 61/128 [00:17<00:20,  3.29it/s, est. speed input: 3605.17 toks/s, output: 3.52 toks/s]
Processed prompts:  48%|     | 62/128 [00:17<00:20,  3.29it/s, est. speed input: 3601.39 toks/s, output: 3.52 toks/s]
Processed prompts:  49%|     | 63/128 [00:17<00:19,  3.30it/s, est. speed input: 3597.93 toks/s, output: 3.51 toks/s]
Processed prompts:  50%|     | 64/128 [00:18<00:19,  3.28it/s, est. speed input: 3592.87 toks/s, output: 3.51 toks/s]
Processed prompts:  51%|     | 65/128 [00:18<00:19,  3.28it/s, est. speed input: 3589.05 toks/s, output: 3.50 toks/s]
Processed prompts:  52%|    | 66/128 [00:18<00:18,  3.28it/s, est. speed input: 3585.59 toks/s, output: 3.50 toks/s]
Processed prompts:  52%|    | 67/128 [00:19<00:18,  3.27it/s, est. speed input: 3581.53 toks/s, output: 3.50 toks/s]
Processed prompts:  53%|    | 68/128 [00:19<00:18,  3.28it/s, est. speed input: 3578.25 toks/s, output: 3.49 toks/s]
Processed prompts:  54%|    | 69/128 [00:19<00:17,  3.28it/s, est. speed input: 3575.07 toks/s, output: 3.49 toks/s]
Processed prompts:  55%|    | 70/128 [00:20<00:17,  3.29it/s, est. speed input: 3572.23 toks/s, output: 3.49 toks/s]
Processed prompts:  55%|    | 71/128 [00:20<00:17,  3.28it/s, est. speed input: 3568.37 toks/s, output: 3.48 toks/s]
Processed prompts:  56%|    | 72/128 [00:20<00:17,  3.28it/s, est. speed input: 3565.50 toks/s, output: 3.48 toks/s]
Processed prompts:  57%|    | 73/128 [00:20<00:16,  3.28it/s, est. speed input: 3562.69 toks/s, output: 3.48 toks/s]
Processed prompts:  58%|    | 74/128 [00:21<00:16,  3.28it/s, est. speed input: 3559.62 toks/s, output: 3.48 toks/s]
Processed prompts:  59%|    | 75/128 [00:21<00:16,  3.29it/s, est. speed input: 3557.20 toks/s, output: 3.47 toks/s]
Processed prompts:  59%|    | 76/128 [00:21<00:15,  3.28it/s, est. speed input: 3554.35 toks/s, output: 3.47 toks/s]
Processed prompts:  60%|    | 77/128 [00:22<00:15,  3.29it/s, est. speed input: 3551.89 toks/s, output: 3.47 toks/s]
Processed prompts:  61%|    | 78/128 [00:22<00:15,  3.28it/s, est. speed input: 3549.12 toks/s, output: 3.47 toks/s]
Processed prompts:  62%|   | 79/128 [00:22<00:14,  3.29it/s, est. speed input: 3547.10 toks/s, output: 3.46 toks/s]
Processed prompts:  62%|   | 80/128 [00:23<00:14,  3.29it/s, est. speed input: 3544.72 toks/s, output: 3.46 toks/s]
Processed prompts:  63%|   | 81/128 [00:23<00:14,  3.27it/s, est. speed input: 3541.58 toks/s, output: 3.46 toks/s]
Processed prompts:  64%|   | 82/128 [00:23<00:14,  3.28it/s, est. speed input: 3539.43 toks/s, output: 3.46 toks/s]
Processed prompts:  65%|   | 83/128 [00:24<00:13,  3.28it/s, est. speed input: 3537.39 toks/s, output: 3.45 toks/s]
Processed prompts:  66%|   | 84/128 [00:24<00:13,  3.29it/s, est. speed input: 3535.40 toks/s, output: 3.45 toks/s]
Processed prompts:  66%|   | 85/128 [00:24<00:13,  3.28it/s, est. speed input: 3532.77 toks/s, output: 3.45 toks/s]
Processed prompts:  67%|   | 86/128 [00:24<00:12,  3.28it/s, est. speed input: 3530.86 toks/s, output: 3.45 toks/s]
Processed prompts:  68%|   | 87/128 [00:25<00:12,  3.28it/s, est. speed input: 3528.80 toks/s, output: 3.45 toks/s]
Processed prompts:  69%|   | 88/128 [00:25<00:12,  3.27it/s, est. speed input: 3526.35 toks/s, output: 3.44 toks/s]
Processed prompts:  70%|   | 89/128 [00:25<00:11,  3.28it/s, est. speed input: 3524.63 toks/s, output: 3.44 toks/s]
Processed prompts:  70%|   | 90/128 [00:26<00:11,  3.28it/s, est. speed input: 3522.65 toks/s, output: 3.44 toks/s]
Processed prompts:  71%|   | 91/128 [00:26<00:11,  3.28it/s, est. speed input: 3520.84 toks/s, output: 3.44 toks/s]
Processed prompts:  72%|  | 92/128 [00:26<00:11,  3.27it/s, est. speed input: 3518.45 toks/s, output: 3.44 toks/s]
Processed prompts:  73%|  | 93/128 [00:27<00:10,  3.27it/s, est. speed input: 3516.70 toks/s, output: 3.43 toks/s]
Processed prompts:  73%|  | 94/128 [00:27<00:10,  3.28it/s, est. speed input: 3515.02 toks/s, output: 3.43 toks/s]
Processed prompts:  74%|  | 95/128 [00:27<00:10,  3.26it/s, est. speed input: 3512.79 toks/s, output: 3.43 toks/s]
Processed prompts:  75%|  | 96/128 [00:27<00:09,  3.26it/s, est. speed input: 3510.90 toks/s, output: 3.43 toks/s]
Processed prompts:  76%|  | 97/128 [00:28<00:09,  3.27it/s, est. speed input: 3509.24 toks/s, output: 3.43 toks/s]
Processed prompts:  77%|  | 98/128 [00:28<00:09,  3.25it/s, est. speed input: 3506.97 toks/s, output: 3.42 toks/s]
Processed prompts:  77%|  | 99/128 [00:28<00:08,  3.27it/s, est. speed input: 3505.56 toks/s, output: 3.42 toks/s]
Processed prompts:  78%|  | 100/128 [00:29<00:08,  3.28it/s, est. speed input: 3504.24 toks/s, output: 3.42 toks/s]
Processed prompts:  79%|  | 101/128 [00:29<00:08,  3.28it/s, est. speed input: 3502.98 toks/s, output: 3.42 toks/s]
Processed prompts:  80%|  | 102/128 [00:29<00:07,  3.28it/s, est. speed input: 3501.40 toks/s, output: 3.42 toks/s]
Processed prompts:  80%|  | 103/128 [00:30<00:07,  3.29it/s, est. speed input: 3500.31 toks/s, output: 3.42 toks/s]
Processed prompts:  81%| | 104/128 [00:30<00:07,  3.29it/s, est. speed input: 3499.08 toks/s, output: 3.42 toks/s]
Processed prompts:  82%| | 105/128 [00:30<00:07,  3.27it/s, est. speed input: 3497.13 toks/s, output: 3.42 toks/s]
Processed prompts:  83%| | 106/128 [00:31<00:06,  3.29it/s, est. speed input: 3496.20 toks/s, output: 3.41 toks/s]
Processed prompts:  84%| | 107/128 [00:31<00:06,  3.28it/s, est. speed input: 3494.74 toks/s, output: 3.41 toks/s]
Processed prompts:  84%| | 108/128 [00:31<00:06,  3.28it/s, est. speed input: 3493.39 toks/s, output: 3.41 toks/s]
Processed prompts:  85%| | 109/128 [00:31<00:05,  3.27it/s, est. speed input: 3491.78 toks/s, output: 3.41 toks/s]
Processed prompts:  86%| | 110/128 [00:32<00:05,  3.28it/s, est. speed input: 3490.60 toks/s, output: 3.41 toks/s]
Processed prompts:  87%| | 111/128 [00:32<00:05,  3.28it/s, est. speed input: 3489.56 toks/s, output: 3.41 toks/s]
Processed prompts:  88%| | 112/128 [00:32<00:04,  3.27it/s, est. speed input: 3487.93 toks/s, output: 3.41 toks/s]
Processed prompts:  88%| | 113/128 [00:33<00:04,  3.27it/s, est. speed input: 3486.78 toks/s, output: 3.41 toks/s]
Processed prompts:  89%| | 114/128 [00:33<00:04,  3.29it/s, est. speed input: 3486.14 toks/s, output: 3.40 toks/s]
Processed prompts:  90%| | 115/128 [00:33<00:03,  3.30it/s, est. speed input: 3485.32 toks/s, output: 3.40 toks/s]
Processed prompts:  91%| | 116/128 [00:34<00:03,  3.28it/s, est. speed input: 3483.67 toks/s, output: 3.40 toks/s]
Processed prompts:  91%|| 117/128 [00:34<00:03,  3.28it/s, est. speed input: 3482.70 toks/s, output: 3.40 toks/s]
Processed prompts:  92%|| 118/128 [00:34<00:03,  3.29it/s, est. speed input: 3481.87 toks/s, output: 3.40 toks/s]
Processed prompts:  93%|| 119/128 [00:35<00:02,  3.27it/s, est. speed input: 3480.16 toks/s, output: 3.40 toks/s]
Processed prompts:  94%|| 120/128 [00:35<00:02,  3.27it/s, est. speed input: 3479.17 toks/s, output: 3.40 toks/s]
Processed prompts:  95%|| 121/128 [00:35<00:02,  3.27it/s, est. speed input: 3477.98 toks/s, output: 3.40 toks/s]
Processed prompts:  95%|| 122/128 [00:35<00:01,  3.27it/s, est. speed input: 3476.95 toks/s, output: 3.40 toks/s]
Processed prompts:  96%|| 123/128 [00:36<00:01,  3.26it/s, est. speed input: 3475.40 toks/s, output: 3.39 toks/s]
Processed prompts:  97%|| 124/128 [00:36<00:01,  3.26it/s, est. speed input: 3474.36 toks/s, output: 3.39 toks/s]
Processed prompts:  98%|| 125/128 [00:36<00:00,  3.26it/s, est. speed input: 3473.34 toks/s, output: 3.39 toks/s]
Processed prompts:  98%|| 126/128 [00:37<00:00,  3.24it/s, est. speed input: 3471.65 toks/s, output: 3.39 toks/s]
Processed prompts:  99%|| 127/128 [00:37<00:00,  3.26it/s, est. speed input: 3470.93 toks/s, output: 3.39 toks/s]
Processed prompts: 100%|| 128/128 [00:37<00:00,  3.23it/s, est. speed input: 3469.04 toks/s, output: 3.39 toks/s]
Processed prompts: 100%|| 128/128 [00:37<00:00,  3.23it/s, est. speed input: 3469.04 toks/s, output: 3.39 toks/s]
Processed prompts: 100%|| 128/128 [00:37<00:00,  3.39it/s, est. speed input: 3469.04 toks/s, output: 3.39 toks/s]
[rank0]:[W127 11:38:56.773711776 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-27 11:39:11
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 11:39:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 11:39:19 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2569272) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2569272) WARNING 01-27 11:41:39 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.15 requests/s, 3226.79 total tokens/s, 3.15 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-27 11:39:18] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:39:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:39:18] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:39:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:39:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:39:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:39:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:39:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 11:39:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:39:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:39:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:39:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:39:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:39:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:39:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:39:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:39:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2569272) [2026-01-27 11:39:23] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2569272) [2026-01-27 11:39:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2569272) [2026-01-27 11:39:23] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2569272) [2026-01-27 11:39:23] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2569272) [2026-01-27 11:39:23] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2569272) [2026-01-27 11:39:23] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2569272) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2569272) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.60s/it]
(EngineCore_DP0 pid=2569272) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:53, 26.95s/it]
(EngineCore_DP0 pid=2569272) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:19<00:28, 28.91s/it]
(EngineCore_DP0 pid=2569272) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 33.70s/it]
(EngineCore_DP0 pid=2569272) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 30.17s/it]
(EngineCore_DP0 pid=2569272) 
(EngineCore_DP0 pid=2569272) [2026-01-27 11:41:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2569272) [2026-01-27 11:41:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=2569272) [2026-01-27 11:41:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2569272) [2026-01-27 11:41:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=2569272) [2026-01-27 11:41:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2569272) [2026-01-27 11:41:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=2569272) [2026-01-27 11:41:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2569272) [2026-01-27 11:41:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=2569272) 2026-01-27 11:41:34,744 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2569272) 2026-01-27 11:41:35,109 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:00<03:22,  1.26it/s]
Adding requests:   1%|          | 2/256 [00:00<01:49,  2.32it/s]
Adding requests:   1%|          | 3/256 [00:01<01:12,  3.48it/s]
Adding requests:   2%|         | 5/256 [00:01<00:42,  5.89it/s]
Adding requests:   3%|         | 7/256 [00:01<00:32,  7.73it/s]
Adding requests:   4%|         | 9/256 [00:01<00:25,  9.84it/s]
Adding requests:   5%|         | 12/256 [00:01<00:17, 13.76it/s]
Adding requests:   7%|         | 17/256 [00:01<00:11, 21.40it/s]
Adding requests:  12%|        | 30/256 [00:01<00:04, 47.25it/s]
Adding requests:  18%|        | 47/256 [00:01<00:02, 77.48it/s]
Adding requests:  25%|       | 65/256 [00:02<00:01, 102.47it/s]
Adding requests:  32%|      | 82/256 [00:02<00:01, 119.38it/s]
Adding requests:  42%|     | 108/256 [00:02<00:00, 158.09it/s]
Adding requests:  54%|    | 138/256 [00:02<00:00, 195.03it/s]
Adding requests:  66%|   | 170/256 [00:02<00:00, 229.42it/s]
Adding requests:  80%|  | 204/256 [00:02<00:00, 186.63it/s]
Adding requests:  95%|| 243/256 [00:02<00:00, 231.99it/s]
Adding requests: 100%|| 256/256 [00:02<00:00, 89.57it/s] 

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:09, 27.36it/s, est. speed input: 28017.84 toks/s, output: 27.36 toks/s]
Processed prompts:   4%|         | 9/256 [00:00<00:26,  9.27it/s, est. speed input: 10938.11 toks/s, output: 10.68 toks/s]
Processed prompts:   4%|         | 11/256 [00:01<00:40,  6.05it/s, est. speed input: 7699.01 toks/s, output: 7.52 toks/s] 
Processed prompts:   5%|         | 12/256 [00:02<00:59,  4.12it/s, est. speed input: 5890.84 toks/s, output: 5.75 toks/s]
Processed prompts:   5%|         | 14/256 [00:02<01:04,  3.78it/s, est. speed input: 5295.17 toks/s, output: 5.17 toks/s]
Processed prompts:   6%|         | 16/256 [00:03<01:07,  3.58it/s, est. speed input: 4918.53 toks/s, output: 4.80 toks/s]
Processed prompts:   7%|         | 18/256 [00:03<01:08,  3.45it/s, est. speed input: 4660.54 toks/s, output: 4.55 toks/s]
Processed prompts:   8%|         | 20/256 [00:04<01:09,  3.38it/s, est. speed input: 4479.07 toks/s, output: 4.37 toks/s]
Processed prompts:   9%|         | 22/256 [00:05<01:10,  3.33it/s, est. speed input: 4335.37 toks/s, output: 4.23 toks/s]
Processed prompts:   9%|         | 24/256 [00:05<01:10,  3.28it/s, est. speed input: 4220.67 toks/s, output: 4.12 toks/s]
Processed prompts:  10%|         | 26/256 [00:06<01:10,  3.27it/s, est. speed input: 4132.14 toks/s, output: 4.04 toks/s]
Processed prompts:  11%|         | 28/256 [00:07<01:10,  3.24it/s, est. speed input: 4055.16 toks/s, output: 3.96 toks/s]
Processed prompts:  12%|        | 30/256 [00:07<01:09,  3.24it/s, est. speed input: 3995.72 toks/s, output: 3.90 toks/s]
Processed prompts:  12%|        | 32/256 [00:08<01:09,  3.23it/s, est. speed input: 3941.70 toks/s, output: 3.85 toks/s]
Processed prompts:  13%|        | 34/256 [00:08<01:08,  3.22it/s, est. speed input: 3894.76 toks/s, output: 3.80 toks/s]
Processed prompts:  14%|        | 36/256 [00:09<01:08,  3.21it/s, est. speed input: 3854.85 toks/s, output: 3.76 toks/s]
Processed prompts:  15%|        | 38/256 [00:10<01:07,  3.21it/s, est. speed input: 3818.45 toks/s, output: 3.73 toks/s]
Processed prompts:  16%|        | 40/256 [00:10<01:07,  3.21it/s, est. speed input: 3787.50 toks/s, output: 3.70 toks/s]
Processed prompts:  16%|        | 42/256 [00:11<01:06,  3.20it/s, est. speed input: 3758.16 toks/s, output: 3.67 toks/s]
Processed prompts:  17%|        | 44/256 [00:12<01:06,  3.20it/s, est. speed input: 3734.31 toks/s, output: 3.65 toks/s]
Processed prompts:  18%|        | 46/256 [00:12<01:05,  3.20it/s, est. speed input: 3711.42 toks/s, output: 3.62 toks/s]
Processed prompts:  19%|        | 48/256 [00:13<01:05,  3.20it/s, est. speed input: 3690.60 toks/s, output: 3.60 toks/s]
Processed prompts:  20%|        | 50/256 [00:13<01:04,  3.20it/s, est. speed input: 3672.52 toks/s, output: 3.59 toks/s]
Processed prompts:  20%|        | 52/256 [00:14<01:03,  3.20it/s, est. speed input: 3655.60 toks/s, output: 3.57 toks/s]
Processed prompts:  21%|        | 54/256 [00:15<01:03,  3.20it/s, est. speed input: 3640.41 toks/s, output: 3.56 toks/s]
Processed prompts:  22%|       | 56/256 [00:15<01:02,  3.20it/s, est. speed input: 3625.95 toks/s, output: 3.54 toks/s]
Processed prompts:  23%|       | 58/256 [00:16<01:01,  3.19it/s, est. speed input: 3611.63 toks/s, output: 3.53 toks/s]
Processed prompts:  23%|       | 60/256 [00:17<01:01,  3.20it/s, est. speed input: 3599.93 toks/s, output: 3.52 toks/s]
Processed prompts:  24%|       | 62/256 [00:17<01:00,  3.20it/s, est. speed input: 3588.00 toks/s, output: 3.50 toks/s]
Processed prompts:  25%|       | 64/256 [00:18<01:00,  3.20it/s, est. speed input: 3577.59 toks/s, output: 3.49 toks/s]
Processed prompts:  26%|       | 66/256 [00:18<00:59,  3.19it/s, est. speed input: 3566.78 toks/s, output: 3.48 toks/s]
Processed prompts:  27%|       | 68/256 [00:19<00:59,  3.19it/s, est. speed input: 3556.54 toks/s, output: 3.47 toks/s]
Processed prompts:  27%|       | 70/256 [00:20<00:58,  3.19it/s, est. speed input: 3547.66 toks/s, output: 3.46 toks/s]
Processed prompts:  28%|       | 72/256 [00:20<00:57,  3.19it/s, est. speed input: 3539.20 toks/s, output: 3.46 toks/s]
Processed prompts:  29%|       | 74/256 [00:21<00:56,  3.19it/s, est. speed input: 3531.79 toks/s, output: 3.45 toks/s]
Processed prompts:  30%|       | 76/256 [00:22<00:56,  3.19it/s, est. speed input: 3523.48 toks/s, output: 3.44 toks/s]
Processed prompts:  30%|       | 78/256 [00:22<00:55,  3.18it/s, est. speed input: 3515.58 toks/s, output: 3.43 toks/s]
Processed prompts:  31%|      | 80/256 [00:23<00:55,  3.18it/s, est. speed input: 3508.62 toks/s, output: 3.43 toks/s]
Processed prompts:  32%|      | 82/256 [00:23<00:54,  3.18it/s, est. speed input: 3502.43 toks/s, output: 3.42 toks/s]
Processed prompts:  33%|      | 84/256 [00:24<00:54,  3.18it/s, est. speed input: 3496.12 toks/s, output: 3.41 toks/s]
Processed prompts:  34%|      | 86/256 [00:25<00:53,  3.18it/s, est. speed input: 3489.58 toks/s, output: 3.41 toks/s]
Processed prompts:  34%|      | 88/256 [00:25<00:52,  3.17it/s, est. speed input: 3483.73 toks/s, output: 3.40 toks/s]
Processed prompts:  35%|      | 90/256 [00:26<00:52,  3.17it/s, est. speed input: 3478.12 toks/s, output: 3.40 toks/s]
Processed prompts:  36%|      | 92/256 [00:27<00:51,  3.18it/s, est. speed input: 3472.92 toks/s, output: 3.39 toks/s]
Processed prompts:  37%|      | 94/256 [00:27<00:50,  3.18it/s, est. speed input: 3468.34 toks/s, output: 3.39 toks/s]
Processed prompts:  38%|      | 96/256 [00:28<00:50,  3.18it/s, est. speed input: 3463.28 toks/s, output: 3.38 toks/s]
Processed prompts:  38%|      | 98/256 [00:29<00:49,  3.18it/s, est. speed input: 3458.95 toks/s, output: 3.38 toks/s]
Processed prompts:  39%|      | 100/256 [00:29<00:49,  3.17it/s, est. speed input: 3454.03 toks/s, output: 3.37 toks/s]
Processed prompts:  40%|      | 102/256 [00:30<00:48,  3.17it/s, est. speed input: 3449.53 toks/s, output: 3.37 toks/s]
Processed prompts:  41%|      | 104/256 [00:30<00:47,  3.18it/s, est. speed input: 3445.85 toks/s, output: 3.37 toks/s]
Processed prompts:  41%|     | 106/256 [00:31<00:47,  3.17it/s, est. speed input: 3441.74 toks/s, output: 3.36 toks/s]
Processed prompts:  42%|     | 108/256 [00:32<00:46,  3.18it/s, est. speed input: 3438.29 toks/s, output: 3.36 toks/s]
Processed prompts:  43%|     | 110/256 [00:32<00:45,  3.18it/s, est. speed input: 3434.77 toks/s, output: 3.35 toks/s]
Processed prompts:  44%|     | 112/256 [00:33<00:45,  3.17it/s, est. speed input: 3430.72 toks/s, output: 3.35 toks/s]
Processed prompts:  45%|     | 114/256 [00:34<00:44,  3.18it/s, est. speed input: 3427.84 toks/s, output: 3.35 toks/s]
Processed prompts:  45%|     | 116/256 [00:34<00:44,  3.17it/s, est. speed input: 3424.13 toks/s, output: 3.34 toks/s]
Processed prompts:  46%|     | 118/256 [00:35<00:43,  3.17it/s, est. speed input: 3421.21 toks/s, output: 3.34 toks/s]
Processed prompts:  47%|     | 120/256 [00:35<00:42,  3.17it/s, est. speed input: 3418.20 toks/s, output: 3.34 toks/s]
Processed prompts:  48%|     | 122/256 [00:36<00:42,  3.17it/s, est. speed input: 3415.13 toks/s, output: 3.34 toks/s]
Processed prompts:  48%|     | 124/256 [00:37<00:41,  3.18it/s, est. speed input: 3412.60 toks/s, output: 3.33 toks/s]
Processed prompts:  49%|     | 126/256 [00:37<00:41,  3.17it/s, est. speed input: 3409.48 toks/s, output: 3.33 toks/s]
Processed prompts:  50%|     | 128/256 [00:38<00:40,  3.18it/s, est. speed input: 3407.30 toks/s, output: 3.33 toks/s]
Processed prompts:  51%|     | 130/256 [00:39<00:39,  3.17it/s, est. speed input: 3404.58 toks/s, output: 3.32 toks/s]
Processed prompts:  52%|    | 132/256 [00:39<00:39,  3.17it/s, est. speed input: 3401.71 toks/s, output: 3.32 toks/s]
Processed prompts:  52%|    | 134/256 [00:40<00:38,  3.17it/s, est. speed input: 3399.61 toks/s, output: 3.32 toks/s]
Processed prompts:  53%|    | 136/256 [00:40<00:37,  3.17it/s, est. speed input: 3397.35 toks/s, output: 3.32 toks/s]
Processed prompts:  54%|    | 138/256 [00:41<00:37,  3.17it/s, est. speed input: 3394.83 toks/s, output: 3.32 toks/s]
Processed prompts:  55%|    | 140/256 [00:42<00:36,  3.16it/s, est. speed input: 3392.27 toks/s, output: 3.31 toks/s]
Processed prompts:  55%|    | 142/256 [00:42<00:36,  3.16it/s, est. speed input: 3390.11 toks/s, output: 3.31 toks/s]
Processed prompts:  56%|    | 144/256 [00:43<00:35,  3.17it/s, est. speed input: 3387.97 toks/s, output: 3.31 toks/s]
Processed prompts:  57%|    | 146/256 [00:44<00:34,  3.16it/s, est. speed input: 3385.83 toks/s, output: 3.31 toks/s]
Processed prompts:  58%|    | 148/256 [00:44<00:34,  3.17it/s, est. speed input: 3384.15 toks/s, output: 3.30 toks/s]
Processed prompts:  59%|    | 150/256 [00:45<00:33,  3.17it/s, est. speed input: 3382.02 toks/s, output: 3.30 toks/s]
Processed prompts:  59%|    | 152/256 [00:46<00:32,  3.16it/s, est. speed input: 3380.01 toks/s, output: 3.30 toks/s]
Processed prompts:  60%|    | 154/256 [00:46<00:32,  3.17it/s, est. speed input: 3378.47 toks/s, output: 3.30 toks/s]
Processed prompts:  61%|    | 156/256 [00:47<00:31,  3.18it/s, est. speed input: 3376.96 toks/s, output: 3.30 toks/s]
Processed prompts:  62%|   | 158/256 [00:47<00:30,  3.18it/s, est. speed input: 3375.44 toks/s, output: 3.30 toks/s]
Processed prompts:  62%|   | 160/256 [00:48<00:30,  3.17it/s, est. speed input: 3373.43 toks/s, output: 3.29 toks/s]
Processed prompts:  63%|   | 162/256 [00:49<00:29,  3.17it/s, est. speed input: 3371.99 toks/s, output: 3.29 toks/s]
Processed prompts:  64%|   | 164/256 [00:49<00:29,  3.17it/s, est. speed input: 3370.29 toks/s, output: 3.29 toks/s]
Processed prompts:  65%|   | 166/256 [00:50<00:28,  3.17it/s, est. speed input: 3368.58 toks/s, output: 3.29 toks/s]
Processed prompts:  66%|   | 168/256 [00:51<00:27,  3.17it/s, est. speed input: 3367.29 toks/s, output: 3.29 toks/s]
Processed prompts:  66%|   | 170/256 [00:51<00:27,  3.17it/s, est. speed input: 3365.58 toks/s, output: 3.29 toks/s]
Processed prompts:  67%|   | 172/256 [00:52<00:26,  3.17it/s, est. speed input: 3364.21 toks/s, output: 3.29 toks/s]
Processed prompts:  68%|   | 174/256 [00:52<00:25,  3.17it/s, est. speed input: 3362.72 toks/s, output: 3.28 toks/s]
Processed prompts:  69%|   | 176/256 [00:53<00:25,  3.17it/s, est. speed input: 3361.22 toks/s, output: 3.28 toks/s]
Processed prompts:  70%|   | 178/256 [00:54<00:24,  3.17it/s, est. speed input: 3360.07 toks/s, output: 3.28 toks/s]
Processed prompts:  70%|   | 180/256 [00:54<00:23,  3.17it/s, est. speed input: 3358.59 toks/s, output: 3.28 toks/s]
Processed prompts:  71%|   | 182/256 [00:55<00:23,  3.17it/s, est. speed input: 3357.40 toks/s, output: 3.28 toks/s]
Processed prompts:  72%|  | 184/256 [00:56<00:22,  3.17it/s, est. speed input: 3355.99 toks/s, output: 3.28 toks/s]
Processed prompts:  73%|  | 186/256 [00:56<00:22,  3.16it/s, est. speed input: 3354.48 toks/s, output: 3.28 toks/s]
Processed prompts:  73%|  | 188/256 [00:57<00:21,  3.16it/s, est. speed input: 3353.24 toks/s, output: 3.27 toks/s]
Processed prompts:  74%|  | 190/256 [00:58<00:20,  3.16it/s, est. speed input: 3351.94 toks/s, output: 3.27 toks/s]
Processed prompts:  75%|  | 192/256 [00:58<00:20,  3.17it/s, est. speed input: 3350.90 toks/s, output: 3.27 toks/s]
Processed prompts:  76%|  | 194/256 [00:59<00:19,  3.16it/s, est. speed input: 3349.48 toks/s, output: 3.27 toks/s]
Processed prompts:  77%|  | 196/256 [00:59<00:19,  3.15it/s, est. speed input: 3348.08 toks/s, output: 3.27 toks/s]
Processed prompts:  77%|  | 198/256 [01:00<00:18,  3.15it/s, est. speed input: 3346.84 toks/s, output: 3.27 toks/s]
Processed prompts:  78%|  | 200/256 [01:01<00:17,  3.16it/s, est. speed input: 3345.78 toks/s, output: 3.27 toks/s]
Processed prompts:  79%|  | 202/256 [01:01<00:14,  3.60it/s, est. speed input: 3358.76 toks/s, output: 3.28 toks/s]
Processed prompts:  80%|  | 204/256 [01:02<00:15,  3.45it/s, est. speed input: 3357.41 toks/s, output: 3.28 toks/s]
Processed prompts:  80%|  | 206/256 [01:02<00:14,  3.36it/s, est. speed input: 3356.25 toks/s, output: 3.28 toks/s]
Processed prompts:  81%| | 208/256 [01:03<00:14,  3.30it/s, est. speed input: 3354.99 toks/s, output: 3.28 toks/s]
Processed prompts:  82%| | 210/256 [01:04<00:14,  3.25it/s, est. speed input: 3353.72 toks/s, output: 3.28 toks/s]
Processed prompts:  83%| | 212/256 [01:04<00:13,  3.23it/s, est. speed input: 3352.72 toks/s, output: 3.27 toks/s]
Processed prompts:  84%| | 214/256 [01:05<00:13,  3.21it/s, est. speed input: 3351.58 toks/s, output: 3.27 toks/s]
Processed prompts:  84%| | 216/256 [01:06<00:12,  3.19it/s, est. speed input: 3350.40 toks/s, output: 3.27 toks/s]
Processed prompts:  85%| | 218/256 [01:06<00:11,  3.18it/s, est. speed input: 3349.29 toks/s, output: 3.27 toks/s]
Processed prompts:  86%| | 220/256 [01:07<00:11,  3.17it/s, est. speed input: 3348.04 toks/s, output: 3.27 toks/s]
Processed prompts:  87%| | 222/256 [01:07<00:10,  3.17it/s, est. speed input: 3347.15 toks/s, output: 3.27 toks/s]
Processed prompts:  88%| | 224/256 [01:08<00:10,  3.16it/s, est. speed input: 3346.03 toks/s, output: 3.27 toks/s]
Processed prompts:  88%| | 226/256 [01:09<00:09,  3.17it/s, est. speed input: 3345.29 toks/s, output: 3.27 toks/s]
Processed prompts:  89%| | 228/256 [01:09<00:08,  3.16it/s, est. speed input: 3344.16 toks/s, output: 3.27 toks/s]
Processed prompts:  90%| | 230/256 [01:10<00:08,  3.16it/s, est. speed input: 3343.22 toks/s, output: 3.26 toks/s]
Processed prompts:  91%| | 232/256 [01:11<00:07,  3.16it/s, est. speed input: 3342.31 toks/s, output: 3.26 toks/s]
Processed prompts:  91%|| 234/256 [01:11<00:06,  3.16it/s, est. speed input: 3341.22 toks/s, output: 3.26 toks/s]
Processed prompts:  92%|| 236/256 [01:12<00:06,  3.16it/s, est. speed input: 3340.42 toks/s, output: 3.26 toks/s]
Processed prompts:  93%|| 238/256 [01:12<00:05,  3.15it/s, est. speed input: 3339.29 toks/s, output: 3.26 toks/s]
Processed prompts:  94%|| 240/256 [01:13<00:05,  3.16it/s, est. speed input: 3338.41 toks/s, output: 3.26 toks/s]
Processed prompts:  95%|| 242/256 [01:14<00:04,  3.16it/s, est. speed input: 3337.49 toks/s, output: 3.26 toks/s]
Processed prompts:  95%|| 244/256 [01:14<00:03,  3.16it/s, est. speed input: 3336.63 toks/s, output: 3.26 toks/s]
Processed prompts:  96%|| 246/256 [01:15<00:03,  3.16it/s, est. speed input: 3335.86 toks/s, output: 3.26 toks/s]
Processed prompts:  97%|| 248/256 [01:16<00:02,  3.16it/s, est. speed input: 3334.91 toks/s, output: 3.26 toks/s]
Processed prompts:  98%|| 250/256 [01:16<00:01,  3.16it/s, est. speed input: 3334.20 toks/s, output: 3.26 toks/s]
Processed prompts:  98%|| 252/256 [01:17<00:01,  3.16it/s, est. speed input: 3333.30 toks/s, output: 3.26 toks/s]
Processed prompts:  99%|| 254/256 [01:18<00:00,  3.15it/s, est. speed input: 3332.33 toks/s, output: 3.25 toks/s]
Processed prompts: 100%|| 256/256 [01:18<00:00,  3.71it/s, est. speed input: 3345.05 toks/s, output: 3.27 toks/s]
Processed prompts: 100%|| 256/256 [01:18<00:00,  3.71it/s, est. speed input: 3345.05 toks/s, output: 3.27 toks/s]
Processed prompts: 100%|| 256/256 [01:18<00:00,  3.27it/s, est. speed input: 3345.05 toks/s, output: 3.27 toks/s]
[rank0]:[W127 11:43:01.386253029 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-27 11:43:15
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 11:43:24 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 11:43:24 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2572858) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2572858) WARNING 01-27 11:45:45 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.16 requests/s, 3243.76 total tokens/s, 3.16 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-27 11:43:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:43:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:43:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:43:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:43:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:43:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:43:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:43:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 11:43:28] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:43:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:43:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:43:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:43:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:43:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:43:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:43:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:43:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2572858) [2026-01-27 11:43:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2572858) [2026-01-27 11:43:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2572858) [2026-01-27 11:43:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2572858) [2026-01-27 11:43:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2572858) [2026-01-27 11:43:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2572858) [2026-01-27 11:43:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2572858) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2572858) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.66s/it]
(EngineCore_DP0 pid=2572858) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:54, 27.12s/it]
(EngineCore_DP0 pid=2572858) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:20<00:29, 29.11s/it]
(EngineCore_DP0 pid=2572858) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 33.70s/it]
(EngineCore_DP0 pid=2572858) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 30.23s/it]
(EngineCore_DP0 pid=2572858) 
(EngineCore_DP0 pid=2572858) [2026-01-27 11:45:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2572858) [2026-01-27 11:45:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=2572858) [2026-01-27 11:45:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2572858) [2026-01-27 11:45:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=2572858) [2026-01-27 11:45:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2572858) [2026-01-27 11:45:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=2572858) [2026-01-27 11:45:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2572858) [2026-01-27 11:45:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=2572858) 2026-01-27 11:45:40,974 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2572858) 2026-01-27 11:45:41,536 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/512 [00:00<07:29,  1.14it/s]
Adding requests:   0%|          | 2/512 [00:01<04:05,  2.08it/s]
Adding requests:   1%|          | 3/512 [00:01<02:39,  3.18it/s]
Adding requests:   1%|          | 5/512 [00:01<01:31,  5.56it/s]
Adding requests:   2%|         | 8/512 [00:01<00:52,  9.52it/s]
Adding requests:   2%|         | 12/512 [00:01<00:33, 15.01it/s]
Adding requests:   4%|         | 18/512 [00:01<00:20, 24.29it/s]
Adding requests:   7%|         | 35/512 [00:01<00:08, 57.67it/s]
Adding requests:  11%|         | 54/512 [00:01<00:05, 89.16it/s]
Adding requests:  15%|        | 79/512 [00:02<00:03, 130.73it/s]
Adding requests:  23%|       | 118/512 [00:02<00:01, 200.01it/s]
Adding requests:  31%|       | 158/512 [00:02<00:01, 254.94it/s]
Adding requests:  38%|      | 197/512 [00:02<00:01, 291.83it/s]
Adding requests:  46%|     | 237/512 [00:02<00:00, 321.35it/s]
Adding requests:  54%|    | 277/512 [00:02<00:00, 342.91it/s]
Adding requests:  62%|   | 318/512 [00:02<00:00, 361.25it/s]
Adding requests:  70%|   | 358/512 [00:02<00:00, 371.66it/s]
Adding requests:  79%|  | 402/512 [00:02<00:00, 391.34it/s]
Adding requests:  87%| | 445/512 [00:02<00:00, 399.32it/s]
Adding requests:  95%|| 486/512 [00:03<00:00, 401.61it/s]
Adding requests: 100%|| 512/512 [00:03<00:00, 165.42it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 5/512 [00:00<00:41, 12.20it/s, est. speed input: 12488.77 toks/s, output: 12.20 toks/s]
Processed prompts:   2%|         | 9/512 [00:01<01:42,  4.91it/s, est. speed input: 5588.09 toks/s, output: 5.46 toks/s]  
Processed prompts:   3%|         | 13/512 [00:02<02:04,  4.00it/s, est. speed input: 4604.79 toks/s, output: 4.50 toks/s]
Processed prompts:   3%|         | 17/512 [00:04<02:15,  3.66it/s, est. speed input: 4206.50 toks/s, output: 4.11 toks/s]
Processed prompts:   4%|         | 21/512 [00:05<02:20,  3.49it/s, est. speed input: 3997.62 toks/s, output: 3.90 toks/s]
Processed prompts:   5%|         | 25/512 [00:06<02:23,  3.40it/s, est. speed input: 3866.24 toks/s, output: 3.78 toks/s]
Processed prompts:   6%|         | 29/512 [00:07<02:24,  3.33it/s, est. speed input: 3774.16 toks/s, output: 3.69 toks/s]
Processed prompts:   6%|         | 33/512 [00:09<02:25,  3.29it/s, est. speed input: 3707.06 toks/s, output: 3.62 toks/s]
Processed prompts:   7%|         | 37/512 [00:10<02:25,  3.26it/s, est. speed input: 3655.08 toks/s, output: 3.57 toks/s]
Processed prompts:   8%|         | 41/512 [00:11<02:25,  3.24it/s, est. speed input: 3613.61 toks/s, output: 3.53 toks/s]
Processed prompts:   9%|         | 45/512 [00:12<02:24,  3.23it/s, est. speed input: 3581.75 toks/s, output: 3.50 toks/s]
Processed prompts:  10%|         | 49/512 [00:14<02:23,  3.22it/s, est. speed input: 3555.85 toks/s, output: 3.47 toks/s]
Processed prompts:  10%|         | 53/512 [00:15<02:22,  3.22it/s, est. speed input: 3532.73 toks/s, output: 3.45 toks/s]
Processed prompts:  11%|         | 57/512 [00:16<02:21,  3.21it/s, est. speed input: 3512.91 toks/s, output: 3.43 toks/s]
Processed prompts:  12%|        | 61/512 [00:17<02:20,  3.20it/s, est. speed input: 3495.36 toks/s, output: 3.41 toks/s]
Processed prompts:  13%|        | 65/512 [00:19<02:19,  3.20it/s, est. speed input: 3480.82 toks/s, output: 3.40 toks/s]
Processed prompts:  13%|        | 69/512 [00:20<02:18,  3.19it/s, est. speed input: 3466.80 toks/s, output: 3.39 toks/s]
Processed prompts:  14%|        | 73/512 [00:21<02:17,  3.19it/s, est. speed input: 3455.09 toks/s, output: 3.37 toks/s]
Processed prompts:  15%|        | 77/512 [00:22<02:16,  3.19it/s, est. speed input: 3444.79 toks/s, output: 3.36 toks/s]
Processed prompts:  16%|        | 81/512 [00:24<02:15,  3.18it/s, est. speed input: 3434.34 toks/s, output: 3.35 toks/s]
Processed prompts:  17%|        | 85/512 [00:25<02:14,  3.18it/s, est. speed input: 3425.58 toks/s, output: 3.35 toks/s]
Processed prompts:  17%|        | 89/512 [00:26<02:12,  3.18it/s, est. speed input: 3417.67 toks/s, output: 3.34 toks/s]
Processed prompts:  18%|        | 93/512 [00:27<02:11,  3.18it/s, est. speed input: 3410.56 toks/s, output: 3.33 toks/s]
Processed prompts:  19%|        | 97/512 [00:29<02:10,  3.19it/s, est. speed input: 3404.38 toks/s, output: 3.32 toks/s]
Processed prompts:  20%|        | 101/512 [00:30<02:09,  3.19it/s, est. speed input: 3398.56 toks/s, output: 3.32 toks/s]
Processed prompts:  21%|        | 105/512 [00:31<02:07,  3.18it/s, est. speed input: 3392.56 toks/s, output: 3.31 toks/s]
Processed prompts:  21%|       | 109/512 [00:32<02:06,  3.18it/s, est. speed input: 3387.58 toks/s, output: 3.31 toks/s]
Processed prompts:  22%|       | 113/512 [00:34<02:05,  3.18it/s, est. speed input: 3382.82 toks/s, output: 3.30 toks/s]
Processed prompts:  23%|       | 117/512 [00:35<02:03,  3.19it/s, est. speed input: 3378.92 toks/s, output: 3.30 toks/s]
Processed prompts:  24%|       | 121/512 [00:36<02:02,  3.18it/s, est. speed input: 3374.68 toks/s, output: 3.30 toks/s]
Processed prompts:  24%|       | 125/512 [00:37<02:01,  3.18it/s, est. speed input: 3370.36 toks/s, output: 3.29 toks/s]
Processed prompts:  25%|       | 129/512 [00:39<02:00,  3.18it/s, est. speed input: 3366.87 toks/s, output: 3.29 toks/s]
Processed prompts:  26%|       | 133/512 [00:40<01:59,  3.18it/s, est. speed input: 3363.53 toks/s, output: 3.28 toks/s]
Processed prompts:  27%|       | 137/512 [00:41<01:57,  3.18it/s, est. speed input: 3360.14 toks/s, output: 3.28 toks/s]
Processed prompts:  28%|       | 141/512 [00:43<01:56,  3.18it/s, est. speed input: 3357.51 toks/s, output: 3.28 toks/s]
Processed prompts:  28%|       | 145/512 [00:44<01:55,  3.18it/s, est. speed input: 3354.10 toks/s, output: 3.28 toks/s]
Processed prompts:  29%|       | 149/512 [00:45<01:54,  3.18it/s, est. speed input: 3351.69 toks/s, output: 3.27 toks/s]
Processed prompts:  30%|       | 153/512 [00:46<01:52,  3.18it/s, est. speed input: 3349.23 toks/s, output: 3.27 toks/s]
Processed prompts:  31%|       | 157/512 [00:48<01:51,  3.18it/s, est. speed input: 3346.69 toks/s, output: 3.27 toks/s]
Processed prompts:  31%|      | 161/512 [00:49<01:50,  3.18it/s, est. speed input: 3344.22 toks/s, output: 3.27 toks/s]
Processed prompts:  32%|      | 165/512 [00:50<01:49,  3.18it/s, est. speed input: 3341.88 toks/s, output: 3.26 toks/s]
Processed prompts:  33%|      | 169/512 [00:51<01:48,  3.17it/s, est. speed input: 3339.22 toks/s, output: 3.26 toks/s]
Processed prompts:  34%|      | 173/512 [00:53<01:46,  3.17it/s, est. speed input: 3337.20 toks/s, output: 3.26 toks/s]
Processed prompts:  35%|      | 177/512 [00:54<01:45,  3.17it/s, est. speed input: 3335.06 toks/s, output: 3.26 toks/s]
Processed prompts:  35%|      | 181/512 [00:55<01:44,  3.17it/s, est. speed input: 3333.30 toks/s, output: 3.26 toks/s]
Processed prompts:  36%|      | 185/512 [00:56<01:43,  3.17it/s, est. speed input: 3331.48 toks/s, output: 3.25 toks/s]
Processed prompts:  37%|      | 189/512 [00:58<01:41,  3.17it/s, est. speed input: 3329.37 toks/s, output: 3.25 toks/s]
Processed prompts:  38%|      | 193/512 [00:59<01:40,  3.17it/s, est. speed input: 3327.62 toks/s, output: 3.25 toks/s]
Processed prompts:  38%|      | 197/512 [01:00<01:39,  3.17it/s, est. speed input: 3325.96 toks/s, output: 3.25 toks/s]
Processed prompts:  39%|      | 201/512 [01:01<01:31,  3.38it/s, est. speed input: 3338.63 toks/s, output: 3.26 toks/s]
Processed prompts:  40%|      | 205/512 [01:02<01:32,  3.32it/s, est. speed input: 3336.71 toks/s, output: 3.26 toks/s]
Processed prompts:  41%|      | 209/512 [01:04<01:32,  3.27it/s, est. speed input: 3334.89 toks/s, output: 3.26 toks/s]
Processed prompts:  42%|     | 213/512 [01:05<01:32,  3.24it/s, est. speed input: 3332.99 toks/s, output: 3.25 toks/s]
Processed prompts:  42%|     | 217/512 [01:06<01:31,  3.21it/s, est. speed input: 3331.23 toks/s, output: 3.25 toks/s]
Processed prompts:  43%|     | 221/512 [01:07<01:30,  3.20it/s, est. speed input: 3329.77 toks/s, output: 3.25 toks/s]
Processed prompts:  44%|     | 225/512 [01:09<01:30,  3.19it/s, est. speed input: 3327.96 toks/s, output: 3.25 toks/s]
Processed prompts:  45%|     | 229/512 [01:10<01:28,  3.19it/s, est. speed input: 3326.72 toks/s, output: 3.25 toks/s]
Processed prompts:  46%|     | 233/512 [01:11<01:27,  3.18it/s, est. speed input: 3325.23 toks/s, output: 3.25 toks/s]
Processed prompts:  46%|     | 237/512 [01:13<01:26,  3.17it/s, est. speed input: 3323.56 toks/s, output: 3.25 toks/s]
Processed prompts:  47%|     | 241/512 [01:14<01:25,  3.17it/s, est. speed input: 3322.39 toks/s, output: 3.24 toks/s]
Processed prompts:  48%|     | 245/512 [01:15<01:24,  3.17it/s, est. speed input: 3321.00 toks/s, output: 3.24 toks/s]
Processed prompts:  49%|     | 249/512 [01:16<01:23,  3.17it/s, est. speed input: 3319.59 toks/s, output: 3.24 toks/s]
Processed prompts:  49%|     | 253/512 [01:18<01:21,  3.17it/s, est. speed input: 3318.31 toks/s, output: 3.24 toks/s]
Processed prompts:  50%|     | 257/512 [01:19<01:20,  3.16it/s, est. speed input: 3316.73 toks/s, output: 3.24 toks/s]
Processed prompts:  51%|     | 261/512 [01:20<01:19,  3.17it/s, est. speed input: 3315.79 toks/s, output: 3.24 toks/s]
Processed prompts:  52%|    | 265/512 [01:21<01:18,  3.16it/s, est. speed input: 3314.46 toks/s, output: 3.24 toks/s]
Processed prompts:  53%|    | 269/512 [01:23<01:16,  3.16it/s, est. speed input: 3313.21 toks/s, output: 3.24 toks/s]
Processed prompts:  53%|    | 273/512 [01:24<01:15,  3.16it/s, est. speed input: 3312.12 toks/s, output: 3.23 toks/s]
Processed prompts:  54%|    | 277/512 [01:25<01:14,  3.16it/s, est. speed input: 3310.76 toks/s, output: 3.23 toks/s]
Processed prompts:  55%|    | 281/512 [01:26<01:13,  3.16it/s, est. speed input: 3309.72 toks/s, output: 3.23 toks/s]
Processed prompts:  56%|    | 285/512 [01:28<01:11,  3.16it/s, est. speed input: 3308.59 toks/s, output: 3.23 toks/s]
Processed prompts:  56%|    | 289/512 [01:29<01:10,  3.16it/s, est. speed input: 3307.53 toks/s, output: 3.23 toks/s]
Processed prompts:  57%|    | 293/512 [01:30<01:09,  3.16it/s, est. speed input: 3306.47 toks/s, output: 3.23 toks/s]
Processed prompts:  58%|    | 297/512 [01:32<01:08,  3.15it/s, est. speed input: 3305.31 toks/s, output: 3.23 toks/s]
Processed prompts:  59%|    | 301/512 [01:33<01:06,  3.15it/s, est. speed input: 3304.30 toks/s, output: 3.23 toks/s]
Processed prompts:  60%|    | 305/512 [01:34<01:01,  3.39it/s, est. speed input: 3313.51 toks/s, output: 3.24 toks/s]
Processed prompts:  60%|    | 309/512 [01:35<01:01,  3.32it/s, est. speed input: 3312.60 toks/s, output: 3.23 toks/s]
Processed prompts:  61%|    | 313/512 [01:36<01:00,  3.27it/s, est. speed input: 3311.52 toks/s, output: 3.23 toks/s]
Processed prompts:  62%|   | 317/512 [01:38<01:00,  3.24it/s, est. speed input: 3310.61 toks/s, output: 3.23 toks/s]
Processed prompts:  63%|   | 321/512 [01:39<00:59,  3.21it/s, est. speed input: 3309.58 toks/s, output: 3.23 toks/s]
Processed prompts:  63%|   | 325/512 [01:40<00:58,  3.19it/s, est. speed input: 3308.32 toks/s, output: 3.23 toks/s]
Processed prompts:  64%|   | 329/512 [01:41<00:57,  3.18it/s, est. speed input: 3307.35 toks/s, output: 3.23 toks/s]
Processed prompts:  65%|   | 333/512 [01:43<00:56,  3.17it/s, est. speed input: 3306.43 toks/s, output: 3.23 toks/s]
Processed prompts:  66%|   | 337/512 [01:44<00:55,  3.17it/s, est. speed input: 3305.55 toks/s, output: 3.23 toks/s]
Processed prompts:  67%|   | 341/512 [01:45<00:54,  3.16it/s, est. speed input: 3304.69 toks/s, output: 3.23 toks/s]
Processed prompts:  67%|   | 345/512 [01:46<00:52,  3.16it/s, est. speed input: 3303.54 toks/s, output: 3.23 toks/s]
Processed prompts:  68%|   | 349/512 [01:48<00:51,  3.16it/s, est. speed input: 3302.83 toks/s, output: 3.23 toks/s]
Processed prompts:  69%|   | 353/512 [01:49<00:50,  3.16it/s, est. speed input: 3302.01 toks/s, output: 3.22 toks/s]
Processed prompts:  70%|   | 357/512 [01:50<00:49,  3.16it/s, est. speed input: 3301.20 toks/s, output: 3.22 toks/s]
Processed prompts:  71%|   | 361/512 [01:52<00:47,  3.16it/s, est. speed input: 3300.48 toks/s, output: 3.22 toks/s]
Processed prompts:  71%|  | 365/512 [01:53<00:46,  3.15it/s, est. speed input: 3299.54 toks/s, output: 3.22 toks/s]
Processed prompts:  72%|  | 369/512 [01:54<00:45,  3.16it/s, est. speed input: 3298.97 toks/s, output: 3.22 toks/s]
Processed prompts:  73%|  | 373/512 [01:55<00:44,  3.16it/s, est. speed input: 3298.22 toks/s, output: 3.22 toks/s]
Processed prompts:  74%|  | 377/512 [01:57<00:42,  3.16it/s, est. speed input: 3297.55 toks/s, output: 3.22 toks/s]
Processed prompts:  74%|  | 381/512 [01:58<00:41,  3.16it/s, est. speed input: 3296.84 toks/s, output: 3.22 toks/s]
Processed prompts:  75%|  | 385/512 [01:59<00:40,  3.15it/s, est. speed input: 3296.00 toks/s, output: 3.22 toks/s]
Processed prompts:  76%|  | 389/512 [02:00<00:38,  3.15it/s, est. speed input: 3295.35 toks/s, output: 3.22 toks/s]
Processed prompts:  77%|  | 393/512 [02:02<00:37,  3.16it/s, est. speed input: 3294.73 toks/s, output: 3.22 toks/s]
Processed prompts:  78%|  | 397/512 [02:03<00:36,  3.16it/s, est. speed input: 3294.09 toks/s, output: 3.22 toks/s]
Processed prompts:  78%|  | 401/512 [02:04<00:35,  3.16it/s, est. speed input: 3293.45 toks/s, output: 3.22 toks/s]
Processed prompts:  79%|  | 405/512 [02:05<00:33,  3.15it/s, est. speed input: 3292.69 toks/s, output: 3.22 toks/s]
Processed prompts:  80%|  | 409/512 [02:07<00:32,  3.15it/s, est. speed input: 3292.10 toks/s, output: 3.21 toks/s]
Processed prompts:  81%|  | 413/512 [02:08<00:31,  3.16it/s, est. speed input: 3291.53 toks/s, output: 3.21 toks/s]
Processed prompts:  81%| | 417/512 [02:09<00:30,  3.16it/s, est. speed input: 3291.11 toks/s, output: 3.21 toks/s]
Processed prompts:  82%| | 421/512 [02:11<00:28,  3.16it/s, est. speed input: 3290.51 toks/s, output: 3.21 toks/s]
Processed prompts:  83%| | 425/512 [02:12<00:27,  3.15it/s, est. speed input: 3289.84 toks/s, output: 3.21 toks/s]
Processed prompts:  84%| | 429/512 [02:13<00:26,  3.15it/s, est. speed input: 3289.28 toks/s, output: 3.21 toks/s]
Processed prompts:  85%| | 433/512 [02:14<00:23,  3.39it/s, est. speed input: 3295.87 toks/s, output: 3.22 toks/s]
Processed prompts:  85%| | 437/512 [02:15<00:22,  3.32it/s, est. speed input: 3295.30 toks/s, output: 3.22 toks/s]
Processed prompts:  86%| | 441/512 [02:17<00:21,  3.27it/s, est. speed input: 3294.68 toks/s, output: 3.22 toks/s]
Processed prompts:  87%| | 445/512 [02:18<00:20,  3.23it/s, est. speed input: 3294.05 toks/s, output: 3.22 toks/s]
Processed prompts:  88%| | 449/512 [02:19<00:19,  3.21it/s, est. speed input: 3293.47 toks/s, output: 3.22 toks/s]
Processed prompts:  88%| | 453/512 [02:20<00:18,  3.19it/s, est. speed input: 3292.92 toks/s, output: 3.22 toks/s]
Processed prompts:  89%| | 457/512 [02:22<00:17,  3.18it/s, est. speed input: 3292.33 toks/s, output: 3.22 toks/s]
Processed prompts:  90%| | 461/512 [02:23<00:16,  3.17it/s, est. speed input: 3291.77 toks/s, output: 3.21 toks/s]
Processed prompts:  91%| | 465/512 [02:24<00:14,  3.17it/s, est. speed input: 3291.31 toks/s, output: 3.21 toks/s]
Processed prompts:  92%|| 469/512 [02:25<00:13,  3.17it/s, est. speed input: 3290.86 toks/s, output: 3.21 toks/s]
Processed prompts:  92%|| 473/512 [02:27<00:12,  3.16it/s, est. speed input: 3290.25 toks/s, output: 3.21 toks/s]
Processed prompts:  93%|| 477/512 [02:28<00:11,  3.16it/s, est. speed input: 3289.77 toks/s, output: 3.21 toks/s]
Processed prompts:  94%|| 481/512 [02:29<00:09,  3.16it/s, est. speed input: 3289.31 toks/s, output: 3.21 toks/s]
Processed prompts:  95%|| 485/512 [02:31<00:08,  3.16it/s, est. speed input: 3288.90 toks/s, output: 3.21 toks/s]
Processed prompts:  96%|| 489/512 [02:32<00:07,  3.16it/s, est. speed input: 3288.41 toks/s, output: 3.21 toks/s]
Processed prompts:  96%|| 493/512 [02:33<00:06,  3.15it/s, est. speed input: 3287.84 toks/s, output: 3.21 toks/s]
Processed prompts:  97%|| 497/512 [02:34<00:04,  3.16it/s, est. speed input: 3287.42 toks/s, output: 3.21 toks/s]
Processed prompts:  98%|| 501/512 [02:36<00:03,  3.16it/s, est. speed input: 3287.06 toks/s, output: 3.21 toks/s]
Processed prompts:  99%|| 505/512 [02:37<00:02,  3.16it/s, est. speed input: 3286.60 toks/s, output: 3.21 toks/s]
Processed prompts:  99%|| 509/512 [02:38<00:00,  3.15it/s, est. speed input: 3286.03 toks/s, output: 3.21 toks/s]
Processed prompts: 100%|| 512/512 [02:38<00:00,  3.15it/s, est. speed input: 3305.40 toks/s, output: 3.23 toks/s]
Processed prompts: 100%|| 512/512 [02:38<00:00,  3.23it/s, est. speed input: 3305.40 toks/s, output: 3.23 toks/s]
[rank0]:[W127 11:48:28.168259647 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-27 11:48:42
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 11:48:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 11:48:53 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2577548) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2577548) WARNING 01-27 11:51:20 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.19 requests/s, 3265.04 total tokens/s, 3.19 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-27 11:48:52] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:48:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:48:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:48:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:48:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:48:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:48:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:48:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 11:48:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:48:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:48:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:48:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:48:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:48:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:48:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:48:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:48:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2577548) [2026-01-27 11:48:57] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2577548) [2026-01-27 11:48:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2577548) [2026-01-27 11:48:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2577548) [2026-01-27 11:48:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2577548) [2026-01-27 11:48:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2577548) [2026-01-27 11:48:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2577548) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2577548) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:26,  8.86s/it]
(EngineCore_DP0 pid=2577548) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:49<00:54, 27.30s/it]
(EngineCore_DP0 pid=2577548) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:20<00:29, 29.21s/it]
(EngineCore_DP0 pid=2577548) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 33.88s/it]
(EngineCore_DP0 pid=2577548) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 30.39s/it]
(EngineCore_DP0 pid=2577548) 
(EngineCore_DP0 pid=2577548) [2026-01-27 11:51:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2577548) [2026-01-27 11:51:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=2577548) [2026-01-27 11:51:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2577548) [2026-01-27 11:51:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=2577548) [2026-01-27 11:51:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2577548) [2026-01-27 11:51:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=2577548) [2026-01-27 11:51:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2577548) [2026-01-27 11:51:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=2577548) 2026-01-27 11:51:10,828 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2577548) 2026-01-27 11:51:12,115 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/1024 [00:00<14:13,  1.20it/s]
Adding requests:   0%|          | 2/1024 [00:00<07:13,  2.36it/s]
Adding requests:   0%|          | 4/1024 [00:01<03:24,  4.99it/s]
Adding requests:   1%|          | 7/1024 [00:01<01:52,  9.01it/s]
Adding requests:   1%|          | 11/1024 [00:01<01:07, 15.03it/s]
Adding requests:   2%|         | 16/1024 [00:01<00:45, 22.34it/s]
Adding requests:   4%|         | 38/1024 [00:01<00:14, 68.60it/s]
Adding requests:   7%|         | 68/1024 [00:01<00:07, 126.40it/s]
Adding requests:  10%|         | 100/1024 [00:01<00:05, 176.89it/s]
Adding requests:  13%|        | 137/1024 [00:01<00:03, 229.27it/s]
Adding requests:  17%|        | 177/1024 [00:01<00:03, 276.59it/s]
Adding requests:  21%|       | 220/1024 [00:02<00:02, 320.33it/s]
Adding requests:  25%|       | 260/1024 [00:02<00:02, 341.64it/s]
Adding requests:  29%|       | 302/1024 [00:02<00:01, 363.21it/s]
Adding requests:  33%|      | 342/1024 [00:02<00:01, 373.75it/s]
Adding requests:  38%|      | 386/1024 [00:02<00:01, 392.53it/s]
Adding requests:  42%|     | 434/1024 [00:02<00:01, 416.14it/s]
Adding requests:  47%|     | 477/1024 [00:02<00:01, 411.34it/s]
Adding requests:  51%|    | 525/1024 [00:02<00:01, 431.20it/s]
Adding requests:  56%|    | 569/1024 [00:02<00:01, 426.21it/s]
Adding requests:  60%|    | 612/1024 [00:02<00:00, 423.62it/s]
Adding requests:  64%|   | 655/1024 [00:03<00:00, 407.48it/s]
Adding requests:  68%|   | 700/1024 [00:03<00:00, 418.92it/s]
Adding requests:  73%|  | 743/1024 [00:03<00:00, 417.55it/s]
Adding requests:  77%|  | 787/1024 [00:03<00:00, 423.70it/s]
Adding requests:  81%| | 832/1024 [00:03<00:00, 428.72it/s]
Adding requests:  85%| | 875/1024 [00:03<00:00, 411.32it/s]
Adding requests:  90%| | 917/1024 [00:03<00:00, 409.64it/s]
Adding requests:  94%|| 959/1024 [00:03<00:00, 410.11it/s]
Adding requests:  98%|| 1001/1024 [00:03<00:00, 402.34it/s]
Adding requests: 100%|| 1024/1024 [00:03<00:00, 256.91it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 9/1024 [00:01<03:42,  4.56it/s, est. speed input: 4667.50 toks/s, output: 4.56 toks/s]
Processed prompts:   2%|         | 17/1024 [00:04<04:31,  3.71it/s, est. speed input: 3915.15 toks/s, output: 3.82 toks/s]
Processed prompts:   2%|         | 25/1024 [00:06<04:47,  3.48it/s, est. speed input: 3696.05 toks/s, output: 3.61 toks/s]
Processed prompts:   3%|         | 33/1024 [00:09<04:53,  3.37it/s, est. speed input: 3591.85 toks/s, output: 3.51 toks/s]
Processed prompts:   4%|         | 41/1024 [00:11<04:56,  3.32it/s, est. speed input: 3531.91 toks/s, output: 3.45 toks/s]
Processed prompts:   5%|         | 49/1024 [00:14<04:56,  3.28it/s, est. speed input: 3489.98 toks/s, output: 3.41 toks/s]
Processed prompts:   6%|         | 57/1024 [00:16<04:56,  3.26it/s, est. speed input: 3461.81 toks/s, output: 3.38 toks/s]
Processed prompts:   6%|         | 65/1024 [00:19<04:55,  3.25it/s, est. speed input: 3439.90 toks/s, output: 3.36 toks/s]
Processed prompts:   7%|         | 73/1024 [00:21<04:54,  3.23it/s, est. speed input: 3422.09 toks/s, output: 3.34 toks/s]
Processed prompts:   8%|         | 81/1024 [00:24<04:52,  3.23it/s, est. speed input: 3408.38 toks/s, output: 3.33 toks/s]
Processed prompts:   9%|         | 89/1024 [00:26<04:50,  3.22it/s, est. speed input: 3396.69 toks/s, output: 3.32 toks/s]
Processed prompts:   9%|         | 97/1024 [00:29<04:48,  3.21it/s, est. speed input: 3386.39 toks/s, output: 3.31 toks/s]
Processed prompts:  10%|         | 105/1024 [00:31<04:46,  3.21it/s, est. speed input: 3377.66 toks/s, output: 3.30 toks/s]
Processed prompts:  11%|         | 113/1024 [00:34<04:44,  3.21it/s, est. speed input: 3370.58 toks/s, output: 3.29 toks/s]
Processed prompts:  12%|        | 121/1024 [00:36<04:41,  3.20it/s, est. speed input: 3364.00 toks/s, output: 3.29 toks/s]
Processed prompts:  13%|        | 129/1024 [00:39<04:39,  3.20it/s, est. speed input: 3358.02 toks/s, output: 3.28 toks/s]
Processed prompts:  13%|        | 137/1024 [00:41<04:37,  3.20it/s, est. speed input: 3352.90 toks/s, output: 3.27 toks/s]
Processed prompts:  14%|        | 145/1024 [00:44<04:35,  3.19it/s, est. speed input: 3347.66 toks/s, output: 3.27 toks/s]
Processed prompts:  15%|        | 153/1024 [00:46<04:32,  3.20it/s, est. speed input: 3343.65 toks/s, output: 3.27 toks/s]
Processed prompts:  16%|        | 161/1024 [00:49<04:30,  3.19it/s, est. speed input: 3339.42 toks/s, output: 3.26 toks/s]
Processed prompts:  17%|        | 169/1024 [00:51<04:28,  3.19it/s, est. speed input: 3335.60 toks/s, output: 3.26 toks/s]
Processed prompts:  17%|        | 177/1024 [00:54<04:25,  3.19it/s, est. speed input: 3332.15 toks/s, output: 3.25 toks/s]
Processed prompts:  18%|        | 185/1024 [00:56<04:23,  3.19it/s, est. speed input: 3328.87 toks/s, output: 3.25 toks/s]
Processed prompts:  19%|        | 193/1024 [00:59<04:20,  3.18it/s, est. speed input: 3325.84 toks/s, output: 3.25 toks/s]
Processed prompts:  20%|        | 201/1024 [01:01<04:11,  3.28it/s, est. speed input: 3335.76 toks/s, output: 3.26 toks/s]
Processed prompts:  20%|        | 209/1024 [01:04<04:11,  3.25it/s, est. speed input: 3332.55 toks/s, output: 3.25 toks/s]
Processed prompts:  21%|        | 217/1024 [01:06<04:10,  3.22it/s, est. speed input: 3329.39 toks/s, output: 3.25 toks/s]
Processed prompts:  22%|       | 225/1024 [01:09<04:08,  3.21it/s, est. speed input: 3327.00 toks/s, output: 3.25 toks/s]
Processed prompts:  23%|       | 233/1024 [01:11<04:07,  3.20it/s, est. speed input: 3324.15 toks/s, output: 3.25 toks/s]
Processed prompts:  24%|       | 241/1024 [01:14<04:05,  3.19it/s, est. speed input: 3321.99 toks/s, output: 3.24 toks/s]
Processed prompts:  24%|       | 249/1024 [01:16<04:03,  3.19it/s, est. speed input: 3319.71 toks/s, output: 3.24 toks/s]
Processed prompts:  25%|       | 257/1024 [01:19<04:00,  3.19it/s, est. speed input: 3317.55 toks/s, output: 3.24 toks/s]
Processed prompts:  26%|       | 265/1024 [01:21<03:58,  3.18it/s, est. speed input: 3315.76 toks/s, output: 3.24 toks/s]
Processed prompts:  27%|       | 273/1024 [01:24<03:55,  3.18it/s, est. speed input: 3313.94 toks/s, output: 3.24 toks/s]
Processed prompts:  27%|       | 281/1024 [01:26<03:53,  3.18it/s, est. speed input: 3312.43 toks/s, output: 3.23 toks/s]
Processed prompts:  28%|       | 289/1024 [01:29<03:50,  3.18it/s, est. speed input: 3311.07 toks/s, output: 3.23 toks/s]
Processed prompts:  29%|       | 297/1024 [01:31<03:48,  3.18it/s, est. speed input: 3309.52 toks/s, output: 3.23 toks/s]
Processed prompts:  30%|       | 305/1024 [01:34<03:39,  3.28it/s, est. speed input: 3316.74 toks/s, output: 3.24 toks/s]
Processed prompts:  31%|       | 313/1024 [01:36<03:38,  3.25it/s, est. speed input: 3315.29 toks/s, output: 3.24 toks/s]
Processed prompts:  31%|      | 321/1024 [01:39<03:37,  3.23it/s, est. speed input: 3313.84 toks/s, output: 3.24 toks/s]
Processed prompts:  32%|      | 329/1024 [01:41<03:36,  3.22it/s, est. speed input: 3312.57 toks/s, output: 3.23 toks/s]
Processed prompts:  33%|      | 337/1024 [01:44<03:34,  3.21it/s, est. speed input: 3311.52 toks/s, output: 3.23 toks/s]
Processed prompts:  34%|      | 345/1024 [01:46<03:32,  3.20it/s, est. speed input: 3310.16 toks/s, output: 3.23 toks/s]
Processed prompts:  34%|      | 353/1024 [01:49<03:29,  3.20it/s, est. speed input: 3309.17 toks/s, output: 3.23 toks/s]
Processed prompts:  35%|      | 361/1024 [01:51<03:27,  3.19it/s, est. speed input: 3308.05 toks/s, output: 3.23 toks/s]
Processed prompts:  36%|      | 369/1024 [01:54<03:25,  3.19it/s, est. speed input: 3307.15 toks/s, output: 3.23 toks/s]
Processed prompts:  37%|      | 377/1024 [01:56<03:22,  3.19it/s, est. speed input: 3306.09 toks/s, output: 3.23 toks/s]
Processed prompts:  38%|      | 385/1024 [01:59<03:20,  3.19it/s, est. speed input: 3305.11 toks/s, output: 3.23 toks/s]
Processed prompts:  38%|      | 393/1024 [02:01<03:18,  3.18it/s, est. speed input: 3304.10 toks/s, output: 3.23 toks/s]
Processed prompts:  39%|      | 401/1024 [02:04<03:15,  3.19it/s, est. speed input: 3303.38 toks/s, output: 3.23 toks/s]
Processed prompts:  40%|      | 409/1024 [02:06<03:13,  3.18it/s, est. speed input: 3302.40 toks/s, output: 3.22 toks/s]
Processed prompts:  41%|      | 417/1024 [02:09<03:10,  3.18it/s, est. speed input: 3301.55 toks/s, output: 3.22 toks/s]
Processed prompts:  42%|     | 425/1024 [02:11<03:08,  3.18it/s, est. speed input: 3300.77 toks/s, output: 3.22 toks/s]
Processed prompts:  42%|     | 433/1024 [02:14<03:00,  3.27it/s, est. speed input: 3305.65 toks/s, output: 3.23 toks/s]
Processed prompts:  43%|     | 441/1024 [02:16<02:59,  3.25it/s, est. speed input: 3305.06 toks/s, output: 3.23 toks/s]
Processed prompts:  44%|     | 449/1024 [02:19<02:57,  3.23it/s, est. speed input: 3304.31 toks/s, output: 3.23 toks/s]
Processed prompts:  45%|     | 457/1024 [02:21<02:56,  3.22it/s, est. speed input: 3303.43 toks/s, output: 3.23 toks/s]
Processed prompts:  45%|     | 465/1024 [02:24<02:54,  3.21it/s, est. speed input: 3302.78 toks/s, output: 3.23 toks/s]
Processed prompts:  46%|     | 473/1024 [02:26<02:52,  3.20it/s, est. speed input: 3302.02 toks/s, output: 3.22 toks/s]
Processed prompts:  47%|     | 481/1024 [02:29<02:49,  3.19it/s, est. speed input: 3301.29 toks/s, output: 3.22 toks/s]
Processed prompts:  48%|     | 489/1024 [02:31<02:47,  3.19it/s, est. speed input: 3300.62 toks/s, output: 3.22 toks/s]
Processed prompts:  49%|     | 497/1024 [02:34<02:45,  3.19it/s, est. speed input: 3299.87 toks/s, output: 3.22 toks/s]
Processed prompts:  49%|     | 505/1024 [02:36<02:42,  3.19it/s, est. speed input: 3299.33 toks/s, output: 3.22 toks/s]
Processed prompts:  50%|     | 513/1024 [02:39<02:40,  3.19it/s, est. speed input: 3298.66 toks/s, output: 3.22 toks/s]
Processed prompts:  51%|     | 521/1024 [02:41<02:37,  3.18it/s, est. speed input: 3297.99 toks/s, output: 3.22 toks/s]
Processed prompts:  52%|    | 529/1024 [02:44<02:35,  3.19it/s, est. speed input: 3297.57 toks/s, output: 3.22 toks/s]
Processed prompts:  52%|    | 537/1024 [02:46<02:32,  3.19it/s, est. speed input: 3297.03 toks/s, output: 3.22 toks/s]
Processed prompts:  53%|    | 545/1024 [02:49<02:30,  3.18it/s, est. speed input: 3296.35 toks/s, output: 3.22 toks/s]
Processed prompts:  54%|    | 553/1024 [02:51<02:27,  3.18it/s, est. speed input: 3295.90 toks/s, output: 3.22 toks/s]
Processed prompts:  55%|    | 561/1024 [02:54<02:25,  3.18it/s, est. speed input: 3295.31 toks/s, output: 3.22 toks/s]
Processed prompts:  56%|    | 569/1024 [02:56<02:22,  3.18it/s, est. speed input: 3294.89 toks/s, output: 3.22 toks/s]
Processed prompts:  56%|    | 577/1024 [02:59<02:20,  3.18it/s, est. speed input: 3294.40 toks/s, output: 3.22 toks/s]
Processed prompts:  57%|    | 585/1024 [03:01<02:17,  3.18it/s, est. speed input: 3293.80 toks/s, output: 3.22 toks/s]
Processed prompts:  58%|    | 593/1024 [03:04<02:15,  3.18it/s, est. speed input: 3293.45 toks/s, output: 3.22 toks/s]
Processed prompts:  59%|    | 601/1024 [03:06<02:12,  3.19it/s, est. speed input: 3293.08 toks/s, output: 3.22 toks/s]
Processed prompts:  59%|    | 609/1024 [03:09<02:10,  3.18it/s, est. speed input: 3292.53 toks/s, output: 3.22 toks/s]
Processed prompts:  60%|    | 617/1024 [03:11<02:07,  3.18it/s, est. speed input: 3292.19 toks/s, output: 3.22 toks/s]
Processed prompts:  61%|    | 625/1024 [03:14<02:05,  3.18it/s, est. speed input: 3291.77 toks/s, output: 3.21 toks/s]
Processed prompts:  62%|   | 633/1024 [03:16<02:02,  3.18it/s, est. speed input: 3291.33 toks/s, output: 3.21 toks/s]
Processed prompts:  63%|   | 641/1024 [03:19<02:00,  3.18it/s, est. speed input: 3290.96 toks/s, output: 3.21 toks/s]
Processed prompts:  63%|   | 649/1024 [03:21<01:57,  3.18it/s, est. speed input: 3290.49 toks/s, output: 3.21 toks/s]
Processed prompts:  64%|   | 657/1024 [03:24<01:55,  3.18it/s, est. speed input: 3290.14 toks/s, output: 3.21 toks/s]
Processed prompts:  65%|   | 665/1024 [03:26<01:52,  3.18it/s, est. speed input: 3289.79 toks/s, output: 3.21 toks/s]
Processed prompts:  66%|   | 673/1024 [03:29<01:50,  3.18it/s, est. speed input: 3289.37 toks/s, output: 3.21 toks/s]
Processed prompts:  67%|   | 681/1024 [03:32<01:47,  3.18it/s, est. speed input: 3289.12 toks/s, output: 3.21 toks/s]
Processed prompts:  67%|   | 689/1024 [03:34<01:45,  3.18it/s, est. speed input: 3288.76 toks/s, output: 3.21 toks/s]
Processed prompts:  68%|   | 697/1024 [03:37<01:42,  3.18it/s, est. speed input: 3288.35 toks/s, output: 3.21 toks/s]
Processed prompts:  69%|   | 705/1024 [03:39<01:40,  3.18it/s, est. speed input: 3288.08 toks/s, output: 3.21 toks/s]
Processed prompts:  70%|   | 713/1024 [03:42<01:37,  3.18it/s, est. speed input: 3287.74 toks/s, output: 3.21 toks/s]
Processed prompts:  70%|   | 721/1024 [03:44<01:35,  3.18it/s, est. speed input: 3287.36 toks/s, output: 3.21 toks/s]
Processed prompts:  71%|   | 729/1024 [03:47<01:32,  3.18it/s, est. speed input: 3287.06 toks/s, output: 3.21 toks/s]
Processed prompts:  72%|  | 737/1024 [03:49<01:30,  3.18it/s, est. speed input: 3286.76 toks/s, output: 3.21 toks/s]
Processed prompts:  73%|  | 745/1024 [03:52<01:27,  3.18it/s, est. speed input: 3286.48 toks/s, output: 3.21 toks/s]
Processed prompts:  74%|  | 753/1024 [03:54<01:25,  3.18it/s, est. speed input: 3286.22 toks/s, output: 3.21 toks/s]
Processed prompts:  74%|  | 761/1024 [03:57<01:22,  3.18it/s, est. speed input: 3285.81 toks/s, output: 3.21 toks/s]
Processed prompts:  75%|  | 769/1024 [03:59<01:20,  3.18it/s, est. speed input: 3285.61 toks/s, output: 3.21 toks/s]
Processed prompts:  76%|  | 777/1024 [04:02<01:17,  3.18it/s, est. speed input: 3285.35 toks/s, output: 3.21 toks/s]
Processed prompts:  77%|  | 785/1024 [04:04<01:12,  3.27it/s, est. speed input: 3288.22 toks/s, output: 3.21 toks/s]
Processed prompts:  77%|  | 793/1024 [04:06<01:11,  3.25it/s, est. speed input: 3287.94 toks/s, output: 3.21 toks/s]
Processed prompts:  78%|  | 801/1024 [04:09<01:09,  3.23it/s, est. speed input: 3287.64 toks/s, output: 3.21 toks/s]
Processed prompts:  79%|  | 809/1024 [04:12<01:06,  3.21it/s, est. speed input: 3287.29 toks/s, output: 3.21 toks/s]
Processed prompts:  80%|  | 817/1024 [04:14<01:04,  3.20it/s, est. speed input: 3287.01 toks/s, output: 3.21 toks/s]
Processed prompts:  81%|  | 825/1024 [04:17<01:02,  3.20it/s, est. speed input: 3286.76 toks/s, output: 3.21 toks/s]
Processed prompts:  81%| | 833/1024 [04:19<00:59,  3.19it/s, est. speed input: 3286.50 toks/s, output: 3.21 toks/s]
Processed prompts:  82%| | 841/1024 [04:22<00:57,  3.19it/s, est. speed input: 3286.23 toks/s, output: 3.21 toks/s]
Processed prompts:  83%| | 849/1024 [04:24<00:54,  3.19it/s, est. speed input: 3285.96 toks/s, output: 3.21 toks/s]
Processed prompts:  84%| | 857/1024 [04:27<00:52,  3.19it/s, est. speed input: 3285.73 toks/s, output: 3.21 toks/s]
Processed prompts:  84%| | 865/1024 [04:29<00:49,  3.19it/s, est. speed input: 3285.48 toks/s, output: 3.21 toks/s]
Processed prompts:  85%| | 873/1024 [04:32<00:47,  3.18it/s, est. speed input: 3285.16 toks/s, output: 3.21 toks/s]
Processed prompts:  86%| | 881/1024 [04:34<00:44,  3.18it/s, est. speed input: 3284.96 toks/s, output: 3.21 toks/s]
Processed prompts:  87%| | 889/1024 [04:37<00:42,  3.18it/s, est. speed input: 3284.70 toks/s, output: 3.21 toks/s]
Processed prompts:  88%| | 897/1024 [04:39<00:39,  3.18it/s, est. speed input: 3284.43 toks/s, output: 3.21 toks/s]
Processed prompts:  88%| | 905/1024 [04:42<00:37,  3.18it/s, est. speed input: 3284.20 toks/s, output: 3.21 toks/s]
Processed prompts:  89%| | 913/1024 [04:44<00:34,  3.18it/s, est. speed input: 3283.99 toks/s, output: 3.21 toks/s]
Processed prompts:  90%| | 921/1024 [04:47<00:32,  3.18it/s, est. speed input: 3283.77 toks/s, output: 3.21 toks/s]
Processed prompts:  91%| | 929/1024 [04:49<00:29,  3.18it/s, est. speed input: 3283.57 toks/s, output: 3.21 toks/s]
Processed prompts:  92%|| 937/1024 [04:52<00:27,  3.18it/s, est. speed input: 3283.31 toks/s, output: 3.21 toks/s]
Processed prompts:  92%|| 945/1024 [04:54<00:24,  3.18it/s, est. speed input: 3283.10 toks/s, output: 3.21 toks/s]
Processed prompts:  93%|| 953/1024 [04:57<00:22,  3.18it/s, est. speed input: 3282.85 toks/s, output: 3.21 toks/s]
Processed prompts:  94%|| 961/1024 [04:59<00:19,  3.18it/s, est. speed input: 3282.59 toks/s, output: 3.21 toks/s]
Processed prompts:  95%|| 969/1024 [05:02<00:17,  3.18it/s, est. speed input: 3282.46 toks/s, output: 3.21 toks/s]
Processed prompts:  95%|| 977/1024 [05:04<00:14,  3.18it/s, est. speed input: 3282.23 toks/s, output: 3.21 toks/s]
Processed prompts:  96%|| 985/1024 [05:07<00:12,  3.18it/s, est. speed input: 3282.02 toks/s, output: 3.21 toks/s]
Processed prompts:  97%|| 993/1024 [05:09<00:09,  3.18it/s, est. speed input: 3281.78 toks/s, output: 3.20 toks/s]
Processed prompts:  98%|| 1001/1024 [05:12<00:07,  3.18it/s, est. speed input: 3281.55 toks/s, output: 3.20 toks/s]
Processed prompts:  99%|| 1009/1024 [05:14<00:04,  3.18it/s, est. speed input: 3281.39 toks/s, output: 3.20 toks/s]
Processed prompts:  99%|| 1017/1024 [05:17<00:02,  3.18it/s, est. speed input: 3281.09 toks/s, output: 3.20 toks/s]
Processed prompts: 100%|| 1024/1024 [05:17<00:00,  3.18it/s, est. speed input: 3303.67 toks/s, output: 3.23 toks/s]
Processed prompts: 100%|| 1024/1024 [05:17<00:00,  3.23it/s, est. speed input: 3303.67 toks/s, output: 3.23 toks/s]
[rank0]:[W127 11:56:43.283873316 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-27 11:56:57
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 11:57:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 11:57:11 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2584593) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2584593) WARNING 01-27 11:59:46 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.20 requests/s, 3280.73 total tokens/s, 3.20 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-27 11:57:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:57:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:57:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:57:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:57:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:57:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:57:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:57:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 11:57:15] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 11:57:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:57:15] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 11:57:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 11:57:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 11:57:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 11:57:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 11:57:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 11:57:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2584593) [2026-01-27 11:57:16] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2584593) [2026-01-27 11:57:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2584593) [2026-01-27 11:57:16] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2584593) [2026-01-27 11:57:16] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2584593) [2026-01-27 11:57:16] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2584593) [2026-01-27 11:57:16] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2584593) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2584593) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.46s/it]
(EngineCore_DP0 pid=2584593) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:53, 27.00s/it]
(EngineCore_DP0 pid=2584593) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:20<00:29, 29.15s/it]
(EngineCore_DP0 pid=2584593) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 33.73s/it]
(EngineCore_DP0 pid=2584593) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:00<00:00, 30.23s/it]
(EngineCore_DP0 pid=2584593) 
(EngineCore_DP0 pid=2584593) [2026-01-27 11:59:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2584593) [2026-01-27 11:59:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=2584593) [2026-01-27 11:59:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2584593) [2026-01-27 11:59:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=2584593) [2026-01-27 11:59:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2584593) [2026-01-27 11:59:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=2584593) [2026-01-27 11:59:19] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2584593) [2026-01-27 11:59:19] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=2584593) 2026-01-27 11:59:32,405 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2584593) 2026-01-27 11:59:35,364 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/2048 [00:00<23:23,  1.46it/s]
Adding requests:   0%|          | 2/2048 [00:00<12:11,  2.80it/s]
Adding requests:   0%|          | 4/2048 [00:00<06:15,  5.44it/s]
Adding requests:   0%|          | 6/2048 [00:01<04:14,  8.01it/s]
Adding requests:   0%|          | 9/2048 [00:01<02:44, 12.40it/s]
Adding requests:   1%|          | 13/2048 [00:01<01:56, 17.48it/s]
Adding requests:   1%|          | 20/2048 [00:01<01:08, 29.48it/s]
Adding requests:   2%|         | 35/2048 [00:01<00:33, 59.32it/s]
Adding requests:   2%|         | 51/2048 [00:01<00:23, 85.31it/s]
Adding requests:   3%|         | 70/2048 [00:01<00:17, 112.66it/s]
Adding requests:   5%|         | 95/2048 [00:01<00:12, 150.58it/s]
Adding requests:   6%|         | 128/2048 [00:01<00:09, 199.60it/s]
Adding requests:   8%|         | 167/2048 [00:02<00:07, 253.53it/s]
Adding requests:  10%|         | 209/2048 [00:02<00:06, 301.74it/s]
Adding requests:  12%|        | 249/2048 [00:02<00:05, 329.36it/s]
Adding requests:  14%|        | 290/2048 [00:02<00:05, 351.33it/s]
Adding requests:  16%|        | 332/2048 [00:02<00:04, 369.09it/s]
Adding requests:  18%|        | 377/2048 [00:02<00:04, 391.39it/s]
Adding requests:  21%|        | 422/2048 [00:02<00:03, 406.81it/s]
Adding requests:  23%|       | 466/2048 [00:02<00:03, 415.10it/s]
Adding requests:  25%|       | 513/2048 [00:02<00:03, 429.62it/s]
Adding requests:  27%|       | 561/2048 [00:02<00:03, 442.23it/s]
Adding requests:  30%|       | 606/2048 [00:03<00:03, 427.36it/s]
Adding requests:  32%|      | 649/2048 [00:03<00:03, 427.34it/s]
Adding requests:  34%|      | 692/2048 [00:03<00:03, 428.03it/s]
Adding requests:  36%|      | 735/2048 [00:03<00:03, 422.50it/s]
Adding requests:  38%|      | 778/2048 [00:03<00:03, 418.96it/s]
Adding requests:  40%|      | 821/2048 [00:03<00:02, 421.18it/s]
Adding requests:  42%|     | 864/2048 [00:03<00:02, 407.20it/s]
Adding requests:  44%|     | 906/2048 [00:03<00:02, 410.18it/s]
Adding requests:  46%|     | 948/2048 [00:03<00:02, 410.94it/s]
Adding requests:  48%|     | 990/2048 [00:10<00:54, 19.40it/s] 
Adding requests:  50%|     | 1026/2048 [00:11<00:39, 25.94it/s]
Adding requests:  52%|    | 1068/2048 [00:11<00:26, 36.45it/s]
Adding requests:  54%|    | 1109/2048 [00:11<00:18, 50.17it/s]
Adding requests:  56%|    | 1154/2048 [00:11<00:12, 70.06it/s]
Adding requests:  58%|    | 1197/2048 [00:11<00:09, 93.90it/s]
Adding requests:  61%|    | 1241/2048 [00:11<00:06, 123.72it/s]
Adding requests:  63%|   | 1282/2048 [00:11<00:04, 154.74it/s]
Adding requests:  65%|   | 1325/2048 [00:11<00:03, 191.98it/s]
Adding requests:  67%|   | 1368/2048 [00:11<00:02, 230.03it/s]
Adding requests:  69%|   | 1410/2048 [00:11<00:02, 263.44it/s]
Adding requests:  71%|   | 1452/2048 [00:12<00:02, 292.07it/s]
Adding requests:  73%|  | 1498/2048 [00:12<00:01, 329.25it/s]
Adding requests:  75%|  | 1541/2048 [00:12<00:01, 352.96it/s]
Adding requests:  77%|  | 1584/2048 [00:12<00:01, 367.74it/s]
Adding requests:  79%|  | 1626/2048 [00:12<00:01, 376.99it/s]
Adding requests:  81%| | 1668/2048 [00:12<00:00, 382.10it/s]
Adding requests:  84%| | 1712/2048 [00:12<00:00, 396.99it/s]
Adding requests:  86%| | 1754/2048 [00:12<00:00, 400.50it/s]
Adding requests:  88%| | 1798/2048 [00:12<00:00, 409.67it/s]
Adding requests:  90%| | 1840/2048 [00:13<00:00, 401.48it/s]
Adding requests:  92%|| 1883/2048 [00:13<00:00, 409.54it/s]
Adding requests:  94%|| 1926/2048 [00:13<00:00, 415.03it/s]
Adding requests:  96%|| 1970/2048 [00:13<00:00, 418.46it/s]
Adding requests:  98%|| 2013/2048 [00:13<00:00, 418.44it/s]
Adding requests: 100%|| 2048/2048 [00:13<00:00, 151.67it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 40/2048 [00:04<03:39,  9.13it/s, est. speed input: 9349.59 toks/s, output: 9.13 toks/s]
Processed prompts:   3%|         | 56/2048 [00:09<06:03,  5.48it/s, est. speed input: 6136.79 toks/s, output: 5.99 toks/s]
Processed prompts:   4%|         | 72/2048 [00:14<07:26,  4.42it/s, est. speed input: 5153.01 toks/s, output: 5.03 toks/s]
Processed prompts:   4%|         | 88/2048 [00:19<08:17,  3.94it/s, est. speed input: 4673.15 toks/s, output: 4.56 toks/s]
Processed prompts:   5%|         | 104/2048 [00:24<08:49,  3.67it/s, est. speed input: 4387.35 toks/s, output: 4.28 toks/s]
Processed prompts:   6%|         | 120/2048 [00:29<09:09,  3.51it/s, est. speed input: 4199.13 toks/s, output: 4.10 toks/s]
Processed prompts:   7%|         | 136/2048 [00:34<09:20,  3.41it/s, est. speed input: 4065.77 toks/s, output: 3.97 toks/s]
Processed prompts:   7%|         | 152/2048 [00:39<09:27,  3.34it/s, est. speed input: 3965.37 toks/s, output: 3.87 toks/s]
Processed prompts:   8%|         | 168/2048 [00:44<09:29,  3.30it/s, est. speed input: 3887.81 toks/s, output: 3.80 toks/s]
Processed prompts:   9%|         | 184/2048 [00:49<09:30,  3.27it/s, est. speed input: 3826.07 toks/s, output: 3.74 toks/s]
Processed prompts:  10%|         | 200/2048 [00:54<09:21,  3.29it/s, est. speed input: 3790.79 toks/s, output: 3.70 toks/s]
Processed prompts:  11%|         | 216/2048 [00:59<09:21,  3.26it/s, est. speed input: 3747.28 toks/s, output: 3.66 toks/s]
Processed prompts:  11%|        | 232/2048 [01:04<09:20,  3.24it/s, est. speed input: 3709.92 toks/s, output: 3.62 toks/s]
Processed prompts:  12%|        | 248/2048 [01:09<09:17,  3.23it/s, est. speed input: 3678.48 toks/s, output: 3.59 toks/s]
Processed prompts:  13%|        | 264/2048 [01:14<09:14,  3.22it/s, est. speed input: 3650.97 toks/s, output: 3.57 toks/s]
Processed prompts:  14%|        | 280/2048 [01:19<09:10,  3.21it/s, est. speed input: 3627.09 toks/s, output: 3.54 toks/s]
Processed prompts:  14%|        | 296/2048 [01:23<08:58,  3.25it/s, est. speed input: 3616.38 toks/s, output: 3.53 toks/s]
Processed prompts:  15%|        | 312/2048 [01:28<08:56,  3.24it/s, est. speed input: 3597.35 toks/s, output: 3.51 toks/s]
Processed prompts:  16%|        | 328/2048 [01:33<08:53,  3.23it/s, est. speed input: 3579.99 toks/s, output: 3.50 toks/s]
Processed prompts:  17%|        | 344/2048 [01:38<08:49,  3.22it/s, est. speed input: 3564.39 toks/s, output: 3.48 toks/s]
Processed prompts:  18%|        | 360/2048 [01:43<08:45,  3.21it/s, est. speed input: 3550.44 toks/s, output: 3.47 toks/s]
Processed prompts:  18%|        | 376/2048 [01:48<08:41,  3.21it/s, est. speed input: 3537.64 toks/s, output: 3.45 toks/s]
Processed prompts:  19%|        | 392/2048 [01:53<08:36,  3.20it/s, est. speed input: 3525.98 toks/s, output: 3.44 toks/s]
Processed prompts:  20%|        | 408/2048 [01:58<08:32,  3.20it/s, est. speed input: 3515.29 toks/s, output: 3.43 toks/s]
Processed prompts:  21%|        | 424/2048 [02:03<08:20,  3.25it/s, est. speed input: 3512.26 toks/s, output: 3.43 toks/s]
Processed prompts:  21%|       | 440/2048 [02:08<08:17,  3.23it/s, est. speed input: 3503.32 toks/s, output: 3.42 toks/s]
Processed prompts:  22%|       | 456/2048 [02:13<08:14,  3.22it/s, est. speed input: 3494.64 toks/s, output: 3.41 toks/s]
Processed prompts:  23%|       | 472/2048 [02:18<08:10,  3.21it/s, est. speed input: 3486.70 toks/s, output: 3.40 toks/s]
Processed prompts:  24%|       | 488/2048 [02:23<08:06,  3.21it/s, est. speed input: 3479.21 toks/s, output: 3.40 toks/s]
Processed prompts:  25%|       | 504/2048 [02:28<08:01,  3.21it/s, est. speed input: 3472.27 toks/s, output: 3.39 toks/s]
Processed prompts:  25%|       | 520/2048 [02:33<07:57,  3.20it/s, est. speed input: 3465.84 toks/s, output: 3.38 toks/s]
Processed prompts:  26%|       | 536/2048 [02:38<07:52,  3.20it/s, est. speed input: 3459.77 toks/s, output: 3.38 toks/s]
Processed prompts:  27%|       | 552/2048 [02:43<07:47,  3.20it/s, est. speed input: 3454.05 toks/s, output: 3.37 toks/s]
Processed prompts:  28%|       | 568/2048 [02:48<07:42,  3.20it/s, est. speed input: 3448.61 toks/s, output: 3.37 toks/s]
Processed prompts:  29%|       | 584/2048 [02:53<07:37,  3.20it/s, est. speed input: 3443.64 toks/s, output: 3.36 toks/s]
Processed prompts:  29%|       | 600/2048 [02:58<07:32,  3.20it/s, est. speed input: 3438.83 toks/s, output: 3.36 toks/s]
Processed prompts:  30%|       | 616/2048 [03:03<07:27,  3.20it/s, est. speed input: 3434.28 toks/s, output: 3.35 toks/s]
Processed prompts:  31%|       | 632/2048 [03:08<07:23,  3.20it/s, est. speed input: 3429.93 toks/s, output: 3.35 toks/s]
Processed prompts:  32%|      | 648/2048 [03:13<07:17,  3.20it/s, est. speed input: 3425.97 toks/s, output: 3.35 toks/s]
Processed prompts:  32%|      | 664/2048 [03:18<07:12,  3.20it/s, est. speed input: 3422.12 toks/s, output: 3.34 toks/s]
Processed prompts:  33%|      | 680/2048 [03:23<07:08,  3.20it/s, est. speed input: 3418.41 toks/s, output: 3.34 toks/s]
Processed prompts:  34%|      | 696/2048 [03:28<07:02,  3.20it/s, est. speed input: 3414.97 toks/s, output: 3.33 toks/s]
Processed prompts:  35%|      | 712/2048 [03:33<06:57,  3.20it/s, est. speed input: 3411.66 toks/s, output: 3.33 toks/s]
Processed prompts:  36%|      | 728/2048 [03:38<06:52,  3.20it/s, est. speed input: 3408.44 toks/s, output: 3.33 toks/s]
Processed prompts:  36%|      | 744/2048 [03:43<06:48,  3.20it/s, est. speed input: 3405.34 toks/s, output: 3.33 toks/s]
Processed prompts:  37%|      | 760/2048 [03:48<06:42,  3.20it/s, est. speed input: 3402.57 toks/s, output: 3.32 toks/s]
Processed prompts:  38%|      | 776/2048 [03:53<06:32,  3.24it/s, est. speed input: 3403.13 toks/s, output: 3.32 toks/s]
Processed prompts:  39%|      | 792/2048 [03:58<06:29,  3.23it/s, est. speed input: 3400.32 toks/s, output: 3.32 toks/s]
Processed prompts:  39%|      | 808/2048 [04:03<06:25,  3.22it/s, est. speed input: 3397.76 toks/s, output: 3.32 toks/s]
Processed prompts:  40%|      | 824/2048 [04:08<06:21,  3.21it/s, est. speed input: 3395.19 toks/s, output: 3.32 toks/s]
Processed prompts:  41%|      | 840/2048 [04:13<06:16,  3.21it/s, est. speed input: 3392.82 toks/s, output: 3.31 toks/s]
Processed prompts:  42%|     | 856/2048 [04:18<06:12,  3.20it/s, est. speed input: 3390.37 toks/s, output: 3.31 toks/s]
Processed prompts:  43%|     | 872/2048 [04:23<06:07,  3.20it/s, est. speed input: 3388.29 toks/s, output: 3.31 toks/s]
Processed prompts:  43%|     | 888/2048 [04:28<06:02,  3.20it/s, est. speed input: 3386.11 toks/s, output: 3.31 toks/s]
Processed prompts:  44%|     | 904/2048 [04:33<05:57,  3.20it/s, est. speed input: 3384.03 toks/s, output: 3.30 toks/s]
Processed prompts:  45%|     | 920/2048 [04:38<05:52,  3.20it/s, est. speed input: 3382.01 toks/s, output: 3.30 toks/s]
Processed prompts:  46%|     | 936/2048 [04:43<05:47,  3.20it/s, est. speed input: 3380.05 toks/s, output: 3.30 toks/s]
Processed prompts:  46%|     | 952/2048 [04:48<05:42,  3.20it/s, est. speed input: 3378.16 toks/s, output: 3.30 toks/s]
Processed prompts:  47%|     | 968/2048 [04:53<05:37,  3.20it/s, est. speed input: 3376.45 toks/s, output: 3.30 toks/s]
Processed prompts:  48%|     | 984/2048 [04:58<05:32,  3.20it/s, est. speed input: 3374.70 toks/s, output: 3.30 toks/s]
Processed prompts:  49%|     | 1000/2048 [05:03<05:27,  3.20it/s, est. speed input: 3373.09 toks/s, output: 3.29 toks/s]
Processed prompts:  50%|     | 1016/2048 [05:08<05:22,  3.20it/s, est. speed input: 3371.44 toks/s, output: 3.29 toks/s]
Processed prompts:  50%|     | 1032/2048 [05:13<05:17,  3.20it/s, est. speed input: 3369.85 toks/s, output: 3.29 toks/s]
Processed prompts:  51%|     | 1048/2048 [05:18<05:12,  3.20it/s, est. speed input: 3368.35 toks/s, output: 3.29 toks/s]
Processed prompts:  52%|    | 1064/2048 [05:23<05:07,  3.20it/s, est. speed input: 3366.84 toks/s, output: 3.29 toks/s]
Processed prompts:  53%|    | 1080/2048 [05:28<05:03,  3.19it/s, est. speed input: 3365.25 toks/s, output: 3.29 toks/s]
Processed prompts:  54%|    | 1096/2048 [05:33<04:58,  3.19it/s, est. speed input: 3363.83 toks/s, output: 3.28 toks/s]
Processed prompts:  54%|    | 1112/2048 [05:38<04:52,  3.20it/s, est. speed input: 3362.54 toks/s, output: 3.28 toks/s]
Processed prompts:  55%|    | 1128/2048 [05:43<04:47,  3.19it/s, est. speed input: 3361.20 toks/s, output: 3.28 toks/s]
Processed prompts:  56%|    | 1144/2048 [05:48<04:42,  3.20it/s, est. speed input: 3359.94 toks/s, output: 3.28 toks/s]
Processed prompts:  57%|    | 1160/2048 [05:53<04:37,  3.19it/s, est. speed input: 3358.65 toks/s, output: 3.28 toks/s]
Processed prompts:  57%|    | 1176/2048 [05:58<04:33,  3.19it/s, est. speed input: 3357.40 toks/s, output: 3.28 toks/s]
Processed prompts:  58%|    | 1192/2048 [06:03<04:28,  3.19it/s, est. speed input: 3356.16 toks/s, output: 3.28 toks/s]
Processed prompts:  59%|    | 1208/2048 [06:08<04:19,  3.24it/s, est. speed input: 3357.11 toks/s, output: 3.28 toks/s]
Processed prompts:  60%|    | 1224/2048 [06:13<04:15,  3.23it/s, est. speed input: 3356.00 toks/s, output: 3.28 toks/s]
Processed prompts:  61%|    | 1240/2048 [06:18<04:11,  3.22it/s, est. speed input: 3354.92 toks/s, output: 3.28 toks/s]
Processed prompts:  61%|   | 1256/2048 [06:23<04:06,  3.21it/s, est. speed input: 3353.77 toks/s, output: 3.28 toks/s]
Processed prompts:  62%|   | 1272/2048 [06:28<04:02,  3.21it/s, est. speed input: 3352.75 toks/s, output: 3.27 toks/s]
Processed prompts:  63%|   | 1288/2048 [06:33<03:57,  3.20it/s, est. speed input: 3351.60 toks/s, output: 3.27 toks/s]
Processed prompts:  64%|   | 1304/2048 [06:38<03:52,  3.20it/s, est. speed input: 3350.60 toks/s, output: 3.27 toks/s]
Processed prompts:  64%|   | 1320/2048 [06:43<03:47,  3.20it/s, est. speed input: 3349.61 toks/s, output: 3.27 toks/s]
Processed prompts:  65%|   | 1336/2048 [06:48<03:42,  3.20it/s, est. speed input: 3348.69 toks/s, output: 3.27 toks/s]
Processed prompts:  66%|   | 1352/2048 [06:53<03:37,  3.20it/s, est. speed input: 3347.78 toks/s, output: 3.27 toks/s]
Processed prompts:  67%|   | 1368/2048 [06:58<03:32,  3.20it/s, est. speed input: 3346.88 toks/s, output: 3.27 toks/s]
Processed prompts:  68%|   | 1384/2048 [07:03<03:27,  3.20it/s, est. speed input: 3346.02 toks/s, output: 3.27 toks/s]
Processed prompts:  68%|   | 1400/2048 [07:08<03:22,  3.20it/s, est. speed input: 3345.16 toks/s, output: 3.27 toks/s]
Processed prompts:  69%|   | 1416/2048 [07:13<03:17,  3.20it/s, est. speed input: 3344.35 toks/s, output: 3.27 toks/s]
Processed prompts:  70%|   | 1432/2048 [07:18<03:12,  3.19it/s, est. speed input: 3343.40 toks/s, output: 3.27 toks/s]
Processed prompts:  71%|   | 1448/2048 [07:23<03:07,  3.19it/s, est. speed input: 3342.57 toks/s, output: 3.26 toks/s]
Processed prompts:  71%|  | 1464/2048 [07:28<03:02,  3.19it/s, est. speed input: 3341.79 toks/s, output: 3.26 toks/s]
Processed prompts:  72%|  | 1480/2048 [07:33<02:57,  3.20it/s, est. speed input: 3341.05 toks/s, output: 3.26 toks/s]
Processed prompts:  73%|  | 1496/2048 [07:38<02:52,  3.19it/s, est. speed input: 3340.19 toks/s, output: 3.26 toks/s]
Processed prompts:  74%|  | 1512/2048 [07:43<02:47,  3.19it/s, est. speed input: 3339.40 toks/s, output: 3.26 toks/s]
Processed prompts:  75%|  | 1528/2048 [07:48<02:42,  3.19it/s, est. speed input: 3338.59 toks/s, output: 3.26 toks/s]
Processed prompts:  75%|  | 1544/2048 [07:53<02:37,  3.19it/s, est. speed input: 3337.88 toks/s, output: 3.26 toks/s]
Processed prompts:  76%|  | 1560/2048 [07:58<02:30,  3.24it/s, est. speed input: 3338.74 toks/s, output: 3.26 toks/s]
Processed prompts:  77%|  | 1576/2048 [08:03<02:26,  3.23it/s, est. speed input: 3338.11 toks/s, output: 3.26 toks/s]
Processed prompts:  78%|  | 1592/2048 [08:08<02:21,  3.22it/s, est. speed input: 3337.39 toks/s, output: 3.26 toks/s]
Processed prompts:  79%|  | 1608/2048 [08:13<02:17,  3.21it/s, est. speed input: 3336.71 toks/s, output: 3.26 toks/s]
Processed prompts:  79%|  | 1624/2048 [08:18<02:10,  3.25it/s, est. speed input: 3337.60 toks/s, output: 3.26 toks/s]
Processed prompts:  80%|  | 1640/2048 [08:23<02:06,  3.23it/s, est. speed input: 3336.87 toks/s, output: 3.26 toks/s]
Processed prompts:  81%|  | 1656/2048 [08:28<02:01,  3.22it/s, est. speed input: 3336.25 toks/s, output: 3.26 toks/s]
Processed prompts:  82%| | 1672/2048 [08:33<01:57,  3.21it/s, est. speed input: 3335.50 toks/s, output: 3.26 toks/s]
Processed prompts:  82%| | 1688/2048 [08:38<01:52,  3.21it/s, est. speed input: 3334.93 toks/s, output: 3.26 toks/s]
Processed prompts:  83%| | 1704/2048 [08:43<01:47,  3.20it/s, est. speed input: 3334.29 toks/s, output: 3.26 toks/s]
Processed prompts:  84%| | 1720/2048 [08:48<01:42,  3.20it/s, est. speed input: 3333.64 toks/s, output: 3.26 toks/s]
Processed prompts:  85%| | 1736/2048 [08:53<01:37,  3.20it/s, est. speed input: 3333.02 toks/s, output: 3.25 toks/s]
Processed prompts:  86%| | 1752/2048 [08:58<01:31,  3.24it/s, est. speed input: 3333.89 toks/s, output: 3.26 toks/s]
Processed prompts:  86%| | 1768/2048 [09:03<01:26,  3.23it/s, est. speed input: 3333.33 toks/s, output: 3.26 toks/s]
Processed prompts:  87%| | 1784/2048 [09:08<01:22,  3.22it/s, est. speed input: 3332.71 toks/s, output: 3.25 toks/s]
Processed prompts:  88%| | 1800/2048 [09:13<01:17,  3.21it/s, est. speed input: 3332.14 toks/s, output: 3.25 toks/s]
Processed prompts:  89%| | 1816/2048 [09:18<01:12,  3.20it/s, est. speed input: 3331.59 toks/s, output: 3.25 toks/s]
Processed prompts:  89%| | 1832/2048 [09:23<01:07,  3.20it/s, est. speed input: 3331.05 toks/s, output: 3.25 toks/s]
Processed prompts:  90%| | 1848/2048 [09:28<01:02,  3.20it/s, est. speed input: 3330.50 toks/s, output: 3.25 toks/s]
Processed prompts:  91%| | 1864/2048 [09:33<00:57,  3.20it/s, est. speed input: 3329.96 toks/s, output: 3.25 toks/s]
Processed prompts:  92%|| 1880/2048 [09:38<00:52,  3.20it/s, est. speed input: 3329.44 toks/s, output: 3.25 toks/s]
Processed prompts:  93%|| 1896/2048 [09:43<00:47,  3.20it/s, est. speed input: 3328.95 toks/s, output: 3.25 toks/s]
Processed prompts:  93%|| 1912/2048 [09:48<00:42,  3.20it/s, est. speed input: 3328.47 toks/s, output: 3.25 toks/s]
Processed prompts:  94%|| 1928/2048 [09:53<00:37,  3.19it/s, est. speed input: 3327.94 toks/s, output: 3.25 toks/s]
Processed prompts:  95%|| 1944/2048 [09:58<00:32,  3.19it/s, est. speed input: 3327.44 toks/s, output: 3.25 toks/s]
Processed prompts:  96%|| 1960/2048 [10:03<00:27,  3.19it/s, est. speed input: 3326.93 toks/s, output: 3.25 toks/s]
Processed prompts:  96%|| 1976/2048 [10:08<00:22,  3.19it/s, est. speed input: 3326.43 toks/s, output: 3.25 toks/s]
Processed prompts:  97%|| 1992/2048 [10:13<00:17,  3.19it/s, est. speed input: 3325.99 toks/s, output: 3.25 toks/s]
Processed prompts:  98%|| 2008/2048 [10:18<00:12,  3.19it/s, est. speed input: 3325.47 toks/s, output: 3.25 toks/s]
Processed prompts:  99%|| 2024/2048 [10:23<00:07,  3.19it/s, est. speed input: 3325.03 toks/s, output: 3.25 toks/s]
Processed prompts: 100%|| 2040/2048 [10:26<00:02,  3.65it/s, est. speed input: 3335.65 toks/s, output: 3.26 toks/s]
Processed prompts: 100%|| 2048/2048 [10:26<00:00,  3.65it/s, est. speed input: 3348.73 toks/s, output: 3.27 toks/s]
Processed prompts: 100%|| 2048/2048 [10:26<00:00,  3.27it/s, est. speed input: 3348.73 toks/s, output: 3.27 toks/s]
[rank0]:[W127 12:10:27.333077573 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-27 12:10:35
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 12:10:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 12:10:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2596119) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2596119) WARNING 01-27 12:13:38 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.08 requests/s, 3154.49 total tokens/s, 3.08 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-27 12:10:55] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 12:10:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 12:10:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 12:10:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 12:10:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 12:10:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 12:10:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 12:10:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 12:10:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 12:10:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 12:10:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:10:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 12:10:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 12:10:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 12:10:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 12:10:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 12:10:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2596119) [2026-01-27 12:11:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2596119) [2026-01-27 12:11:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2596119) [2026-01-27 12:11:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2596119) [2026-01-27 12:11:00] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2596119) [2026-01-27 12:11:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2596119) [2026-01-27 12:11:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2596119) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2596119) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.46s/it]
(EngineCore_DP0 pid=2596119) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:54, 27.04s/it]
(EngineCore_DP0 pid=2596119) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:19<00:29, 29.00s/it]
(EngineCore_DP0 pid=2596119) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 33.94s/it]
(EngineCore_DP0 pid=2596119) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 30.34s/it]
(EngineCore_DP0 pid=2596119) 
(EngineCore_DP0 pid=2596119) [2026-01-27 12:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2596119) [2026-01-27 12:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=2596119) [2026-01-27 12:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2596119) [2026-01-27 12:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=2596119) [2026-01-27 12:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2596119) [2026-01-27 12:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=2596119) [2026-01-27 12:13:04] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2596119) [2026-01-27 12:13:04] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=2596119) 2026-01-27 12:13:20,598 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2596119) 2026-01-27 12:13:24,602 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/4096 [00:00<54:54,  1.24it/s]
Adding requests:   0%|          | 2/4096 [00:01<30:42,  2.22it/s]
Adding requests:   0%|          | 3/4096 [00:01<20:21,  3.35it/s]
Adding requests:   0%|          | 5/4096 [00:01<11:32,  5.90it/s]
Adding requests:   0%|          | 8/4096 [00:01<06:42, 10.16it/s]
Adding requests:   0%|          | 12/4096 [00:01<04:25, 15.39it/s]
Adding requests:   0%|          | 18/4096 [00:01<02:45, 24.64it/s]
Adding requests:   1%|          | 34/4096 [00:01<01:12, 55.81it/s]
Adding requests:   1%|          | 50/4096 [00:01<00:49, 81.15it/s]
Adding requests:   2%|         | 70/4096 [00:01<00:36, 109.93it/s]
Adding requests:   2%|         | 92/4096 [00:02<00:28, 138.78it/s]
Adding requests:   3%|         | 122/4096 [00:02<00:21, 183.19it/s]
Adding requests:   4%|         | 160/4096 [00:02<00:16, 238.46it/s]
Adding requests:   5%|         | 201/4096 [00:02<00:13, 287.16it/s]
Adding requests:   6%|         | 239/4096 [00:02<00:12, 311.89it/s]
Adding requests:   7%|         | 280/4096 [00:02<00:11, 339.78it/s]
Adding requests:   8%|         | 321/4096 [00:02<00:10, 357.90it/s]
Adding requests:   9%|         | 366/4096 [00:02<00:09, 383.77it/s]
Adding requests:  10%|         | 409/4096 [00:02<00:09, 395.83it/s]
Adding requests:  11%|         | 449/4096 [00:02<00:09, 382.63it/s]
Adding requests:  12%|        | 493/4096 [00:03<00:09, 397.22it/s]
Adding requests:  13%|        | 538/4096 [00:03<00:08, 411.35it/s]
Adding requests:  14%|        | 580/4096 [00:03<00:08, 410.99it/s]
Adding requests:  15%|        | 622/4096 [00:03<00:08, 409.85it/s]
Adding requests:  16%|        | 664/4096 [00:03<00:08, 405.34it/s]
Adding requests:  17%|        | 705/4096 [00:03<00:08, 397.33it/s]
Adding requests:  18%|        | 745/4096 [00:03<00:08, 396.19it/s]
Adding requests:  19%|        | 785/4096 [00:03<00:08, 397.24it/s]
Adding requests:  20%|        | 829/4096 [00:03<00:08, 408.30it/s]
Adding requests:  21%|        | 870/4096 [00:03<00:07, 405.65it/s]
Adding requests:  22%|       | 913/4096 [00:04<00:07, 412.79it/s]
Adding requests:  23%|       | 955/4096 [00:04<00:07, 403.43it/s]
Adding requests:  24%|       | 998/4096 [00:04<00:07, 409.38it/s]
Adding requests:  25%|       | 1039/4096 [00:04<00:07, 401.06it/s]
Adding requests:  26%|       | 1080/4096 [00:04<00:07, 403.04it/s]
Adding requests:  27%|       | 1121/4096 [00:04<00:07, 396.31it/s]
Adding requests:  28%|       | 1162/4096 [00:04<00:07, 400.23it/s]
Adding requests:  29%|       | 1203/4096 [00:04<00:07, 371.02it/s]
Adding requests:  30%|       | 1246/4096 [00:04<00:07, 386.83it/s]
Adding requests:  31%|      | 1286/4096 [00:05<00:07, 389.95it/s]
Adding requests:  32%|      | 1330/4096 [00:05<00:06, 403.89it/s]
Adding requests:  33%|      | 1372/4096 [00:05<00:06, 407.22it/s]
Adding requests:  35%|      | 1414/4096 [00:05<00:06, 408.42it/s]
Adding requests:  36%|      | 1455/4096 [00:05<00:06, 398.85it/s]
Adding requests:  37%|      | 1498/4096 [00:05<00:06, 406.48it/s]
Adding requests:  38%|      | 1539/4096 [00:05<00:06, 389.80it/s]
Adding requests:  39%|      | 1582/4096 [00:05<00:06, 400.92it/s]
Adding requests:  40%|      | 1623/4096 [00:05<00:06, 375.98it/s]
Adding requests:  41%|      | 1666/4096 [00:06<00:06, 389.79it/s]
Adding requests:  42%|     | 1706/4096 [00:06<00:06, 387.18it/s]
Adding requests:  43%|     | 1752/4096 [00:06<00:05, 404.89it/s]
Adding requests:  44%|     | 1793/4096 [00:06<00:05, 395.56it/s]
Adding requests:  45%|     | 1833/4096 [00:06<00:05, 395.52it/s]
Adding requests:  46%|     | 1873/4096 [00:06<00:05, 388.84it/s]
Adding requests:  47%|     | 1917/4096 [00:06<00:05, 401.42it/s]
Adding requests:  48%|     | 1958/4096 [00:06<00:05, 397.01it/s]
Adding requests:  49%|     | 1998/4096 [00:06<00:05, 397.71it/s]
Adding requests:  50%|     | 2038/4096 [00:06<00:05, 389.24it/s]
Adding requests:  51%|     | 2079/4096 [00:07<00:05, 392.64it/s]
Adding requests:  52%|    | 2119/4096 [00:07<00:05, 393.12it/s]
Adding requests:  53%|    | 2159/4096 [00:07<00:04, 395.05it/s]
Adding requests:  54%|    | 2199/4096 [00:07<00:04, 392.18it/s]
Adding requests:  55%|    | 2239/4096 [00:07<00:04, 377.87it/s]
Adding requests:  56%|    | 2279/4096 [00:07<00:04, 383.99it/s]
Adding requests:  57%|    | 2319/4096 [00:07<00:04, 386.48it/s]
Adding requests:  58%|    | 2361/4096 [00:07<00:04, 393.43it/s]
Adding requests:  59%|    | 2403/4096 [00:07<00:04, 400.57it/s]
Adding requests:  60%|    | 2444/4096 [00:08<00:04, 374.84it/s]
Adding requests:  61%|    | 2482/4096 [00:08<00:04, 375.67it/s]
Adding requests:  62%|   | 2527/4096 [00:08<00:03, 394.82it/s]
Adding requests:  63%|   | 2571/4096 [00:08<00:03, 407.22it/s]
Adding requests:  64%|   | 2614/4096 [00:08<00:03, 413.66it/s]
Adding requests:  65%|   | 2656/4096 [00:08<00:03, 409.52it/s]
Adding requests:  66%|   | 2699/4096 [00:08<00:03, 413.35it/s]
Adding requests:  67%|   | 2741/4096 [00:08<00:03, 405.54it/s]
Adding requests:  68%|   | 2789/4096 [00:08<00:03, 425.83it/s]
Adding requests:  69%|   | 2832/4096 [00:08<00:03, 409.17it/s]
Adding requests:  70%|   | 2877/4096 [00:09<00:02, 420.29it/s]
Adding requests:  71%|  | 2920/4096 [00:09<00:02, 407.51it/s]
Adding requests:  72%|  | 2966/4096 [00:09<00:02, 421.28it/s]
Adding requests:  73%|  | 3009/4096 [00:09<00:02, 416.11it/s]
Adding requests:  75%|  | 3056/4096 [00:09<00:02, 428.00it/s]
Adding requests:  76%|  | 3099/4096 [00:09<00:02, 419.21it/s]
Adding requests:  77%|  | 3145/4096 [00:09<00:02, 429.77it/s]
Adding requests:  78%|  | 3189/4096 [00:09<00:02, 399.21it/s]
Adding requests:  79%|  | 3232/4096 [00:09<00:02, 404.28it/s]
Adding requests:  80%|  | 3273/4096 [00:10<00:02, 396.52it/s]
Adding requests:  81%|  | 3315/4096 [00:10<00:01, 400.55it/s]
Adding requests:  82%| | 3356/4096 [00:10<00:01, 400.08it/s]
Adding requests:  83%| | 3401/4096 [00:10<00:01, 412.93it/s]
Adding requests:  84%| | 3443/4096 [00:10<00:01, 405.66it/s]
Adding requests:  85%| | 3488/4096 [00:10<00:01, 417.04it/s]
Adding requests:  86%| | 3530/4096 [00:10<00:01, 416.76it/s]
Adding requests:  87%| | 3575/4096 [00:10<00:01, 425.83it/s]
Adding requests:  88%| | 3618/4096 [00:10<00:01, 418.51it/s]
Adding requests:  89%| | 3661/4096 [00:10<00:01, 419.67it/s]
Adding requests:  90%| | 3704/4096 [00:11<00:00, 419.85it/s]
Adding requests:  91%|| 3747/4096 [00:11<00:00, 414.87it/s]
Adding requests:  93%|| 3789/4096 [00:11<00:00, 388.72it/s]
Adding requests:  93%|| 3829/4096 [00:11<00:00, 380.31it/s]
Adding requests:  94%|| 3869/4096 [00:11<00:00, 384.52it/s]
Adding requests:  95%|| 3910/4096 [00:11<00:00, 391.53it/s]
Adding requests:  96%|| 3950/4096 [00:11<00:00, 389.80it/s]
Adding requests:  97%|| 3990/4096 [00:11<00:00, 389.34it/s]
Adding requests:  98%|| 4033/4096 [00:11<00:00, 400.64it/s]
Adding requests:  99%|| 4074/4096 [00:11<00:00, 395.83it/s]
Adding requests: 100%|| 4096/4096 [00:12<00:00, 340.16it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 5/4096 [00:00<07:22,  9.25it/s, est. speed input: 9468.93 toks/s, output: 9.25 toks/s]
Processed prompts:   1%|          | 37/4096 [00:10<20:26,  3.31it/s, est. speed input: 3480.57 toks/s, output: 3.40 toks/s]
Processed prompts:   2%|         | 69/4096 [00:21<21:06,  3.18it/s, est. speed input: 3322.92 toks/s, output: 3.25 toks/s]
Processed prompts:   2%|         | 101/4096 [00:31<21:14,  3.13it/s, est. speed input: 3267.37 toks/s, output: 3.19 toks/s]
Processed prompts:   3%|         | 133/4096 [00:42<21:13,  3.11it/s, est. speed input: 3238.96 toks/s, output: 3.16 toks/s]
Processed prompts:   4%|         | 165/4096 [00:52<21:08,  3.10it/s, est. speed input: 3221.25 toks/s, output: 3.15 toks/s]
Processed prompts:   5%|         | 197/4096 [01:02<20:52,  3.11it/s, est. speed input: 3220.32 toks/s, output: 3.14 toks/s]
Processed prompts:   6%|         | 229/4096 [01:13<20:46,  3.10it/s, est. speed input: 3210.64 toks/s, output: 3.14 toks/s]
Processed prompts:   6%|         | 261/4096 [01:23<20:39,  3.09it/s, est. speed input: 3203.58 toks/s, output: 3.13 toks/s]
Processed prompts:   7%|         | 293/4096 [01:33<20:22,  3.11it/s, est. speed input: 3205.42 toks/s, output: 3.13 toks/s]
Processed prompts:   8%|         | 325/4096 [01:44<20:16,  3.10it/s, est. speed input: 3199.76 toks/s, output: 3.12 toks/s]
Processed prompts:   9%|         | 357/4096 [01:54<20:08,  3.09it/s, est. speed input: 3195.54 toks/s, output: 3.12 toks/s]
Processed prompts:   9%|         | 389/4096 [02:04<20:00,  3.09it/s, est. speed input: 3191.76 toks/s, output: 3.12 toks/s]
Processed prompts:  10%|         | 421/4096 [02:14<19:43,  3.10it/s, est. speed input: 3193.65 toks/s, output: 3.12 toks/s]
Processed prompts:  11%|         | 453/4096 [02:25<19:36,  3.10it/s, est. speed input: 3190.73 toks/s, output: 3.12 toks/s]
Processed prompts:  12%|        | 485/4096 [02:35<19:28,  3.09it/s, est. speed input: 3187.87 toks/s, output: 3.11 toks/s]
Processed prompts:  13%|        | 517/4096 [02:46<19:19,  3.09it/s, est. speed input: 3185.56 toks/s, output: 3.11 toks/s]
Processed prompts:  13%|        | 549/4096 [02:56<19:10,  3.08it/s, est. speed input: 3183.38 toks/s, output: 3.11 toks/s]
Processed prompts:  14%|        | 581/4096 [03:07<19:01,  3.08it/s, est. speed input: 3181.32 toks/s, output: 3.11 toks/s]
Processed prompts:  15%|        | 613/4096 [03:17<18:51,  3.08it/s, est. speed input: 3179.47 toks/s, output: 3.10 toks/s]
Processed prompts:  16%|        | 645/4096 [03:27<18:41,  3.08it/s, est. speed input: 3178.02 toks/s, output: 3.10 toks/s]
Processed prompts:  17%|        | 677/4096 [03:38<18:31,  3.08it/s, est. speed input: 3176.55 toks/s, output: 3.10 toks/s]
Processed prompts:  17%|        | 709/4096 [03:48<18:21,  3.07it/s, est. speed input: 3175.15 toks/s, output: 3.10 toks/s]
Processed prompts:  18%|        | 741/4096 [03:59<18:11,  3.07it/s, est. speed input: 3173.89 toks/s, output: 3.10 toks/s]
Processed prompts:  19%|        | 773/4096 [04:09<17:54,  3.09it/s, est. speed input: 3175.58 toks/s, output: 3.10 toks/s]
Processed prompts:  20%|        | 805/4096 [04:19<17:46,  3.09it/s, est. speed input: 3174.38 toks/s, output: 3.10 toks/s]
Processed prompts:  20%|        | 837/4096 [04:30<17:37,  3.08it/s, est. speed input: 3173.30 toks/s, output: 3.10 toks/s]
Processed prompts:  21%|        | 869/4096 [04:40<17:27,  3.08it/s, est. speed input: 3172.36 toks/s, output: 3.10 toks/s]
Processed prompts:  22%|       | 901/4096 [04:50<17:18,  3.08it/s, est. speed input: 3171.43 toks/s, output: 3.10 toks/s]
Processed prompts:  23%|       | 933/4096 [05:01<17:08,  3.08it/s, est. speed input: 3170.57 toks/s, output: 3.10 toks/s]
Processed prompts:  24%|       | 965/4096 [05:11<16:58,  3.07it/s, est. speed input: 3169.72 toks/s, output: 3.10 toks/s]
Processed prompts:  24%|       | 997/4096 [05:22<16:47,  3.08it/s, est. speed input: 3169.06 toks/s, output: 3.09 toks/s]
Processed prompts:  25%|       | 1029/4096 [05:32<16:38,  3.07it/s, est. speed input: 3168.22 toks/s, output: 3.09 toks/s]
Processed prompts:  26%|       | 1061/4096 [05:43<16:27,  3.07it/s, est. speed input: 3167.51 toks/s, output: 3.09 toks/s]
Processed prompts:  27%|       | 1093/4096 [05:53<16:17,  3.07it/s, est. speed input: 3166.87 toks/s, output: 3.09 toks/s]
Processed prompts:  27%|       | 1125/4096 [06:03<16:07,  3.07it/s, est. speed input: 3166.26 toks/s, output: 3.09 toks/s]
Processed prompts:  28%|       | 1157/4096 [06:14<15:56,  3.07it/s, est. speed input: 3165.64 toks/s, output: 3.09 toks/s]
Processed prompts:  29%|       | 1189/4096 [06:24<15:40,  3.09it/s, est. speed input: 3166.98 toks/s, output: 3.09 toks/s]
Processed prompts:  30%|       | 1221/4096 [06:34<15:31,  3.09it/s, est. speed input: 3166.40 toks/s, output: 3.09 toks/s]
Processed prompts:  31%|       | 1253/4096 [06:45<15:22,  3.08it/s, est. speed input: 3165.88 toks/s, output: 3.09 toks/s]
Processed prompts:  31%|      | 1285/4096 [06:55<15:13,  3.08it/s, est. speed input: 3165.30 toks/s, output: 3.09 toks/s]
Processed prompts:  32%|      | 1317/4096 [07:06<15:03,  3.08it/s, est. speed input: 3164.84 toks/s, output: 3.09 toks/s]
Processed prompts:  33%|      | 1349/4096 [07:16<14:53,  3.07it/s, est. speed input: 3164.35 toks/s, output: 3.09 toks/s]
Processed prompts:  34%|      | 1381/4096 [07:26<14:43,  3.07it/s, est. speed input: 3163.88 toks/s, output: 3.09 toks/s]
Processed prompts:  34%|      | 1413/4096 [07:37<14:33,  3.07it/s, est. speed input: 3163.47 toks/s, output: 3.09 toks/s]
Processed prompts:  35%|      | 1445/4096 [07:47<14:23,  3.07it/s, est. speed input: 3163.00 toks/s, output: 3.09 toks/s]
Processed prompts:  36%|      | 1477/4096 [07:58<14:12,  3.07it/s, est. speed input: 3162.60 toks/s, output: 3.09 toks/s]
Processed prompts:  37%|      | 1509/4096 [08:08<14:02,  3.07it/s, est. speed input: 3162.21 toks/s, output: 3.09 toks/s]
Processed prompts:  38%|      | 1541/4096 [08:18<13:46,  3.09it/s, est. speed input: 3163.29 toks/s, output: 3.09 toks/s]
Processed prompts:  38%|      | 1573/4096 [08:29<13:37,  3.08it/s, est. speed input: 3162.87 toks/s, output: 3.09 toks/s]
Processed prompts:  39%|      | 1605/4096 [08:39<13:23,  3.10it/s, est. speed input: 3163.86 toks/s, output: 3.09 toks/s]
Processed prompts:  40%|      | 1637/4096 [08:49<13:15,  3.09it/s, est. speed input: 3163.44 toks/s, output: 3.09 toks/s]
Processed prompts:  41%|      | 1669/4096 [09:00<13:06,  3.08it/s, est. speed input: 3163.05 toks/s, output: 3.09 toks/s]
Processed prompts:  42%|     | 1701/4096 [09:10<12:57,  3.08it/s, est. speed input: 3162.64 toks/s, output: 3.09 toks/s]
Processed prompts:  42%|     | 1733/4096 [09:20<12:42,  3.10it/s, est. speed input: 3163.58 toks/s, output: 3.09 toks/s]
Processed prompts:  43%|     | 1765/4096 [09:31<12:34,  3.09it/s, est. speed input: 3163.20 toks/s, output: 3.09 toks/s]
Processed prompts:  44%|     | 1797/4096 [09:41<12:25,  3.08it/s, est. speed input: 3162.86 toks/s, output: 3.09 toks/s]
Processed prompts:  45%|     | 1829/4096 [09:52<12:16,  3.08it/s, est. speed input: 3162.53 toks/s, output: 3.09 toks/s]
Processed prompts:  45%|     | 1861/4096 [10:02<12:06,  3.08it/s, est. speed input: 3162.15 toks/s, output: 3.09 toks/s]
Processed prompts:  46%|     | 1893/4096 [10:13<11:56,  3.07it/s, est. speed input: 3161.82 toks/s, output: 3.09 toks/s]
Processed prompts:  47%|     | 1925/4096 [10:23<11:46,  3.07it/s, est. speed input: 3161.50 toks/s, output: 3.09 toks/s]
Processed prompts:  48%|     | 1957/4096 [10:33<11:36,  3.07it/s, est. speed input: 3161.21 toks/s, output: 3.09 toks/s]
Processed prompts:  49%|     | 1989/4096 [10:44<11:25,  3.07it/s, est. speed input: 3160.95 toks/s, output: 3.09 toks/s]
Processed prompts:  49%|     | 2021/4096 [10:54<11:15,  3.07it/s, est. speed input: 3160.66 toks/s, output: 3.09 toks/s]
Processed prompts:  50%|     | 2053/4096 [11:05<11:05,  3.07it/s, est. speed input: 3160.34 toks/s, output: 3.09 toks/s]
Processed prompts:  51%|     | 2085/4096 [11:15<10:55,  3.07it/s, est. speed input: 3160.04 toks/s, output: 3.09 toks/s]
Processed prompts:  52%|    | 2117/4096 [11:26<10:44,  3.07it/s, est. speed input: 3159.80 toks/s, output: 3.09 toks/s]
Processed prompts:  52%|    | 2149/4096 [11:36<10:34,  3.07it/s, est. speed input: 3159.57 toks/s, output: 3.09 toks/s]
Processed prompts:  53%|    | 2181/4096 [11:46<10:19,  3.09it/s, est. speed input: 3160.32 toks/s, output: 3.09 toks/s]
Processed prompts:  54%|    | 2213/4096 [11:57<10:10,  3.08it/s, est. speed input: 3160.06 toks/s, output: 3.09 toks/s]
Processed prompts:  55%|    | 2245/4096 [12:07<10:01,  3.08it/s, est. speed input: 3159.85 toks/s, output: 3.09 toks/s]
Processed prompts:  56%|    | 2277/4096 [12:17<09:51,  3.08it/s, est. speed input: 3159.62 toks/s, output: 3.09 toks/s]
Processed prompts:  56%|    | 2309/4096 [12:28<09:41,  3.07it/s, est. speed input: 3159.41 toks/s, output: 3.09 toks/s]
Processed prompts:  57%|    | 2341/4096 [12:38<09:31,  3.07it/s, est. speed input: 3159.16 toks/s, output: 3.09 toks/s]
Processed prompts:  58%|    | 2373/4096 [12:49<09:20,  3.07it/s, est. speed input: 3158.95 toks/s, output: 3.08 toks/s]
Processed prompts:  59%|    | 2405/4096 [12:59<09:10,  3.07it/s, est. speed input: 3158.76 toks/s, output: 3.08 toks/s]
Processed prompts:  59%|    | 2437/4096 [13:10<09:00,  3.07it/s, est. speed input: 3158.54 toks/s, output: 3.08 toks/s]
Processed prompts:  60%|    | 2469/4096 [13:20<08:50,  3.07it/s, est. speed input: 3158.29 toks/s, output: 3.08 toks/s]
Processed prompts:  61%|    | 2501/4096 [13:30<08:39,  3.07it/s, est. speed input: 3158.08 toks/s, output: 3.08 toks/s]
Processed prompts:  62%|   | 2533/4096 [13:41<08:29,  3.07it/s, est. speed input: 3157.88 toks/s, output: 3.08 toks/s]
Processed prompts:  63%|   | 2565/4096 [13:51<08:18,  3.07it/s, est. speed input: 3157.74 toks/s, output: 3.08 toks/s]
Processed prompts:  63%|   | 2597/4096 [14:01<08:05,  3.09it/s, est. speed input: 3158.40 toks/s, output: 3.08 toks/s]
Processed prompts:  64%|   | 2629/4096 [14:12<07:55,  3.08it/s, est. speed input: 3158.19 toks/s, output: 3.08 toks/s]
Processed prompts:  65%|   | 2661/4096 [14:22<07:45,  3.08it/s, est. speed input: 3158.06 toks/s, output: 3.08 toks/s]
Processed prompts:  66%|   | 2693/4096 [14:33<07:35,  3.08it/s, est. speed input: 3157.92 toks/s, output: 3.08 toks/s]
Processed prompts:  67%|   | 2725/4096 [14:43<07:22,  3.10it/s, est. speed input: 3158.55 toks/s, output: 3.08 toks/s]
Processed prompts:  67%|   | 2757/4096 [14:53<07:13,  3.09it/s, est. speed input: 3158.37 toks/s, output: 3.08 toks/s]
Processed prompts:  68%|   | 2789/4096 [15:04<07:04,  3.08it/s, est. speed input: 3158.17 toks/s, output: 3.08 toks/s]
Processed prompts:  69%|   | 2821/4096 [15:14<06:54,  3.08it/s, est. speed input: 3157.97 toks/s, output: 3.08 toks/s]
Processed prompts:  70%|   | 2853/4096 [15:25<06:44,  3.08it/s, est. speed input: 3157.82 toks/s, output: 3.08 toks/s]
Processed prompts:  70%|   | 2885/4096 [15:35<06:31,  3.09it/s, est. speed input: 3158.43 toks/s, output: 3.08 toks/s]
Processed prompts:  71%|   | 2917/4096 [15:45<06:19,  3.11it/s, est. speed input: 3159.02 toks/s, output: 3.08 toks/s]
Processed prompts:  72%|  | 2949/4096 [15:55<06:10,  3.09it/s, est. speed input: 3158.82 toks/s, output: 3.08 toks/s]
Processed prompts:  73%|  | 2981/4096 [16:06<06:01,  3.09it/s, est. speed input: 3158.65 toks/s, output: 3.08 toks/s]
Processed prompts:  74%|  | 3013/4096 [16:16<05:51,  3.08it/s, est. speed input: 3158.51 toks/s, output: 3.08 toks/s]
Processed prompts:  74%|  | 3045/4096 [16:27<05:41,  3.08it/s, est. speed input: 3158.35 toks/s, output: 3.08 toks/s]
Processed prompts:  75%|  | 3077/4096 [16:37<05:31,  3.08it/s, est. speed input: 3158.17 toks/s, output: 3.08 toks/s]
Processed prompts:  76%|  | 3109/4096 [16:48<05:21,  3.07it/s, est. speed input: 3158.03 toks/s, output: 3.08 toks/s]
Processed prompts:  77%|  | 3141/4096 [16:58<05:10,  3.07it/s, est. speed input: 3157.88 toks/s, output: 3.08 toks/s]
Processed prompts:  77%|  | 3173/4096 [17:08<05:00,  3.07it/s, est. speed input: 3157.70 toks/s, output: 3.08 toks/s]
Processed prompts:  78%|  | 3205/4096 [17:19<04:50,  3.07it/s, est. speed input: 3157.55 toks/s, output: 3.08 toks/s]
Processed prompts:  79%|  | 3237/4096 [17:29<04:39,  3.07it/s, est. speed input: 3157.41 toks/s, output: 3.08 toks/s]
Processed prompts:  80%|  | 3269/4096 [17:40<04:29,  3.07it/s, est. speed input: 3157.25 toks/s, output: 3.08 toks/s]
Processed prompts:  81%|  | 3301/4096 [17:50<04:19,  3.07it/s, est. speed input: 3157.10 toks/s, output: 3.08 toks/s]
Processed prompts:  81%| | 3333/4096 [18:01<04:08,  3.07it/s, est. speed input: 3156.97 toks/s, output: 3.08 toks/s]
Processed prompts:  82%| | 3365/4096 [18:11<03:58,  3.07it/s, est. speed input: 3156.81 toks/s, output: 3.08 toks/s]
Processed prompts:  83%| | 3397/4096 [18:21<03:47,  3.07it/s, est. speed input: 3156.70 toks/s, output: 3.08 toks/s]
Processed prompts:  84%| | 3429/4096 [18:32<03:37,  3.07it/s, est. speed input: 3156.56 toks/s, output: 3.08 toks/s]
Processed prompts:  84%| | 3461/4096 [18:42<03:26,  3.07it/s, est. speed input: 3156.40 toks/s, output: 3.08 toks/s]
Processed prompts:  85%| | 3493/4096 [18:53<03:16,  3.07it/s, est. speed input: 3156.27 toks/s, output: 3.08 toks/s]
Processed prompts:  86%| | 3525/4096 [19:03<03:06,  3.07it/s, est. speed input: 3156.17 toks/s, output: 3.08 toks/s]
Processed prompts:  87%| | 3557/4096 [19:14<02:55,  3.07it/s, est. speed input: 3156.03 toks/s, output: 3.08 toks/s]
Processed prompts:  88%| | 3589/4096 [19:24<02:45,  3.07it/s, est. speed input: 3155.92 toks/s, output: 3.08 toks/s]
Processed prompts:  88%| | 3621/4096 [19:34<02:34,  3.07it/s, est. speed input: 3155.79 toks/s, output: 3.08 toks/s]
Processed prompts:  89%| | 3653/4096 [19:45<02:24,  3.07it/s, est. speed input: 3155.65 toks/s, output: 3.08 toks/s]
Processed prompts:  90%| | 3685/4096 [19:55<02:13,  3.09it/s, est. speed input: 3156.19 toks/s, output: 3.08 toks/s]
Processed prompts:  91%| | 3717/4096 [20:05<02:02,  3.08it/s, est. speed input: 3156.09 toks/s, output: 3.08 toks/s]
Processed prompts:  92%|| 3749/4096 [20:16<01:52,  3.08it/s, est. speed input: 3155.98 toks/s, output: 3.08 toks/s]
Processed prompts:  92%|| 3781/4096 [20:26<01:42,  3.08it/s, est. speed input: 3155.88 toks/s, output: 3.08 toks/s]
Processed prompts:  93%|| 3813/4096 [20:37<01:32,  3.07it/s, est. speed input: 3155.77 toks/s, output: 3.08 toks/s]
Processed prompts:  94%|| 3845/4096 [20:47<01:21,  3.07it/s, est. speed input: 3155.70 toks/s, output: 3.08 toks/s]
Processed prompts:  95%|| 3877/4096 [20:58<01:11,  3.07it/s, est. speed input: 3155.57 toks/s, output: 3.08 toks/s]
Processed prompts:  95%|| 3909/4096 [21:08<01:00,  3.09it/s, est. speed input: 3156.06 toks/s, output: 3.08 toks/s]
Processed prompts:  96%|| 3941/4096 [21:18<00:50,  3.09it/s, est. speed input: 3155.95 toks/s, output: 3.08 toks/s]
Processed prompts:  97%|| 3973/4096 [21:29<00:39,  3.08it/s, est. speed input: 3155.83 toks/s, output: 3.08 toks/s]
Processed prompts:  98%|| 4005/4096 [21:39<00:29,  3.10it/s, est. speed input: 3156.27 toks/s, output: 3.08 toks/s]
Processed prompts:  99%|| 4037/4096 [21:49<00:19,  3.09it/s, est. speed input: 3156.14 toks/s, output: 3.08 toks/s]
Processed prompts:  99%|| 4069/4096 [21:58<00:08,  3.21it/s, est. speed input: 3159.23 toks/s, output: 3.09 toks/s]
Processed prompts: 100%|| 4096/4096 [21:58<00:00,  3.21it/s, est. speed input: 3180.19 toks/s, output: 3.11 toks/s]
Processed prompts: 100%|| 4096/4096 [21:58<00:00,  3.11it/s, est. speed input: 3180.19 toks/s, output: 3.11 toks/s]
[rank0]:[W127 12:35:58.327544241 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-27 12:36:06
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M65536.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-27 12:36:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-27 12:36:41 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=2617452) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2617452) WARNING 01-27 12:39:44 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 3.12 requests/s, 3192.93 total tokens/s, 3.12 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-27 12:36:41] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 12:36:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 12:36:41] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 12:36:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 12:36:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 12:36:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 12:36:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 12:36:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-27 12:36:45] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-27 12:36:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-27 12:36:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-27 12:36:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-27 12:36:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-27 12:36:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-27 12:36:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-27 12:36:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-27 12:36:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=2617452) [2026-01-27 12:36:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=2617452) [2026-01-27 12:36:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=2617452) [2026-01-27 12:36:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=2617452) [2026-01-27 12:36:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=2617452) [2026-01-27 12:36:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=2617452) [2026-01-27 12:36:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=2617452) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=2617452) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:08<00:25,  8.41s/it]
(EngineCore_DP0 pid=2617452) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:48<00:54, 27.09s/it]
(EngineCore_DP0 pid=2617452) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [01:20<00:29, 29.26s/it]
(EngineCore_DP0 pid=2617452) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 33.79s/it]
(EngineCore_DP0 pid=2617452) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [02:01<00:00, 30.29s/it]
(EngineCore_DP0 pid=2617452) 
(EngineCore_DP0 pid=2617452) [2026-01-27 12:38:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=2617452) [2026-01-27 12:38:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=2617452) [2026-01-27 12:38:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=2617452) [2026-01-27 12:38:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=2617452) [2026-01-27 12:38:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=2617452) [2026-01-27 12:38:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=2617452) [2026-01-27 12:38:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=2617452) [2026-01-27 12:38:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=2617452) 2026-01-27 12:39:14,909 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=2617452) 2026-01-27 12:39:23,057 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/8192 [00:00<1:55:22,  1.18it/s]
Adding requests:   0%|          | 2/8192 [00:01<1:03:55,  2.14it/s]
Adding requests:   0%|          | 3/8192 [00:01<40:59,  3.33it/s]  
Adding requests:   0%|          | 5/8192 [00:01<22:23,  6.09it/s]
Adding requests:   0%|          | 9/8192 [00:01<11:04, 12.32it/s]
Adding requests:   0%|          | 14/8192 [00:01<06:42, 20.32it/s]
Adding requests:   0%|          | 25/8192 [00:01<03:19, 41.01it/s]
Adding requests:   1%|          | 41/8192 [00:01<01:55, 70.46it/s]
Adding requests:   1%|          | 56/8192 [00:01<01:30, 89.87it/s]
Adding requests:   1%|          | 83/8192 [00:01<00:58, 138.33it/s]
Adding requests:   1%|         | 113/8192 [00:02<00:44, 181.60it/s]
Adding requests:   2%|         | 146/8192 [00:02<00:36, 222.58it/s]
Adding requests:   2%|         | 185/8192 [00:02<00:29, 268.78it/s]
Adding requests:   3%|         | 221/8192 [00:02<00:27, 292.98it/s]
Adding requests:   3%|         | 256/8192 [00:02<00:25, 308.72it/s]
Adding requests:   4%|         | 291/8192 [00:02<00:24, 319.18it/s]
Adding requests:   4%|         | 330/8192 [00:02<00:23, 339.30it/s]
Adding requests:   5%|         | 373/8192 [00:02<00:21, 364.66it/s]
Adding requests:   5%|         | 420/8192 [00:02<00:19, 393.46it/s]
Adding requests:   6%|         | 460/8192 [00:02<00:19, 390.43it/s]
Adding requests:   6%|         | 502/8192 [00:03<00:19, 395.28it/s]
Adding requests:   7%|         | 545/8192 [00:03<00:18, 404.02it/s]
Adding requests:   7%|         | 591/8192 [00:03<00:18, 419.59it/s]
Adding requests:   8%|         | 634/8192 [00:03<00:18, 405.53it/s]
Adding requests:   8%|         | 675/8192 [00:03<00:18, 398.34it/s]
Adding requests:   9%|         | 715/8192 [00:03<00:19, 388.56it/s]
Adding requests:   9%|         | 758/8192 [00:03<00:18, 398.31it/s]
Adding requests:  10%|         | 798/8192 [00:03<00:19, 383.05it/s]
Adding requests:  10%|         | 837/8192 [00:03<00:19, 383.47it/s]
Adding requests:  11%|         | 876/8192 [00:03<00:19, 383.49it/s]
Adding requests:  11%|         | 919/8192 [00:04<00:18, 396.55it/s]
Adding requests:  12%|        | 961/8192 [00:04<00:18, 397.27it/s]
Adding requests:  12%|        | 1001/8192 [00:04<00:18, 391.86it/s]
Adding requests:  13%|        | 1041/8192 [00:04<00:18, 386.30it/s]
Adding requests:  13%|        | 1084/8192 [00:04<00:17, 398.02it/s]
Adding requests:  14%|        | 1124/8192 [00:04<00:18, 391.36it/s]
Adding requests:  14%|        | 1164/8192 [00:04<00:17, 392.86it/s]
Adding requests:  15%|        | 1204/8192 [00:04<00:18, 379.01it/s]
Adding requests:  15%|        | 1249/8192 [00:04<00:17, 396.96it/s]
Adding requests:  16%|        | 1291/8192 [00:05<00:17, 401.68it/s]
Adding requests:  16%|        | 1332/8192 [00:05<00:17, 398.01it/s]
Adding requests:  17%|        | 1372/8192 [00:05<00:17, 396.06it/s]
Adding requests:  17%|        | 1412/8192 [00:05<00:17, 395.70it/s]
Adding requests:  18%|        | 1458/8192 [00:05<00:16, 414.36it/s]
Adding requests:  18%|        | 1500/8192 [00:05<00:16, 396.04it/s]
Adding requests:  19%|        | 1540/8192 [00:05<00:17, 389.25it/s]
Adding requests:  19%|        | 1580/8192 [00:05<00:16, 390.23it/s]
Adding requests:  20%|        | 1624/8192 [00:05<00:16, 400.73it/s]
Adding requests:  20%|        | 1665/8192 [00:05<00:17, 374.09it/s]
Adding requests:  21%|        | 1703/8192 [00:06<00:17, 363.21it/s]
Adding requests:  21%|       | 1745/8192 [00:06<00:17, 378.82it/s]
Adding requests:  22%|       | 1790/8192 [00:06<00:16, 397.58it/s]
Adding requests:  22%|       | 1831/8192 [00:06<00:16, 384.19it/s]
Adding requests:  23%|       | 1870/8192 [00:06<00:16, 376.75it/s]
Adding requests:  23%|       | 1912/8192 [00:06<00:16, 388.07it/s]
Adding requests:  24%|       | 1957/8192 [00:06<00:15, 403.15it/s]
Adding requests:  24%|       | 1998/8192 [00:06<00:17, 349.07it/s]
Adding requests:  25%|       | 2037/8192 [00:06<00:17, 359.31it/s]
Adding requests:  25%|       | 2080/8192 [00:07<00:16, 378.41it/s]
Adding requests:  26%|       | 2120/8192 [00:07<00:15, 384.01it/s]
Adding requests:  26%|       | 2160/8192 [00:07<00:15, 378.29it/s]
Adding requests:  27%|       | 2199/8192 [00:07<00:15, 376.50it/s]
Adding requests:  27%|       | 2239/8192 [00:07<00:15, 380.91it/s]
Adding requests:  28%|       | 2283/8192 [00:07<00:14, 396.78it/s]
Adding requests:  28%|       | 2325/8192 [00:07<00:14, 400.94it/s]
Adding requests:  29%|       | 2366/8192 [00:07<00:14, 392.94it/s]
Adding requests:  29%|       | 2411/8192 [00:07<00:14, 408.98it/s]
Adding requests:  30%|       | 2456/8192 [00:08<00:13, 419.88it/s]
Adding requests:  31%|       | 2499/8192 [00:08<00:13, 408.65it/s]
Adding requests:  31%|       | 2541/8192 [00:08<00:13, 411.39it/s]
Adding requests:  32%|      | 2583/8192 [00:08<00:13, 409.98it/s]
Adding requests:  32%|      | 2630/8192 [00:08<00:13, 425.83it/s]
Adding requests:  33%|      | 2673/8192 [00:08<00:13, 403.73it/s]
Adding requests:  33%|      | 2714/8192 [00:08<00:13, 394.95it/s]
Adding requests:  34%|      | 2759/8192 [00:08<00:13, 409.06it/s]
Adding requests:  34%|      | 2805/8192 [00:08<00:12, 421.89it/s]
Adding requests:  35%|      | 2848/8192 [00:08<00:13, 403.31it/s]
Adding requests:  35%|      | 2889/8192 [00:09<00:13, 398.31it/s]
Adding requests:  36%|      | 2930/8192 [00:09<00:13, 401.40it/s]
Adding requests:  36%|      | 2980/8192 [00:09<00:12, 427.43it/s]
Adding requests:  37%|      | 3023/8192 [00:09<00:12, 416.85it/s]
Adding requests:  37%|      | 3065/8192 [00:09<00:12, 416.94it/s]
Adding requests:  38%|      | 3107/8192 [00:09<00:12, 416.81it/s]
Adding requests:  39%|      | 3156/8192 [00:09<00:11, 437.99it/s]
Adding requests:  39%|      | 3200/8192 [00:09<00:12, 401.26it/s]
Adding requests:  40%|      | 3242/8192 [00:09<00:12, 406.43it/s]
Adding requests:  40%|      | 3284/8192 [00:10<00:12, 407.54it/s]
Adding requests:  41%|      | 3329/8192 [00:10<00:11, 415.80it/s]
Adding requests:  41%|      | 3371/8192 [00:10<00:13, 370.67it/s]
Adding requests:  42%|     | 3411/8192 [00:10<00:12, 378.36it/s]
Adding requests:  42%|     | 3454/8192 [00:10<00:12, 392.40it/s]
Adding requests:  43%|     | 3497/8192 [00:10<00:11, 401.24it/s]
Adding requests:  43%|     | 3538/8192 [00:10<00:11, 400.81it/s]
Adding requests:  44%|     | 3579/8192 [00:10<00:11, 401.38it/s]
Adding requests:  44%|     | 3620/8192 [00:10<00:11, 395.14it/s]
Adding requests:  45%|     | 3667/8192 [00:10<00:10, 413.52it/s]
Adding requests:  45%|     | 3709/8192 [00:11<00:11, 391.29it/s]
Adding requests:  46%|     | 3749/8192 [00:11<00:11, 387.23it/s]
Adding requests:  46%|     | 3788/8192 [00:11<00:11, 377.86it/s]
Adding requests:  47%|     | 3830/8192 [00:11<00:11, 388.37it/s]
Adding requests:  47%|     | 3870/8192 [00:11<00:11, 383.74it/s]
Adding requests:  48%|     | 3909/8192 [00:11<00:11, 381.50it/s]
Adding requests:  48%|     | 3949/8192 [00:11<00:11, 384.39it/s]
Adding requests:  49%|     | 3995/8192 [00:11<00:10, 404.06it/s]
Adding requests:  49%|     | 4036/8192 [00:11<00:10, 392.21it/s]
Adding requests:  50%|     | 4076/8192 [00:12<00:10, 388.09it/s]
Adding requests:  50%|     | 4118/8192 [00:12<00:10, 395.53it/s]
Adding requests:  51%|     | 4168/8192 [00:12<00:09, 425.29it/s]
Adding requests:  51%|    | 4211/8192 [00:12<00:10, 395.12it/s]
Adding requests:  52%|    | 4252/8192 [00:12<00:10, 391.77it/s]
Adding requests:  52%|    | 4292/8192 [00:12<00:10, 388.27it/s]
Adding requests:  53%|    | 4341/8192 [00:12<00:09, 413.36it/s]
Adding requests:  54%|    | 4383/8192 [00:12<00:09, 394.49it/s]
Adding requests:  54%|    | 4423/8192 [00:12<00:09, 381.06it/s]
Adding requests:  55%|    | 4468/8192 [00:13<00:09, 399.39it/s]
Adding requests:  55%|    | 4509/8192 [00:13<00:09, 393.14it/s]
Adding requests:  56%|    | 4549/8192 [00:13<00:09, 390.16it/s]
Adding requests:  56%|    | 4589/8192 [00:13<00:09, 391.39it/s]
Adding requests:  57%|    | 4631/8192 [00:13<00:08, 398.06it/s]
Adding requests:  57%|    | 4676/8192 [00:13<00:08, 410.01it/s]
Adding requests:  58%|    | 4718/8192 [00:13<00:08, 397.93it/s]
Adding requests:  58%|    | 4758/8192 [00:13<00:09, 371.47it/s]
Adding requests:  59%|    | 4797/8192 [00:13<00:09, 375.63it/s]
Adding requests:  59%|    | 4843/8192 [00:14<00:08, 396.24it/s]
Adding requests:  60%|    | 4883/8192 [00:14<00:08, 392.66it/s]
Adding requests:  60%|    | 4925/8192 [00:14<00:08, 399.53it/s]
Adding requests:  61%|    | 4966/8192 [00:14<00:08, 390.24it/s]
Adding requests:  61%|    | 5013/8192 [00:14<00:07, 411.06it/s]
Adding requests:  62%|   | 5055/8192 [00:14<00:07, 409.09it/s]
Adding requests:  62%|   | 5097/8192 [00:14<00:07, 408.01it/s]
Adding requests:  63%|   | 5139/8192 [00:14<00:07, 410.57it/s]
Adding requests:  63%|   | 5189/8192 [00:14<00:06, 433.87it/s]
Adding requests:  64%|   | 5233/8192 [00:14<00:07, 410.24it/s]
Adding requests:  64%|   | 5277/8192 [00:15<00:07, 415.74it/s]
Adding requests:  65%|   | 5319/8192 [00:15<00:06, 414.84it/s]
Adding requests:  66%|   | 5372/8192 [00:15<00:06, 447.01it/s]
Adding requests:  66%|   | 5417/8192 [00:15<00:06, 427.78it/s]
Adding requests:  67%|   | 5462/8192 [00:15<00:06, 432.83it/s]
Adding requests:  67%|   | 5506/8192 [00:15<00:06, 430.84it/s]
Adding requests:  68%|   | 5557/8192 [00:15<00:05, 452.73it/s]
Adding requests:  68%|   | 5603/8192 [00:15<00:05, 435.89it/s]
Adding requests:  69%|   | 5647/8192 [00:15<00:05, 435.40it/s]
Adding requests:  69%|   | 5691/8192 [00:16<00:06, 404.19it/s]
Adding requests:  70%|   | 5741/8192 [00:16<00:05, 429.11it/s]
Adding requests:  71%|   | 5785/8192 [00:16<00:05, 408.50it/s]
Adding requests:  71%|   | 5827/8192 [00:16<00:05, 411.18it/s]
Adding requests:  72%|  | 5871/8192 [00:16<00:05, 417.16it/s]
Adding requests:  72%|  | 5921/8192 [00:16<00:05, 438.84it/s]
Adding requests:  73%|  | 5966/8192 [00:16<00:05, 415.34it/s]
Adding requests:  73%|  | 6008/8192 [00:16<00:05, 403.89it/s]
Adding requests:  74%|  | 6050/8192 [00:16<00:05, 407.80it/s]
Adding requests:  74%|  | 6099/8192 [00:16<00:04, 429.07it/s]
Adding requests:  75%|  | 6143/8192 [00:17<00:05, 367.50it/s]
Adding requests:  76%|  | 6185/8192 [00:17<00:05, 380.82it/s]
Adding requests:  76%|  | 6229/8192 [00:17<00:04, 396.13it/s]
Adding requests:  77%|  | 6273/8192 [00:17<00:04, 407.66it/s]
Adding requests:  77%|  | 6317/8192 [00:17<00:04, 414.12it/s]
Adding requests:  78%|  | 6360/8192 [00:17<00:04, 412.54it/s]
Adding requests:  78%|  | 6402/8192 [00:17<00:04, 413.37it/s]
Adding requests:  79%|  | 6447/8192 [00:17<00:04, 422.74it/s]
Adding requests:  79%|  | 6490/8192 [00:17<00:04, 407.98it/s]
Adding requests:  80%|  | 6532/8192 [00:18<00:04, 407.90it/s]
Adding requests:  80%|  | 6575/8192 [00:18<00:03, 414.18it/s]
Adding requests:  81%|  | 6624/8192 [00:18<00:03, 436.07it/s]
Adding requests:  81%| | 6668/8192 [00:18<00:03, 420.57it/s]
Adding requests:  82%| | 6711/8192 [00:18<00:03, 416.48it/s]
Adding requests:  82%| | 6756/8192 [00:18<00:03, 426.13it/s]
Adding requests:  83%| | 6799/8192 [00:18<00:03, 426.08it/s]
Adding requests:  84%| | 6842/8192 [00:18<00:03, 401.64it/s]
Adding requests:  84%| | 6886/8192 [00:18<00:03, 408.25it/s]
Adding requests:  85%| | 6928/8192 [00:19<00:03, 408.57it/s]
Adding requests:  85%| | 6975/8192 [00:19<00:02, 425.78it/s]
Adding requests:  86%| | 7018/8192 [00:19<00:02, 419.42it/s]
Adding requests:  86%| | 7061/8192 [00:19<00:02, 410.72it/s]
Adding requests:  87%| | 7103/8192 [00:19<00:02, 394.68it/s]
Adding requests:  87%| | 7153/8192 [00:19<00:02, 421.40it/s]
Adding requests:  88%| | 7196/8192 [00:19<00:02, 404.11it/s]
Adding requests:  88%| | 7241/8192 [00:19<00:02, 413.78it/s]
Adding requests:  89%| | 7286/8192 [00:19<00:02, 422.73it/s]
Adding requests:  90%| | 7338/8192 [00:19<00:01, 448.28it/s]
Adding requests:  90%| | 7384/8192 [00:20<00:01, 432.96it/s]
Adding requests:  91%| | 7428/8192 [00:20<00:01, 433.44it/s]
Adding requests:  91%| | 7472/8192 [00:20<00:01, 426.98it/s]
Adding requests:  92%|| 7518/8192 [00:20<00:01, 436.16it/s]
Adding requests:  92%|| 7562/8192 [00:20<00:01, 416.63it/s]
Adding requests:  93%|| 7604/8192 [00:20<00:01, 412.40it/s]
Adding requests:  93%|| 7646/8192 [00:20<00:01, 408.42it/s]
Adding requests:  94%|| 7694/8192 [00:20<00:01, 428.50it/s]
Adding requests:  94%|| 7738/8192 [00:20<00:01, 409.43it/s]
Adding requests:  95%|| 7780/8192 [00:21<00:01, 408.78it/s]
Adding requests:  95%|| 7822/8192 [00:21<00:00, 409.36it/s]
Adding requests:  96%|| 7868/8192 [00:21<00:00, 423.68it/s]
Adding requests:  97%|| 7911/8192 [00:21<00:00, 411.37it/s]
Adding requests:  97%|| 7954/8192 [00:21<00:00, 416.59it/s]
Adding requests:  98%|| 7996/8192 [00:21<00:00, 411.01it/s]
Adding requests:  98%|| 8044/8192 [00:21<00:00, 429.50it/s]
Adding requests:  99%|| 8088/8192 [00:21<00:00, 418.00it/s]
Adding requests:  99%|| 8130/8192 [00:21<00:00, 410.98it/s]
Adding requests: 100%|| 8172/8192 [00:21<00:00, 413.56it/s]
Adding requests: 100%|| 8192/8192 [00:22<00:00, 371.67it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 6/8192 [00:01<25:45,  5.30it/s, est. speed input: 5425.40 toks/s, output: 5.30 toks/s]
Processed prompts:   1%|          | 70/8192 [00:21<42:20,  3.20it/s, est. speed input: 3307.34 toks/s, output: 3.23 toks/s]
Processed prompts:   2%|         | 134/8192 [00:42<42:39,  3.15it/s, est. speed input: 3249.40 toks/s, output: 3.17 toks/s]
Processed prompts:   2%|         | 198/8192 [01:02<42:17,  3.15it/s, est. speed input: 3242.25 toks/s, output: 3.17 toks/s]
Processed prompts:   3%|         | 262/8192 [01:22<41:55,  3.15it/s, est. speed input: 3239.34 toks/s, output: 3.16 toks/s]
Processed prompts:   4%|         | 326/8192 [01:43<41:46,  3.14it/s, est. speed input: 3229.18 toks/s, output: 3.15 toks/s]
Processed prompts:   5%|         | 390/8192 [02:03<41:21,  3.14it/s, est. speed input: 3229.64 toks/s, output: 3.15 toks/s]
Processed prompts:   6%|         | 454/8192 [02:24<41:09,  3.13it/s, est. speed input: 3223.63 toks/s, output: 3.15 toks/s]
Processed prompts:   6%|         | 518/8192 [02:44<40:54,  3.13it/s, est. speed input: 3218.71 toks/s, output: 3.14 toks/s]
Processed prompts:   7%|         | 582/8192 [03:05<40:38,  3.12it/s, est. speed input: 3215.04 toks/s, output: 3.14 toks/s]
Processed prompts:   8%|         | 646/8192 [03:25<40:20,  3.12it/s, est. speed input: 3211.96 toks/s, output: 3.14 toks/s]
Processed prompts:   9%|         | 710/8192 [03:46<40:01,  3.12it/s, est. speed input: 3209.45 toks/s, output: 3.13 toks/s]
Processed prompts:   9%|         | 774/8192 [04:06<39:32,  3.13it/s, est. speed input: 3211.13 toks/s, output: 3.14 toks/s]
Processed prompts:  10%|         | 838/8192 [04:27<39:15,  3.12it/s, est. speed input: 3208.98 toks/s, output: 3.13 toks/s]
Processed prompts:  11%|         | 902/8192 [04:47<38:57,  3.12it/s, est. speed input: 3207.37 toks/s, output: 3.13 toks/s]
Processed prompts:  12%|        | 966/8192 [05:08<38:39,  3.12it/s, est. speed input: 3205.79 toks/s, output: 3.13 toks/s]
Processed prompts:  13%|        | 1030/8192 [05:29<38:20,  3.11it/s, est. speed input: 3204.30 toks/s, output: 3.13 toks/s]
Processed prompts:  13%|        | 1094/8192 [05:49<38:00,  3.11it/s, est. speed input: 3203.16 toks/s, output: 3.13 toks/s]
Processed prompts:  14%|        | 1158/8192 [06:10<37:31,  3.12it/s, est. speed input: 3204.50 toks/s, output: 3.13 toks/s]
Processed prompts:  15%|        | 1222/8192 [06:30<37:14,  3.12it/s, est. speed input: 3203.34 toks/s, output: 3.13 toks/s]
Processed prompts:  16%|        | 1286/8192 [06:51<36:56,  3.12it/s, est. speed input: 3202.38 toks/s, output: 3.13 toks/s]
Processed prompts:  16%|        | 1350/8192 [07:11<36:37,  3.11it/s, est. speed input: 3201.47 toks/s, output: 3.13 toks/s]
Processed prompts:  17%|        | 1414/8192 [07:32<36:17,  3.11it/s, est. speed input: 3200.73 toks/s, output: 3.13 toks/s]
Processed prompts:  18%|        | 1478/8192 [07:52<35:58,  3.11it/s, est. speed input: 3199.85 toks/s, output: 3.12 toks/s]
Processed prompts:  19%|        | 1542/8192 [08:13<35:29,  3.12it/s, est. speed input: 3200.96 toks/s, output: 3.13 toks/s]
Processed prompts:  20%|        | 1606/8192 [08:33<35:03,  3.13it/s, est. speed input: 3201.93 toks/s, output: 3.13 toks/s]
Processed prompts:  20%|        | 1670/8192 [08:54<34:47,  3.12it/s, est. speed input: 3201.21 toks/s, output: 3.13 toks/s]
Processed prompts:  21%|        | 1734/8192 [09:14<34:30,  3.12it/s, est. speed input: 3200.54 toks/s, output: 3.13 toks/s]
Processed prompts:  22%|       | 1798/8192 [09:35<34:12,  3.12it/s, est. speed input: 3199.84 toks/s, output: 3.12 toks/s]
Processed prompts:  23%|       | 1862/8192 [09:55<33:53,  3.11it/s, est. speed input: 3199.24 toks/s, output: 3.12 toks/s]
Processed prompts:  24%|       | 1926/8192 [10:16<33:34,  3.11it/s, est. speed input: 3198.61 toks/s, output: 3.12 toks/s]
Processed prompts:  24%|       | 1990/8192 [10:37<33:14,  3.11it/s, est. speed input: 3198.08 toks/s, output: 3.12 toks/s]
Processed prompts:  25%|       | 2054/8192 [10:57<32:53,  3.11it/s, est. speed input: 3197.60 toks/s, output: 3.12 toks/s]
Processed prompts:  26%|       | 2118/8192 [11:18<32:33,  3.11it/s, est. speed input: 3197.13 toks/s, output: 3.12 toks/s]
Processed prompts:  27%|       | 2182/8192 [11:38<32:05,  3.12it/s, est. speed input: 3198.02 toks/s, output: 3.12 toks/s]
Processed prompts:  27%|       | 2246/8192 [11:59<31:47,  3.12it/s, est. speed input: 3197.54 toks/s, output: 3.12 toks/s]
Processed prompts:  28%|       | 2310/8192 [12:19<31:28,  3.11it/s, est. speed input: 3197.11 toks/s, output: 3.12 toks/s]
Processed prompts:  29%|       | 2374/8192 [12:40<31:09,  3.11it/s, est. speed input: 3196.74 toks/s, output: 3.12 toks/s]
Processed prompts:  30%|       | 2438/8192 [13:01<30:49,  3.11it/s, est. speed input: 3196.36 toks/s, output: 3.12 toks/s]
Processed prompts:  31%|       | 2502/8192 [13:21<30:29,  3.11it/s, est. speed input: 3196.02 toks/s, output: 3.12 toks/s]
Processed prompts:  31%|      | 2566/8192 [13:41<30:01,  3.12it/s, est. speed input: 3196.75 toks/s, output: 3.12 toks/s]
Processed prompts:  32%|      | 2630/8192 [14:02<29:44,  3.12it/s, est. speed input: 3196.34 toks/s, output: 3.12 toks/s]
Processed prompts:  33%|      | 2694/8192 [14:22<29:18,  3.13it/s, est. speed input: 3197.04 toks/s, output: 3.12 toks/s]
Processed prompts:  34%|      | 2758/8192 [14:43<29:01,  3.12it/s, est. speed input: 3196.69 toks/s, output: 3.12 toks/s]
Processed prompts:  34%|      | 2822/8192 [15:04<28:43,  3.12it/s, est. speed input: 3196.32 toks/s, output: 3.12 toks/s]
Processed prompts:  35%|      | 2886/8192 [15:24<28:10,  3.14it/s, est. speed input: 3197.85 toks/s, output: 3.12 toks/s]
Processed prompts:  36%|      | 2950/8192 [15:44<27:55,  3.13it/s, est. speed input: 3197.50 toks/s, output: 3.12 toks/s]
Processed prompts:  37%|      | 3014/8192 [16:05<27:38,  3.12it/s, est. speed input: 3197.21 toks/s, output: 3.12 toks/s]
Processed prompts:  38%|      | 3078/8192 [16:25<27:19,  3.12it/s, est. speed input: 3196.92 toks/s, output: 3.12 toks/s]
Processed prompts:  38%|      | 3142/8192 [16:46<27:00,  3.12it/s, est. speed input: 3196.65 toks/s, output: 3.12 toks/s]
Processed prompts:  39%|      | 3206/8192 [17:07<26:41,  3.11it/s, est. speed input: 3196.34 toks/s, output: 3.12 toks/s]
Processed prompts:  40%|      | 3270/8192 [17:27<26:21,  3.11it/s, est. speed input: 3196.06 toks/s, output: 3.12 toks/s]
Processed prompts:  41%|      | 3334/8192 [17:48<26:01,  3.11it/s, est. speed input: 3195.81 toks/s, output: 3.12 toks/s]
Processed prompts:  41%|     | 3398/8192 [18:08<25:41,  3.11it/s, est. speed input: 3195.55 toks/s, output: 3.12 toks/s]
Processed prompts:  42%|     | 3462/8192 [18:29<25:21,  3.11it/s, est. speed input: 3195.29 toks/s, output: 3.12 toks/s]
Processed prompts:  43%|     | 3526/8192 [18:50<25:00,  3.11it/s, est. speed input: 3195.09 toks/s, output: 3.12 toks/s]
Processed prompts:  44%|     | 3590/8192 [19:10<24:40,  3.11it/s, est. speed input: 3194.89 toks/s, output: 3.12 toks/s]
Processed prompts:  45%|     | 3654/8192 [19:30<24:13,  3.12it/s, est. speed input: 3195.47 toks/s, output: 3.12 toks/s]
Processed prompts:  45%|     | 3718/8192 [19:51<23:54,  3.12it/s, est. speed input: 3195.26 toks/s, output: 3.12 toks/s]
Processed prompts:  46%|     | 3782/8192 [20:12<23:35,  3.11it/s, est. speed input: 3195.04 toks/s, output: 3.12 toks/s]
Processed prompts:  47%|     | 3846/8192 [20:32<23:16,  3.11it/s, est. speed input: 3194.80 toks/s, output: 3.12 toks/s]
Processed prompts:  48%|     | 3910/8192 [20:53<22:50,  3.12it/s, est. speed input: 3195.32 toks/s, output: 3.12 toks/s]
Processed prompts:  49%|     | 3974/8192 [21:13<22:26,  3.13it/s, est. speed input: 3195.79 toks/s, output: 3.12 toks/s]
Processed prompts:  49%|     | 4038/8192 [21:33<22:04,  3.14it/s, est. speed input: 3196.26 toks/s, output: 3.12 toks/s]
Processed prompts:  50%|     | 4102/8192 [21:54<21:47,  3.13it/s, est. speed input: 3196.06 toks/s, output: 3.12 toks/s]
Processed prompts:  51%|     | 4166/8192 [22:14<21:29,  3.12it/s, est. speed input: 3195.83 toks/s, output: 3.12 toks/s]
Processed prompts:  52%|    | 4230/8192 [22:35<21:10,  3.12it/s, est. speed input: 3195.63 toks/s, output: 3.12 toks/s]
Processed prompts:  52%|    | 4294/8192 [22:56<20:51,  3.11it/s, est. speed input: 3195.43 toks/s, output: 3.12 toks/s]
Processed prompts:  53%|    | 4358/8192 [23:16<20:31,  3.11it/s, est. speed input: 3195.23 toks/s, output: 3.12 toks/s]
Processed prompts:  54%|    | 4422/8192 [23:36<20:07,  3.12it/s, est. speed input: 3195.64 toks/s, output: 3.12 toks/s]
Processed prompts:  55%|    | 4486/8192 [23:57<19:48,  3.12it/s, est. speed input: 3195.44 toks/s, output: 3.12 toks/s]
Processed prompts:  56%|    | 4550/8192 [24:17<19:24,  3.13it/s, est. speed input: 3195.84 toks/s, output: 3.12 toks/s]
Processed prompts:  56%|    | 4614/8192 [24:38<19:06,  3.12it/s, est. speed input: 3195.65 toks/s, output: 3.12 toks/s]
Processed prompts:  57%|    | 4678/8192 [24:59<18:47,  3.12it/s, est. speed input: 3195.45 toks/s, output: 3.12 toks/s]
Processed prompts:  58%|    | 4742/8192 [25:19<18:27,  3.11it/s, est. speed input: 3195.26 toks/s, output: 3.12 toks/s]
Processed prompts:  59%|    | 4806/8192 [25:40<18:08,  3.11it/s, est. speed input: 3195.08 toks/s, output: 3.12 toks/s]
Processed prompts:  59%|    | 4870/8192 [26:00<17:48,  3.11it/s, est. speed input: 3194.88 toks/s, output: 3.12 toks/s]
Processed prompts:  60%|    | 4934/8192 [26:21<17:24,  3.12it/s, est. speed input: 3195.21 toks/s, output: 3.12 toks/s]
Processed prompts:  61%|    | 4998/8192 [26:41<17:05,  3.12it/s, est. speed input: 3195.02 toks/s, output: 3.12 toks/s]
Processed prompts:  62%|   | 5062/8192 [27:02<16:45,  3.11it/s, est. speed input: 3194.87 toks/s, output: 3.12 toks/s]
Processed prompts:  63%|   | 5126/8192 [27:23<16:25,  3.11it/s, est. speed input: 3194.72 toks/s, output: 3.12 toks/s]
Processed prompts:  63%|   | 5190/8192 [27:43<16:01,  3.12it/s, est. speed input: 3195.10 toks/s, output: 3.12 toks/s]
Processed prompts:  64%|   | 5254/8192 [28:03<15:38,  3.13it/s, est. speed input: 3195.45 toks/s, output: 3.12 toks/s]
Processed prompts:  65%|   | 5318/8192 [28:24<15:19,  3.12it/s, est. speed input: 3195.30 toks/s, output: 3.12 toks/s]
Processed prompts:  66%|   | 5382/8192 [28:44<15:00,  3.12it/s, est. speed input: 3195.13 toks/s, output: 3.12 toks/s]
Processed prompts:  66%|   | 5446/8192 [29:05<14:41,  3.12it/s, est. speed input: 3195.01 toks/s, output: 3.12 toks/s]
Processed prompts:  67%|   | 5510/8192 [29:25<14:18,  3.13it/s, est. speed input: 3195.33 toks/s, output: 3.12 toks/s]
Processed prompts:  68%|   | 5574/8192 [29:46<13:55,  3.13it/s, est. speed input: 3195.67 toks/s, output: 3.12 toks/s]
Processed prompts:  69%|   | 5638/8192 [30:06<13:37,  3.12it/s, est. speed input: 3195.50 toks/s, output: 3.12 toks/s]
Processed prompts:  70%|   | 5702/8192 [30:27<13:18,  3.12it/s, est. speed input: 3195.36 toks/s, output: 3.12 toks/s]
Processed prompts:  70%|   | 5766/8192 [30:47<12:58,  3.12it/s, est. speed input: 3195.22 toks/s, output: 3.12 toks/s]
Processed prompts:  71%|   | 5830/8192 [31:08<12:38,  3.11it/s, est. speed input: 3195.06 toks/s, output: 3.12 toks/s]
Processed prompts:  72%|  | 5894/8192 [31:28<12:15,  3.12it/s, est. speed input: 3195.39 toks/s, output: 3.12 toks/s]
Processed prompts:  73%|  | 5958/8192 [31:49<11:53,  3.13it/s, est. speed input: 3195.72 toks/s, output: 3.12 toks/s]
Processed prompts:  74%|  | 6022/8192 [32:09<11:34,  3.13it/s, est. speed input: 3195.59 toks/s, output: 3.12 toks/s]
Processed prompts:  74%|  | 6086/8192 [32:30<11:14,  3.12it/s, est. speed input: 3195.46 toks/s, output: 3.12 toks/s]
Processed prompts:  75%|  | 6150/8192 [32:50<10:55,  3.12it/s, est. speed input: 3195.33 toks/s, output: 3.12 toks/s]
Processed prompts:  76%|  | 6214/8192 [33:11<10:35,  3.11it/s, est. speed input: 3195.20 toks/s, output: 3.12 toks/s]
Processed prompts:  77%|  | 6278/8192 [33:32<10:15,  3.11it/s, est. speed input: 3195.06 toks/s, output: 3.12 toks/s]
Processed prompts:  77%|  | 6342/8192 [33:52<09:54,  3.11it/s, est. speed input: 3194.95 toks/s, output: 3.12 toks/s]
Processed prompts:  78%|  | 6406/8192 [34:13<09:34,  3.11it/s, est. speed input: 3194.82 toks/s, output: 3.12 toks/s]
Processed prompts:  79%|  | 6470/8192 [34:33<09:13,  3.11it/s, est. speed input: 3194.69 toks/s, output: 3.12 toks/s]
Processed prompts:  80%|  | 6534/8192 [34:54<08:53,  3.11it/s, est. speed input: 3194.55 toks/s, output: 3.12 toks/s]
Processed prompts:  81%|  | 6598/8192 [35:15<08:32,  3.11it/s, est. speed input: 3194.45 toks/s, output: 3.12 toks/s]
Processed prompts:  81%| | 6662/8192 [35:35<08:12,  3.11it/s, est. speed input: 3194.33 toks/s, output: 3.12 toks/s]
Processed prompts:  82%| | 6726/8192 [35:56<07:51,  3.11it/s, est. speed input: 3194.22 toks/s, output: 3.12 toks/s]
Processed prompts:  83%| | 6790/8192 [36:16<07:31,  3.11it/s, est. speed input: 3194.11 toks/s, output: 3.12 toks/s]
Processed prompts:  84%| | 6854/8192 [36:37<07:10,  3.11it/s, est. speed input: 3194.03 toks/s, output: 3.12 toks/s]
Processed prompts:  84%| | 6918/8192 [36:57<06:49,  3.11it/s, est. speed input: 3193.92 toks/s, output: 3.12 toks/s]
Processed prompts:  85%| | 6982/8192 [37:18<06:29,  3.11it/s, est. speed input: 3193.81 toks/s, output: 3.12 toks/s]
Processed prompts:  86%| | 7046/8192 [37:39<06:08,  3.11it/s, est. speed input: 3193.68 toks/s, output: 3.12 toks/s]
Processed prompts:  87%| | 7110/8192 [37:59<05:48,  3.11it/s, est. speed input: 3193.56 toks/s, output: 3.12 toks/s]
Processed prompts:  88%| | 7174/8192 [38:20<05:27,  3.11it/s, est. speed input: 3193.45 toks/s, output: 3.12 toks/s]
Processed prompts:  88%| | 7238/8192 [38:40<05:07,  3.11it/s, est. speed input: 3193.35 toks/s, output: 3.12 toks/s]
Processed prompts:  89%| | 7302/8192 [39:01<04:46,  3.11it/s, est. speed input: 3193.27 toks/s, output: 3.12 toks/s]
Processed prompts:  90%| | 7366/8192 [39:22<04:25,  3.11it/s, est. speed input: 3193.16 toks/s, output: 3.12 toks/s]
Processed prompts:  91%| | 7430/8192 [39:42<04:05,  3.11it/s, est. speed input: 3193.06 toks/s, output: 3.12 toks/s]
Processed prompts:  91%|| 7494/8192 [40:03<03:44,  3.11it/s, est. speed input: 3192.97 toks/s, output: 3.12 toks/s]
Processed prompts:  92%|| 7558/8192 [40:23<03:23,  3.11it/s, est. speed input: 3192.90 toks/s, output: 3.12 toks/s]
Processed prompts:  93%|| 7622/8192 [40:44<03:03,  3.11it/s, est. speed input: 3192.82 toks/s, output: 3.12 toks/s]
Processed prompts:  94%|| 7686/8192 [41:05<02:42,  3.11it/s, est. speed input: 3192.72 toks/s, output: 3.12 toks/s]
Processed prompts:  95%|| 7750/8192 [41:25<02:22,  3.11it/s, est. speed input: 3192.62 toks/s, output: 3.12 toks/s]
Processed prompts:  95%|| 7814/8192 [41:46<02:01,  3.11it/s, est. speed input: 3192.53 toks/s, output: 3.12 toks/s]
Processed prompts:  96%|| 7878/8192 [42:06<01:41,  3.11it/s, est. speed input: 3192.42 toks/s, output: 3.12 toks/s]
Processed prompts:  97%|| 7942/8192 [42:27<01:20,  3.11it/s, est. speed input: 3192.32 toks/s, output: 3.12 toks/s]
Processed prompts:  98%|| 8006/8192 [42:48<00:59,  3.11it/s, est. speed input: 3192.24 toks/s, output: 3.12 toks/s]
Processed prompts:  99%|| 8070/8192 [43:08<00:39,  3.11it/s, est. speed input: 3192.15 toks/s, output: 3.12 toks/s]
Processed prompts:  99%|| 8134/8192 [43:27<00:18,  3.18it/s, est. speed input: 3194.01 toks/s, output: 3.12 toks/s]
Processed prompts: 100%|| 8192/8192 [43:27<00:00,  3.18it/s, est. speed input: 3216.78 toks/s, output: 3.14 toks/s]
Processed prompts: 100%|| 8192/8192 [43:27<00:00,  3.14it/s, est. speed input: 3216.78 toks/s, output: 3.14 toks/s]
[rank0]:[W127 13:23:43.880264956 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-28 09:16:52
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/BitNet-2B-FP8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:16:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:16:56 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3736616) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3736616) WARNING 01-28 09:17:25 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 27.56 requests/s, 14137.71 total tokens/s, 27.56 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-28 09:16:56] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:16:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:16:56] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:16:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:16:56] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:16:56] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:16:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:16:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:16:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:16:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:16:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:16:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:16:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:16:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:16:59] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:16:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:16:59] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:16:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:16:59] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:16:59] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:16:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:16:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:16:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:16:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:16:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:16:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:16:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:16:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:00] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:00] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:00] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:00] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:00] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:00] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3736616) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3736616) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:17<00:00, 17.43s/it]
(EngineCore_DP0 pid=3736616) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:17<00:00, 17.43s/it]
(EngineCore_DP0 pid=3736616) 
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3840] -> 1D uint8
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9216000 bytes
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3840] -> 1D uint8
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6144000 bytes
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3840] -> 1D uint8
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33177600 bytes
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 10368] -> 1D uint8
(EngineCore_DP0 pid=3736616) [2026-01-28 09:17:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=3736616) 2026-01-28 09:17:24,578 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3736616) 2026-01-28 09:17:24,602 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  70%|   | 90/128 [00:00<00:00, 895.67it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 979.62it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:04, 26.54it/s, est. speed input: 13589.43 toks/s, output: 26.54 toks/s]
Processed prompts:   5%|         | 6/128 [00:00<00:04, 27.44it/s, est. speed input: 13979.22 toks/s, output: 27.30 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:04, 27.87it/s, est. speed input: 14161.01 toks/s, output: 27.66 toks/s]
Processed prompts:   9%|         | 12/128 [00:00<00:04, 28.16it/s, est. speed input: 14279.16 toks/s, output: 27.89 toks/s]
Processed prompts:  12%|        | 15/128 [00:00<00:03, 28.35it/s, est. speed input: 14360.31 toks/s, output: 28.05 toks/s]
Processed prompts:  14%|        | 18/128 [00:00<00:03, 28.23it/s, est. speed input: 14357.14 toks/s, output: 28.04 toks/s]
Processed prompts:  16%|        | 21/128 [00:00<00:03, 28.52it/s, est. speed input: 14434.85 toks/s, output: 28.19 toks/s]
Processed prompts:  19%|        | 24/128 [00:00<00:03, 28.13it/s, est. speed input: 14377.24 toks/s, output: 28.08 toks/s]
Processed prompts:  21%|        | 27/128 [00:00<00:03, 28.25it/s, est. speed input: 14402.61 toks/s, output: 28.13 toks/s]
Processed prompts:  23%|       | 30/128 [00:01<00:03, 28.39it/s, est. speed input: 14431.67 toks/s, output: 28.19 toks/s]
Processed prompts:  26%|       | 33/128 [00:01<00:03, 28.48it/s, est. speed input: 14453.80 toks/s, output: 28.23 toks/s]
Processed prompts:  28%|       | 36/128 [00:01<00:03, 28.53it/s, est. speed input: 14471.91 toks/s, output: 28.26 toks/s]
Processed prompts:  30%|       | 39/128 [00:01<00:03, 28.39it/s, est. speed input: 14464.02 toks/s, output: 28.25 toks/s]
Processed prompts:  33%|      | 42/128 [00:01<00:03, 28.39it/s, est. speed input: 14469.70 toks/s, output: 28.26 toks/s]
Processed prompts:  35%|      | 45/128 [00:01<00:02, 28.46it/s, est. speed input: 14481.04 toks/s, output: 28.28 toks/s]
Processed prompts:  38%|      | 48/128 [00:01<00:02, 28.59it/s, est. speed input: 14500.95 toks/s, output: 28.32 toks/s]
Processed prompts:  40%|      | 51/128 [00:01<00:02, 28.44it/s, est. speed input: 14494.30 toks/s, output: 28.31 toks/s]
Processed prompts:  42%|     | 54/128 [00:01<00:02, 28.15it/s, est. speed input: 14470.06 toks/s, output: 28.26 toks/s]
Processed prompts:  45%|     | 57/128 [00:02<00:02, 28.18it/s, est. speed input: 14470.19 toks/s, output: 28.26 toks/s]
Processed prompts:  47%|     | 60/128 [00:02<00:02, 28.39it/s, est. speed input: 14485.43 toks/s, output: 28.29 toks/s]
Processed prompts:  49%|     | 63/128 [00:02<00:02, 28.44it/s, est. speed input: 14492.19 toks/s, output: 28.30 toks/s]
Processed prompts:  52%|    | 66/128 [00:02<00:02, 28.45it/s, est. speed input: 14495.82 toks/s, output: 28.31 toks/s]
Processed prompts:  54%|    | 69/128 [00:02<00:02, 28.56it/s, est. speed input: 14506.99 toks/s, output: 28.33 toks/s]
Processed prompts:  56%|    | 72/128 [00:02<00:01, 28.59it/s, est. speed input: 14513.91 toks/s, output: 28.35 toks/s]
Processed prompts:  59%|    | 75/128 [00:02<00:01, 28.60it/s, est. speed input: 14519.82 toks/s, output: 28.36 toks/s]
Processed prompts:  61%|    | 78/128 [00:02<00:01, 28.63it/s, est. speed input: 14526.19 toks/s, output: 28.37 toks/s]
Processed prompts:  63%|   | 81/128 [00:02<00:01, 28.69it/s, est. speed input: 14534.91 toks/s, output: 28.39 toks/s]
Processed prompts:  66%|   | 84/128 [00:02<00:01, 28.23it/s, est. speed input: 14512.48 toks/s, output: 28.34 toks/s]
Processed prompts:  68%|   | 87/128 [00:03<00:01, 28.23it/s, est. speed input: 14510.53 toks/s, output: 28.34 toks/s]
Processed prompts:  70%|   | 90/128 [00:03<00:01, 28.26it/s, est. speed input: 14510.17 toks/s, output: 28.34 toks/s]
Processed prompts:  73%|  | 93/128 [00:03<00:01, 28.43it/s, est. speed input: 14518.30 toks/s, output: 28.36 toks/s]
Processed prompts:  75%|  | 96/128 [00:03<00:01, 28.32it/s, est. speed input: 14513.56 toks/s, output: 28.35 toks/s]
Processed prompts:  77%|  | 99/128 [00:03<00:01, 28.50it/s, est. speed input: 14522.23 toks/s, output: 28.36 toks/s]
Processed prompts:  80%|  | 102/128 [00:03<00:00, 28.47it/s, est. speed input: 14522.88 toks/s, output: 28.36 toks/s]
Processed prompts:  82%| | 105/128 [00:03<00:00, 28.54it/s, est. speed input: 14527.86 toks/s, output: 28.37 toks/s]
Processed prompts:  84%| | 108/128 [00:03<00:00, 28.50it/s, est. speed input: 14528.40 toks/s, output: 28.38 toks/s]
Processed prompts:  87%| | 111/128 [00:03<00:00, 28.60it/s, est. speed input: 14534.44 toks/s, output: 28.39 toks/s]
Processed prompts:  89%| | 114/128 [00:04<00:00, 28.02it/s, est. speed input: 14511.40 toks/s, output: 28.34 toks/s]
Processed prompts:  91%|| 117/128 [00:04<00:00, 28.05it/s, est. speed input: 14508.21 toks/s, output: 28.34 toks/s]
Processed prompts:  94%|| 120/128 [00:04<00:00, 28.28it/s, est. speed input: 14514.57 toks/s, output: 28.35 toks/s]
Processed prompts:  96%|| 123/128 [00:04<00:00, 28.34it/s, est. speed input: 14516.27 toks/s, output: 28.35 toks/s]
Processed prompts:  98%|| 126/128 [00:04<00:00, 28.28it/s, est. speed input: 14513.44 toks/s, output: 28.35 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.28it/s, est. speed input: 14522.95 toks/s, output: 28.37 toks/s]
Processed prompts: 100%|| 128/128 [00:04<00:00, 28.36it/s, est. speed input: 14522.95 toks/s, output: 28.37 toks/s]
[rank0]:[W128 09:17:30.117908666 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-28 09:17:32
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/BitNet-2B-FP8_M1024.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:17:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:17:36 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3737370) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3737370) WARNING 01-28 09:18:04 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.65 requests/s, 15011.83 total tokens/s, 14.65 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-28 09:17:36] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:17:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:17:36] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:17:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:17:36] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:17:36] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:17:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:17:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:17:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:17:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:17:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:17:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:17:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:17:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:17:39] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:17:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:17:39] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:17:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:17:39] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:17:39] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:17:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:17:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:17:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:17:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:17:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:17:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:17:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:17:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3737370) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3737370) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.43s/it]
(EngineCore_DP0 pid=3737370) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.43s/it]
(EngineCore_DP0 pid=3737370) 
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3840] -> 1D uint8
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9216000 bytes
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3840] -> 1D uint8
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6144000 bytes
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3840] -> 1D uint8
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33177600 bytes
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 10368] -> 1D uint8
(EngineCore_DP0 pid=3737370) [2026-01-28 09:17:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=3737370) 2026-01-28 09:18:03,505 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3737370) 2026-01-28 09:18:03,517 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  51%|     | 65/128 [00:00<00:00, 645.08it/s]
Adding requests: 100%|| 128/128 [00:00<00:00, 677.49it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:13,  9.12it/s, est. speed input: 9337.76 toks/s, output: 9.12 toks/s]
Processed prompts:   2%|         | 3/128 [00:00<00:09, 12.87it/s, est. speed input: 12656.68 toks/s, output: 12.36 toks/s]
Processed prompts:   4%|         | 5/128 [00:00<00:08, 13.84it/s, est. speed input: 13586.63 toks/s, output: 13.27 toks/s]
Processed prompts:   5%|         | 7/128 [00:00<00:08, 14.42it/s, est. speed input: 14121.96 toks/s, output: 13.79 toks/s]
Processed prompts:   7%|         | 9/128 [00:00<00:08, 14.75it/s, est. speed input: 14441.79 toks/s, output: 14.10 toks/s]
Processed prompts:   9%|         | 11/128 [00:00<00:07, 14.82it/s, est. speed input: 14591.18 toks/s, output: 14.25 toks/s]
Processed prompts:  10%|         | 13/128 [00:00<00:07, 14.78it/s, est. speed input: 14661.85 toks/s, output: 14.32 toks/s]
Processed prompts:  12%|        | 15/128 [00:01<00:07, 14.85it/s, est. speed input: 14750.60 toks/s, output: 14.40 toks/s]
Processed prompts:  13%|        | 17/128 [00:01<00:07, 15.03it/s, est. speed input: 14866.01 toks/s, output: 14.52 toks/s]
Processed prompts:  15%|        | 19/128 [00:01<00:07, 15.05it/s, est. speed input: 14926.70 toks/s, output: 14.58 toks/s]
Processed prompts:  16%|        | 21/128 [00:01<00:07, 14.99it/s, est. speed input: 14952.75 toks/s, output: 14.60 toks/s]
Processed prompts:  18%|        | 23/128 [00:01<00:06, 15.10it/s, est. speed input: 15018.71 toks/s, output: 14.67 toks/s]
Processed prompts:  20%|        | 25/128 [00:01<00:06, 15.10it/s, est. speed input: 15051.87 toks/s, output: 14.70 toks/s]
Processed prompts:  21%|        | 27/128 [00:01<00:06, 15.03it/s, est. speed input: 15065.90 toks/s, output: 14.71 toks/s]
Processed prompts:  23%|       | 29/128 [00:01<00:06, 14.84it/s, est. speed input: 15043.62 toks/s, output: 14.69 toks/s]
Processed prompts:  24%|       | 31/128 [00:02<00:06, 14.95it/s, est. speed input: 15077.51 toks/s, output: 14.72 toks/s]
Processed prompts:  26%|       | 33/128 [00:02<00:06, 15.09it/s, est. speed input: 15119.57 toks/s, output: 14.77 toks/s]
Processed prompts:  27%|       | 35/128 [00:02<00:06, 15.03it/s, est. speed input: 15127.14 toks/s, output: 14.77 toks/s]
Processed prompts:  29%|       | 37/128 [00:02<00:06, 15.08it/s, est. speed input: 15149.40 toks/s, output: 14.79 toks/s]
Processed prompts:  30%|       | 39/128 [00:02<00:05, 15.08it/s, est. speed input: 15164.57 toks/s, output: 14.81 toks/s]
Processed prompts:  32%|      | 41/128 [00:02<00:05, 15.02it/s, est. speed input: 15168.24 toks/s, output: 14.81 toks/s]
Processed prompts:  34%|      | 43/128 [00:02<00:05, 14.91it/s, est. speed input: 15160.94 toks/s, output: 14.81 toks/s]
Processed prompts:  35%|      | 45/128 [00:03<00:05, 14.92it/s, est. speed input: 15167.60 toks/s, output: 14.81 toks/s]
Processed prompts:  37%|      | 47/128 [00:03<00:05, 14.99it/s, est. speed input: 15182.40 toks/s, output: 14.83 toks/s]
Processed prompts:  38%|      | 49/128 [00:03<00:05, 14.99it/s, est. speed input: 15188.24 toks/s, output: 14.83 toks/s]
Processed prompts:  40%|      | 51/128 [00:03<00:05, 15.15it/s, est. speed input: 15215.57 toks/s, output: 14.86 toks/s]
Processed prompts:  41%|     | 53/128 [00:03<00:04, 15.22it/s, est. speed input: 15235.71 toks/s, output: 14.88 toks/s]
Processed prompts:  43%|     | 55/128 [00:03<00:04, 15.15it/s, est. speed input: 15238.90 toks/s, output: 14.88 toks/s]
Processed prompts:  45%|     | 57/128 [00:03<00:04, 15.15it/s, est. speed input: 15249.30 toks/s, output: 14.89 toks/s]
Processed prompts:  46%|     | 59/128 [00:03<00:04, 15.04it/s, est. speed input: 15244.93 toks/s, output: 14.89 toks/s]
Processed prompts:  48%|     | 61/128 [00:04<00:04, 15.04it/s, est. speed input: 15249.83 toks/s, output: 14.89 toks/s]
Processed prompts:  49%|     | 63/128 [00:04<00:04, 15.08it/s, est. speed input: 15259.45 toks/s, output: 14.90 toks/s]
Processed prompts:  51%|     | 65/128 [00:04<00:04, 15.07it/s, est. speed input: 15263.69 toks/s, output: 14.91 toks/s]
Processed prompts:  52%|    | 67/128 [00:04<00:04, 15.12it/s, est. speed input: 15273.57 toks/s, output: 14.92 toks/s]
Processed prompts:  54%|    | 69/128 [00:04<00:03, 15.17it/s, est. speed input: 15284.76 toks/s, output: 14.93 toks/s]
Processed prompts:  55%|    | 71/128 [00:04<00:03, 15.10it/s, est. speed input: 15284.57 toks/s, output: 14.93 toks/s]
Processed prompts:  57%|    | 73/128 [00:04<00:03, 15.14it/s, est. speed input: 15293.05 toks/s, output: 14.93 toks/s]
Processed prompts:  59%|    | 75/128 [00:05<00:03, 14.96it/s, est. speed input: 15282.42 toks/s, output: 14.92 toks/s]
Processed prompts:  60%|    | 77/128 [00:05<00:03, 14.95it/s, est. speed input: 15282.31 toks/s, output: 14.92 toks/s]
Processed prompts:  62%|   | 79/128 [00:05<00:03, 15.08it/s, est. speed input: 15294.08 toks/s, output: 14.94 toks/s]
Processed prompts:  63%|   | 81/128 [00:05<00:03, 15.08it/s, est. speed input: 15297.43 toks/s, output: 14.94 toks/s]
Processed prompts:  65%|   | 83/128 [00:05<00:02, 15.11it/s, est. speed input: 15303.77 toks/s, output: 14.95 toks/s]
Processed prompts:  66%|   | 85/128 [00:05<00:02, 15.10it/s, est. speed input: 15307.02 toks/s, output: 14.95 toks/s]
Processed prompts:  68%|   | 87/128 [00:05<00:02, 15.09it/s, est. speed input: 15309.60 toks/s, output: 14.95 toks/s]
Processed prompts:  70%|   | 89/128 [00:05<00:02, 15.09it/s, est. speed input: 15313.10 toks/s, output: 14.95 toks/s]
Processed prompts:  71%|   | 91/128 [00:06<00:02, 14.97it/s, est. speed input: 15306.85 toks/s, output: 14.95 toks/s]
Processed prompts:  73%|  | 93/128 [00:06<00:02, 15.00it/s, est. speed input: 15309.53 toks/s, output: 14.95 toks/s]
Processed prompts:  74%|  | 95/128 [00:06<00:02, 15.05it/s, est. speed input: 15314.25 toks/s, output: 14.96 toks/s]
Processed prompts:  76%|  | 97/128 [00:06<00:02, 15.10it/s, est. speed input: 15319.44 toks/s, output: 14.96 toks/s]
Processed prompts:  77%|  | 99/128 [00:06<00:01, 15.20it/s, est. speed input: 15328.91 toks/s, output: 14.97 toks/s]
Processed prompts:  79%|  | 101/128 [00:06<00:01, 15.18it/s, est. speed input: 15332.64 toks/s, output: 14.97 toks/s]
Processed prompts:  80%|  | 103/128 [00:06<00:01, 15.09it/s, est. speed input: 15330.53 toks/s, output: 14.97 toks/s]
Processed prompts:  82%| | 105/128 [00:07<00:01, 15.16it/s, est. speed input: 15337.55 toks/s, output: 14.98 toks/s]
Processed prompts:  84%| | 107/128 [00:07<00:01, 14.88it/s, est. speed input: 15323.19 toks/s, output: 14.96 toks/s]
Processed prompts:  85%| | 109/128 [00:07<00:01, 14.94it/s, est. speed input: 15325.06 toks/s, output: 14.97 toks/s]
Processed prompts:  87%| | 111/128 [00:07<00:01, 14.98it/s, est. speed input: 15327.12 toks/s, output: 14.97 toks/s]
Processed prompts:  88%| | 113/128 [00:07<00:01, 14.98it/s, est. speed input: 15327.30 toks/s, output: 14.97 toks/s]
Processed prompts:  90%| | 115/128 [00:07<00:00, 14.96it/s, est. speed input: 15326.27 toks/s, output: 14.97 toks/s]
Processed prompts:  91%|| 117/128 [00:07<00:00, 14.97it/s, est. speed input: 15326.59 toks/s, output: 14.97 toks/s]
Processed prompts:  93%|| 119/128 [00:07<00:00, 15.07it/s, est. speed input: 15332.70 toks/s, output: 14.97 toks/s]
Processed prompts:  95%|| 121/128 [00:08<00:00, 15.06it/s, est. speed input: 15333.55 toks/s, output: 14.97 toks/s]
Processed prompts:  96%|| 123/128 [00:08<00:00, 14.88it/s, est. speed input: 15324.92 toks/s, output: 14.97 toks/s]
Processed prompts:  98%|| 125/128 [00:08<00:00, 14.84it/s, est. speed input: 15321.62 toks/s, output: 14.96 toks/s]
Processed prompts:  99%|| 127/128 [00:08<00:00, 15.03it/s, est. speed input: 15329.50 toks/s, output: 14.97 toks/s]
Processed prompts: 100%|| 128/128 [00:08<00:00, 15.03it/s, est. speed input: 15331.48 toks/s, output: 14.97 toks/s]
Processed prompts: 100%|| 128/128 [00:08<00:00, 14.97it/s, est. speed input: 15331.48 toks/s, output: 14.97 toks/s]
[rank0]:[W128 09:18:13.051095293 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-28 09:18:15
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/BitNet-2B-FP8_M2048.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:18:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:18:19 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3738166) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3738166) WARNING 01-28 09:18:46 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.84 requests/s, 15211.39 total tokens/s, 14.84 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-28 09:18:19] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:18:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:18:19] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:18:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:18:19] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:18:19] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:18:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:18:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:18:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:18:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:18:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:18:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:18:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:18:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:18:22] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:18:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:18:22] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:18:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:18:22] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:18:22] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:18:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:18:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:18:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:18:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:18:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:18:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:18:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:18:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:23] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:23] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:23] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:23] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:23] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3738166) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3738166) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.08s/it]
(EngineCore_DP0 pid=3738166) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.08s/it]
(EngineCore_DP0 pid=3738166) 
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3840] -> 1D uint8
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9216000 bytes
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3840] -> 1D uint8
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6144000 bytes
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3840] -> 1D uint8
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33177600 bytes
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 10368] -> 1D uint8
(EngineCore_DP0 pid=3738166) [2026-01-28 09:18:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=3738166) 2026-01-28 09:18:46,102 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3738166) 2026-01-28 09:18:46,113 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  24%|       | 62/256 [00:00<00:00, 612.18it/s]
Adding requests:  48%|     | 124/256 [00:00<00:00, 596.94it/s]
Adding requests:  72%|  | 184/256 [00:00<00:00, 572.39it/s]
Adding requests:  95%|| 242/256 [00:00<00:00, 557.14it/s]
Adding requests: 100%|| 256/256 [00:00<00:00, 567.05it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 6/256 [00:00<00:06, 41.35it/s, est. speed input: 42349.51 toks/s, output: 41.35 toks/s]
Processed prompts:   4%|         | 11/256 [00:00<00:09, 24.76it/s, est. speed input: 27141.75 toks/s, output: 26.50 toks/s]
Processed prompts:   5%|         | 14/256 [00:00<00:13, 17.98it/s, est. speed input: 21078.57 toks/s, output: 20.58 toks/s]
Processed prompts:   7%|         | 17/256 [00:00<00:12, 18.94it/s, est. speed input: 21234.34 toks/s, output: 20.74 toks/s]
Processed prompts:   8%|         | 20/256 [00:01<00:15, 15.65it/s, est. speed input: 18852.42 toks/s, output: 18.41 toks/s]
Processed prompts:   9%|         | 22/256 [00:01<00:15, 15.58it/s, est. speed input: 18519.06 toks/s, output: 18.08 toks/s]
Processed prompts:   9%|         | 24/256 [00:01<00:15, 15.44it/s, est. speed input: 18211.47 toks/s, output: 17.78 toks/s]
Processed prompts:  10%|         | 26/256 [00:01<00:14, 15.40it/s, est. speed input: 17983.56 toks/s, output: 17.56 toks/s]
Processed prompts:  11%|         | 28/256 [00:01<00:14, 15.26it/s, est. speed input: 17758.28 toks/s, output: 17.34 toks/s]
Processed prompts:  12%|        | 30/256 [00:01<00:14, 15.19it/s, est. speed input: 17573.80 toks/s, output: 17.16 toks/s]
Processed prompts:  12%|        | 32/256 [00:01<00:14, 15.01it/s, est. speed input: 17382.72 toks/s, output: 16.98 toks/s]
Processed prompts:  13%|        | 34/256 [00:02<00:14, 14.99it/s, est. speed input: 17243.80 toks/s, output: 16.84 toks/s]
Processed prompts:  14%|        | 36/256 [00:02<00:14, 15.07it/s, est. speed input: 17144.75 toks/s, output: 16.74 toks/s]
Processed prompts:  15%|        | 38/256 [00:02<00:14, 15.14it/s, est. speed input: 17062.50 toks/s, output: 16.66 toks/s]
Processed prompts:  16%|        | 40/256 [00:02<00:14, 15.16it/s, est. speed input: 16980.93 toks/s, output: 16.58 toks/s]
Processed prompts:  16%|        | 42/256 [00:02<00:14, 15.19it/s, est. speed input: 16911.17 toks/s, output: 16.51 toks/s]
Processed prompts:  17%|        | 44/256 [00:02<00:13, 15.25it/s, est. speed input: 16854.53 toks/s, output: 16.46 toks/s]
Processed prompts:  18%|        | 46/256 [00:02<00:13, 15.17it/s, est. speed input: 16783.72 toks/s, output: 16.39 toks/s]
Processed prompts:  19%|        | 48/256 [00:02<00:13, 15.02it/s, est. speed input: 16702.23 toks/s, output: 16.31 toks/s]
Processed prompts:  20%|        | 50/256 [00:03<00:13, 15.02it/s, est. speed input: 16645.76 toks/s, output: 16.26 toks/s]
Processed prompts:  20%|        | 52/256 [00:03<00:13, 15.12it/s, est. speed input: 16607.34 toks/s, output: 16.22 toks/s]
Processed prompts:  21%|        | 54/256 [00:03<00:13, 15.00it/s, est. speed input: 16546.47 toks/s, output: 16.16 toks/s]
Processed prompts:  22%|       | 56/256 [00:03<00:13, 15.01it/s, est. speed input: 16501.30 toks/s, output: 16.11 toks/s]
Processed prompts:  23%|       | 58/256 [00:03<00:13, 15.12it/s, est. speed input: 16474.07 toks/s, output: 16.09 toks/s]
Processed prompts:  23%|       | 60/256 [00:03<00:13, 15.07it/s, est. speed input: 16433.04 toks/s, output: 16.05 toks/s]
Processed prompts:  24%|       | 62/256 [00:03<00:12, 15.05it/s, est. speed input: 16395.86 toks/s, output: 16.01 toks/s]
Processed prompts:  25%|       | 64/256 [00:04<00:12, 14.86it/s, est. speed input: 16340.06 toks/s, output: 15.96 toks/s]
Processed prompts:  26%|       | 66/256 [00:04<00:12, 14.86it/s, est. speed input: 16304.00 toks/s, output: 15.92 toks/s]
Processed prompts:  27%|       | 68/256 [00:04<00:12, 14.90it/s, est. speed input: 16274.48 toks/s, output: 15.89 toks/s]
Processed prompts:  27%|       | 70/256 [00:04<00:12, 14.89it/s, est. speed input: 16242.48 toks/s, output: 15.86 toks/s]
Processed prompts:  28%|       | 72/256 [00:04<00:12, 15.00it/s, est. speed input: 16224.87 toks/s, output: 15.84 toks/s]
Processed prompts:  29%|       | 74/256 [00:04<00:12, 15.00it/s, est. speed input: 16200.18 toks/s, output: 15.82 toks/s]
Processed prompts:  30%|       | 76/256 [00:04<00:11, 15.02it/s, est. speed input: 16179.26 toks/s, output: 15.80 toks/s]
Processed prompts:  30%|       | 78/256 [00:04<00:11, 15.06it/s, est. speed input: 16161.49 toks/s, output: 15.78 toks/s]
Processed prompts:  31%|      | 80/256 [00:05<00:11, 14.89it/s, est. speed input: 16126.27 toks/s, output: 15.75 toks/s]
Processed prompts:  32%|      | 82/256 [00:05<00:11, 14.92it/s, est. speed input: 16106.29 toks/s, output: 15.73 toks/s]
Processed prompts:  33%|      | 84/256 [00:05<00:11, 14.99it/s, est. speed input: 16091.98 toks/s, output: 15.71 toks/s]
Processed prompts:  34%|      | 86/256 [00:05<00:11, 15.03it/s, est. speed input: 16077.43 toks/s, output: 15.70 toks/s]
Processed prompts:  34%|      | 88/256 [00:05<00:11, 15.02it/s, est. speed input: 16060.02 toks/s, output: 15.68 toks/s]
Processed prompts:  35%|      | 90/256 [00:05<00:11, 15.08it/s, est. speed input: 16049.32 toks/s, output: 15.67 toks/s]
Processed prompts:  36%|      | 92/256 [00:05<00:10, 15.15it/s, est. speed input: 16040.93 toks/s, output: 15.66 toks/s]
Processed prompts:  37%|      | 94/256 [00:06<00:10, 15.13it/s, est. speed input: 16028.33 toks/s, output: 15.65 toks/s]
Processed prompts:  38%|      | 96/256 [00:06<00:10, 14.88it/s, est. speed input: 15997.50 toks/s, output: 15.62 toks/s]
Processed prompts:  38%|      | 98/256 [00:06<00:10, 14.88it/s, est. speed input: 15980.99 toks/s, output: 15.61 toks/s]
Processed prompts:  39%|      | 100/256 [00:06<00:10, 14.95it/s, est. speed input: 15970.49 toks/s, output: 15.60 toks/s]
Processed prompts:  40%|      | 102/256 [00:06<00:10, 14.91it/s, est. speed input: 15954.45 toks/s, output: 15.58 toks/s]
Processed prompts:  41%|      | 104/256 [00:06<00:10, 15.01it/s, est. speed input: 15947.86 toks/s, output: 15.57 toks/s]
Processed prompts:  41%|     | 106/256 [00:06<00:09, 15.07it/s, est. speed input: 15940.31 toks/s, output: 15.57 toks/s]
Processed prompts:  42%|     | 108/256 [00:06<00:09, 15.07it/s, est. speed input: 15930.66 toks/s, output: 15.56 toks/s]
Processed prompts:  43%|     | 110/256 [00:07<00:09, 14.98it/s, est. speed input: 15915.12 toks/s, output: 15.54 toks/s]
Processed prompts:  44%|     | 112/256 [00:07<00:09, 14.76it/s, est. speed input: 15889.85 toks/s, output: 15.52 toks/s]
Processed prompts:  45%|     | 114/256 [00:07<00:09, 14.91it/s, est. speed input: 15885.68 toks/s, output: 15.51 toks/s]
Processed prompts:  45%|     | 116/256 [00:07<00:09, 14.87it/s, est. speed input: 15871.75 toks/s, output: 15.50 toks/s]
Processed prompts:  46%|     | 118/256 [00:07<00:09, 14.93it/s, est. speed input: 15864.44 toks/s, output: 15.49 toks/s]
Processed prompts:  47%|     | 120/256 [00:07<00:09, 14.95it/s, est. speed input: 15855.55 toks/s, output: 15.48 toks/s]
Processed prompts:  48%|     | 122/256 [00:07<00:08, 14.97it/s, est. speed input: 15847.31 toks/s, output: 15.48 toks/s]
Processed prompts:  48%|     | 124/256 [00:08<00:08, 14.94it/s, est. speed input: 15837.26 toks/s, output: 15.47 toks/s]
Processed prompts:  49%|     | 126/256 [00:08<00:08, 14.92it/s, est. speed input: 15826.89 toks/s, output: 15.46 toks/s]
Processed prompts:  50%|     | 128/256 [00:08<00:08, 14.78it/s, est. speed input: 15810.35 toks/s, output: 15.44 toks/s]
Processed prompts:  51%|     | 130/256 [00:08<00:08, 14.87it/s, est. speed input: 15804.20 toks/s, output: 15.43 toks/s]
Processed prompts:  52%|    | 132/256 [00:08<00:08, 14.88it/s, est. speed input: 15795.65 toks/s, output: 15.43 toks/s]
Processed prompts:  52%|    | 134/256 [00:08<00:08, 14.93it/s, est. speed input: 15789.95 toks/s, output: 15.42 toks/s]
Processed prompts:  53%|    | 136/256 [00:08<00:08, 14.92it/s, est. speed input: 15781.77 toks/s, output: 15.41 toks/s]
Processed prompts:  54%|    | 138/256 [00:08<00:07, 14.95it/s, est. speed input: 15775.64 toks/s, output: 15.41 toks/s]
Processed prompts:  55%|    | 140/256 [00:09<00:07, 15.06it/s, est. speed input: 15774.32 toks/s, output: 15.40 toks/s]
Processed prompts:  55%|    | 142/256 [00:09<00:07, 14.83it/s, est. speed input: 15757.66 toks/s, output: 15.39 toks/s]
Processed prompts:  56%|    | 144/256 [00:09<00:07, 14.89it/s, est. speed input: 15752.25 toks/s, output: 15.38 toks/s]
Processed prompts:  57%|    | 146/256 [00:09<00:07, 14.87it/s, est. speed input: 15744.19 toks/s, output: 15.38 toks/s]
Processed prompts:  58%|    | 148/256 [00:09<00:07, 14.89it/s, est. speed input: 15738.07 toks/s, output: 15.37 toks/s]
Processed prompts:  59%|    | 150/256 [00:09<00:07, 14.83it/s, est. speed input: 15728.31 toks/s, output: 15.36 toks/s]
Processed prompts:  59%|    | 152/256 [00:09<00:06, 14.89it/s, est. speed input: 15723.80 toks/s, output: 15.36 toks/s]
Processed prompts:  60%|    | 154/256 [00:10<00:06, 14.91it/s, est. speed input: 15718.17 toks/s, output: 15.35 toks/s]
Processed prompts:  61%|    | 156/256 [00:10<00:06, 14.90it/s, est. speed input: 15711.90 toks/s, output: 15.34 toks/s]
Processed prompts:  62%|   | 158/256 [00:10<00:06, 14.83it/s, est. speed input: 15702.59 toks/s, output: 15.33 toks/s]
Processed prompts:  62%|   | 160/256 [00:10<00:06, 14.87it/s, est. speed input: 15697.69 toks/s, output: 15.33 toks/s]
Processed prompts:  63%|   | 162/256 [00:10<00:06, 14.89it/s, est. speed input: 15692.87 toks/s, output: 15.33 toks/s]
Processed prompts:  64%|   | 164/256 [00:10<00:06, 14.93it/s, est. speed input: 15688.84 toks/s, output: 15.32 toks/s]
Processed prompts:  65%|   | 166/256 [00:10<00:06, 14.98it/s, est. speed input: 15686.22 toks/s, output: 15.32 toks/s]
Processed prompts:  66%|   | 168/256 [00:10<00:05, 15.02it/s, est. speed input: 15683.50 toks/s, output: 15.32 toks/s]
Processed prompts:  66%|   | 170/256 [00:11<00:05, 14.99it/s, est. speed input: 15678.52 toks/s, output: 15.31 toks/s]
Processed prompts:  67%|   | 172/256 [00:11<00:05, 14.98it/s, est. speed input: 15674.38 toks/s, output: 15.31 toks/s]
Processed prompts:  68%|   | 174/256 [00:11<00:05, 14.85it/s, est. speed input: 15665.14 toks/s, output: 15.30 toks/s]
Processed prompts:  69%|   | 176/256 [00:11<00:05, 14.87it/s, est. speed input: 15660.41 toks/s, output: 15.29 toks/s]
Processed prompts:  70%|   | 178/256 [00:11<00:05, 14.96it/s, est. speed input: 15658.92 toks/s, output: 15.29 toks/s]
Processed prompts:  70%|   | 180/256 [00:11<00:05, 14.94it/s, est. speed input: 15654.44 toks/s, output: 15.29 toks/s]
Processed prompts:  71%|   | 182/256 [00:11<00:04, 15.05it/s, est. speed input: 15654.83 toks/s, output: 15.29 toks/s]
Processed prompts:  72%|  | 184/256 [00:12<00:04, 15.07it/s, est. speed input: 15652.72 toks/s, output: 15.29 toks/s]
Processed prompts:  73%|  | 186/256 [00:12<00:04, 15.06it/s, est. speed input: 15650.13 toks/s, output: 15.28 toks/s]
Processed prompts:  73%|  | 188/256 [00:12<00:04, 15.00it/s, est. speed input: 15645.33 toks/s, output: 15.28 toks/s]
Processed prompts:  74%|  | 190/256 [00:12<00:04, 14.86it/s, est. speed input: 15637.19 toks/s, output: 15.27 toks/s]
Processed prompts:  75%|  | 192/256 [00:12<00:04, 14.81it/s, est. speed input: 15630.69 toks/s, output: 15.26 toks/s]
Processed prompts:  76%|  | 194/256 [00:12<00:04, 14.85it/s, est. speed input: 15627.40 toks/s, output: 15.26 toks/s]
Processed prompts:  77%|  | 196/256 [00:12<00:04, 14.89it/s, est. speed input: 15624.22 toks/s, output: 15.26 toks/s]
Processed prompts:  77%|  | 198/256 [00:12<00:03, 14.89it/s, est. speed input: 15620.45 toks/s, output: 15.25 toks/s]
Processed prompts:  78%|  | 200/256 [00:13<00:03, 14.95it/s, est. speed input: 15618.77 toks/s, output: 15.25 toks/s]
Processed prompts:  79%|  | 202/256 [00:13<00:03, 14.95it/s, est. speed input: 15615.78 toks/s, output: 15.25 toks/s]
Processed prompts:  80%|  | 204/256 [00:13<00:03, 14.99it/s, est. speed input: 15613.93 toks/s, output: 15.25 toks/s]
Processed prompts:  80%|  | 206/256 [00:13<00:03, 14.84it/s, est. speed input: 15606.04 toks/s, output: 15.24 toks/s]
Processed prompts:  81%| | 208/256 [00:13<00:03, 14.92it/s, est. speed input: 15604.69 toks/s, output: 15.24 toks/s]
Processed prompts:  82%| | 210/256 [00:13<00:03, 14.94it/s, est. speed input: 15602.37 toks/s, output: 15.24 toks/s]
Processed prompts:  83%| | 212/256 [00:13<00:02, 14.95it/s, est. speed input: 15599.84 toks/s, output: 15.23 toks/s]
Processed prompts:  84%| | 214/256 [00:14<00:02, 14.93it/s, est. speed input: 15596.48 toks/s, output: 15.23 toks/s]
Processed prompts:  84%| | 216/256 [00:14<00:02, 14.90it/s, est. speed input: 15592.59 toks/s, output: 15.23 toks/s]
Processed prompts:  85%| | 218/256 [00:14<00:02, 14.85it/s, est. speed input: 15587.87 toks/s, output: 15.22 toks/s]
Processed prompts:  86%| | 220/256 [00:14<00:02, 14.89it/s, est. speed input: 15585.66 toks/s, output: 15.22 toks/s]
Processed prompts:  87%| | 222/256 [00:14<00:02, 14.77it/s, est. speed input: 15578.48 toks/s, output: 15.21 toks/s]
Processed prompts:  88%| | 224/256 [00:14<00:02, 14.75it/s, est. speed input: 15573.71 toks/s, output: 15.21 toks/s]
Processed prompts:  88%| | 226/256 [00:14<00:02, 14.81it/s, est. speed input: 15571.31 toks/s, output: 15.21 toks/s]
Processed prompts:  89%| | 228/256 [00:14<00:01, 14.99it/s, est. speed input: 15573.26 toks/s, output: 15.21 toks/s]
Processed prompts:  90%| | 230/256 [00:15<00:01, 14.96it/s, est. speed input: 15570.24 toks/s, output: 15.21 toks/s]
Processed prompts:  91%| | 232/256 [00:15<00:01, 14.94it/s, est. speed input: 15567.56 toks/s, output: 15.20 toks/s]
Processed prompts:  91%|| 234/256 [00:15<00:01, 14.93it/s, est. speed input: 15564.87 toks/s, output: 15.20 toks/s]
Processed prompts:  92%|| 236/256 [00:15<00:01, 14.97it/s, est. speed input: 15563.85 toks/s, output: 15.20 toks/s]
Processed prompts:  93%|| 238/256 [00:15<00:01, 14.82it/s, est. speed input: 15557.25 toks/s, output: 15.19 toks/s]
Processed prompts:  94%|| 240/256 [00:15<00:01, 14.89it/s, est. speed input: 15556.17 toks/s, output: 15.19 toks/s]
Processed prompts:  95%|| 242/256 [00:15<00:00, 14.97it/s, est. speed input: 15555.72 toks/s, output: 15.19 toks/s]
Processed prompts:  95%|| 244/256 [00:16<00:00, 15.03it/s, est. speed input: 15555.75 toks/s, output: 15.19 toks/s]
Processed prompts:  96%|| 246/256 [00:16<00:00, 15.05it/s, est. speed input: 15554.97 toks/s, output: 15.19 toks/s]
Processed prompts:  97%|| 248/256 [00:16<00:00, 14.98it/s, est. speed input: 15551.69 toks/s, output: 15.19 toks/s]
Processed prompts:  98%|| 250/256 [00:16<00:00, 15.05it/s, est. speed input: 15551.95 toks/s, output: 15.19 toks/s]
Processed prompts:  98%|| 252/256 [00:16<00:00, 15.13it/s, est. speed input: 15552.98 toks/s, output: 15.19 toks/s]
Processed prompts:  99%|| 254/256 [00:16<00:00, 14.95it/s, est. speed input: 15547.50 toks/s, output: 15.18 toks/s]
Processed prompts: 100%|| 256/256 [00:16<00:00, 14.95it/s, est. speed input: 15606.08 toks/s, output: 15.24 toks/s]
Processed prompts: 100%|| 256/256 [00:16<00:00, 15.24it/s, est. speed input: 15606.08 toks/s, output: 15.24 toks/s]
[rank0]:[W128 09:19:04.298536020 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-28 09:19:06
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/BitNet-2B-FP8_M4096.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:19:11 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:19:11 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3739073) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3739073) WARNING 01-28 09:19:39 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.07 requests/s, 14421.86 total tokens/s, 14.07 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-28 09:19:11] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:19:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:19:11] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:19:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:19:11] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:19:11] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:19:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:19:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:19:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:19:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:19:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:19:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:19:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:19:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:19:14] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:19:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:19:14] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:19:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:19:14] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:19:14] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:19:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:19:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:19:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:19:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:19:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:19:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:19:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:19:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:15] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:15] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:15] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:15] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:15] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3739073) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3739073) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.45s/it]
(EngineCore_DP0 pid=3739073) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.45s/it]
(EngineCore_DP0 pid=3739073) 
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3840] -> 1D uint8
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9216000 bytes
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3840] -> 1D uint8
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6144000 bytes
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3840] -> 1D uint8
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33177600 bytes
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:32] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 10368] -> 1D uint8
(EngineCore_DP0 pid=3739073) [2026-01-28 09:19:32] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=3739073) 2026-01-28 09:19:38,518 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3739073) 2026-01-28 09:19:38,529 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  12%|        | 61/512 [00:00<00:00, 605.00it/s]
Adding requests:  24%|       | 122/512 [00:00<00:00, 592.42it/s]
Adding requests:  36%|      | 182/512 [00:00<00:00, 562.88it/s]
Adding requests:  47%|     | 239/512 [00:00<00:00, 559.30it/s]
Adding requests:  58%|    | 296/512 [00:00<00:00, 551.09it/s]
Adding requests:  69%|   | 353/512 [00:00<00:00, 555.42it/s]
Adding requests:  80%|  | 410/512 [00:00<00:00, 558.86it/s]
Adding requests:  91%| | 466/512 [00:00<00:00, 552.79it/s]
Adding requests: 100%|| 512/512 [00:00<00:00, 555.79it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 10/512 [00:00<00:05, 95.85it/s, est. speed input: 98166.19 toks/s, output: 95.85 toks/s]
Processed prompts:   4%|         | 20/512 [00:00<00:18, 26.51it/s, est. speed input: 30446.89 toks/s, output: 29.73 toks/s]
Processed prompts:   5%|         | 25/512 [00:00<00:21, 23.03it/s, est. speed input: 26738.90 toks/s, output: 26.11 toks/s]
Processed prompts:   6%|         | 29/512 [00:01<00:24, 19.82it/s, est. speed input: 23902.54 toks/s, output: 23.34 toks/s]
Processed prompts:   6%|         | 32/512 [00:01<00:28, 16.63it/s, est. speed input: 21412.96 toks/s, output: 20.91 toks/s]
Processed prompts:   7%|         | 35/512 [00:01<00:32, 14.69it/s, est. speed input: 19773.60 toks/s, output: 19.31 toks/s]
Processed prompts:   7%|         | 38/512 [00:02<00:35, 13.43it/s, est. speed input: 18587.72 toks/s, output: 18.15 toks/s]
Processed prompts:   8%|         | 42/512 [00:02<00:34, 13.66it/s, est. speed input: 18103.38 toks/s, output: 17.68 toks/s]
Processed prompts:   9%|         | 46/512 [00:02<00:33, 13.75it/s, est. speed input: 17691.42 toks/s, output: 17.28 toks/s]
Processed prompts:  10%|         | 50/512 [00:02<00:33, 13.88it/s, est. speed input: 17386.36 toks/s, output: 16.98 toks/s]
Processed prompts:  11%|         | 54/512 [00:03<00:32, 13.98it/s, est. speed input: 17140.08 toks/s, output: 16.74 toks/s]
Processed prompts:  11%|        | 58/512 [00:03<00:32, 14.02it/s, est. speed input: 16922.87 toks/s, output: 16.53 toks/s]
Processed prompts:  12%|        | 62/512 [00:03<00:32, 14.03it/s, est. speed input: 16731.44 toks/s, output: 16.34 toks/s]
Processed prompts:  13%|        | 66/512 [00:04<00:31, 14.10it/s, est. speed input: 16585.77 toks/s, output: 16.20 toks/s]
Processed prompts:  14%|        | 70/512 [00:04<00:31, 14.11it/s, est. speed input: 16448.47 toks/s, output: 16.06 toks/s]
Processed prompts:  14%|        | 74/512 [00:04<00:31, 14.07it/s, est. speed input: 16316.47 toks/s, output: 15.93 toks/s]
Processed prompts:  15%|        | 78/512 [00:04<00:30, 14.07it/s, est. speed input: 16206.21 toks/s, output: 15.83 toks/s]
Processed prompts:  16%|        | 82/512 [00:05<00:30, 14.12it/s, est. speed input: 16119.47 toks/s, output: 15.74 toks/s]
Processed prompts:  17%|        | 86/512 [00:05<00:30, 14.19it/s, est. speed input: 16047.62 toks/s, output: 15.67 toks/s]
Processed prompts:  18%|        | 90/512 [00:05<00:29, 14.14it/s, est. speed input: 15964.84 toks/s, output: 15.59 toks/s]
Processed prompts:  18%|        | 94/512 [00:06<00:29, 14.21it/s, est. speed input: 15906.17 toks/s, output: 15.53 toks/s]
Processed prompts:  19%|        | 98/512 [00:06<00:29, 14.26it/s, est. speed input: 15854.20 toks/s, output: 15.48 toks/s]
Processed prompts:  20%|        | 102/512 [00:06<00:28, 14.21it/s, est. speed input: 15793.93 toks/s, output: 15.42 toks/s]
Processed prompts:  21%|        | 106/512 [00:06<00:28, 14.12it/s, est. speed input: 15728.72 toks/s, output: 15.36 toks/s]
Processed prompts:  21%|       | 110/512 [00:07<00:28, 14.12it/s, est. speed input: 15678.50 toks/s, output: 15.31 toks/s]
Processed prompts:  22%|       | 114/512 [00:07<00:28, 14.11it/s, est. speed input: 15630.56 toks/s, output: 15.26 toks/s]
Processed prompts:  23%|       | 118/512 [00:07<00:27, 14.08it/s, est. speed input: 15583.28 toks/s, output: 15.22 toks/s]
Processed prompts:  24%|       | 122/512 [00:08<00:27, 14.12it/s, est. speed input: 15547.18 toks/s, output: 15.18 toks/s]
Processed prompts:  25%|       | 126/512 [00:08<00:27, 14.13it/s, est. speed input: 15511.76 toks/s, output: 15.15 toks/s]
Processed prompts:  25%|       | 130/512 [00:08<00:26, 14.16it/s, est. speed input: 15480.79 toks/s, output: 15.12 toks/s]
Processed prompts:  26%|       | 134/512 [00:08<00:26, 14.08it/s, est. speed input: 15440.46 toks/s, output: 15.08 toks/s]
Processed prompts:  27%|       | 138/512 [00:09<00:26, 14.07it/s, est. speed input: 15408.15 toks/s, output: 15.05 toks/s]
Processed prompts:  28%|       | 142/512 [00:09<00:26, 14.10it/s, est. speed input: 15380.94 toks/s, output: 15.02 toks/s]
Processed prompts:  29%|       | 146/512 [00:09<00:25, 14.10it/s, est. speed input: 15353.32 toks/s, output: 14.99 toks/s]
Processed prompts:  29%|       | 150/512 [00:10<00:25, 14.04it/s, est. speed input: 15321.56 toks/s, output: 14.96 toks/s]
Processed prompts:  30%|       | 154/512 [00:10<00:25, 14.05it/s, est. speed input: 15296.12 toks/s, output: 14.94 toks/s]
Processed prompts:  31%|       | 158/512 [00:10<00:25, 14.09it/s, est. speed input: 15275.66 toks/s, output: 14.92 toks/s]
Processed prompts:  32%|      | 162/512 [00:10<00:24, 14.15it/s, est. speed input: 15258.94 toks/s, output: 14.90 toks/s]
Processed prompts:  32%|      | 166/512 [00:11<00:24, 14.12it/s, est. speed input: 15236.92 toks/s, output: 14.88 toks/s]
Processed prompts:  33%|      | 170/512 [00:11<00:24, 14.12it/s, est. speed input: 15217.46 toks/s, output: 14.86 toks/s]
Processed prompts:  34%|      | 174/512 [00:11<00:23, 14.09it/s, est. speed input: 15196.37 toks/s, output: 14.84 toks/s]
Processed prompts:  35%|      | 178/512 [00:12<00:23, 14.01it/s, est. speed input: 15171.83 toks/s, output: 14.82 toks/s]
Processed prompts:  36%|      | 182/512 [00:12<00:23, 14.05it/s, est. speed input: 15155.66 toks/s, output: 14.80 toks/s]
Processed prompts:  36%|      | 186/512 [00:12<00:23, 14.09it/s, est. speed input: 15142.03 toks/s, output: 14.79 toks/s]
Processed prompts:  37%|      | 190/512 [00:12<00:22, 14.10it/s, est. speed input: 15126.76 toks/s, output: 14.77 toks/s]
Processed prompts:  38%|      | 194/512 [00:13<00:22, 14.05it/s, est. speed input: 15108.42 toks/s, output: 14.75 toks/s]
Processed prompts:  39%|      | 198/512 [00:13<00:22, 14.06it/s, est. speed input: 15093.36 toks/s, output: 14.74 toks/s]
Processed prompts:  39%|      | 202/512 [00:13<00:22, 14.05it/s, est. speed input: 15078.34 toks/s, output: 14.72 toks/s]
Processed prompts:  40%|      | 206/512 [00:13<00:21, 14.13it/s, est. speed input: 15069.72 toks/s, output: 14.72 toks/s]
Processed prompts:  41%|      | 210/512 [00:14<00:21, 14.05it/s, est. speed input: 15052.38 toks/s, output: 14.70 toks/s]
Processed prompts:  42%|     | 214/512 [00:14<00:21, 14.08it/s, est. speed input: 15041.80 toks/s, output: 14.69 toks/s]
Processed prompts:  43%|     | 218/512 [00:14<00:20, 14.09it/s, est. speed input: 15030.39 toks/s, output: 14.68 toks/s]
Processed prompts:  43%|     | 222/512 [00:15<00:20, 14.12it/s, est. speed input: 15020.73 toks/s, output: 14.67 toks/s]
Processed prompts:  44%|     | 226/512 [00:15<00:20, 14.05it/s, est. speed input: 15005.84 toks/s, output: 14.65 toks/s]
Processed prompts:  45%|     | 230/512 [00:15<00:20, 14.08it/s, est. speed input: 14996.95 toks/s, output: 14.65 toks/s]
Processed prompts:  46%|     | 234/512 [00:15<00:19, 14.11it/s, est. speed input: 14988.51 toks/s, output: 14.64 toks/s]
Processed prompts:  46%|     | 238/512 [00:16<00:19, 14.05it/s, est. speed input: 14975.03 toks/s, output: 14.62 toks/s]
Processed prompts:  47%|     | 242/512 [00:16<00:19, 14.13it/s, est. speed input: 14969.90 toks/s, output: 14.62 toks/s]
Processed prompts:  48%|     | 246/512 [00:16<00:18, 14.13it/s, est. speed input: 14961.27 toks/s, output: 14.61 toks/s]
Processed prompts:  49%|     | 250/512 [00:17<00:18, 14.12it/s, est. speed input: 14952.67 toks/s, output: 14.60 toks/s]
Processed prompts:  50%|     | 254/512 [00:17<00:18, 14.05it/s, est. speed input: 14940.69 toks/s, output: 14.59 toks/s]
Processed prompts:  50%|     | 258/512 [00:17<00:18, 14.10it/s, est. speed input: 14934.51 toks/s, output: 14.58 toks/s]
Processed prompts:  51%|     | 262/512 [00:17<00:17, 14.11it/s, est. speed input: 14927.27 toks/s, output: 14.58 toks/s]
Processed prompts:  52%|    | 266/512 [00:18<00:17, 14.07it/s, est. speed input: 14917.56 toks/s, output: 14.57 toks/s]
Processed prompts:  53%|    | 270/512 [00:18<00:17, 14.00it/s, est. speed input: 14905.95 toks/s, output: 14.56 toks/s]
Processed prompts:  54%|    | 274/512 [00:18<00:17, 13.99it/s, est. speed input: 14896.53 toks/s, output: 14.55 toks/s]
Processed prompts:  54%|    | 278/512 [00:19<00:16, 14.02it/s, est. speed input: 14889.97 toks/s, output: 14.54 toks/s]
Processed prompts:  55%|    | 282/512 [00:19<00:16, 14.02it/s, est. speed input: 14882.08 toks/s, output: 14.53 toks/s]
Processed prompts:  56%|    | 286/512 [00:19<00:16, 14.09it/s, est. speed input: 14877.99 toks/s, output: 14.53 toks/s]
Processed prompts:  57%|    | 290/512 [00:19<00:15, 14.17it/s, est. speed input: 14875.52 toks/s, output: 14.53 toks/s]
Processed prompts:  57%|    | 294/512 [00:20<00:15, 14.18it/s, est. speed input: 14870.81 toks/s, output: 14.52 toks/s]
Processed prompts:  58%|    | 298/512 [00:20<00:15, 14.08it/s, est. speed input: 14861.27 toks/s, output: 14.51 toks/s]
Processed prompts:  59%|    | 302/512 [00:20<00:14, 14.08it/s, est. speed input: 14855.20 toks/s, output: 14.51 toks/s]
Processed prompts:  60%|    | 306/512 [00:21<00:14, 14.10it/s, est. speed input: 14850.18 toks/s, output: 14.50 toks/s]
Processed prompts:  61%|    | 310/512 [00:21<00:14, 14.08it/s, est. speed input: 14844.05 toks/s, output: 14.50 toks/s]
Processed prompts:  61%|   | 314/512 [00:21<00:14, 14.02it/s, est. speed input: 14835.36 toks/s, output: 14.49 toks/s]
Processed prompts:  62%|   | 318/512 [00:21<00:13, 14.06it/s, est. speed input: 14830.90 toks/s, output: 14.48 toks/s]
Processed prompts:  63%|   | 322/512 [00:22<00:13, 14.06it/s, est. speed input: 14825.39 toks/s, output: 14.48 toks/s]
Processed prompts:  64%|   | 326/512 [00:22<00:13, 14.09it/s, est. speed input: 14821.38 toks/s, output: 14.47 toks/s]
Processed prompts:  64%|   | 330/512 [00:22<00:12, 14.04it/s, est. speed input: 14814.29 toks/s, output: 14.47 toks/s]
Processed prompts:  65%|   | 334/512 [00:23<00:12, 14.13it/s, est. speed input: 14812.64 toks/s, output: 14.47 toks/s]
Processed prompts:  66%|   | 338/512 [00:23<00:12, 14.11it/s, est. speed input: 14807.87 toks/s, output: 14.46 toks/s]
Processed prompts:  67%|   | 342/512 [00:23<00:11, 14.68it/s, est. speed input: 14826.30 toks/s, output: 14.48 toks/s]
Processed prompts:  68%|   | 346/512 [00:23<00:11, 14.39it/s, est. speed input: 14817.37 toks/s, output: 14.47 toks/s]
Processed prompts:  68%|   | 350/512 [00:24<00:11, 14.29it/s, est. speed input: 14812.49 toks/s, output: 14.47 toks/s]
Processed prompts:  69%|   | 354/512 [00:24<00:11, 14.28it/s, est. speed input: 14809.97 toks/s, output: 14.46 toks/s]
Processed prompts:  70%|   | 358/512 [00:24<00:10, 14.15it/s, est. speed input: 14802.85 toks/s, output: 14.46 toks/s]
Processed prompts:  71%|   | 362/512 [00:25<00:10, 14.17it/s, est. speed input: 14799.92 toks/s, output: 14.45 toks/s]
Processed prompts:  71%|  | 366/512 [00:25<00:10, 14.17it/s, est. speed input: 14796.87 toks/s, output: 14.45 toks/s]
Processed prompts:  72%|  | 370/512 [00:25<00:10, 14.18it/s, est. speed input: 14793.88 toks/s, output: 14.45 toks/s]
Processed prompts:  73%|  | 374/512 [00:25<00:09, 14.10it/s, est. speed input: 14787.92 toks/s, output: 14.44 toks/s]
Processed prompts:  74%|  | 378/512 [00:26<00:09, 14.11it/s, est. speed input: 14784.63 toks/s, output: 14.44 toks/s]
Processed prompts:  75%|  | 382/512 [00:26<00:09, 14.13it/s, est. speed input: 14781.53 toks/s, output: 14.44 toks/s]
Processed prompts:  75%|  | 386/512 [00:26<00:08, 14.10it/s, est. speed input: 14777.39 toks/s, output: 14.43 toks/s]
Processed prompts:  76%|  | 390/512 [00:27<00:08, 13.99it/s, est. speed input: 14769.74 toks/s, output: 14.42 toks/s]
Processed prompts:  77%|  | 394/512 [00:27<00:08, 14.04it/s, est. speed input: 14766.78 toks/s, output: 14.42 toks/s]
Processed prompts:  78%|  | 398/512 [00:27<00:08, 14.06it/s, est. speed input: 14763.60 toks/s, output: 14.42 toks/s]
Processed prompts:  79%|  | 402/512 [00:27<00:07, 13.98it/s, est. speed input: 14756.92 toks/s, output: 14.41 toks/s]
Processed prompts:  79%|  | 406/512 [00:28<00:07, 14.03it/s, est. speed input: 14754.43 toks/s, output: 14.41 toks/s]
Processed prompts:  80%|  | 410/512 [00:28<00:07, 14.05it/s, est. speed input: 14751.16 toks/s, output: 14.41 toks/s]
Processed prompts:  81%|  | 414/512 [00:28<00:06, 14.03it/s, est. speed input: 14747.00 toks/s, output: 14.40 toks/s]
Processed prompts:  82%| | 418/512 [00:29<00:06, 13.96it/s, est. speed input: 14740.62 toks/s, output: 14.40 toks/s]
Processed prompts:  82%| | 422/512 [00:29<00:06, 13.97it/s, est. speed input: 14736.82 toks/s, output: 14.39 toks/s]
Processed prompts:  83%| | 426/512 [00:29<00:06, 14.03it/s, est. speed input: 14734.55 toks/s, output: 14.39 toks/s]
Processed prompts:  84%| | 430/512 [00:29<00:05, 14.06it/s, est. speed input: 14732.20 toks/s, output: 14.39 toks/s]
Processed prompts:  85%| | 434/512 [00:30<00:05, 14.02it/s, est. speed input: 14727.59 toks/s, output: 14.38 toks/s]
Processed prompts:  86%| | 438/512 [00:30<00:05, 14.05it/s, est. speed input: 14725.10 toks/s, output: 14.38 toks/s]
Processed prompts:  86%| | 442/512 [00:30<00:04, 14.08it/s, est. speed input: 14723.05 toks/s, output: 14.38 toks/s]
Processed prompts:  87%| | 446/512 [00:31<00:04, 14.13it/s, est. speed input: 14721.78 toks/s, output: 14.38 toks/s]
Processed prompts:  88%| | 450/512 [00:31<00:04, 14.87it/s, est. speed input: 14741.50 toks/s, output: 14.40 toks/s]
Processed prompts:  89%| | 454/512 [00:31<00:03, 14.63it/s, est. speed input: 14738.76 toks/s, output: 14.39 toks/s]
Processed prompts:  89%| | 458/512 [00:31<00:03, 14.51it/s, est. speed input: 14737.48 toks/s, output: 14.39 toks/s]
Processed prompts:  90%| | 462/512 [00:32<00:03, 14.40it/s, est. speed input: 14735.31 toks/s, output: 14.39 toks/s]
Processed prompts:  91%| | 466/512 [00:32<00:03, 14.26it/s, est. speed input: 14731.16 toks/s, output: 14.39 toks/s]
Processed prompts:  92%|| 470/512 [00:32<00:02, 14.21it/s, est. speed input: 14728.57 toks/s, output: 14.38 toks/s]
Processed prompts:  93%|| 474/512 [00:32<00:02, 14.16it/s, est. speed input: 14725.74 toks/s, output: 14.38 toks/s]
Processed prompts:  93%|| 478/512 [00:33<00:02, 14.08it/s, est. speed input: 14721.25 toks/s, output: 14.38 toks/s]
Processed prompts:  94%|| 482/512 [00:33<00:02, 14.09it/s, est. speed input: 14718.99 toks/s, output: 14.37 toks/s]
Processed prompts:  95%|| 486/512 [00:33<00:01, 14.09it/s, est. speed input: 14716.46 toks/s, output: 14.37 toks/s]
Processed prompts:  96%|| 490/512 [00:34<00:01, 14.09it/s, est. speed input: 14714.05 toks/s, output: 14.37 toks/s]
Processed prompts:  96%|| 494/512 [00:34<00:01, 14.04it/s, est. speed input: 14710.25 toks/s, output: 14.37 toks/s]
Processed prompts:  97%|| 498/512 [00:34<00:00, 14.13it/s, est. speed input: 14710.01 toks/s, output: 14.37 toks/s]
Processed prompts:  98%|| 502/512 [00:34<00:00, 14.15it/s, est. speed input: 14708.79 toks/s, output: 14.36 toks/s]
Processed prompts:  99%|| 506/512 [00:35<00:00, 14.16it/s, est. speed input: 14707.20 toks/s, output: 14.36 toks/s]
Processed prompts: 100%|| 510/512 [00:35<00:00, 14.90it/s, est. speed input: 14724.93 toks/s, output: 14.38 toks/s]
Processed prompts: 100%|| 512/512 [00:35<00:00, 14.90it/s, est. speed input: 14782.59 toks/s, output: 14.44 toks/s]
Processed prompts: 100%|| 512/512 [00:35<00:00, 14.44it/s, est. speed input: 14782.59 toks/s, output: 14.44 toks/s]
[rank0]:[W128 09:20:16.020525345 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-28 09:20:18
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/BitNet-2B-FP8_M8192.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:20:24 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:20:24 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3740281) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3740281) WARNING 01-28 09:20:53 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.14 requests/s, 14489.86 total tokens/s, 14.14 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-28 09:20:24] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:20:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:20:24] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:20:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:20:24] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:20:24] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:20:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:20:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:20:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:20:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:20:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:20:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:20:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:20:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:20:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:20:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:20:28] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:20:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:20:28] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:20:28] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:20:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:20:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:20:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:20:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:20:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:20:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:20:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:20:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:28] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3740281) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3740281) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.43s/it]
(EngineCore_DP0 pid=3740281) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.43s/it]
(EngineCore_DP0 pid=3740281) 
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3840] -> 1D uint8
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9216000 bytes
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3840] -> 1D uint8
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6144000 bytes
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3840] -> 1D uint8
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33177600 bytes
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 10368] -> 1D uint8
(EngineCore_DP0 pid=3740281) [2026-01-28 09:20:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=3740281) 2026-01-28 09:20:52,040 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3740281) 2026-01-28 09:20:52,093 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   6%|         | 60/1024 [00:00<00:01, 592.64it/s]
Adding requests:  12%|        | 120/1024 [00:00<00:01, 581.66it/s]
Adding requests:  17%|        | 179/1024 [00:00<00:01, 543.33it/s]
Adding requests:  23%|       | 235/1024 [00:00<00:01, 549.54it/s]
Adding requests:  28%|       | 291/1024 [00:00<00:01, 540.97it/s]
Adding requests:  34%|      | 346/1024 [00:00<00:01, 538.50it/s]
Adding requests:  39%|      | 402/1024 [00:00<00:01, 544.86it/s]
Adding requests:  45%|     | 457/1024 [00:00<00:01, 535.42it/s]
Adding requests:  50%|     | 511/1024 [00:00<00:00, 529.91it/s]
Adding requests:  55%|    | 565/1024 [00:01<00:00, 512.34it/s]
Adding requests:  60%|    | 618/1024 [00:01<00:00, 516.56it/s]
Adding requests:  66%|   | 672/1024 [00:01<00:00, 522.23it/s]
Adding requests:  71%|   | 726/1024 [00:01<00:00, 526.01it/s]
Adding requests:  76%|  | 779/1024 [00:01<00:00, 520.75it/s]
Adding requests:  81%| | 832/1024 [00:01<00:00, 517.57it/s]
Adding requests:  87%| | 888/1024 [00:01<00:00, 527.87it/s]
Adding requests:  92%|| 942/1024 [00:01<00:00, 530.25it/s]
Adding requests:  97%|| 996/1024 [00:01<00:00, 531.42it/s]
Adding requests: 100%|| 1024/1024 [00:01<00:00, 532.12it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|         | 26/1024 [00:00<00:19, 50.57it/s, est. speed input: 51789.26 toks/s, output: 50.57 toks/s]
Processed prompts:   3%|         | 34/1024 [00:01<00:34, 28.34it/s, est. speed input: 32278.10 toks/s, output: 31.52 toks/s]
Processed prompts:   4%|         | 42/1024 [00:01<00:45, 21.75it/s, est. speed input: 26184.14 toks/s, output: 25.57 toks/s]
Processed prompts:   5%|         | 50/1024 [00:02<00:52, 18.72it/s, est. speed input: 23198.49 toks/s, output: 22.65 toks/s]
Processed prompts:   6%|         | 58/1024 [00:02<00:56, 17.03it/s, est. speed input: 21405.68 toks/s, output: 20.90 toks/s]
Processed prompts:   6%|         | 66/1024 [00:03<00:59, 16.08it/s, est. speed input: 20256.40 toks/s, output: 19.78 toks/s]
Processed prompts:   7%|         | 74/1024 [00:03<01:01, 15.45it/s, est. speed input: 19423.94 toks/s, output: 18.97 toks/s]
Processed prompts:   8%|         | 82/1024 [00:04<01:02, 15.06it/s, est. speed input: 18811.02 toks/s, output: 18.37 toks/s]
Processed prompts:   9%|         | 90/1024 [00:05<01:03, 14.76it/s, est. speed input: 18318.86 toks/s, output: 17.89 toks/s]
Processed prompts:  10%|         | 98/1024 [00:05<01:03, 14.59it/s, est. speed input: 17938.38 toks/s, output: 17.52 toks/s]
Processed prompts:  10%|         | 106/1024 [00:06<01:03, 14.45it/s, est. speed input: 17621.85 toks/s, output: 17.21 toks/s]
Processed prompts:  11%|         | 114/1024 [00:06<01:03, 14.41it/s, est. speed input: 17374.58 toks/s, output: 16.97 toks/s]
Processed prompts:  12%|        | 122/1024 [00:07<01:02, 14.34it/s, est. speed input: 17152.73 toks/s, output: 16.75 toks/s]
Processed prompts:  13%|        | 130/1024 [00:07<01:02, 14.32it/s, est. speed input: 16971.17 toks/s, output: 16.57 toks/s]
Processed prompts:  13%|        | 138/1024 [00:08<01:02, 14.26it/s, est. speed input: 16801.93 toks/s, output: 16.41 toks/s]
Processed prompts:  14%|        | 146/1024 [00:08<01:01, 14.23it/s, est. speed input: 16658.14 toks/s, output: 16.27 toks/s]
Processed prompts:  15%|        | 154/1024 [00:09<01:01, 14.21it/s, est. speed input: 16529.86 toks/s, output: 16.14 toks/s]
Processed prompts:  16%|        | 162/1024 [00:10<01:00, 14.20it/s, est. speed input: 16418.22 toks/s, output: 16.03 toks/s]
Processed prompts:  17%|        | 170/1024 [00:10<01:00, 14.19it/s, est. speed input: 16316.14 toks/s, output: 15.93 toks/s]
Processed prompts:  17%|        | 178/1024 [00:11<00:59, 14.18it/s, est. speed input: 16224.73 toks/s, output: 15.84 toks/s]
Processed prompts:  18%|        | 186/1024 [00:11<00:58, 14.21it/s, est. speed input: 16149.05 toks/s, output: 15.77 toks/s]
Processed prompts:  19%|        | 194/1024 [00:12<00:58, 14.18it/s, est. speed input: 16070.84 toks/s, output: 15.69 toks/s]
Processed prompts:  20%|        | 202/1024 [00:12<00:57, 14.19it/s, est. speed input: 16004.24 toks/s, output: 15.63 toks/s]
Processed prompts:  21%|        | 210/1024 [00:13<00:57, 14.18it/s, est. speed input: 15941.81 toks/s, output: 15.57 toks/s]
Processed prompts:  21%|       | 218/1024 [00:14<00:56, 14.19it/s, est. speed input: 15886.03 toks/s, output: 15.51 toks/s]
Processed prompts:  22%|       | 226/1024 [00:14<00:56, 14.17it/s, est. speed input: 15831.39 toks/s, output: 15.46 toks/s]
Processed prompts:  23%|       | 234/1024 [00:15<00:55, 14.20it/s, est. speed input: 15785.80 toks/s, output: 15.42 toks/s]
Processed prompts:  24%|       | 242/1024 [00:15<00:55, 14.19it/s, est. speed input: 15740.57 toks/s, output: 15.37 toks/s]
Processed prompts:  24%|       | 250/1024 [00:16<00:54, 14.21it/s, est. speed input: 15701.21 toks/s, output: 15.33 toks/s]
Processed prompts:  25%|       | 258/1024 [00:16<00:54, 14.18it/s, est. speed input: 15659.37 toks/s, output: 15.29 toks/s]
Processed prompts:  26%|       | 266/1024 [00:17<00:53, 14.19it/s, est. speed input: 15623.63 toks/s, output: 15.26 toks/s]
Processed prompts:  27%|       | 274/1024 [00:18<00:52, 14.16it/s, est. speed input: 15586.06 toks/s, output: 15.22 toks/s]
Processed prompts:  28%|       | 282/1024 [00:18<00:52, 14.17it/s, est. speed input: 15553.54 toks/s, output: 15.19 toks/s]
Processed prompts:  28%|       | 290/1024 [00:19<00:51, 14.15it/s, est. speed input: 15520.44 toks/s, output: 15.16 toks/s]
Processed prompts:  29%|       | 298/1024 [00:19<00:51, 14.15it/s, est. speed input: 15490.94 toks/s, output: 15.13 toks/s]
Processed prompts:  30%|       | 306/1024 [00:20<00:50, 14.20it/s, est. speed input: 15468.04 toks/s, output: 15.11 toks/s]
Processed prompts:  31%|       | 314/1024 [00:20<00:50, 14.17it/s, est. speed input: 15440.55 toks/s, output: 15.08 toks/s]
Processed prompts:  31%|      | 322/1024 [00:21<00:49, 14.19it/s, est. speed input: 15417.82 toks/s, output: 15.06 toks/s]
Processed prompts:  32%|      | 330/1024 [00:21<00:48, 14.17it/s, est. speed input: 15393.40 toks/s, output: 15.03 toks/s]
Processed prompts:  33%|      | 338/1024 [00:22<00:47, 14.36it/s, est. speed input: 15388.11 toks/s, output: 15.03 toks/s]
Processed prompts:  34%|      | 346/1024 [00:23<00:47, 14.29it/s, est. speed input: 15365.24 toks/s, output: 15.01 toks/s]
Processed prompts:  35%|      | 354/1024 [00:23<00:46, 14.27it/s, est. speed input: 15346.26 toks/s, output: 14.99 toks/s]
Processed prompts:  35%|      | 362/1024 [00:24<00:46, 14.21it/s, est. speed input: 15324.57 toks/s, output: 14.97 toks/s]
Processed prompts:  36%|      | 370/1024 [00:24<00:46, 14.22it/s, est. speed input: 15307.23 toks/s, output: 14.95 toks/s]
Processed prompts:  37%|      | 378/1024 [00:25<00:45, 14.19it/s, est. speed input: 15288.65 toks/s, output: 14.93 toks/s]
Processed prompts:  38%|      | 386/1024 [00:25<00:44, 14.20it/s, est. speed input: 15272.69 toks/s, output: 14.91 toks/s]
Processed prompts:  38%|      | 394/1024 [00:26<00:44, 14.17it/s, est. speed input: 15254.83 toks/s, output: 14.90 toks/s]
Processed prompts:  39%|      | 402/1024 [00:27<00:43, 14.20it/s, est. speed input: 15241.44 toks/s, output: 14.88 toks/s]
Processed prompts:  40%|      | 410/1024 [00:27<00:43, 14.17it/s, est. speed input: 15224.77 toks/s, output: 14.87 toks/s]
Processed prompts:  41%|      | 418/1024 [00:28<00:42, 14.15it/s, est. speed input: 15208.86 toks/s, output: 14.85 toks/s]
Processed prompts:  42%|     | 426/1024 [00:28<00:42, 14.15it/s, est. speed input: 15194.56 toks/s, output: 14.84 toks/s]
Processed prompts:  42%|     | 434/1024 [00:29<00:41, 14.14it/s, est. speed input: 15180.56 toks/s, output: 14.82 toks/s]
Processed prompts:  43%|     | 442/1024 [00:29<00:41, 14.16it/s, est. speed input: 15168.30 toks/s, output: 14.81 toks/s]
Processed prompts:  44%|     | 450/1024 [00:30<00:41, 13.68it/s, est. speed input: 15123.01 toks/s, output: 14.77 toks/s]
Processed prompts:  45%|     | 458/1024 [00:31<00:40, 13.82it/s, est. speed input: 15112.01 toks/s, output: 14.76 toks/s]
Processed prompts:  46%|     | 466/1024 [00:31<00:40, 13.89it/s, est. speed input: 15098.80 toks/s, output: 14.74 toks/s]
Processed prompts:  46%|     | 474/1024 [00:32<00:39, 13.99it/s, est. speed input: 15089.62 toks/s, output: 14.74 toks/s]
Processed prompts:  47%|     | 482/1024 [00:32<00:38, 14.02it/s, est. speed input: 15078.36 toks/s, output: 14.72 toks/s]
Processed prompts:  48%|     | 490/1024 [00:33<00:37, 14.08it/s, est. speed input: 15069.24 toks/s, output: 14.72 toks/s]
Processed prompts:  49%|     | 498/1024 [00:33<00:37, 14.06it/s, est. speed input: 15057.48 toks/s, output: 14.70 toks/s]
Processed prompts:  49%|     | 506/1024 [00:34<00:36, 14.09it/s, est. speed input: 15048.33 toks/s, output: 14.70 toks/s]
Processed prompts:  50%|     | 514/1024 [00:34<00:36, 14.14it/s, est. speed input: 15040.99 toks/s, output: 14.69 toks/s]
Processed prompts:  51%|     | 522/1024 [00:35<00:35, 14.10it/s, est. speed input: 15029.98 toks/s, output: 14.68 toks/s]
Processed prompts:  52%|    | 530/1024 [00:36<00:34, 14.15it/s, est. speed input: 15023.25 toks/s, output: 14.67 toks/s]
Processed prompts:  53%|    | 538/1024 [00:36<00:34, 14.13it/s, est. speed input: 15013.94 toks/s, output: 14.66 toks/s]
Processed prompts:  53%|    | 546/1024 [00:37<00:33, 14.17it/s, est. speed input: 15008.08 toks/s, output: 14.66 toks/s]
Processed prompts:  54%|    | 554/1024 [00:37<00:33, 14.16it/s, est. speed input: 15000.22 toks/s, output: 14.65 toks/s]
Processed prompts:  55%|    | 562/1024 [00:38<00:32, 14.16it/s, est. speed input: 14992.87 toks/s, output: 14.64 toks/s]
Processed prompts:  56%|    | 570/1024 [00:38<00:32, 14.13it/s, est. speed input: 14984.28 toks/s, output: 14.63 toks/s]
Processed prompts:  56%|    | 578/1024 [00:39<00:31, 14.15it/s, est. speed input: 14977.89 toks/s, output: 14.63 toks/s]
Processed prompts:  57%|    | 586/1024 [00:40<00:30, 14.14it/s, est. speed input: 14970.25 toks/s, output: 14.62 toks/s]
Processed prompts:  58%|    | 594/1024 [00:40<00:30, 14.17it/s, est. speed input: 14964.78 toks/s, output: 14.61 toks/s]
Processed prompts:  59%|    | 602/1024 [00:41<00:29, 14.13it/s, est. speed input: 14956.67 toks/s, output: 14.61 toks/s]
Processed prompts:  60%|    | 610/1024 [00:41<00:29, 14.16it/s, est. speed input: 14951.52 toks/s, output: 14.60 toks/s]
Processed prompts:  60%|    | 618/1024 [00:42<00:28, 14.13it/s, est. speed input: 14944.17 toks/s, output: 14.59 toks/s]
Processed prompts:  61%|    | 626/1024 [00:42<00:28, 14.16it/s, est. speed input: 14939.27 toks/s, output: 14.59 toks/s]
Processed prompts:  62%|   | 634/1024 [00:43<00:27, 14.13it/s, est. speed input: 14932.27 toks/s, output: 14.58 toks/s]
Processed prompts:  63%|   | 642/1024 [00:44<00:26, 14.15it/s, est. speed input: 14927.09 toks/s, output: 14.58 toks/s]
Processed prompts:  63%|   | 650/1024 [00:44<00:26, 14.12it/s, est. speed input: 14920.16 toks/s, output: 14.57 toks/s]
Processed prompts:  64%|   | 658/1024 [00:45<00:25, 14.12it/s, est. speed input: 14914.40 toks/s, output: 14.56 toks/s]
Processed prompts:  65%|   | 666/1024 [00:45<00:25, 14.15it/s, est. speed input: 14909.89 toks/s, output: 14.56 toks/s]
Processed prompts:  66%|   | 674/1024 [00:46<00:24, 14.12it/s, est. speed input: 14903.55 toks/s, output: 14.55 toks/s]
Processed prompts:  67%|   | 682/1024 [00:46<00:24, 14.14it/s, est. speed input: 14899.21 toks/s, output: 14.55 toks/s]
Processed prompts:  67%|   | 690/1024 [00:47<00:23, 14.10it/s, est. speed input: 14892.57 toks/s, output: 14.54 toks/s]
Processed prompts:  68%|   | 698/1024 [00:48<00:23, 14.13it/s, est. speed input: 14888.34 toks/s, output: 14.54 toks/s]
Processed prompts:  69%|   | 706/1024 [00:48<00:22, 14.12it/s, est. speed input: 14883.11 toks/s, output: 14.53 toks/s]
Processed prompts:  70%|   | 714/1024 [00:49<00:21, 14.16it/s, est. speed input: 14879.83 toks/s, output: 14.53 toks/s]
Processed prompts:  71%|   | 722/1024 [00:49<00:21, 14.15it/s, est. speed input: 14875.19 toks/s, output: 14.53 toks/s]
Processed prompts:  71%|  | 730/1024 [00:50<00:20, 14.17it/s, est. speed input: 14871.42 toks/s, output: 14.52 toks/s]
Processed prompts:  72%|  | 738/1024 [00:50<00:20, 14.15it/s, est. speed input: 14866.67 toks/s, output: 14.52 toks/s]
Processed prompts:  73%|  | 746/1024 [00:51<00:19, 14.14it/s, est. speed input: 14862.33 toks/s, output: 14.51 toks/s]
Processed prompts:  74%|  | 754/1024 [00:51<00:19, 14.13it/s, est. speed input: 14857.51 toks/s, output: 14.51 toks/s]
Processed prompts:  74%|  | 762/1024 [00:52<00:18, 14.13it/s, est. speed input: 14853.45 toks/s, output: 14.51 toks/s]
Processed prompts:  75%|  | 770/1024 [00:53<00:17, 14.12it/s, est. speed input: 14848.83 toks/s, output: 14.50 toks/s]
Processed prompts:  76%|  | 778/1024 [00:53<00:17, 14.12it/s, est. speed input: 14844.86 toks/s, output: 14.50 toks/s]
Processed prompts:  77%|  | 786/1024 [00:54<00:16, 14.14it/s, est. speed input: 14841.36 toks/s, output: 14.49 toks/s]
Processed prompts:  78%|  | 794/1024 [00:54<00:16, 14.11it/s, est. speed input: 14836.82 toks/s, output: 14.49 toks/s]
Processed prompts:  78%|  | 802/1024 [00:55<00:15, 14.13it/s, est. speed input: 14833.29 toks/s, output: 14.49 toks/s]
Processed prompts:  79%|  | 810/1024 [00:55<00:15, 14.13it/s, est. speed input: 14829.61 toks/s, output: 14.48 toks/s]
Processed prompts:  80%|  | 818/1024 [00:56<00:14, 14.14it/s, est. speed input: 14826.35 toks/s, output: 14.48 toks/s]
Processed prompts:  81%|  | 826/1024 [00:57<00:14, 14.13it/s, est. speed input: 14822.51 toks/s, output: 14.48 toks/s]
Processed prompts:  81%| | 834/1024 [00:57<00:13, 14.14it/s, est. speed input: 14819.56 toks/s, output: 14.47 toks/s]
Processed prompts:  82%| | 842/1024 [00:58<00:12, 14.13it/s, est. speed input: 14815.92 toks/s, output: 14.47 toks/s]
Processed prompts:  83%| | 850/1024 [00:58<00:12, 14.14it/s, est. speed input: 14812.72 toks/s, output: 14.47 toks/s]
Processed prompts:  84%| | 858/1024 [00:59<00:11, 14.14it/s, est. speed input: 14809.55 toks/s, output: 14.46 toks/s]
Processed prompts:  85%| | 866/1024 [00:59<00:11, 14.16it/s, est. speed input: 14807.00 toks/s, output: 14.46 toks/s]
Processed prompts:  85%| | 874/1024 [01:00<00:10, 14.15it/s, est. speed input: 14803.88 toks/s, output: 14.46 toks/s]
Processed prompts:  86%| | 882/1024 [01:01<00:10, 14.15it/s, est. speed input: 14801.01 toks/s, output: 14.45 toks/s]
Processed prompts:  87%| | 890/1024 [01:01<00:09, 14.12it/s, est. speed input: 14797.25 toks/s, output: 14.45 toks/s]
Processed prompts:  88%| | 898/1024 [01:02<00:08, 14.11it/s, est. speed input: 14793.64 toks/s, output: 14.45 toks/s]
Processed prompts:  88%| | 906/1024 [01:02<00:08, 14.11it/s, est. speed input: 14790.48 toks/s, output: 14.44 toks/s]
Processed prompts:  89%| | 914/1024 [01:03<00:07, 13.96it/s, est. speed input: 14782.84 toks/s, output: 14.44 toks/s]
Processed prompts:  90%| | 922/1024 [01:03<00:07, 14.04it/s, est. speed input: 14780.98 toks/s, output: 14.43 toks/s]
Processed prompts:  91%| | 930/1024 [01:04<00:06, 14.06it/s, est. speed input: 14778.00 toks/s, output: 14.43 toks/s]
Processed prompts:  92%|| 938/1024 [01:04<00:05, 14.52it/s, est. speed input: 14788.46 toks/s, output: 14.44 toks/s]
Processed prompts:  92%|| 946/1024 [01:05<00:05, 14.39it/s, est. speed input: 14785.24 toks/s, output: 14.44 toks/s]
Processed prompts:  93%|| 954/1024 [01:06<00:04, 14.32it/s, est. speed input: 14782.78 toks/s, output: 14.44 toks/s]
Processed prompts:  94%|| 962/1024 [01:06<00:04, 14.25it/s, est. speed input: 14779.90 toks/s, output: 14.43 toks/s]
Processed prompts:  95%|| 970/1024 [01:07<00:03, 14.22it/s, est. speed input: 14777.52 toks/s, output: 14.43 toks/s]
Processed prompts:  96%|| 978/1024 [01:07<00:03, 14.18it/s, est. speed input: 14774.61 toks/s, output: 14.43 toks/s]
Processed prompts:  96%|| 986/1024 [01:08<00:02, 14.64it/s, est. speed input: 14785.19 toks/s, output: 14.44 toks/s]
Processed prompts:  97%|| 994/1024 [01:08<00:02, 14.49it/s, est. speed input: 14782.77 toks/s, output: 14.44 toks/s]
Processed prompts:  98%|| 1002/1024 [01:09<00:01, 14.38it/s, est. speed input: 14780.10 toks/s, output: 14.43 toks/s]
Processed prompts:  99%|| 1010/1024 [01:09<00:00, 14.29it/s, est. speed input: 14777.17 toks/s, output: 14.43 toks/s]
Processed prompts:  99%|| 1018/1024 [01:10<00:00, 14.58it/s, est. speed input: 14783.95 toks/s, output: 14.44 toks/s]
Processed prompts: 100%|| 1024/1024 [01:10<00:00, 14.58it/s, est. speed input: 14871.04 toks/s, output: 14.52 toks/s]
Processed prompts: 100%|| 1024/1024 [01:10<00:00, 14.52it/s, est. speed input: 14871.04 toks/s, output: 14.52 toks/s]
[rank0]:[W128 09:22:05.864806271 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-28 09:22:08
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/BitNet-2B-FP8_M16384.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:22:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:22:17 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3742012) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3742012) WARNING 01-28 09:22:47 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.39 requests/s, 14748.03 total tokens/s, 14.39 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-28 09:22:17] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:22:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:22:17] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:22:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:22:17] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:22:17] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:22:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:22:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:22:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:22:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:22:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:22:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:22:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:22:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:22:20] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:22:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:22:20] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:22:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:22:20] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:22:20] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:22:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:22:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:22:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:22:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:22:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:22:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:22:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:22:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:21] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:21] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:21] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:21] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:21] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3742012) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3742012) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.88s/it]
(EngineCore_DP0 pid=3742012) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.88s/it]
(EngineCore_DP0 pid=3742012) 
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3840] -> 1D uint8
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9216000 bytes
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3840] -> 1D uint8
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6144000 bytes
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3840] -> 1D uint8
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33177600 bytes
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 10368] -> 1D uint8
(EngineCore_DP0 pid=3742012) [2026-01-28 09:22:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=3742012) 2026-01-28 09:22:45,684 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3742012) 2026-01-28 09:22:45,754 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   3%|         | 64/2048 [00:00<00:03, 629.48it/s]
Adding requests:   6%|         | 127/2048 [00:00<00:03, 585.05it/s]
Adding requests:   9%|         | 186/2048 [00:00<00:03, 556.82it/s]
Adding requests:  12%|        | 243/2048 [00:00<00:03, 558.69it/s]
Adding requests:  15%|        | 299/2048 [00:00<00:03, 539.62it/s]
Adding requests:  17%|        | 354/2048 [00:00<00:03, 534.22it/s]
Adding requests:  20%|        | 409/2048 [00:00<00:03, 538.45it/s]
Adding requests:  23%|       | 463/2048 [00:00<00:02, 537.99it/s]
Adding requests:  25%|       | 517/2048 [00:00<00:02, 531.98it/s]
Adding requests:  28%|       | 571/2048 [00:01<00:02, 533.51it/s]
Adding requests:  31%|       | 627/2048 [00:01<00:02, 540.22it/s]
Adding requests:  33%|      | 684/2048 [00:01<00:02, 545.82it/s]
Adding requests:  36%|      | 739/2048 [00:01<00:02, 547.05it/s]
Adding requests:  39%|      | 794/2048 [00:01<00:02, 518.98it/s]
Adding requests:  41%|     | 847/2048 [00:01<00:02, 518.88it/s]
Adding requests:  44%|     | 900/2048 [00:02<00:05, 207.67it/s]
Adding requests:  46%|     | 952/2048 [00:02<00:04, 251.75it/s]
Adding requests:  49%|     | 1006/2048 [00:02<00:03, 299.68it/s]
Adding requests:  52%|    | 1058/2048 [00:02<00:02, 341.98it/s]
Adding requests:  54%|    | 1112/2048 [00:02<00:02, 384.71it/s]
Adding requests:  57%|    | 1165/2048 [00:02<00:02, 418.23it/s]
Adding requests:  60%|    | 1222/2048 [00:02<00:01, 454.77it/s]
Adding requests:  62%|   | 1275/2048 [00:02<00:01, 470.27it/s]
Adding requests:  65%|   | 1327/2048 [00:03<00:01, 482.86it/s]
Adding requests:  68%|   | 1383/2048 [00:03<00:01, 501.71it/s]
Adding requests:  70%|   | 1440/2048 [00:03<00:01, 519.25it/s]
Adding requests:  73%|  | 1495/2048 [00:03<00:01, 526.99it/s]
Adding requests:  76%|  | 1550/2048 [00:03<00:00, 531.44it/s]
Adding requests:  78%|  | 1607/2048 [00:03<00:00, 542.30it/s]
Adding requests:  81%|  | 1662/2048 [00:03<00:00, 540.37it/s]
Adding requests:  84%| | 1718/2048 [00:03<00:00, 544.73it/s]
Adding requests:  87%| | 1773/2048 [00:03<00:00, 541.33it/s]
Adding requests:  89%| | 1829/2048 [00:03<00:00, 546.75it/s]
Adding requests:  92%|| 1884/2048 [00:04<00:00, 547.58it/s]
Adding requests:  95%|| 1939/2048 [00:04<00:00, 546.65it/s]
Adding requests:  97%|| 1994/2048 [00:04<00:00, 543.91it/s]
Adding requests: 100%|| 2048/2048 [00:04<00:00, 472.46it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 50/2048 [00:00<00:12, 163.74it/s, est. speed input: 167686.88 toks/s, output: 163.75 toks/s]
Processed prompts:   3%|         | 67/2048 [00:01<00:50, 39.11it/s, est. speed input: 48273.85 toks/s, output: 47.14 toks/s]   
Processed prompts:   4%|         | 82/2048 [00:02<01:18, 25.18it/s, est. speed input: 33162.73 toks/s, output: 32.39 toks/s]
Processed prompts:   5%|         | 98/2048 [00:03<01:35, 20.44it/s, est. speed input: 27525.17 toks/s, output: 26.88 toks/s]
Processed prompts:   6%|         | 114/2048 [00:04<01:46, 18.10it/s, est. speed input: 24521.91 toks/s, output: 23.95 toks/s]
Processed prompts:   6%|         | 130/2048 [00:05<01:54, 16.79it/s, est. speed input: 22672.72 toks/s, output: 22.14 toks/s]
Processed prompts:   7%|         | 146/2048 [00:06<01:58, 16.00it/s, est. speed input: 21421.75 toks/s, output: 20.92 toks/s]
Processed prompts:   8%|         | 162/2048 [00:08<02:01, 15.48it/s, est. speed input: 20504.15 toks/s, output: 20.02 toks/s]
Processed prompts:   9%|         | 178/2048 [00:09<02:03, 15.11it/s, est. speed input: 19796.01 toks/s, output: 19.33 toks/s]
Processed prompts:   9%|         | 194/2048 [00:10<02:04, 14.89it/s, est. speed input: 19250.39 toks/s, output: 18.80 toks/s]
Processed prompts:  10%|         | 210/2048 [00:11<02:04, 14.73it/s, est. speed input: 18811.21 toks/s, output: 18.37 toks/s]
Processed prompts:  11%|         | 226/2048 [00:12<02:04, 14.63it/s, est. speed input: 18449.10 toks/s, output: 18.02 toks/s]
Processed prompts:  12%|        | 242/2048 [00:13<02:04, 14.55it/s, est. speed input: 18145.87 toks/s, output: 17.72 toks/s]
Processed prompts:  13%|        | 258/2048 [00:14<02:03, 14.50it/s, est. speed input: 17887.96 toks/s, output: 17.47 toks/s]
Processed prompts:  13%|        | 274/2048 [00:15<02:02, 14.48it/s, est. speed input: 17670.22 toks/s, output: 17.26 toks/s]
Processed prompts:  14%|        | 290/2048 [00:16<02:01, 14.45it/s, est. speed input: 17477.24 toks/s, output: 17.07 toks/s]
Processed prompts:  15%|        | 306/2048 [00:18<02:00, 14.42it/s, est. speed input: 17305.63 toks/s, output: 16.90 toks/s]
Processed prompts:  16%|        | 322/2048 [00:19<01:59, 14.41it/s, est. speed input: 17156.97 toks/s, output: 16.75 toks/s]
Processed prompts:  17%|        | 338/2048 [00:20<01:57, 14.54it/s, est. speed input: 17053.36 toks/s, output: 16.65 toks/s]
Processed prompts:  17%|        | 354/2048 [00:21<01:56, 14.50it/s, est. speed input: 16933.36 toks/s, output: 16.54 toks/s]
Processed prompts:  18%|        | 370/2048 [00:22<01:56, 14.46it/s, est. speed input: 16824.15 toks/s, output: 16.43 toks/s]
Processed prompts:  19%|        | 386/2048 [00:23<01:55, 14.43it/s, est. speed input: 16724.13 toks/s, output: 16.33 toks/s]
Processed prompts:  20%|        | 402/2048 [00:24<01:54, 14.40it/s, est. speed input: 16631.52 toks/s, output: 16.24 toks/s]
Processed prompts:  20%|        | 418/2048 [00:25<01:53, 14.38it/s, est. speed input: 16547.64 toks/s, output: 16.16 toks/s]
Processed prompts:  21%|        | 434/2048 [00:26<01:52, 14.38it/s, est. speed input: 16472.93 toks/s, output: 16.09 toks/s]
Processed prompts:  22%|       | 450/2048 [00:28<01:52, 14.24it/s, est. speed input: 16382.63 toks/s, output: 16.00 toks/s]
Processed prompts:  23%|       | 466/2048 [00:29<01:50, 14.28it/s, est. speed input: 16319.46 toks/s, output: 15.94 toks/s]
Processed prompts:  24%|       | 482/2048 [00:30<01:49, 14.30it/s, est. speed input: 16259.93 toks/s, output: 15.88 toks/s]
Processed prompts:  24%|       | 498/2048 [00:31<01:48, 14.32it/s, est. speed input: 16204.71 toks/s, output: 15.82 toks/s]
Processed prompts:  25%|       | 514/2048 [00:32<01:46, 14.34it/s, est. speed input: 16154.89 toks/s, output: 15.78 toks/s]
Processed prompts:  26%|       | 530/2048 [00:33<01:45, 14.36it/s, est. speed input: 16107.87 toks/s, output: 15.73 toks/s]
Processed prompts:  27%|       | 546/2048 [00:34<01:44, 14.35it/s, est. speed input: 16062.12 toks/s, output: 15.69 toks/s]
Processed prompts:  27%|       | 562/2048 [00:35<01:43, 14.35it/s, est. speed input: 16019.75 toks/s, output: 15.64 toks/s]
Processed prompts:  28%|       | 578/2048 [00:37<01:42, 14.36it/s, est. speed input: 15981.42 toks/s, output: 15.61 toks/s]
Processed prompts:  29%|       | 594/2048 [00:38<01:41, 14.35it/s, est. speed input: 15942.81 toks/s, output: 15.57 toks/s]
Processed prompts:  30%|       | 610/2048 [00:39<01:40, 14.34it/s, est. speed input: 15906.61 toks/s, output: 15.53 toks/s]
Processed prompts:  31%|       | 626/2048 [00:40<01:39, 14.35it/s, est. speed input: 15873.26 toks/s, output: 15.50 toks/s]
Processed prompts:  31%|      | 642/2048 [00:41<01:38, 14.33it/s, est. speed input: 15840.29 toks/s, output: 15.47 toks/s]
Processed prompts:  32%|      | 658/2048 [00:42<01:36, 14.35it/s, est. speed input: 15811.37 toks/s, output: 15.44 toks/s]
Processed prompts:  33%|      | 674/2048 [00:43<01:35, 14.34it/s, est. speed input: 15782.26 toks/s, output: 15.41 toks/s]
Processed prompts:  34%|      | 690/2048 [00:44<01:34, 14.35it/s, est. speed input: 15755.58 toks/s, output: 15.39 toks/s]
Processed prompts:  34%|      | 706/2048 [00:45<01:33, 14.36it/s, est. speed input: 15730.45 toks/s, output: 15.36 toks/s]
Processed prompts:  35%|      | 722/2048 [00:47<01:32, 14.34it/s, est. speed input: 15704.51 toks/s, output: 15.34 toks/s]
Processed prompts:  36%|      | 738/2048 [00:48<01:31, 14.34it/s, est. speed input: 15681.06 toks/s, output: 15.31 toks/s]
Processed prompts:  37%|      | 754/2048 [00:49<01:30, 14.34it/s, est. speed input: 15658.75 toks/s, output: 15.29 toks/s]
Processed prompts:  38%|      | 770/2048 [00:50<01:29, 14.34it/s, est. speed input: 15637.21 toks/s, output: 15.27 toks/s]
Processed prompts:  38%|      | 786/2048 [00:51<01:27, 14.34it/s, est. speed input: 15616.75 toks/s, output: 15.25 toks/s]
Processed prompts:  39%|      | 802/2048 [00:52<01:26, 14.35it/s, est. speed input: 15597.24 toks/s, output: 15.23 toks/s]
Processed prompts:  40%|      | 818/2048 [00:53<01:25, 14.35it/s, est. speed input: 15578.41 toks/s, output: 15.21 toks/s]
Processed prompts:  41%|      | 834/2048 [00:54<01:24, 14.35it/s, est. speed input: 15560.68 toks/s, output: 15.20 toks/s]
Processed prompts:  42%|     | 850/2048 [00:56<01:23, 14.33it/s, est. speed input: 15542.12 toks/s, output: 15.18 toks/s]
Processed prompts:  42%|     | 866/2048 [00:57<01:22, 14.34it/s, est. speed input: 15526.01 toks/s, output: 15.16 toks/s]
Processed prompts:  43%|     | 882/2048 [00:58<01:21, 14.34it/s, est. speed input: 15509.55 toks/s, output: 15.15 toks/s]
Processed prompts:  44%|     | 898/2048 [00:59<01:20, 14.33it/s, est. speed input: 15493.65 toks/s, output: 15.13 toks/s]
Processed prompts:  45%|     | 914/2048 [01:00<01:19, 14.28it/s, est. speed input: 15475.21 toks/s, output: 15.11 toks/s]
Processed prompts:  45%|     | 930/2048 [01:01<01:16, 14.53it/s, est. speed input: 15475.93 toks/s, output: 15.11 toks/s]
Processed prompts:  46%|     | 946/2048 [01:02<01:16, 14.47it/s, est. speed input: 15461.40 toks/s, output: 15.10 toks/s]
Processed prompts:  47%|     | 962/2048 [01:03<01:15, 14.43it/s, est. speed input: 15447.64 toks/s, output: 15.09 toks/s]
Processed prompts:  48%|     | 978/2048 [01:04<01:12, 14.66it/s, est. speed input: 15450.22 toks/s, output: 15.09 toks/s]
Processed prompts:  49%|     | 994/2048 [01:05<01:12, 14.55it/s, est. speed input: 15436.54 toks/s, output: 15.07 toks/s]
Processed prompts:  49%|     | 1010/2048 [01:07<01:11, 14.50it/s, est. speed input: 15424.89 toks/s, output: 15.06 toks/s]
Processed prompts:  50%|     | 1026/2048 [01:08<01:10, 14.44it/s, est. speed input: 15411.89 toks/s, output: 15.05 toks/s]
Processed prompts:  51%|     | 1042/2048 [01:09<01:09, 14.40it/s, est. speed input: 15399.71 toks/s, output: 15.04 toks/s]
Processed prompts:  52%|    | 1058/2048 [01:10<01:08, 14.36it/s, est. speed input: 15387.03 toks/s, output: 15.03 toks/s]
Processed prompts:  52%|    | 1074/2048 [01:11<01:07, 14.35it/s, est. speed input: 15376.01 toks/s, output: 15.02 toks/s]
Processed prompts:  53%|    | 1090/2048 [01:12<01:06, 14.33it/s, est. speed input: 15364.61 toks/s, output: 15.00 toks/s]
Processed prompts:  54%|    | 1106/2048 [01:13<01:05, 14.33it/s, est. speed input: 15354.01 toks/s, output: 14.99 toks/s]
Processed prompts:  55%|    | 1122/2048 [01:14<01:04, 14.33it/s, est. speed input: 15343.77 toks/s, output: 14.98 toks/s]
Processed prompts:  56%|    | 1138/2048 [01:15<01:03, 14.32it/s, est. speed input: 15333.23 toks/s, output: 14.97 toks/s]
Processed prompts:  56%|    | 1154/2048 [01:17<01:01, 14.57it/s, est. speed input: 15336.44 toks/s, output: 14.98 toks/s]
Processed prompts:  57%|    | 1170/2048 [01:18<01:00, 14.49it/s, est. speed input: 15326.69 toks/s, output: 14.97 toks/s]
Processed prompts:  58%|    | 1186/2048 [01:19<00:59, 14.44it/s, est. speed input: 15317.14 toks/s, output: 14.96 toks/s]
Processed prompts:  59%|    | 1202/2048 [01:20<00:58, 14.40it/s, est. speed input: 15308.18 toks/s, output: 14.95 toks/s]
Processed prompts:  59%|    | 1218/2048 [01:21<00:57, 14.38it/s, est. speed input: 15299.48 toks/s, output: 14.94 toks/s]
Processed prompts:  60%|    | 1234/2048 [01:22<00:56, 14.36it/s, est. speed input: 15290.61 toks/s, output: 14.93 toks/s]
Processed prompts:  61%|    | 1250/2048 [01:23<00:55, 14.34it/s, est. speed input: 15282.07 toks/s, output: 14.92 toks/s]
Processed prompts:  62%|   | 1266/2048 [01:24<00:53, 14.60it/s, est. speed input: 15286.09 toks/s, output: 14.93 toks/s]
Processed prompts:  63%|   | 1282/2048 [01:25<00:52, 14.52it/s, est. speed input: 15278.22 toks/s, output: 14.92 toks/s]
Processed prompts:  63%|   | 1298/2048 [01:26<00:50, 14.73it/s, est. speed input: 15282.15 toks/s, output: 14.92 toks/s]
Processed prompts:  64%|   | 1314/2048 [01:28<00:50, 14.59it/s, est. speed input: 15273.90 toks/s, output: 14.92 toks/s]
Processed prompts:  65%|   | 1330/2048 [01:29<00:49, 14.51it/s, est. speed input: 15266.33 toks/s, output: 14.91 toks/s]
Processed prompts:  66%|   | 1346/2048 [01:30<00:48, 14.45it/s, est. speed input: 15258.91 toks/s, output: 14.90 toks/s]
Processed prompts:  67%|   | 1362/2048 [01:31<00:47, 14.41it/s, est. speed input: 15251.32 toks/s, output: 14.89 toks/s]
Processed prompts:  67%|   | 1378/2048 [01:32<00:46, 14.31it/s, est. speed input: 15241.27 toks/s, output: 14.88 toks/s]
Processed prompts:  68%|   | 1394/2048 [01:33<00:45, 14.33it/s, est. speed input: 15235.05 toks/s, output: 14.88 toks/s]
Processed prompts:  69%|   | 1410/2048 [01:34<00:44, 14.31it/s, est. speed input: 15227.70 toks/s, output: 14.87 toks/s]
Processed prompts:  70%|   | 1426/2048 [01:35<00:43, 14.32it/s, est. speed input: 15221.24 toks/s, output: 14.86 toks/s]
Processed prompts:  70%|   | 1442/2048 [01:37<00:42, 14.32it/s, est. speed input: 15214.96 toks/s, output: 14.86 toks/s]
Processed prompts:  71%|   | 1458/2048 [01:38<00:41, 14.32it/s, est. speed input: 15208.76 toks/s, output: 14.85 toks/s]
Processed prompts:  72%|  | 1474/2048 [01:39<00:40, 14.33it/s, est. speed input: 15202.83 toks/s, output: 14.85 toks/s]
Processed prompts:  73%|  | 1490/2048 [01:40<00:38, 14.32it/s, est. speed input: 15196.54 toks/s, output: 14.84 toks/s]
Processed prompts:  74%|  | 1506/2048 [01:41<00:37, 14.32it/s, est. speed input: 15190.61 toks/s, output: 14.83 toks/s]
Processed prompts:  74%|  | 1522/2048 [01:42<00:36, 14.31it/s, est. speed input: 15184.74 toks/s, output: 14.83 toks/s]
Processed prompts:  75%|  | 1538/2048 [01:43<00:35, 14.32it/s, est. speed input: 15179.43 toks/s, output: 14.82 toks/s]
Processed prompts:  76%|  | 1554/2048 [01:44<00:34, 14.31it/s, est. speed input: 15173.57 toks/s, output: 14.82 toks/s]
Processed prompts:  77%|  | 1570/2048 [01:45<00:33, 14.32it/s, est. speed input: 15168.34 toks/s, output: 14.81 toks/s]
Processed prompts:  77%|  | 1586/2048 [01:47<00:31, 14.57it/s, est. speed input: 15172.04 toks/s, output: 14.82 toks/s]
Processed prompts:  78%|  | 1602/2048 [01:48<00:30, 14.50it/s, est. speed input: 15167.12 toks/s, output: 14.81 toks/s]
Processed prompts:  79%|  | 1618/2048 [01:49<00:29, 14.45it/s, est. speed input: 15162.22 toks/s, output: 14.81 toks/s]
Processed prompts:  80%|  | 1634/2048 [01:50<00:28, 14.42it/s, est. speed input: 15157.27 toks/s, output: 14.80 toks/s]
Processed prompts:  81%|  | 1650/2048 [01:51<00:27, 14.64it/s, est. speed input: 15161.06 toks/s, output: 14.81 toks/s]
Processed prompts:  81%| | 1666/2048 [01:52<00:26, 14.55it/s, est. speed input: 15156.20 toks/s, output: 14.80 toks/s]
Processed prompts:  82%| | 1682/2048 [01:53<00:25, 14.48it/s, est. speed input: 15151.35 toks/s, output: 14.80 toks/s]
Processed prompts:  83%| | 1698/2048 [01:54<00:24, 14.43it/s, est. speed input: 15146.74 toks/s, output: 14.79 toks/s]
Processed prompts:  84%| | 1714/2048 [01:55<00:23, 14.40it/s, est. speed input: 15142.17 toks/s, output: 14.79 toks/s]
Processed prompts:  84%| | 1730/2048 [01:57<00:22, 14.38it/s, est. speed input: 15137.57 toks/s, output: 14.78 toks/s]
Processed prompts:  85%| | 1746/2048 [01:58<00:21, 14.37it/s, est. speed input: 15133.47 toks/s, output: 14.78 toks/s]
Processed prompts:  86%| | 1762/2048 [01:59<00:19, 14.36it/s, est. speed input: 15129.11 toks/s, output: 14.77 toks/s]
Processed prompts:  87%| | 1778/2048 [02:00<00:18, 14.34it/s, est. speed input: 15124.49 toks/s, output: 14.77 toks/s]
Processed prompts:  88%| | 1794/2048 [02:01<00:17, 14.33it/s, est. speed input: 15120.08 toks/s, output: 14.77 toks/s]
Processed prompts:  88%| | 1810/2048 [02:02<00:16, 14.32it/s, est. speed input: 15115.86 toks/s, output: 14.76 toks/s]
Processed prompts:  89%| | 1826/2048 [02:03<00:15, 14.33it/s, est. speed input: 15111.92 toks/s, output: 14.76 toks/s]
Processed prompts:  90%| | 1842/2048 [02:04<00:14, 14.30it/s, est. speed input: 15107.26 toks/s, output: 14.75 toks/s]
Processed prompts:  91%| | 1858/2048 [02:05<00:13, 14.30it/s, est. speed input: 15103.10 toks/s, output: 14.75 toks/s]
Processed prompts:  92%|| 1874/2048 [02:07<00:11, 14.55it/s, est. speed input: 15106.69 toks/s, output: 14.75 toks/s]
Processed prompts:  92%|| 1890/2048 [02:08<00:10, 14.48it/s, est. speed input: 15102.81 toks/s, output: 14.75 toks/s]
Processed prompts:  93%|| 1906/2048 [02:09<00:09, 14.45it/s, est. speed input: 15099.55 toks/s, output: 14.75 toks/s]
Processed prompts:  94%|| 1922/2048 [02:10<00:08, 14.42it/s, est. speed input: 15095.98 toks/s, output: 14.74 toks/s]
Processed prompts:  95%|| 1938/2048 [02:11<00:07, 14.40it/s, est. speed input: 15092.53 toks/s, output: 14.74 toks/s]
Processed prompts:  95%|| 1954/2048 [02:12<00:06, 14.64it/s, est. speed input: 15096.52 toks/s, output: 14.74 toks/s]
Processed prompts:  96%|| 1970/2048 [02:13<00:05, 14.55it/s, est. speed input: 15093.16 toks/s, output: 14.74 toks/s]
Processed prompts:  97%|| 1986/2048 [02:14<00:04, 14.75it/s, est. speed input: 15097.13 toks/s, output: 14.74 toks/s]
Processed prompts:  98%|| 2002/2048 [02:15<00:03, 14.63it/s, est. speed input: 15093.84 toks/s, output: 14.74 toks/s]
Processed prompts:  99%|| 2018/2048 [02:16<00:02, 14.53it/s, est. speed input: 15090.18 toks/s, output: 14.74 toks/s]
Processed prompts:  99%|| 2034/2048 [02:18<00:00, 14.69it/s, est. speed input: 15092.78 toks/s, output: 14.74 toks/s]
Processed prompts: 100%|| 2048/2048 [02:18<00:00, 14.69it/s, est. speed input: 15196.63 toks/s, output: 14.84 toks/s]
Processed prompts: 100%|| 2048/2048 [02:18<00:00, 14.84it/s, est. speed input: 15196.63 toks/s, output: 14.84 toks/s]
[rank0]:[W128 09:25:10.161980092 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-28 09:25:12
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_8 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/GB10_cc121_FP8E4M3_py312_cu129_aarch64/cusparselt/2_8/json/BitNet-2B-FP8_M32768.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 09:25:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-28 09:25:27 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=3744814) [INFO] Loading compress extension: cusparselt_compress_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3744814) WARNING 01-28 09:26:00 [vllm.py:629] Inductor compilation was disabled by user settings,Optimizations settings that are only active duringInductor compilation will be ignored.
Throughput: 14.02 requests/s, 14374.44 total tokens/s, 14.02 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-28 09:25:27] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:25:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:25:27] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:25:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:27] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:27] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:25:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:25:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:25:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:25:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:25:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 09:25:30] INFO kernels.py:578: Triton kernel custom ops registered
/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:283: UserWarning: 
    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.
    Minimum and Maximum cuda capability supported by this version of PyTorch is
    (8.0) - (12.0)
    
  warnings.warn(
[2026-01-28 09:25:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 09:25:30] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 09:25:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:30] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:30] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 09:25:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 09:25:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 09:25:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 09:25:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 09:25:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 09:25:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:31] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_GB10_cc121_py312_cu129_aarch64.so
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:31] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:31] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:31] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:31] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3744814) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3744814) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.51s/it]
(EngineCore_DP0 pid=3744814) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16<00:00, 16.51s/it]
(EngineCore_DP0 pid=3744814) 
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 3840] -> 1D uint8
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9216000 bytes
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 3840] -> 1D uint8
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6144000 bytes
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 3840] -> 1D uint8
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33177600 bytes
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 10368] -> 1D uint8
(EngineCore_DP0 pid=3744814) [2026-01-28 09:25:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=3744814) 2026-01-28 09:25:56,619 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3744814) 2026-01-28 09:25:56,911 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   2%|         | 67/4096 [00:00<00:06, 667.18it/s]
Adding requests:   3%|         | 134/4096 [00:00<00:06, 632.88it/s]
Adding requests:   5%|         | 198/4096 [00:00<00:06, 566.80it/s]
Adding requests:   6%|         | 256/4096 [00:00<00:06, 555.05it/s]
Adding requests:   8%|         | 312/4096 [00:00<00:06, 546.77it/s]
Adding requests:   9%|         | 367/4096 [00:00<00:06, 546.48it/s]
Adding requests:  10%|         | 422/4096 [00:00<00:06, 545.21it/s]
Adding requests:  12%|        | 477/4096 [00:00<00:06, 542.70it/s]
Adding requests:  13%|        | 532/4096 [00:00<00:06, 524.90it/s]
Adding requests:  14%|        | 590/4096 [00:01<00:06, 539.07it/s]
Adding requests:  16%|        | 645/4096 [00:01<00:06, 532.96it/s]
Adding requests:  17%|        | 700/4096 [00:01<00:06, 536.63it/s]
Adding requests:  18%|        | 754/4096 [00:01<00:06, 534.27it/s]
Adding requests:  20%|        | 808/4096 [00:01<00:06, 523.67it/s]
Adding requests:  21%|        | 863/4096 [00:01<00:06, 529.31it/s]
Adding requests:  22%|       | 919/4096 [00:01<00:05, 537.58it/s]
Adding requests:  24%|       | 973/4096 [00:01<00:05, 537.71it/s]
Adding requests:  25%|       | 1028/4096 [00:01<00:05, 541.11it/s]
Adding requests:  26%|       | 1083/4096 [00:01<00:05, 532.48it/s]
Adding requests:  28%|       | 1137/4096 [00:02<00:05, 527.83it/s]
Adding requests:  29%|       | 1190/4096 [00:02<00:05, 519.76it/s]
Adding requests:  30%|       | 1243/4096 [00:02<00:05, 517.34it/s]
Adding requests:  32%|      | 1297/4096 [00:02<00:05, 522.77it/s]
Adding requests:  33%|      | 1351/4096 [00:02<00:05, 523.92it/s]
Adding requests:  34%|      | 1405/4096 [00:02<00:05, 525.33it/s]
Adding requests:  36%|      | 1460/4096 [00:02<00:04, 529.66it/s]
Adding requests:  37%|      | 1516/4096 [00:02<00:04, 535.97it/s]
Adding requests:  38%|      | 1571/4096 [00:02<00:04, 538.13it/s]
Adding requests:  40%|      | 1627/4096 [00:03<00:04, 541.53it/s]
Adding requests:  41%|      | 1682/4096 [00:03<00:04, 542.55it/s]
Adding requests:  42%|     | 1738/4096 [00:03<00:04, 546.56it/s]
Adding requests:  44%|     | 1793/4096 [00:03<00:04, 540.14it/s]
Adding requests:  45%|     | 1848/4096 [00:03<00:04, 542.22it/s]
Adding requests:  46%|     | 1903/4096 [00:03<00:04, 537.49it/s]
Adding requests:  48%|     | 1957/4096 [00:03<00:03, 537.87it/s]
Adding requests:  49%|     | 2013/4096 [00:03<00:03, 542.01it/s]
Adding requests:  50%|     | 2068/4096 [00:03<00:03, 543.94it/s]
Adding requests:  52%|    | 2123/4096 [00:03<00:03, 540.04it/s]
Adding requests:  53%|    | 2178/4096 [00:04<00:03, 534.65it/s]
Adding requests:  54%|    | 2232/4096 [00:04<00:03, 525.54it/s]
Adding requests:  56%|    | 2286/4096 [00:04<00:03, 527.49it/s]
Adding requests:  57%|    | 2341/4096 [00:04<00:03, 530.72it/s]
Adding requests:  58%|    | 2396/4096 [00:04<00:03, 533.49it/s]
Adding requests:  60%|    | 2450/4096 [00:04<00:03, 502.72it/s]
Adding requests:  61%|    | 2503/4096 [00:04<00:03, 510.34it/s]
Adding requests:  62%|   | 2560/4096 [00:04<00:02, 519.97it/s]
Adding requests:  64%|   | 2624/4096 [00:04<00:02, 551.50it/s]
Adding requests:  65%|   | 2680/4096 [00:04<00:02, 540.11it/s]
Adding requests:  67%|   | 2735/4096 [00:05<00:02, 532.19it/s]
Adding requests:  68%|   | 2789/4096 [00:05<00:02, 531.83it/s]
Adding requests:  69%|   | 2845/4096 [00:05<00:02, 539.78it/s]
Adding requests:  71%|   | 2900/4096 [00:05<00:02, 534.35it/s]
Adding requests:  72%|  | 2954/4096 [00:05<00:02, 527.90it/s]
Adding requests:  73%|  | 3008/4096 [00:05<00:02, 531.21it/s]
Adding requests:  75%|  | 3062/4096 [00:05<00:01, 529.55it/s]
Adding requests:  76%|  | 3117/4096 [00:05<00:01, 534.53it/s]
Adding requests:  77%|  | 3172/4096 [00:05<00:01, 537.94it/s]
Adding requests:  79%|  | 3228/4096 [00:06<00:01, 541.59it/s]
Adding requests:  80%|  | 3285/4096 [00:06<00:01, 547.24it/s]
Adding requests:  82%| | 3340/4096 [00:06<00:01, 538.66it/s]
Adding requests:  83%| | 3394/4096 [00:06<00:01, 537.80it/s]
Adding requests:  84%| | 3450/4096 [00:06<00:01, 538.33it/s]
Adding requests:  86%| | 3504/4096 [00:06<00:01, 526.72it/s]
Adding requests:  87%| | 3560/4096 [00:06<00:01, 533.61it/s]
Adding requests:  88%| | 3614/4096 [00:06<00:00, 534.83it/s]
Adding requests:  90%| | 3669/4096 [00:06<00:00, 538.06it/s]
Adding requests:  91%| | 3724/4096 [00:06<00:00, 540.42it/s]
Adding requests:  92%|| 3783/4096 [00:07<00:00, 554.06it/s]
Adding requests:  94%|| 3839/4096 [00:07<00:00, 517.95it/s]
Adding requests:  95%|| 3892/4096 [00:07<00:00, 520.00it/s]
Adding requests:  96%|| 3947/4096 [00:07<00:00, 528.36it/s]
Adding requests:  98%|| 4003/4096 [00:07<00:00, 535.71it/s]
Adding requests:  99%|| 4057/4096 [00:07<00:00, 534.46it/s]
Adding requests: 100%|| 4096/4096 [00:07<00:00, 536.03it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|         | 98/4096 [00:01<01:14, 54.01it/s, est. speed input: 55306.62 toks/s, output: 54.01 toks/s]
Processed prompts:   3%|         | 130/4096 [00:04<02:20, 28.24it/s, est. speed input: 32420.84 toks/s, output: 31.66 toks/s]
Processed prompts:   4%|         | 162/4096 [00:06<03:03, 21.45it/s, est. speed input: 25968.41 toks/s, output: 25.36 toks/s]
Processed prompts:   5%|         | 194/4096 [00:08<03:31, 18.42it/s, est. speed input: 22897.35 toks/s, output: 22.36 toks/s]
Processed prompts:   6%|         | 226/4096 [00:10<03:50, 16.80it/s, est. speed input: 21113.91 toks/s, output: 20.62 toks/s]
Processed prompts:   6%|         | 258/4096 [00:13<04:02, 15.83it/s, est. speed input: 19938.57 toks/s, output: 19.47 toks/s]
Processed prompts:   7%|         | 290/4096 [00:15<04:10, 15.21it/s, est. speed input: 19106.67 toks/s, output: 18.66 toks/s]
Processed prompts:   8%|         | 322/4096 [00:17<04:13, 14.89it/s, est. speed input: 18529.35 toks/s, output: 18.09 toks/s]
Processed prompts:   9%|         | 354/4096 [00:20<04:16, 14.60it/s, est. speed input: 18047.51 toks/s, output: 17.62 toks/s]
Processed prompts:   9%|         | 386/4096 [00:22<04:17, 14.41it/s, est. speed input: 17665.16 toks/s, output: 17.25 toks/s]
Processed prompts:  10%|         | 418/4096 [00:24<04:17, 14.28it/s, est. speed input: 17355.67 toks/s, output: 16.95 toks/s]
Processed prompts:  11%|         | 450/4096 [00:26<04:15, 14.26it/s, est. speed input: 17120.04 toks/s, output: 16.72 toks/s]
Processed prompts:  12%|        | 482/4096 [00:29<04:15, 14.17it/s, est. speed input: 16899.82 toks/s, output: 16.50 toks/s]
Processed prompts:  13%|        | 514/4096 [00:31<04:16, 13.94it/s, est. speed input: 16661.97 toks/s, output: 16.27 toks/s]
Processed prompts:  13%|        | 546/4096 [00:33<04:14, 13.94it/s, est. speed input: 16500.12 toks/s, output: 16.11 toks/s]
Processed prompts:  14%|        | 578/4096 [00:36<04:12, 13.95it/s, est. speed input: 16360.46 toks/s, output: 15.98 toks/s]
Processed prompts:  15%|        | 610/4096 [00:38<04:09, 13.95it/s, est. speed input: 16237.69 toks/s, output: 15.86 toks/s]
Processed prompts:  16%|        | 642/4096 [00:40<04:07, 13.95it/s, est. speed input: 16128.11 toks/s, output: 15.75 toks/s]
Processed prompts:  16%|        | 674/4096 [00:43<04:05, 13.95it/s, est. speed input: 16030.59 toks/s, output: 15.65 toks/s]
Processed prompts:  17%|        | 706/4096 [00:45<04:02, 13.96it/s, est. speed input: 15943.30 toks/s, output: 15.57 toks/s]
Processed prompts:  18%|        | 738/4096 [00:47<04:00, 13.95it/s, est. speed input: 15862.91 toks/s, output: 15.49 toks/s]
Processed prompts:  19%|        | 770/4096 [00:49<03:58, 13.96it/s, est. speed input: 15791.31 toks/s, output: 15.42 toks/s]
Processed prompts:  20%|        | 802/4096 [00:52<03:55, 13.96it/s, est. speed input: 15726.09 toks/s, output: 15.36 toks/s]
Processed prompts:  20%|        | 834/4096 [00:54<03:53, 13.96it/s, est. speed input: 15666.22 toks/s, output: 15.30 toks/s]
Processed prompts:  21%|        | 866/4096 [00:56<03:51, 13.96it/s, est. speed input: 15611.25 toks/s, output: 15.25 toks/s]
Processed prompts:  22%|       | 898/4096 [00:59<03:49, 13.96it/s, est. speed input: 15559.79 toks/s, output: 15.20 toks/s]
Processed prompts:  23%|       | 930/4096 [01:01<03:45, 14.05it/s, est. speed input: 15524.68 toks/s, output: 15.16 toks/s]
Processed prompts:  23%|       | 962/4096 [01:03<03:42, 14.11it/s, est. speed input: 15491.75 toks/s, output: 15.13 toks/s]
Processed prompts:  24%|       | 994/4096 [01:05<03:41, 13.99it/s, est. speed input: 15440.25 toks/s, output: 15.08 toks/s]
Processed prompts:  25%|       | 1026/4096 [01:08<03:39, 13.98it/s, est. speed input: 15402.14 toks/s, output: 15.04 toks/s]
Processed prompts:  26%|       | 1058/4096 [01:10<03:37, 13.98it/s, est. speed input: 15366.28 toks/s, output: 15.01 toks/s]
Processed prompts:  27%|       | 1090/4096 [01:12<03:35, 13.97it/s, est. speed input: 15331.93 toks/s, output: 14.97 toks/s]
Processed prompts:  27%|       | 1122/4096 [01:15<03:32, 13.97it/s, est. speed input: 15300.77 toks/s, output: 14.94 toks/s]
Processed prompts:  28%|       | 1154/4096 [01:17<03:29, 14.05it/s, est. speed input: 15280.03 toks/s, output: 14.92 toks/s]
Processed prompts:  29%|       | 1186/4096 [01:19<03:27, 14.02it/s, est. speed input: 15251.63 toks/s, output: 14.89 toks/s]
Processed prompts:  30%|       | 1218/4096 [01:21<03:25, 14.01it/s, est. speed input: 15225.29 toks/s, output: 14.87 toks/s]
Processed prompts:  31%|       | 1250/4096 [01:24<03:21, 14.09it/s, est. speed input: 15209.31 toks/s, output: 14.85 toks/s]
Processed prompts:  31%|      | 1282/4096 [01:26<03:19, 14.14it/s, est. speed input: 15193.41 toks/s, output: 14.84 toks/s]
Processed prompts:  32%|      | 1314/4096 [01:28<03:17, 14.08it/s, est. speed input: 15170.01 toks/s, output: 14.81 toks/s]
Processed prompts:  33%|      | 1346/4096 [01:30<03:15, 14.05it/s, est. speed input: 15147.98 toks/s, output: 14.79 toks/s]
Processed prompts:  34%|      | 1378/4096 [01:33<03:13, 14.02it/s, est. speed input: 15127.07 toks/s, output: 14.77 toks/s]
Processed prompts:  34%|      | 1410/4096 [01:35<03:11, 13.99it/s, est. speed input: 15106.11 toks/s, output: 14.75 toks/s]
Processed prompts:  35%|      | 1442/4096 [01:37<03:10, 13.94it/s, est. speed input: 15083.58 toks/s, output: 14.73 toks/s]
Processed prompts:  36%|      | 1474/4096 [01:40<03:07, 13.95it/s, est. speed input: 15066.02 toks/s, output: 14.71 toks/s]
Processed prompts:  37%|      | 1506/4096 [01:42<03:05, 13.95it/s, est. speed input: 15048.13 toks/s, output: 14.70 toks/s]
Processed prompts:  38%|      | 1538/4096 [01:44<03:03, 13.96it/s, est. speed input: 15032.08 toks/s, output: 14.68 toks/s]
Processed prompts:  38%|      | 1570/4096 [01:47<02:59, 14.06it/s, est. speed input: 15023.95 toks/s, output: 14.67 toks/s]
Processed prompts:  39%|      | 1602/4096 [01:49<02:57, 14.02it/s, est. speed input: 15007.96 toks/s, output: 14.66 toks/s]
Processed prompts:  40%|      | 1634/4096 [01:51<02:54, 14.09it/s, est. speed input: 15000.00 toks/s, output: 14.65 toks/s]
Processed prompts:  41%|      | 1666/4096 [01:53<02:52, 14.06it/s, est. speed input: 14986.28 toks/s, output: 14.64 toks/s]
Processed prompts:  41%|     | 1698/4096 [01:56<02:51, 14.02it/s, est. speed input: 14972.20 toks/s, output: 14.62 toks/s]
Processed prompts:  42%|     | 1730/4096 [01:58<02:48, 14.00it/s, est. speed input: 14958.85 toks/s, output: 14.61 toks/s]
Processed prompts:  43%|     | 1762/4096 [02:00<02:46, 13.99it/s, est. speed input: 14946.61 toks/s, output: 14.60 toks/s]
Processed prompts:  44%|     | 1794/4096 [02:03<02:44, 13.99it/s, est. speed input: 14934.65 toks/s, output: 14.58 toks/s]
Processed prompts:  45%|     | 1826/4096 [02:05<02:42, 13.97it/s, est. speed input: 14922.68 toks/s, output: 14.57 toks/s]
Processed prompts:  45%|     | 1858/4096 [02:07<02:39, 14.05it/s, est. speed input: 14916.69 toks/s, output: 14.57 toks/s]
Processed prompts:  46%|     | 1890/4096 [02:09<02:37, 13.96it/s, est. speed input: 14901.87 toks/s, output: 14.55 toks/s]
Processed prompts:  47%|     | 1922/4096 [02:12<02:35, 13.97it/s, est. speed input: 14891.53 toks/s, output: 14.54 toks/s]
Processed prompts:  48%|     | 1954/4096 [02:14<02:32, 14.06it/s, est. speed input: 14887.03 toks/s, output: 14.54 toks/s]
Processed prompts:  48%|     | 1986/4096 [02:16<02:29, 14.12it/s, est. speed input: 14882.22 toks/s, output: 14.53 toks/s]
Processed prompts:  49%|     | 2018/4096 [02:18<02:27, 14.07it/s, est. speed input: 14872.34 toks/s, output: 14.52 toks/s]
Processed prompts:  50%|     | 2050/4096 [02:21<02:25, 14.02it/s, est. speed input: 14862.38 toks/s, output: 14.51 toks/s]
Processed prompts:  51%|     | 2082/4096 [02:23<02:23, 14.00it/s, est. speed input: 14853.21 toks/s, output: 14.51 toks/s]
Processed prompts:  52%|    | 2114/4096 [02:25<02:21, 13.99it/s, est. speed input: 14844.72 toks/s, output: 14.50 toks/s]
Processed prompts:  52%|    | 2146/4096 [02:28<02:19, 13.99it/s, est. speed input: 14836.72 toks/s, output: 14.49 toks/s]
Processed prompts:  53%|    | 2178/4096 [02:30<02:17, 13.98it/s, est. speed input: 14828.09 toks/s, output: 14.48 toks/s]
Processed prompts:  54%|    | 2210/4096 [02:32<02:12, 14.20it/s, est. speed input: 14832.00 toks/s, output: 14.48 toks/s]
Processed prompts:  55%|    | 2242/4096 [02:34<02:11, 14.13it/s, est. speed input: 14824.01 toks/s, output: 14.48 toks/s]
Processed prompts:  56%|    | 2274/4096 [02:37<02:08, 14.15it/s, est. speed input: 14820.27 toks/s, output: 14.47 toks/s]
Processed prompts:  56%|    | 2306/4096 [02:39<02:07, 14.09it/s, est. speed input: 14812.52 toks/s, output: 14.47 toks/s]
Processed prompts:  57%|    | 2338/4096 [02:41<02:04, 14.11it/s, est. speed input: 14807.93 toks/s, output: 14.46 toks/s]
Processed prompts:  58%|    | 2370/4096 [02:43<02:00, 14.31it/s, est. speed input: 14812.36 toks/s, output: 14.47 toks/s]
Processed prompts:  59%|    | 2402/4096 [02:46<01:58, 14.30it/s, est. speed input: 14809.69 toks/s, output: 14.46 toks/s]
Processed prompts:  59%|    | 2434/4096 [02:48<01:57, 14.18it/s, est. speed input: 14802.22 toks/s, output: 14.46 toks/s]
Processed prompts:  60%|    | 2466/4096 [02:50<01:55, 14.12it/s, est. speed input: 14795.39 toks/s, output: 14.45 toks/s]
Processed prompts:  61%|    | 2498/4096 [02:52<01:52, 14.16it/s, est. speed input: 14792.86 toks/s, output: 14.45 toks/s]
Processed prompts:  62%|   | 2530/4096 [02:55<01:51, 14.09it/s, est. speed input: 14786.00 toks/s, output: 14.44 toks/s]
Processed prompts:  63%|   | 2562/4096 [02:57<01:48, 14.15it/s, est. speed input: 14783.87 toks/s, output: 14.44 toks/s]
Processed prompts:  63%|   | 2594/4096 [02:59<01:46, 14.09it/s, est. speed input: 14777.61 toks/s, output: 14.43 toks/s]
Processed prompts:  64%|   | 2626/4096 [03:02<01:44, 14.05it/s, est. speed input: 14771.57 toks/s, output: 14.43 toks/s]
Processed prompts:  65%|   | 2658/4096 [03:04<01:42, 14.03it/s, est. speed input: 14765.77 toks/s, output: 14.42 toks/s]
Processed prompts:  66%|   | 2690/4096 [03:06<01:39, 14.10it/s, est. speed input: 14763.81 toks/s, output: 14.42 toks/s]
Processed prompts:  66%|   | 2722/4096 [03:08<01:37, 14.06it/s, est. speed input: 14758.22 toks/s, output: 14.41 toks/s]
Processed prompts:  67%|   | 2754/4096 [03:11<01:35, 14.02it/s, est. speed input: 14752.27 toks/s, output: 14.41 toks/s]
Processed prompts:  68%|   | 2786/4096 [03:13<01:33, 13.94it/s, est. speed input: 14744.29 toks/s, output: 14.40 toks/s]
Processed prompts:  69%|   | 2818/4096 [03:15<01:31, 13.95it/s, est. speed input: 14739.33 toks/s, output: 14.39 toks/s]
Processed prompts:  70%|   | 2850/4096 [03:18<01:28, 14.04it/s, est. speed input: 14737.82 toks/s, output: 14.39 toks/s]
Processed prompts:  70%|   | 2882/4096 [03:20<01:26, 14.02it/s, est. speed input: 14732.91 toks/s, output: 14.39 toks/s]
Processed prompts:  71%|   | 2914/4096 [03:22<01:24, 14.00it/s, est. speed input: 14727.65 toks/s, output: 14.38 toks/s]
Processed prompts:  72%|  | 2946/4096 [03:24<01:22, 13.98it/s, est. speed input: 14722.54 toks/s, output: 14.38 toks/s]
Processed prompts:  73%|  | 2978/4096 [03:27<01:20, 13.97it/s, est. speed input: 14717.80 toks/s, output: 14.37 toks/s]
Processed prompts:  73%|  | 3010/4096 [03:29<01:17, 13.97it/s, est. speed input: 14713.08 toks/s, output: 14.37 toks/s]
Processed prompts:  74%|  | 3042/4096 [03:31<01:15, 13.97it/s, est. speed input: 14708.63 toks/s, output: 14.36 toks/s]
Processed prompts:  75%|  | 3074/4096 [03:34<01:13, 13.97it/s, est. speed input: 14704.40 toks/s, output: 14.36 toks/s]
Processed prompts:  76%|  | 3106/4096 [03:36<01:09, 14.21it/s, est. speed input: 14708.86 toks/s, output: 14.36 toks/s]
Processed prompts:  77%|  | 3138/4096 [03:38<01:07, 14.22it/s, est. speed input: 14707.51 toks/s, output: 14.36 toks/s]
Processed prompts:  77%|  | 3170/4096 [03:40<01:05, 14.14it/s, est. speed input: 14703.20 toks/s, output: 14.36 toks/s]
Processed prompts:  78%|  | 3202/4096 [03:43<01:03, 14.07it/s, est. speed input: 14698.45 toks/s, output: 14.35 toks/s]
Processed prompts:  79%|  | 3234/4096 [03:45<01:01, 14.12it/s, est. speed input: 14697.37 toks/s, output: 14.35 toks/s]
Processed prompts:  80%|  | 3266/4096 [03:47<00:58, 14.07it/s, est. speed input: 14693.35 toks/s, output: 14.35 toks/s]
Processed prompts:  81%|  | 3298/4096 [03:49<00:56, 14.04it/s, est. speed input: 14689.43 toks/s, output: 14.35 toks/s]
Processed prompts:  81%| | 3330/4096 [03:52<00:54, 14.02it/s, est. speed input: 14685.50 toks/s, output: 14.34 toks/s]
Processed prompts:  82%| | 3362/4096 [03:54<00:52, 14.00it/s, est. speed input: 14681.56 toks/s, output: 14.34 toks/s]
Processed prompts:  83%| | 3394/4096 [03:56<00:50, 13.99it/s, est. speed input: 14677.85 toks/s, output: 14.33 toks/s]
Processed prompts:  84%| | 3426/4096 [03:59<00:47, 14.05it/s, est. speed input: 14676.69 toks/s, output: 14.33 toks/s]
Processed prompts:  84%| | 3458/4096 [04:01<00:45, 14.03it/s, est. speed input: 14673.10 toks/s, output: 14.33 toks/s]
Processed prompts:  85%| | 3490/4096 [04:03<00:42, 14.25it/s, est. speed input: 14677.36 toks/s, output: 14.33 toks/s]
Processed prompts:  86%| | 3522/4096 [04:05<00:40, 14.17it/s, est. speed input: 14674.02 toks/s, output: 14.33 toks/s]
Processed prompts:  87%| | 3554/4096 [04:08<00:38, 14.11it/s, est. speed input: 14670.57 toks/s, output: 14.33 toks/s]
Processed prompts:  88%| | 3586/4096 [04:10<00:36, 14.05it/s, est. speed input: 14666.85 toks/s, output: 14.32 toks/s]
Processed prompts:  88%| | 3618/4096 [04:12<00:34, 14.03it/s, est. speed input: 14663.50 toks/s, output: 14.32 toks/s]
Processed prompts:  89%| | 3650/4096 [04:14<00:31, 14.00it/s, est. speed input: 14659.95 toks/s, output: 14.32 toks/s]
Processed prompts:  90%| | 3682/4096 [04:17<00:29, 13.98it/s, est. speed input: 14656.47 toks/s, output: 14.31 toks/s]
Processed prompts:  91%| | 3714/4096 [04:19<00:27, 14.06it/s, est. speed input: 14655.79 toks/s, output: 14.31 toks/s]
Processed prompts:  91%|| 3746/4096 [04:21<00:24, 14.03it/s, est. speed input: 14652.59 toks/s, output: 14.31 toks/s]
Processed prompts:  92%|| 3778/4096 [04:24<00:22, 14.01it/s, est. speed input: 14649.55 toks/s, output: 14.31 toks/s]
Processed prompts:  93%|| 3810/4096 [04:26<00:20, 14.00it/s, est. speed input: 14646.64 toks/s, output: 14.30 toks/s]
Processed prompts:  94%|| 3842/4096 [04:28<00:18, 14.07it/s, est. speed input: 14646.19 toks/s, output: 14.30 toks/s]
Processed prompts:  95%|| 3874/4096 [04:30<00:15, 14.04it/s, est. speed input: 14643.19 toks/s, output: 14.30 toks/s]
Processed prompts:  95%|| 3906/4096 [04:33<00:13, 14.00it/s, est. speed input: 14639.95 toks/s, output: 14.30 toks/s]
Processed prompts:  96%|| 3938/4096 [04:35<00:11, 13.99it/s, est. speed input: 14637.10 toks/s, output: 14.29 toks/s]
Processed prompts:  97%|| 3970/4096 [04:37<00:09, 13.98it/s, est. speed input: 14634.36 toks/s, output: 14.29 toks/s]
Processed prompts:  98%|| 4002/4096 [04:40<00:06, 13.98it/s, est. speed input: 14631.63 toks/s, output: 14.29 toks/s]
Processed prompts:  98%|| 4034/4096 [04:42<00:04, 14.32it/s, est. speed input: 14638.58 toks/s, output: 14.30 toks/s]
Processed prompts:  99%|| 4066/4096 [04:44<00:02, 14.31it/s, est. speed input: 14638.32 toks/s, output: 14.30 toks/s]
Processed prompts: 100%|| 4096/4096 [04:44<00:00, 14.31it/s, est. speed input: 14746.31 toks/s, output: 14.40 toks/s]
Processed prompts: 100%|| 4096/4096 [04:44<00:00, 14.40it/s, est. speed input: 14746.31 toks/s, output: 14.40 toks/s]
[rank0]:[W128 09:30:52.847483187 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

