
========== M=16 ==========
Time: 2026-01-25 17:29:57
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=16, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 16 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 17 --max-num-batched-tokens 17 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 17:30:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 17:30:06 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=192720) WARNING 01-25 17:30:14 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=192720) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=192720) WARNING 01-25 17:30:21 [backends.py:609] Failed to read file <frozen os>
Throughput: 15.05 requests/s, 255.77 total tokens/s, 15.05 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128

STDERR:
[2026-01-25 17:30:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:30:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 17:30:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 17:30:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 17:30:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:30:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:30:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:30:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:30:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 17:30:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:30:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 17:30:14] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 17:30:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 17:30:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:30:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:30:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:30:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:30:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:15] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:15] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:15] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:15] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:15] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=192720) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=192720) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.64s/it]
(EngineCore_DP0 pid=192720) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.64s/it]
(EngineCore_DP0 pid=192720) 
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=192720) [2026-01-25 17:30:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=192720) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.78it/s]
(EngineCore_DP0 pid=192720) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.92it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.90it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2705.13it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:38,  3.32it/s, est. speed input: 53.07 toks/s, output: 3.32 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:15,  8.14it/s, est. speed input: 113.68 toks/s, output: 7.10 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:11, 10.97it/s, est. speed input: 146.87 toks/s, output: 9.18 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:09, 12.65it/s, est. speed input: 167.22 toks/s, output: 10.45 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:08, 13.75it/s, est. speed input: 181.32 toks/s, output: 11.33 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:07, 14.64it/s, est. speed input: 192.45 toks/s, output: 12.03 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:07, 15.24it/s, est. speed input: 201.00 toks/s, output: 12.56 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:07, 15.58it/s, est. speed input: 207.38 toks/s, output: 12.96 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:06, 15.90it/s, est. speed input: 212.91 toks/s, output: 13.31 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:06, 16.08it/s, est. speed input: 217.35 toks/s, output: 13.58 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:06, 16.35it/s, est. speed input: 221.59 toks/s, output: 13.85 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:06, 16.56it/s, est. speed input: 225.25 toks/s, output: 14.08 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:06, 16.68it/s, est. speed input: 228.37 toks/s, output: 14.27 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:06, 16.62it/s, est. speed input: 230.65 toks/s, output: 14.42 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 16.64it/s, est. speed input: 232.84 toks/s, output: 14.55 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:02<00:05, 16.74it/s, est. speed input: 235.01 toks/s, output: 14.69 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:02<00:05, 16.29it/s, est. speed input: 235.60 toks/s, output: 14.72 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:02<00:05, 16.38it/s, est. speed input: 237.14 toks/s, output: 14.82 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:05, 16.38it/s, est. speed input: 238.36 toks/s, output: 14.90 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 16.36it/s, est. speed input: 239.43 toks/s, output: 14.96 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:05, 16.46it/s, est. speed input: 240.65 toks/s, output: 15.04 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:05, 16.58it/s, est. speed input: 241.87 toks/s, output: 15.12 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:04, 16.93it/s, est. speed input: 243.50 toks/s, output: 15.22 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:03<00:04, 17.26it/s, est. speed input: 245.16 toks/s, output: 15.32 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:03<00:04, 17.42it/s, est. speed input: 246.56 toks/s, output: 15.41 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:03<00:04, 17.53it/s, est. speed input: 247.86 toks/s, output: 15.49 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 17.63it/s, est. speed input: 249.11 toks/s, output: 15.57 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:04, 17.04it/s, est. speed input: 249.24 toks/s, output: 15.58 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 16.62it/s, est. speed input: 249.33 toks/s, output: 15.58 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:04, 16.31it/s, est. speed input: 249.35 toks/s, output: 15.58 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:04, 16.19it/s, est. speed input: 249.52 toks/s, output: 15.59 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:04<00:04, 16.03it/s, est. speed input: 249.56 toks/s, output: 15.60 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:04<00:03, 15.94it/s, est. speed input: 249.62 toks/s, output: 15.60 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:04<00:03, 15.81it/s, est. speed input: 249.57 toks/s, output: 15.60 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:04<00:03, 15.74it/s, est. speed input: 249.56 toks/s, output: 15.60 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:04<00:03, 15.74it/s, est. speed input: 249.64 toks/s, output: 15.60 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 15.64it/s, est. speed input: 249.55 toks/s, output: 15.60 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:04<00:03, 15.26it/s, est. speed input: 249.02 toks/s, output: 15.56 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:03, 15.04it/s, est. speed input: 248.57 toks/s, output: 15.54 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:05<00:03, 14.89it/s, est. speed input: 248.15 toks/s, output: 15.51 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:05<00:03, 14.83it/s, est. speed input: 247.80 toks/s, output: 15.49 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:05<00:03, 14.74it/s, est. speed input: 247.42 toks/s, output: 15.46 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:05<00:02, 14.72it/s, est. speed input: 247.10 toks/s, output: 15.44 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:05<00:02, 14.63it/s, est. speed input: 246.69 toks/s, output: 15.42 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:05<00:02, 14.73it/s, est. speed input: 246.53 toks/s, output: 15.41 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:05<00:02, 14.71it/s, est. speed input: 246.26 toks/s, output: 15.39 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:06<00:02, 14.75it/s, est. speed input: 246.06 toks/s, output: 15.38 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:06<00:02, 14.75it/s, est. speed input: 245.84 toks/s, output: 15.37 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:06<00:02, 14.84it/s, est. speed input: 245.74 toks/s, output: 15.36 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:06<00:01, 14.84it/s, est. speed input: 245.56 toks/s, output: 15.35 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:06<00:01, 14.78it/s, est. speed input: 245.33 toks/s, output: 15.33 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:06<00:01, 14.63it/s, est. speed input: 244.98 toks/s, output: 15.31 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:06<00:01, 14.54it/s, est. speed input: 244.67 toks/s, output: 15.29 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:07<00:01, 14.45it/s, est. speed input: 244.33 toks/s, output: 15.27 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:07<00:01, 14.37it/s, est. speed input: 243.99 toks/s, output: 15.25 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:07<00:01, 14.45it/s, est. speed input: 243.80 toks/s, output: 15.24 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:07<00:01, 14.48it/s, est. speed input: 243.61 toks/s, output: 15.23 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:07<00:00, 14.44it/s, est. speed input: 243.34 toks/s, output: 15.21 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:07<00:00, 14.50it/s, est. speed input: 243.18 toks/s, output: 15.20 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:07<00:00, 14.51it/s, est. speed input: 242.99 toks/s, output: 15.19 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:07<00:00, 14.46it/s, est. speed input: 242.75 toks/s, output: 15.17 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:08<00:00, 14.41it/s, est. speed input: 242.52 toks/s, output: 15.16 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:08<00:00, 14.36it/s, est. speed input: 242.27 toks/s, output: 15.14 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:08<00:00, 14.49it/s, est. speed input: 242.18 toks/s, output: 15.14 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 14.49it/s, est. speed input: 242.12 toks/s, output: 15.13 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.13it/s, est. speed input: 242.12 toks/s, output: 15.13 toks/s]
[rank0]:[W125 17:30:43.914471925 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-25 17:30:46
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=128, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 128 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 129 --max-num-batched-tokens 129 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 17:30:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 17:30:54 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=193659) WARNING 01-25 17:31:02 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=193659) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=193659) WARNING 01-25 17:31:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 15.69 requests/s, 2023.96 total tokens/s, 15.69 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128

STDERR:
[2026-01-25 17:30:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:30:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 17:30:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 17:30:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:30:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 17:30:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:30:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:30:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:30:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:30:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 17:31:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:31:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 17:31:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 17:31:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 17:31:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:31:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:31:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:31:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:31:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=193659) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=193659) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=193659) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.57it/s]
(EngineCore_DP0 pid=193659) 
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=193659) [2026-01-25 17:31:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=193659) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.83it/s]
(EngineCore_DP0 pid=193659) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1286.38it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:30,  4.15it/s, est. speed input: 531.48 toks/s, output: 4.15 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:13,  9.37it/s, est. speed input: 1065.08 toks/s, output: 8.32 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:10, 12.18it/s, est. speed input: 1338.33 toks/s, output: 10.46 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:08, 13.84it/s, est. speed input: 1503.73 toks/s, output: 11.75 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:08, 14.84it/s, est. speed input: 1612.04 toks/s, output: 12.59 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:07, 15.49it/s, est. speed input: 1689.96 toks/s, output: 13.20 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:07, 15.69it/s, est. speed input: 1738.25 toks/s, output: 13.58 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:07, 16.01it/s, est. speed input: 1783.02 toks/s, output: 13.93 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:06, 16.14it/s, est. speed input: 1815.43 toks/s, output: 14.18 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:06, 16.23it/s, est. speed input: 1842.13 toks/s, output: 14.39 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:06, 16.36it/s, est. speed input: 1866.37 toks/s, output: 14.58 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:06, 16.44it/s, est. speed input: 1886.40 toks/s, output: 14.74 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:06, 16.51it/s, est. speed input: 1904.04 toks/s, output: 14.88 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:00, 84.88it/s, est. speed input: 3799.61 toks/s, output: 29.68 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:02<00:01, 37.94it/s, est. speed input: 3385.71 toks/s, output: 26.45 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:02<00:01, 30.18it/s, est. speed input: 3235.10 toks/s, output: 25.27 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:03<00:01, 26.05it/s, est. speed input: 3128.04 toks/s, output: 24.44 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:03<00:01, 23.81it/s, est. speed input: 3059.85 toks/s, output: 23.90 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:03<00:01, 22.00it/s, est. speed input: 2998.94 toks/s, output: 23.43 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:03<00:01, 20.62it/s, est. speed input: 2950.50 toks/s, output: 23.05 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:04<00:01, 19.42it/s, est. speed input: 2905.68 toks/s, output: 22.70 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:04<00:01, 18.53it/s, est. speed input: 2866.73 toks/s, output: 22.40 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 17.90it/s, est. speed input: 2832.76 toks/s, output: 22.13 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:04<00:01, 17.49it/s, est. speed input: 2810.62 toks/s, output: 21.96 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:04<00:01, 17.20it/s, est. speed input: 2790.83 toks/s, output: 21.80 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:04<00:01, 16.90it/s, est. speed input: 2771.22 toks/s, output: 21.65 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:04<00:01, 16.62it/s, est. speed input: 2751.84 toks/s, output: 21.50 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:05<00:01, 16.33it/s, est. speed input: 2732.45 toks/s, output: 21.35 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:05<00:01, 15.74it/s, est. speed input: 2708.22 toks/s, output: 21.16 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:05<00:01, 15.37it/s, est. speed input: 2685.97 toks/s, output: 20.98 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:05<00:00, 15.03it/s, est. speed input: 2663.67 toks/s, output: 20.81 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:05<00:00, 14.86it/s, est. speed input: 2643.44 toks/s, output: 20.65 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:05<00:00, 14.82it/s, est. speed input: 2625.38 toks/s, output: 20.51 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:05<00:00, 14.55it/s, est. speed input: 2604.71 toks/s, output: 20.35 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:05<00:00, 14.49it/s, est. speed input: 2586.92 toks/s, output: 20.21 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:06<00:00, 14.43it/s, est. speed input: 2569.59 toks/s, output: 20.07 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:06<00:00, 14.55it/s, est. speed input: 2555.22 toks/s, output: 19.96 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:06<00:00, 14.60it/s, est. speed input: 2540.97 toks/s, output: 19.85 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 14.60it/s, est. speed input: 2533.07 toks/s, output: 19.79 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 19.79it/s, est. speed input: 2533.07 toks/s, output: 19.79 toks/s]
[rank0]:[W125 17:31:29.982381239 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-25 17:31:32
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=256, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 256 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 257 --max-num-batched-tokens 257 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 17:31:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 17:31:42 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=194557) WARNING 01-25 17:31:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=194557) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=194557) WARNING 01-25 17:31:55 [backends.py:609] Failed to read file <frozen os>
Throughput: 16.23 requests/s, 4171.52 total tokens/s, 16.23 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128

STDERR:
[2026-01-25 17:31:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:31:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 17:31:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 17:31:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 17:31:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:31:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:31:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:31:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:31:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 17:31:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:31:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 17:31:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 17:31:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 17:31:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 17:31:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:31:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:31:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:31:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:31:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:50] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:50] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:50] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:50] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=194557) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=194557) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.66it/s]
(EngineCore_DP0 pid=194557) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.65it/s]
(EngineCore_DP0 pid=194557) 
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=194557) [2026-01-25 17:31:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=194557) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  9.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 10.05it/s]
(EngineCore_DP0 pid=194557) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.65it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  64%|██████▍   | 82/128 [00:00<00:00, 819.48it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 821.76it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:25,  4.90it/s, est. speed input: 1253.49 toks/s, output: 4.90 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:12,  9.98it/s, est. speed input: 2313.85 toks/s, output: 9.04 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 12.36it/s, est. speed input: 2799.64 toks/s, output: 10.94 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:08, 13.67it/s, est. speed input: 3077.49 toks/s, output: 12.02 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:08, 14.55it/s, est. speed input: 3267.33 toks/s, output: 12.76 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:07, 15.13it/s, est. speed input: 3402.54 toks/s, output: 13.29 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:07, 15.51it/s, est. speed input: 3503.08 toks/s, output: 13.68 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:07, 15.82it/s, est. speed input: 3584.77 toks/s, output: 14.00 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:06, 15.95it/s, est. speed input: 3643.51 toks/s, output: 14.23 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:06, 16.01it/s, est. speed input: 3689.87 toks/s, output: 14.41 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:06, 16.17it/s, est. speed input: 3735.58 toks/s, output: 14.59 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:06, 16.37it/s, est. speed input: 3779.43 toks/s, output: 14.76 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:06, 16.51it/s, est. speed input: 3817.34 toks/s, output: 14.91 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:06, 16.57it/s, est. speed input: 3848.09 toks/s, output: 15.03 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:06, 16.34it/s, est. speed input: 3861.42 toks/s, output: 15.08 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:02<00:05, 16.37it/s, est. speed input: 3881.93 toks/s, output: 15.16 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:02<00:05, 16.44it/s, est. speed input: 3902.55 toks/s, output: 15.24 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:02<00:05, 16.55it/s, est. speed input: 3923.52 toks/s, output: 15.33 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:05, 16.52it/s, est. speed input: 3937.94 toks/s, output: 15.38 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 16.61it/s, est. speed input: 3955.28 toks/s, output: 15.45 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:05, 16.61it/s, est. speed input: 3968.95 toks/s, output: 15.50 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:05, 16.51it/s, est. speed input: 3977.83 toks/s, output: 15.54 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:05, 16.49it/s, est. speed input: 3987.40 toks/s, output: 15.58 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:03<00:04, 16.42it/s, est. speed input: 3994.74 toks/s, output: 15.60 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:03<00:04, 16.48it/s, est. speed input: 4004.66 toks/s, output: 15.64 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:03<00:04, 16.48it/s, est. speed input: 4012.61 toks/s, output: 15.67 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 16.45it/s, est. speed input: 4019.31 toks/s, output: 15.70 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:04, 16.50it/s, est. speed input: 4027.18 toks/s, output: 15.73 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 16.44it/s, est. speed input: 4032.15 toks/s, output: 15.75 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:04, 16.43it/s, est. speed input: 4037.77 toks/s, output: 15.77 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:04, 16.43it/s, est. speed input: 4043.12 toks/s, output: 15.79 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:03<00:03, 16.35it/s, est. speed input: 4046.12 toks/s, output: 15.81 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:04<00:03, 16.45it/s, est. speed input: 4052.71 toks/s, output: 15.83 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:04<00:03, 16.53it/s, est. speed input: 4059.13 toks/s, output: 15.86 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:04<00:03, 16.61it/s, est. speed input: 4065.67 toks/s, output: 15.88 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:04<00:03, 16.57it/s, est. speed input: 4069.74 toks/s, output: 15.90 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 16.62it/s, est. speed input: 4075.42 toks/s, output: 15.92 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:04<00:03, 16.45it/s, est. speed input: 4076.39 toks/s, output: 15.92 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:03, 16.44it/s, est. speed input: 4079.64 toks/s, output: 15.94 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:04<00:02, 16.68it/s, est. speed input: 4087.54 toks/s, output: 15.97 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:05<00:02, 16.98it/s, est. speed input: 4097.65 toks/s, output: 16.01 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:05<00:02, 17.22it/s, est. speed input: 4107.63 toks/s, output: 16.05 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:05<00:02, 17.50it/s, est. speed input: 4119.08 toks/s, output: 16.09 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:05<00:02, 17.56it/s, est. speed input: 4127.68 toks/s, output: 16.12 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:05<00:02, 17.65it/s, est. speed input: 4136.75 toks/s, output: 16.16 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:05<00:02, 17.75it/s, est. speed input: 4145.98 toks/s, output: 16.20 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:05<00:01, 17.71it/s, est. speed input: 4153.22 toks/s, output: 16.22 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:05<00:01, 17.77it/s, est. speed input: 4161.51 toks/s, output: 16.26 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:05<00:01, 17.75it/s, est. speed input: 4168.48 toks/s, output: 16.28 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:06<00:01, 17.63it/s, est. speed input: 4173.66 toks/s, output: 16.30 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:06<00:01, 17.66it/s, est. speed input: 4180.39 toks/s, output: 16.33 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:06<00:01, 17.62it/s, est. speed input: 4185.87 toks/s, output: 16.35 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:06<00:01, 17.73it/s, est. speed input: 4193.13 toks/s, output: 16.38 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:06<00:01, 17.56it/s, est. speed input: 4196.86 toks/s, output: 16.39 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:06<00:01, 17.56it/s, est. speed input: 4201.94 toks/s, output: 16.41 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:06<00:00, 17.66it/s, est. speed input: 4208.23 toks/s, output: 16.44 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:06<00:00, 17.64it/s, est. speed input: 4213.12 toks/s, output: 16.46 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:06<00:00, 17.71it/s, est. speed input: 4218.99 toks/s, output: 16.48 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:07<00:00, 17.66it/s, est. speed input: 4223.31 toks/s, output: 16.50 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:07<00:00, 17.45it/s, est. speed input: 4225.28 toks/s, output: 16.50 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:07<00:00, 17.72it/s, est. speed input: 4232.50 toks/s, output: 16.53 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:07<00:00, 17.69it/s, est. speed input: 4236.74 toks/s, output: 16.55 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:07<00:00, 17.56it/s, est. speed input: 4239.57 toks/s, output: 16.56 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:07<00:00, 17.26it/s, est. speed input: 4239.72 toks/s, output: 16.56 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.26it/s, est. speed input: 4239.94 toks/s, output: 16.56 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 16.56it/s, est. speed input: 4239.94 toks/s, output: 16.56 toks/s]
[rank0]:[W125 17:32:16.641536757 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-25 18:59:19
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:59:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 18:59:27 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=284325) WARNING 01-25 18:59:35 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=284325) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=284325) WARNING 01-25 18:59:43 [backends.py:609] Failed to read file <frozen os>
Throughput: 16.50 requests/s, 8466.95 total tokens/s, 16.50 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-25 18:59:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 18:59:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:59:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:59:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:59:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:59:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:59:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:59:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:59:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:59:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:59:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:59:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:59:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:59:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:59:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 18:59:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 18:59:34] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 18:59:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:59:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:59:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:59:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:59:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 18:59:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 18:59:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:59:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:59:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:59:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:59:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:36] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:36] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:36] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:36] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:36] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=284325) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=284325) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.00it/s]
(EngineCore_DP0 pid=284325) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.00it/s]
(EngineCore_DP0 pid=284325) 
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:37] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=284325) [2026-01-25 18:59:37] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=284325) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  5.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  4.26it/s]
(EngineCore_DP0 pid=284325) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.54it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  44%|████▍     | 56/128 [00:00<00:00, 558.94it/s]
Adding requests:  90%|████████▉ | 115/128 [00:00<00:00, 575.09it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 577.75it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:03, 40.46it/s, est. speed input: 20719.89 toks/s, output: 40.46 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:05, 22.94it/s, est. speed input: 12561.04 toks/s, output: 24.53 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:05, 20.13it/s, est. speed input: 11225.69 toks/s, output: 21.92 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:06, 18.66it/s, est. speed input: 10528.85 toks/s, output: 20.56 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:06, 18.05it/s, est. speed input: 10232.04 toks/s, output: 19.98 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:06, 17.61it/s, est. speed input: 10014.09 toks/s, output: 19.56 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:06, 17.09it/s, est. speed input: 9802.09 toks/s, output: 19.14 toks/s] 
Processed prompts:  19%|█▉        | 24/128 [00:01<00:06, 16.86it/s, est. speed input: 9661.43 toks/s, output: 18.87 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:06, 16.81it/s, est. speed input: 9563.64 toks/s, output: 18.68 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 16.69it/s, est. speed input: 9470.48 toks/s, output: 18.50 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 16.65it/s, est. speed input: 9396.21 toks/s, output: 18.35 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 16.58it/s, est. speed input: 9327.75 toks/s, output: 18.22 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 16.68it/s, est. speed input: 9285.94 toks/s, output: 18.14 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:05, 16.67it/s, est. speed input: 9240.46 toks/s, output: 18.05 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 16.73it/s, est. speed input: 9206.59 toks/s, output: 17.98 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 16.71it/s, est. speed input: 9170.64 toks/s, output: 17.91 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:05, 16.78it/s, est. speed input: 9145.58 toks/s, output: 17.86 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 16.82it/s, est. speed input: 9122.75 toks/s, output: 17.82 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 16.65it/s, est. speed input: 9084.46 toks/s, output: 17.74 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 16.57it/s, est. speed input: 9053.41 toks/s, output: 17.68 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 16.48it/s, est. speed input: 9022.44 toks/s, output: 17.62 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:04, 16.47it/s, est. speed input: 8997.35 toks/s, output: 17.57 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:03<00:04, 16.39it/s, est. speed input: 8969.72 toks/s, output: 17.52 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 16.36it/s, est. speed input: 8945.37 toks/s, output: 17.47 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:04, 16.39it/s, est. speed input: 8926.41 toks/s, output: 17.43 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:04, 16.46it/s, est. speed input: 8912.15 toks/s, output: 17.41 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:04, 16.23it/s, est. speed input: 8881.20 toks/s, output: 17.35 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 16.10it/s, est. speed input: 8853.98 toks/s, output: 17.29 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 16.15it/s, est. speed input: 8837.31 toks/s, output: 17.26 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 16.18it/s, est. speed input: 8821.24 toks/s, output: 17.23 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:04<00:03, 16.09it/s, est. speed input: 8800.07 toks/s, output: 17.19 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:04<00:03, 16.09it/s, est. speed input: 8783.33 toks/s, output: 17.15 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:04<00:03, 16.02it/s, est. speed input: 8764.20 toks/s, output: 17.12 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:04<00:03, 16.00it/s, est. speed input: 8747.33 toks/s, output: 17.08 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:03, 15.87it/s, est. speed input: 8725.76 toks/s, output: 17.04 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:03, 15.75it/s, est. speed input: 8703.66 toks/s, output: 17.00 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 15.86it/s, est. speed input: 8692.04 toks/s, output: 16.98 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 15.85it/s, est. speed input: 8677.19 toks/s, output: 16.95 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:05<00:02, 15.88it/s, est. speed input: 8664.49 toks/s, output: 16.92 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:05<00:02, 15.78it/s, est. speed input: 8647.39 toks/s, output: 16.89 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:05<00:02, 15.88it/s, est. speed input: 8638.23 toks/s, output: 16.87 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:05<00:02, 16.05it/s, est. speed input: 8633.38 toks/s, output: 16.86 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:05<00:02, 16.09it/s, est. speed input: 8625.57 toks/s, output: 16.85 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:05<00:01, 16.14it/s, est. speed input: 8619.06 toks/s, output: 16.83 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 16.27it/s, est. speed input: 8616.44 toks/s, output: 16.83 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 16.65it/s, est. speed input: 8624.00 toks/s, output: 16.84 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:06<00:01, 16.91it/s, est. speed input: 8630.92 toks/s, output: 16.86 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:06<00:01, 17.19it/s, est. speed input: 8640.31 toks/s, output: 16.88 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:06<00:01, 17.35it/s, est. speed input: 8648.15 toks/s, output: 16.89 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:06<00:01, 17.49it/s, est. speed input: 8656.63 toks/s, output: 16.91 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:06<00:01, 17.51it/s, est. speed input: 8662.59 toks/s, output: 16.92 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:06<00:00, 17.59it/s, est. speed input: 8669.98 toks/s, output: 16.93 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:06<00:00, 17.63it/s, est. speed input: 8676.88 toks/s, output: 16.95 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 17.58it/s, est. speed input: 8681.16 toks/s, output: 16.96 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 17.52it/s, est. speed input: 8684.80 toks/s, output: 16.96 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:07<00:00, 17.46it/s, est. speed input: 8687.75 toks/s, output: 16.97 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:07<00:00, 17.44it/s, est. speed input: 8691.35 toks/s, output: 16.98 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:07<00:00, 17.37it/s, est. speed input: 8693.31 toks/s, output: 16.98 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:07<00:00, 17.36it/s, est. speed input: 8695.98 toks/s, output: 16.98 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.43it/s, est. speed input: 8700.88 toks/s, output: 16.99 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.43it/s, est. speed input: 8700.88 toks/s, output: 16.99 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 16.99it/s, est. speed input: 8700.88 toks/s, output: 16.99 toks/s]
[rank0]:[W125 19:00:03.378770388 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-25 19:00:05
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:00:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:00:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=285221) WARNING 01-25 19:00:24 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=285221) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=285221) WARNING 01-25 19:00:30 [backends.py:609] Failed to read file <frozen os>
Throughput: 16.34 requests/s, 16750.04 total tokens/s, 16.34 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-25 19:00:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:00:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:00:14] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:00:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:00:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:00:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:00:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:00:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:00:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:00:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:00:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:00:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:00:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:00:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:00:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:00:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:00:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:00:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:00:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:00:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:00:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:00:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:00:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:00:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:00:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:00:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:00:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:00:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=285221) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=285221) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.35it/s]
(EngineCore_DP0 pid=285221) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.35it/s]
(EngineCore_DP0 pid=285221) 
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=285221) [2026-01-25 19:00:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=285221) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  9.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  9.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  9.59it/s]
(EngineCore_DP0 pid=285221) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.39it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  8.38it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  23%|██▎       | 30/128 [00:00<00:00, 296.70it/s]
Adding requests:  48%|████▊     | 62/128 [00:00<00:00, 307.62it/s]
Adding requests:  73%|███████▎  | 93/128 [00:00<00:00, 307.84it/s]
Adding requests:  98%|█████████▊| 126/128 [00:00<00:00, 314.98it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 311.38it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:02, 44.37it/s, est. speed input: 45444.10 toks/s, output: 44.37 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:05, 23.30it/s, est. speed input: 25875.72 toks/s, output: 25.27 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:05, 20.54it/s, est. speed input: 23177.36 toks/s, output: 22.63 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:05, 19.15it/s, est. speed input: 21797.04 toks/s, output: 21.29 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:00<00:05, 18.08it/s, est. speed input: 20785.78 toks/s, output: 20.30 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:06, 17.66it/s, est. speed input: 20342.03 toks/s, output: 19.86 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:06, 17.33it/s, est. speed input: 19987.99 toks/s, output: 19.52 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:05, 17.10it/s, est. speed input: 19706.12 toks/s, output: 19.24 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 16.83it/s, est. speed input: 19439.95 toks/s, output: 18.98 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 16.54it/s, est. speed input: 19186.12 toks/s, output: 18.74 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 16.15it/s, est. speed input: 18916.54 toks/s, output: 18.47 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 15.96it/s, est. speed input: 18704.04 toks/s, output: 18.27 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:05, 15.91it/s, est. speed input: 18543.24 toks/s, output: 18.11 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 15.97it/s, est. speed input: 18422.96 toks/s, output: 17.99 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 16.01it/s, est. speed input: 18316.32 toks/s, output: 17.89 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:05, 16.06it/s, est. speed input: 18224.86 toks/s, output: 17.80 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:05, 16.16it/s, est. speed input: 18154.97 toks/s, output: 17.73 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:05, 16.04it/s, est. speed input: 18056.83 toks/s, output: 17.63 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 16.21it/s, est. speed input: 18011.30 toks/s, output: 17.59 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 16.39it/s, est. speed input: 17978.55 toks/s, output: 17.56 toks/s]
Processed prompts:  41%|████      | 52/128 [00:02<00:04, 16.53it/s, est. speed input: 17949.99 toks/s, output: 17.53 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:03<00:04, 16.53it/s, est. speed input: 17909.91 toks/s, output: 17.49 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 16.40it/s, est. speed input: 17855.20 toks/s, output: 17.44 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:03<00:04, 16.37it/s, est. speed input: 17811.91 toks/s, output: 17.39 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:03<00:04, 16.27it/s, est. speed input: 17762.48 toks/s, output: 17.35 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:03<00:04, 16.30it/s, est. speed input: 17728.72 toks/s, output: 17.31 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:03<00:03, 16.32it/s, est. speed input: 17695.89 toks/s, output: 17.28 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:03<00:03, 16.46it/s, est. speed input: 17680.56 toks/s, output: 17.27 toks/s]
Processed prompts:  53%|█████▎    | 68/128 [00:03<00:03, 16.40it/s, est. speed input: 17648.81 toks/s, output: 17.24 toks/s]
Processed prompts:  55%|█████▍    | 70/128 [00:04<00:03, 16.39it/s, est. speed input: 17621.95 toks/s, output: 17.21 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:04<00:03, 16.25it/s, est. speed input: 17582.41 toks/s, output: 17.17 toks/s]
Processed prompts:  58%|█████▊    | 74/128 [00:04<00:03, 16.18it/s, est. speed input: 17548.81 toks/s, output: 17.14 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:04<00:03, 16.28it/s, est. speed input: 17532.03 toks/s, output: 17.12 toks/s]
Processed prompts:  61%|██████    | 78/128 [00:04<00:03, 16.29it/s, est. speed input: 17509.56 toks/s, output: 17.10 toks/s]
Processed prompts:  62%|██████▎   | 80/128 [00:04<00:02, 16.35it/s, est. speed input: 17493.44 toks/s, output: 17.08 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:04<00:02, 16.29it/s, est. speed input: 17469.00 toks/s, output: 17.06 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:04<00:02, 16.35it/s, est. speed input: 17454.18 toks/s, output: 17.05 toks/s]
Processed prompts:  67%|██████▋   | 86/128 [00:05<00:02, 16.58it/s, est. speed input: 17456.52 toks/s, output: 17.05 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:05<00:02, 16.89it/s, est. speed input: 17470.05 toks/s, output: 17.06 toks/s]
Processed prompts:  70%|███████   | 90/128 [00:05<00:02, 17.20it/s, est. speed input: 17489.83 toks/s, output: 17.08 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:05<00:02, 17.43it/s, est. speed input: 17509.39 toks/s, output: 17.10 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:05<00:01, 17.63it/s, est. speed input: 17530.17 toks/s, output: 17.12 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:05<00:01, 17.73it/s, est. speed input: 17547.12 toks/s, output: 17.14 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:05<00:01, 17.75it/s, est. speed input: 17560.96 toks/s, output: 17.15 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:05<00:01, 17.75it/s, est. speed input: 17572.86 toks/s, output: 17.16 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:05<00:01, 17.73it/s, est. speed input: 17582.97 toks/s, output: 17.17 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:06<00:01, 17.86it/s, est. speed input: 17601.45 toks/s, output: 17.19 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:06<00:01, 17.85it/s, est. speed input: 17613.19 toks/s, output: 17.20 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:06<00:01, 17.65it/s, est. speed input: 17613.07 toks/s, output: 17.20 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:06<00:01, 17.47it/s, est. speed input: 17610.51 toks/s, output: 17.20 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:06<00:00, 17.48it/s, est. speed input: 17616.33 toks/s, output: 17.20 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:06<00:00, 17.46it/s, est. speed input: 17619.91 toks/s, output: 17.21 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 17.37it/s, est. speed input: 17619.36 toks/s, output: 17.21 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 17.38it/s, est. speed input: 17622.31 toks/s, output: 17.21 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 17.63it/s, est. speed input: 17639.42 toks/s, output: 17.23 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:07<00:00, 17.76it/s, est. speed input: 17652.72 toks/s, output: 17.24 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:07<00:00, 17.76it/s, est. speed input: 17661.33 toks/s, output: 17.25 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:07<00:00, 17.71it/s, est. speed input: 17666.46 toks/s, output: 17.25 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.53it/s, est. speed input: 17664.42 toks/s, output: 17.25 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.53it/s, est. speed input: 17664.42 toks/s, output: 17.25 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 17.25it/s, est. speed input: 17664.42 toks/s, output: 17.25 toks/s]
[rank0]:[W125 19:00:51.449782848 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-25 19:00:54
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:01:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:01:03 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=286136) WARNING 01-25 19:01:12 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=286136) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=286136) WARNING 01-25 19:01:19 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.52 requests/s, 33337.09 total tokens/s, 32.52 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-25 19:01:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:01:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:01:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:01:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:01:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:01:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:01:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:01:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:01:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:01:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:01:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:01:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:01:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:01:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:01:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:01:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:01:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:01:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:12] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:12] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:12] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:12] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:12] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=286136) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=286136) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.43it/s]
(EngineCore_DP0 pid=286136) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.43it/s]
(EngineCore_DP0 pid=286136) 
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=286136) [2026-01-25 19:01:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=286136) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  7.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  3.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  4.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  4.80it/s]
(EngineCore_DP0 pid=286136) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  4.07it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  5.82it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  5.46it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  12%|█▏        | 30/256 [00:00<00:00, 294.92it/s]
Adding requests:  24%|██▍       | 62/256 [00:00<00:00, 304.37it/s]
Adding requests:  36%|███▋      | 93/256 [00:00<00:00, 302.85it/s]
Adding requests:  48%|████▊     | 124/256 [00:00<00:00, 291.13it/s]
Adding requests:  60%|██████    | 154/256 [00:00<00:00, 274.85it/s]
Adding requests:  71%|███████▏  | 183/256 [00:00<00:00, 277.79it/s]
Adding requests:  82%|████████▏ | 211/256 [00:00<00:00, 274.36it/s]
Adding requests:  94%|█████████▍| 241/256 [00:00<00:00, 280.23it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 283.83it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  10%|█         | 26/256 [00:00<00:01, 205.49it/s, est. speed input: 210474.91 toks/s, output: 205.51 toks/s]
Processed prompts:  18%|█▊        | 47/256 [00:00<00:03, 54.86it/s, est. speed input: 63963.21 toks/s, output: 62.46 toks/s]   
Processed prompts:  23%|██▎       | 58/256 [00:01<00:04, 44.33it/s, est. speed input: 53052.54 toks/s, output: 51.81 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:01<00:04, 41.38it/s, est. speed input: 49835.79 toks/s, output: 48.67 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:01<00:04, 39.31it/s, est. speed input: 47879.14 toks/s, output: 46.76 toks/s]
Processed prompts:  30%|███       | 77/256 [00:01<00:04, 39.30it/s, est. speed input: 47292.11 toks/s, output: 46.18 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:01<00:04, 36.02it/s, est. speed input: 45421.92 toks/s, output: 44.36 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:01<00:04, 35.23it/s, est. speed input: 44649.90 toks/s, output: 43.60 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:02<00:04, 34.81it/s, est. speed input: 44049.17 toks/s, output: 43.02 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:02<00:04, 33.60it/s, est. speed input: 43272.62 toks/s, output: 42.26 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:02<00:04, 33.41it/s, est. speed input: 42772.73 toks/s, output: 41.77 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:02<00:04, 33.28it/s, est. speed input: 42326.56 toks/s, output: 41.33 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:02<00:04, 33.14it/s, est. speed input: 41913.47 toks/s, output: 40.93 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:02<00:04, 33.08it/s, est. speed input: 41547.03 toks/s, output: 40.57 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:02<00:04, 33.23it/s, est. speed input: 41247.54 toks/s, output: 40.28 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:02<00:04, 33.35it/s, est. speed input: 40973.87 toks/s, output: 40.01 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:03<00:04, 33.42it/s, est. speed input: 40718.30 toks/s, output: 39.76 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:03<00:03, 32.96it/s, est. speed input: 40403.16 toks/s, output: 39.46 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:03<00:03, 32.88it/s, est. speed input: 40146.88 toks/s, output: 39.21 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:03<00:03, 32.80it/s, est. speed input: 39906.48 toks/s, output: 38.97 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:03<00:03, 32.65it/s, est. speed input: 39668.65 toks/s, output: 38.74 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:03<00:03, 32.63it/s, est. speed input: 39459.18 toks/s, output: 38.53 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:03<00:03, 32.65it/s, est. speed input: 39266.83 toks/s, output: 38.35 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:03<00:03, 32.47it/s, est. speed input: 39062.33 toks/s, output: 38.15 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:04<00:03, 32.68it/s, est. speed input: 38910.84 toks/s, output: 38.00 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:04<00:02, 32.94it/s, est. speed input: 38780.77 toks/s, output: 37.87 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:04<00:02, 32.98it/s, est. speed input: 38643.23 toks/s, output: 37.74 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:04<00:02, 33.11it/s, est. speed input: 38524.60 toks/s, output: 37.62 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:04<00:02, 32.99it/s, est. speed input: 38387.49 toks/s, output: 37.49 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:04<00:02, 32.95it/s, est. speed input: 38263.42 toks/s, output: 37.37 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:04<00:02, 33.18it/s, est. speed input: 38170.68 toks/s, output: 37.28 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:04<00:02, 33.46it/s, est. speed input: 38093.29 toks/s, output: 37.20 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:05<00:02, 33.39it/s, est. speed input: 37996.19 toks/s, output: 37.11 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:05<00:01, 33.74it/s, est. speed input: 37937.77 toks/s, output: 37.05 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:05<00:01, 34.67it/s, est. speed input: 37937.53 toks/s, output: 37.05 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:05<00:01, 34.89it/s, est. speed input: 37902.25 toks/s, output: 37.01 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:05<00:01, 35.15it/s, est. speed input: 37876.65 toks/s, output: 36.99 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:05<00:01, 35.39it/s, est. speed input: 37855.60 toks/s, output: 36.97 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:05<00:01, 35.61it/s, est. speed input: 37838.45 toks/s, output: 36.95 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:05<00:01, 35.73it/s, est. speed input: 37820.31 toks/s, output: 36.93 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:05<00:01, 35.63it/s, est. speed input: 37790.12 toks/s, output: 36.90 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:06<00:00, 35.74it/s, est. speed input: 37772.87 toks/s, output: 36.89 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:06<00:00, 35.70it/s, est. speed input: 37748.61 toks/s, output: 36.86 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:06<00:00, 35.73it/s, est. speed input: 37729.15 toks/s, output: 36.84 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:06<00:00, 35.76it/s, est. speed input: 37711.33 toks/s, output: 36.83 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:06<00:00, 35.97it/s, est. speed input: 37704.71 toks/s, output: 36.82 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:06<00:00, 35.82it/s, est. speed input: 37681.35 toks/s, output: 36.80 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:06<00:00, 35.65it/s, est. speed input: 37654.64 toks/s, output: 36.77 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:06<00:00, 35.56it/s, est. speed input: 37630.48 toks/s, output: 36.75 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:06<00:00, 35.75it/s, est. speed input: 37621.66 toks/s, output: 36.74 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:06<00:00, 35.75it/s, est. speed input: 37623.86 toks/s, output: 36.74 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:06<00:00, 36.74it/s, est. speed input: 37623.86 toks/s, output: 36.74 toks/s]
[rank0]:[W125 19:01:39.117925819 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-25 19:01:42
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:01:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:01:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=287062) WARNING 01-25 19:02:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=287062) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=287062) WARNING 01-25 19:02:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 63.35 requests/s, 64936.43 total tokens/s, 63.35 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-25 19:01:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:01:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:01:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:01:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:01:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:01:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:01:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:01:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:01:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:01:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:02:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:02:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:02:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:02:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:02:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:02:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:02:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:02:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:02:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:01] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:01] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:01] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:01] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:01] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=287062) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=287062) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.52it/s]
(EngineCore_DP0 pid=287062) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.52it/s]
(EngineCore_DP0 pid=287062) 
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=287062) [2026-01-25 19:02:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=287062) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  9.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00, 10.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  9.70it/s]
(EngineCore_DP0 pid=287062) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.67it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  9.42it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  9.21it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▌         | 27/512 [00:00<00:01, 265.48it/s]
Adding requests:  11%|█▏        | 58/512 [00:00<00:01, 289.50it/s]
Adding requests:  17%|█▋        | 89/512 [00:00<00:01, 295.66it/s]
Adding requests:  23%|██▎       | 119/512 [00:00<00:01, 291.74it/s]
Adding requests:  29%|██▉       | 149/512 [00:00<00:01, 290.71it/s]
Adding requests:  35%|███▍      | 179/512 [00:00<00:01, 290.34it/s]
Adding requests:  41%|████      | 210/512 [00:00<00:01, 294.19it/s]
Adding requests:  47%|████▋     | 242/512 [00:00<00:00, 301.11it/s]
Adding requests:  53%|█████▎    | 273/512 [00:00<00:00, 301.79it/s]
Adding requests:  59%|█████▉    | 304/512 [00:01<00:00, 290.21it/s]
Adding requests:  65%|██████▌   | 334/512 [00:01<00:00, 287.67it/s]
Adding requests:  71%|███████▏  | 365/512 [00:01<00:00, 292.23it/s]
Adding requests:  77%|███████▋  | 395/512 [00:01<00:00, 293.25it/s]
Adding requests:  83%|████████▎ | 426/512 [00:01<00:00, 294.16it/s]
Adding requests:  89%|████████▉ | 456/512 [00:01<00:00, 292.65it/s]
Adding requests:  95%|█████████▍| 486/512 [00:01<00:00, 288.89it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 291.15it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:00<00:00, 550.84it/s, est. speed input: 564164.97 toks/s, output: 550.88 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:01<00:03, 118.51it/s, est. speed input: 141101.14 toks/s, output: 137.79 toks/s]
Processed prompts:  32%|███▏      | 165/512 [00:01<00:03, 104.95it/s, est. speed input: 125584.97 toks/s, output: 122.64 toks/s]
Processed prompts:  36%|███▌      | 184/512 [00:01<00:03, 94.16it/s, est. speed input: 115705.01 toks/s, output: 112.99 toks/s] 
Processed prompts:  39%|███▊      | 198/512 [00:01<00:03, 86.43it/s, est. speed input: 109444.94 toks/s, output: 106.88 toks/s]
Processed prompts:  41%|████      | 209/512 [00:01<00:03, 88.26it/s, est. speed input: 108978.96 toks/s, output: 106.42 toks/s]
Processed prompts:  43%|████▎     | 220/512 [00:02<00:03, 82.79it/s, est. speed input: 105684.49 toks/s, output: 103.21 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:02<00:03, 76.83it/s, est. speed input: 102421.21 toks/s, output: 100.02 toks/s]
Processed prompts:  47%|████▋     | 239/512 [00:02<00:03, 77.38it/s, est. speed input: 101440.69 toks/s, output: 99.06 toks/s] 
Processed prompts:  48%|████▊     | 248/512 [00:02<00:03, 77.82it/s, est. speed input: 100535.31 toks/s, output: 98.18 toks/s]
Processed prompts:  50%|█████     | 257/512 [00:02<00:03, 78.13it/s, est. speed input: 99693.98 toks/s, output: 97.36 toks/s] 
Processed prompts:  52%|█████▏    | 266/512 [00:02<00:03, 69.46it/s, est. speed input: 96911.53 toks/s, output: 94.64 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:02<00:03, 69.60it/s, est. speed input: 95927.28 toks/s, output: 93.68 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:03<00:03, 69.78it/s, est. speed input: 95030.59 toks/s, output: 92.80 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:03<00:03, 70.31it/s, est. speed input: 94268.80 toks/s, output: 92.06 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:03<00:03, 70.70it/s, est. speed input: 93556.27 toks/s, output: 91.36 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:03<00:02, 70.84it/s, est. speed input: 92868.80 toks/s, output: 90.69 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:03<00:02, 70.77it/s, est. speed input: 92199.53 toks/s, output: 90.04 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:03<00:02, 70.76it/s, est. speed input: 91578.17 toks/s, output: 89.43 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:03<00:00, 361.14it/s, est. speed input: 123293.69 toks/s, output: 120.40 toks/s]
Processed prompts:  95%|█████████▍| 484/512 [00:04<00:00, 181.89it/s, est. speed input: 117851.36 toks/s, output: 115.09 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:04<00:00, 127.19it/s, est. speed input: 112634.12 toks/s, output: 109.99 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:04<00:00, 127.19it/s, est. speed input: 113070.25 toks/s, output: 110.42 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:04<00:00, 110.42it/s, est. speed input: 113070.25 toks/s, output: 110.42 toks/s]
[rank0]:[W125 19:02:29.830124914 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-25 19:02:32
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:02:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:02:48 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=288036) WARNING 01-25 19:02:55 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=288036) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=288036) WARNING 01-25 19:03:01 [backends.py:609] Failed to read file <frozen os>
Throughput: 91.37 requests/s, 93650.59 total tokens/s, 91.37 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-25 19:02:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:02:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:02:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:02:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:02:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:02:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:02:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:02:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:02:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:02:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:02:55] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:02:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:02:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:02:55] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:02:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:02:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:02:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:02:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:02:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:56] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:56] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:56] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:56] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:56] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:56] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=288036) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=288036) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.35it/s]
(EngineCore_DP0 pid=288036) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.35it/s]
(EngineCore_DP0 pid=288036) 
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:57] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=288036) [2026-01-25 19:02:57] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=288036) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:00,  8.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  8.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  8.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  8.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  8.34it/s]
(EngineCore_DP0 pid=288036) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  7.26it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  8.65it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  9.48it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  9.16it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 28/1024 [00:00<00:03, 279.12it/s]
Adding requests:   6%|▌         | 61/1024 [00:00<00:03, 305.73it/s]
Adding requests:   9%|▉         | 94/1024 [00:00<00:02, 316.43it/s]
Adding requests:  12%|█▏        | 126/1024 [00:00<00:02, 313.32it/s]
Adding requests:  15%|█▌        | 158/1024 [00:00<00:02, 307.68it/s]
Adding requests:  19%|█▊        | 190/1024 [00:00<00:02, 308.79it/s]
Adding requests:  22%|██▏       | 221/1024 [00:00<00:02, 306.57it/s]
Adding requests:  25%|██▍       | 252/1024 [00:00<00:02, 305.87it/s]
Adding requests:  28%|██▊       | 283/1024 [00:00<00:02, 303.80it/s]
Adding requests:  31%|███       | 314/1024 [00:01<00:02, 302.20it/s]
Adding requests:  34%|███▎      | 345/1024 [00:01<00:02, 293.97it/s]
Adding requests:  37%|███▋      | 376/1024 [00:01<00:02, 297.51it/s]
Adding requests:  40%|███▉      | 407/1024 [00:01<00:02, 299.31it/s]
Adding requests:  43%|████▎     | 437/1024 [00:01<00:01, 296.12it/s]
Adding requests:  46%|████▌     | 467/1024 [00:01<00:01, 291.70it/s]
Adding requests:  49%|████▊     | 497/1024 [00:01<00:01, 288.99it/s]
Adding requests:  51%|█████▏    | 526/1024 [00:01<00:01, 277.15it/s]
Adding requests:  54%|█████▍    | 557/1024 [00:01<00:01, 283.86it/s]
Adding requests:  57%|█████▋    | 587/1024 [00:01<00:01, 287.69it/s]
Adding requests:  60%|██████    | 616/1024 [00:02<00:01, 279.84it/s]
Adding requests:  63%|██████▎   | 645/1024 [00:02<00:01, 282.09it/s]
Adding requests:  66%|██████▌   | 674/1024 [00:02<00:01, 283.56it/s]
Adding requests:  69%|██████▊   | 703/1024 [00:02<00:01, 281.06it/s]
Adding requests:  71%|███████▏  | 732/1024 [00:02<00:01, 283.37it/s]
Adding requests:  74%|███████▍  | 761/1024 [00:02<00:00, 276.71it/s]
Adding requests:  77%|███████▋  | 789/1024 [00:02<00:00, 273.76it/s]
Adding requests:  80%|███████▉  | 817/1024 [00:02<00:00, 270.80it/s]
Adding requests:  83%|████████▎ | 846/1024 [00:02<00:00, 274.96it/s]
Adding requests:  86%|████████▌ | 877/1024 [00:03<00:00, 282.84it/s]
Adding requests:  89%|████████▊ | 908/1024 [00:03<00:00, 288.49it/s]
Adding requests:  92%|█████████▏| 938/1024 [00:03<00:00, 289.78it/s]
Adding requests:  95%|█████████▍| 968/1024 [00:03<00:00, 292.53it/s]
Adding requests:  97%|█████████▋| 998/1024 [00:03<00:00, 284.90it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 290.45it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:00<00:00, 2868.05it/s, est. speed input: 2938941.61 toks/s, output: 2868.31 toks/s]
Processed prompts:  57%|█████▋    | 585/1024 [00:03<00:02, 162.91it/s, est. speed input: 194921.29 toks/s, output: 190.35 toks/s]   
Processed prompts:  69%|██████▉   | 709/1024 [00:04<00:02, 137.83it/s, est. speed input: 166499.75 toks/s, output: 162.60 toks/s]
Processed prompts:  76%|███████▋  | 781/1024 [00:05<00:01, 128.75it/s, est. speed input: 157172.98 toks/s, output: 153.49 toks/s]
Processed prompts:  81%|████████  | 829/1024 [00:05<00:01, 121.50it/s, est. speed input: 151220.17 toks/s, output: 147.68 toks/s]
Processed prompts:  84%|████████▍ | 863/1024 [00:05<00:01, 117.83it/s, est. speed input: 148239.92 toks/s, output: 144.77 toks/s]
Processed prompts:  87%|████████▋ | 889/1024 [00:06<00:01, 115.26it/s, est. speed input: 146310.52 toks/s, output: 142.88 toks/s]
Processed prompts:  89%|████████▉ | 910/1024 [00:06<00:01, 109.39it/s, est. speed input: 143743.62 toks/s, output: 140.37 toks/s]
Processed prompts:  91%|█████████ | 927/1024 [00:06<00:00, 107.77it/s, est. speed input: 142603.05 toks/s, output: 139.26 toks/s]
Processed prompts:  92%|█████████▏| 942/1024 [00:06<00:00, 105.01it/s, est. speed input: 141385.05 toks/s, output: 138.07 toks/s]
Processed prompts:  93%|█████████▎| 955/1024 [00:06<00:00, 99.20it/s, est. speed input: 139774.18 toks/s, output: 136.50 toks/s] 
Processed prompts:  95%|█████████▍| 970/1024 [00:07<00:00, 96.30it/s, est. speed input: 138508.57 toks/s, output: 135.26 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:07<00:00, 96.18it/s, est. speed input: 137587.84 toks/s, output: 134.36 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:07<00:00, 95.11it/s, est. speed input: 136582.13 toks/s, output: 133.38 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:07<00:00, 95.19it/s, est. speed input: 135734.28 toks/s, output: 132.55 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:07<00:00, 95.19it/s, est. speed input: 136528.84 toks/s, output: 133.33 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:07<00:00, 133.33it/s, est. speed input: 136528.84 toks/s, output: 133.33 toks/s]
[rank0]:[W125 19:03:27.647775777 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-25 19:03:29
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:03:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:03:51 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=289151) WARNING 01-25 19:03:59 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=289151) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=289151) WARNING 01-25 19:04:05 [backends.py:609] Failed to read file <frozen os>
Throughput: 92.18 requests/s, 94480.90 total tokens/s, 92.18 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-25 19:03:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:03:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:03:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:03:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:03:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:03:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:03:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:03:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:03:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:03:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:03:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:03:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:03:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:03:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:03:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:03:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:03:58] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:03:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:03:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:03:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:03:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:03:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:03:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:03:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:03:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:03:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:03:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:03:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=289151) [2026-01-25 19:03:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=289151) [2026-01-25 19:03:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=289151) [2026-01-25 19:03:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=289151) [2026-01-25 19:03:59] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=289151) [2026-01-25 19:03:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=289151) [2026-01-25 19:03:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=289151) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=289151) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.35it/s]
(EngineCore_DP0 pid=289151) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.35it/s]
(EngineCore_DP0 pid=289151) 
(EngineCore_DP0 pid=289151) [2026-01-25 19:04:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=289151) [2026-01-25 19:04:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=289151) [2026-01-25 19:04:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=289151) [2026-01-25 19:04:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=289151) [2026-01-25 19:04:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=289151) [2026-01-25 19:04:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=289151) [2026-01-25 19:04:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=289151) [2026-01-25 19:04:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=289151) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  8.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  9.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  9.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  9.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  9.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  9.50it/s]
(EngineCore_DP0 pid=289151) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  7.57it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  9.21it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  9.73it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  9.48it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|▏         | 30/2048 [00:00<00:06, 297.81it/s]
Adding requests:   3%|▎         | 63/2048 [00:00<00:06, 315.01it/s]
Adding requests:   5%|▍         | 96/2048 [00:00<00:06, 317.46it/s]
Adding requests:   6%|▋         | 128/2048 [00:00<00:06, 316.94it/s]
Adding requests:   8%|▊         | 161/2048 [00:00<00:05, 320.38it/s]
Adding requests:   9%|▉         | 194/2048 [00:00<00:05, 312.89it/s]
Adding requests:  11%|█         | 226/2048 [00:00<00:05, 314.27it/s]
Adding requests:  13%|█▎        | 260/2048 [00:00<00:05, 320.42it/s]
Adding requests:  14%|█▍        | 293/2048 [00:00<00:05, 321.55it/s]
Adding requests:  16%|█▌        | 326/2048 [00:01<00:05, 321.85it/s]
Adding requests:  18%|█▊        | 359/2048 [00:01<00:05, 319.58it/s]
Adding requests:  19%|█▉        | 392/2048 [00:01<00:05, 320.82it/s]
Adding requests:  21%|██        | 426/2048 [00:01<00:05, 323.05it/s]
Adding requests:  22%|██▏       | 459/2048 [00:01<00:05, 316.91it/s]
Adding requests:  24%|██▍       | 491/2048 [00:01<00:04, 314.64it/s]
Adding requests:  26%|██▌       | 523/2048 [00:01<00:04, 306.98it/s]
Adding requests:  27%|██▋       | 554/2048 [00:01<00:04, 299.74it/s]
Adding requests:  29%|██▊       | 585/2048 [00:01<00:04, 298.14it/s]
Adding requests:  30%|███       | 615/2048 [00:01<00:04, 297.11it/s]
Adding requests:  31%|███▏      | 645/2048 [00:02<00:04, 296.49it/s]
Adding requests:  33%|███▎      | 676/2048 [00:02<00:04, 297.98it/s]
Adding requests:  34%|███▍      | 706/2048 [00:02<00:04, 298.04it/s]
Adding requests:  36%|███▌      | 736/2048 [00:02<00:04, 295.21it/s]
Adding requests:  37%|███▋      | 766/2048 [00:02<00:04, 288.53it/s]
Adding requests:  39%|███▉      | 795/2048 [00:02<00:04, 284.43it/s]
Adding requests:  40%|████      | 824/2048 [00:02<00:04, 270.19it/s]
Adding requests:  42%|████▏     | 854/2048 [00:02<00:04, 277.27it/s]
Adding requests:  43%|████▎     | 885/2048 [00:02<00:04, 286.26it/s]
Adding requests:  45%|████▍     | 917/2048 [00:03<00:03, 294.05it/s]
Adding requests:  46%|████▌     | 947/2048 [00:03<00:03, 291.69it/s]
Adding requests:  48%|████▊     | 979/2048 [00:03<00:03, 297.62it/s]
Adding requests:  49%|████▉     | 1010/2048 [00:03<00:03, 300.87it/s]
Adding requests:  51%|█████     | 1041/2048 [00:03<00:03, 300.65it/s]
Adding requests:  52%|█████▏    | 1072/2048 [00:03<00:03, 300.18it/s]
Adding requests:  54%|█████▍    | 1104/2048 [00:03<00:03, 301.73it/s]
Adding requests:  55%|█████▌    | 1135/2048 [00:03<00:03, 299.15it/s]
Adding requests:  57%|█████▋    | 1166/2048 [00:03<00:02, 301.96it/s]
Adding requests:  58%|█████▊    | 1198/2048 [00:03<00:02, 304.67it/s]
Adding requests:  60%|██████    | 1229/2048 [00:04<00:02, 305.71it/s]
Adding requests:  62%|██████▏   | 1260/2048 [00:04<00:02, 298.10it/s]
Adding requests:  63%|██████▎   | 1291/2048 [00:04<00:02, 301.32it/s]
Adding requests:  65%|██████▍   | 1322/2048 [00:04<00:02, 302.12it/s]
Adding requests:  66%|██████▌   | 1353/2048 [00:04<00:02, 296.65it/s]
Adding requests:  68%|██████▊   | 1384/2048 [00:04<00:02, 299.28it/s]
Adding requests:  69%|██████▉   | 1414/2048 [00:04<00:02, 298.56it/s]
Adding requests:  71%|███████   | 1444/2048 [00:04<00:02, 292.43it/s]
Adding requests:  72%|███████▏  | 1474/2048 [00:04<00:01, 291.07it/s]
Adding requests:  73%|███████▎  | 1504/2048 [00:04<00:01, 293.30it/s]
Adding requests:  75%|███████▍  | 1534/2048 [00:05<00:01, 293.62it/s]
Adding requests:  76%|███████▋  | 1564/2048 [00:05<00:01, 292.64it/s]
Adding requests:  78%|███████▊  | 1594/2048 [00:05<00:01, 290.88it/s]
Adding requests:  79%|███████▉  | 1624/2048 [00:05<00:01, 289.46it/s]
Adding requests:  81%|████████  | 1653/2048 [00:05<00:01, 289.39it/s]
Adding requests:  82%|████████▏ | 1682/2048 [00:05<00:01, 287.17it/s]
Adding requests:  84%|████████▎ | 1712/2048 [00:05<00:01, 289.77it/s]
Adding requests:  85%|████████▌ | 1741/2048 [00:05<00:01, 289.44it/s]
Adding requests:  86%|████████▋ | 1771/2048 [00:05<00:00, 291.06it/s]
Adding requests:  88%|████████▊ | 1802/2048 [00:06<00:00, 294.68it/s]
Adding requests:  90%|████████▉ | 1833/2048 [00:06<00:00, 297.70it/s]
Adding requests:  91%|█████████ | 1863/2048 [00:06<00:00, 293.62it/s]
Adding requests:  92%|█████████▏| 1894/2048 [00:06<00:00, 295.83it/s]
Adding requests:  94%|█████████▍| 1927/2048 [00:06<00:00, 303.09it/s]
Adding requests:  96%|█████████▌| 1958/2048 [00:06<00:00, 295.20it/s]
Adding requests:  97%|█████████▋| 1991/2048 [00:06<00:00, 304.58it/s]
Adding requests:  99%|█████████▉| 2025/2048 [00:06<00:00, 314.77it/s]
Adding requests: 100%|██████████| 2048/2048 [00:06<00:00, 300.78it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:00<00:00, 2722.73it/s, est. speed input: 2788450.03 toks/s, output: 2722.83 toks/s]
Processed prompts:  43%|████▎     | 883/2048 [00:03<00:04, 238.67it/s, est. speed input: 301380.85 toks/s, output: 294.32 toks/s]   
Processed prompts:  49%|████▉     | 1001/2048 [00:04<00:05, 186.17it/s, est. speed input: 243306.43 toks/s, output: 237.60 toks/s]
Processed prompts:  52%|█████▏    | 1070/2048 [00:04<00:05, 165.38it/s, est. speed input: 222812.51 toks/s, output: 217.59 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:05<00:03, 224.56it/s, est. speed input: 248214.60 toks/s, output: 242.40 toks/s]
Processed prompts:  63%|██████▎   | 1297/2048 [00:05<00:03, 189.36it/s, est. speed input: 231849.97 toks/s, output: 226.42 toks/s]
Processed prompts:  66%|██████▌   | 1353/2048 [00:06<00:04, 155.33it/s, est. speed input: 215363.86 toks/s, output: 210.32 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:06<00:04, 135.98it/s, est. speed input: 205055.27 toks/s, output: 200.25 toks/s]
Processed prompts:  70%|██████▉   | 1424/2048 [00:07<00:04, 139.62it/s, est. speed input: 204297.94 toks/s, output: 199.51 toks/s]
Processed prompts:  71%|███████   | 1450/2048 [00:07<00:04, 124.34it/s, est. speed input: 198253.53 toks/s, output: 193.61 toks/s]
Processed prompts:  72%|███████▏  | 1471/2048 [00:07<00:04, 123.61it/s, est. speed input: 196502.41 toks/s, output: 191.90 toks/s]
Processed prompts:  73%|███████▎  | 1489/2048 [00:07<00:04, 120.00it/s, est. speed input: 194441.62 toks/s, output: 189.88 toks/s]
Processed prompts:  73%|███████▎  | 1505/2048 [00:08<00:04, 114.32it/s, est. speed input: 192211.52 toks/s, output: 187.71 toks/s]
Processed prompts:  74%|███████▍  | 1519/2048 [00:08<00:04, 106.69it/s, est. speed input: 189819.71 toks/s, output: 185.37 toks/s]
Processed prompts:  75%|███████▍  | 1531/2048 [00:08<00:05, 99.31it/s, est. speed input: 187588.94 toks/s, output: 183.19 toks/s] 
Processed prompts:  75%|███████▌  | 1542/2048 [00:08<00:05, 91.70it/s, est. speed input: 185335.33 toks/s, output: 180.99 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:08<00:05, 87.15it/s, est. speed input: 183287.54 toks/s, output: 178.99 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:08<00:05, 90.20it/s, est. speed input: 181774.69 toks/s, output: 177.51 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:09<00:05, 92.37it/s, est. speed input: 180298.77 toks/s, output: 176.07 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:09<00:04, 94.05it/s, est. speed input: 178885.58 toks/s, output: 174.69 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:09<00:04, 95.29it/s, est. speed input: 177522.82 toks/s, output: 173.36 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:09<00:04, 96.20it/s, est. speed input: 176208.83 toks/s, output: 172.08 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:09<00:04, 96.83it/s, est. speed input: 174937.05 toks/s, output: 170.84 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:09<00:03, 97.21it/s, est. speed input: 173700.62 toks/s, output: 169.63 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:09<00:03, 97.52it/s, est. speed input: 172508.38 toks/s, output: 168.46 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:10<00:03, 97.77it/s, est. speed input: 171358.65 toks/s, output: 167.34 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:10<00:03, 97.97it/s, est. speed input: 170245.31 toks/s, output: 166.25 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:10<00:03, 98.04it/s, est. speed input: 169161.20 toks/s, output: 165.20 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:10<00:03, 98.16it/s, est. speed input: 168116.49 toks/s, output: 164.18 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:10<00:02, 98.28it/s, est. speed input: 167106.21 toks/s, output: 163.19 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:10<00:02, 97.00it/s, est. speed input: 166010.07 toks/s, output: 162.12 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:11<00:02, 95.00it/s, est. speed input: 164850.78 toks/s, output: 160.99 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:11<00:02, 93.67it/s, est. speed input: 163729.77 toks/s, output: 159.89 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:11<00:02, 92.76it/s, est. speed input: 162642.25 toks/s, output: 158.83 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:11<00:02, 92.13it/s, est. speed input: 161588.40 toks/s, output: 157.80 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:11<00:02, 91.76it/s, est. speed input: 160570.82 toks/s, output: 156.81 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:12<00:01, 92.81it/s, est. speed input: 159691.64 toks/s, output: 155.95 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:12<00:01, 92.09it/s, est. speed input: 158718.80 toks/s, output: 155.00 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:12<00:01, 91.65it/s, est. speed input: 157778.58 toks/s, output: 154.08 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:12<00:01, 91.34it/s, est. speed input: 156863.88 toks/s, output: 153.19 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:12<00:01, 91.12it/s, est. speed input: 155975.07 toks/s, output: 152.32 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:12<00:01, 92.26it/s, est. speed input: 155208.56 toks/s, output: 151.57 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:13<00:00, 91.73it/s, est. speed input: 154363.25 toks/s, output: 150.75 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:13<00:00, 91.37it/s, est. speed input: 153540.50 toks/s, output: 149.94 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:13<00:00, 91.17it/s, est. speed input: 152743.36 toks/s, output: 149.16 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:13<00:00, 91.11it/s, est. speed input: 151972.57 toks/s, output: 148.41 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:13<00:00, 92.59it/s, est. speed input: 151327.20 toks/s, output: 147.78 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:13<00:00, 92.59it/s, est. speed input: 152364.30 toks/s, output: 148.79 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:13<00:00, 148.79it/s, est. speed input: 152364.30 toks/s, output: 148.79 toks/s]
[rank0]:[W125 19:04:40.257408500 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-25 19:04:43
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:05:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:05:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=290584) WARNING 01-25 19:05:24 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=290584) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=290584) WARNING 01-25 19:05:32 [backends.py:609] Failed to read file <frozen os>
Throughput: 93.21 requests/s, 95544.80 total tokens/s, 93.21 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-25 19:05:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:05:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:05:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:05:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:05:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:05:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:05:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:05:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:05:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:05:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:05:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:05:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:05:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:05:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:05:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:05:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:05:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:05:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:05:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:05:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:05:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:05:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:05:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:05:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:05:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:05:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:05:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:05:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=290584) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=290584) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.35it/s]
(EngineCore_DP0 pid=290584) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.35it/s]
(EngineCore_DP0 pid=290584) 
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=290584) [2026-01-25 19:05:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=290584) [rank0]:W0125 19:05:36.202000 290584 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=290584) [rank0]:W0125 19:05:36.280000 290584 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=290584) [rank0]:W0125 19:05:37.381000 290584 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=290584) [rank0]:W0125 19:05:37.491000 290584 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=290584) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  8.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  8.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:00,  8.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  9.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  9.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  9.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  9.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:00<00:00,  9.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:00<00:00,  9.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  9.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  8.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  9.16it/s]
(EngineCore_DP0 pid=290584) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  7.52it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  8.66it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  9.54it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  9.62it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  9.59it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  8.73it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  8.99it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 27/4096 [00:00<00:15, 266.91it/s]
Adding requests:   1%|▏         | 58/4096 [00:00<00:14, 288.12it/s]
Adding requests:   2%|▏         | 88/4096 [00:00<00:13, 289.74it/s]
Adding requests:   3%|▎         | 118/4096 [00:00<00:13, 290.95it/s]
Adding requests:   4%|▎         | 148/4096 [00:00<00:13, 290.28it/s]
Adding requests:   4%|▍         | 178/4096 [00:00<00:13, 287.44it/s]
Adding requests:   5%|▌         | 208/4096 [00:00<00:13, 290.82it/s]
Adding requests:   6%|▌         | 239/4096 [00:00<00:13, 295.85it/s]
Adding requests:   7%|▋         | 270/4096 [00:00<00:12, 299.53it/s]
Adding requests:   7%|▋         | 300/4096 [00:01<00:12, 293.34it/s]
Adding requests:   8%|▊         | 330/4096 [00:01<00:12, 289.81it/s]
Adding requests:   9%|▉         | 362/4096 [00:01<00:12, 298.52it/s]
Adding requests:  10%|▉         | 394/4096 [00:01<00:12, 304.79it/s]
Adding requests:  10%|█         | 425/4096 [00:01<00:12, 305.15it/s]
Adding requests:  11%|█         | 457/4096 [00:01<00:11, 307.23it/s]
Adding requests:  12%|█▏        | 489/4096 [00:01<00:11, 308.14it/s]
Adding requests:  13%|█▎        | 520/4096 [00:01<00:11, 303.25it/s]
Adding requests:  13%|█▎        | 552/4096 [00:01<00:11, 306.08it/s]
Adding requests:  14%|█▍        | 585/4096 [00:01<00:11, 310.90it/s]
Adding requests:  15%|█▌        | 617/4096 [00:02<00:11, 308.68it/s]
Adding requests:  16%|█▌        | 650/4096 [00:02<00:11, 312.66it/s]
Adding requests:  17%|█▋        | 685/4096 [00:02<00:10, 323.17it/s]
Adding requests:  18%|█▊        | 718/4096 [00:02<00:10, 323.48it/s]
Adding requests:  18%|█▊        | 751/4096 [00:02<00:10, 320.65it/s]
Adding requests:  19%|█▉        | 784/4096 [00:02<00:10, 322.20it/s]
Adding requests:  20%|█▉        | 817/4096 [00:02<00:10, 315.37it/s]
Adding requests:  21%|██        | 849/4096 [00:02<00:10, 310.09it/s]
Adding requests:  22%|██▏       | 883/4096 [00:02<00:10, 316.38it/s]
Adding requests:  22%|██▏       | 916/4096 [00:02<00:09, 318.38it/s]
Adding requests:  23%|██▎       | 948/4096 [00:03<00:10, 311.74it/s]
Adding requests:  24%|██▍       | 980/4096 [00:03<00:10, 306.18it/s]
Adding requests:  25%|██▍       | 1011/4096 [00:03<00:10, 305.63it/s]
Adding requests:  25%|██▌       | 1042/4096 [00:03<00:10, 300.84it/s]
Adding requests:  26%|██▌       | 1073/4096 [00:03<00:10, 295.83it/s]
Adding requests:  27%|██▋       | 1104/4096 [00:03<00:09, 299.57it/s]
Adding requests:  28%|██▊       | 1134/4096 [00:03<00:10, 293.25it/s]
Adding requests:  28%|██▊       | 1164/4096 [00:03<00:10, 287.48it/s]
Adding requests:  29%|██▉       | 1196/4096 [00:03<00:09, 296.31it/s]
Adding requests:  30%|██▉       | 1227/4096 [00:04<00:09, 299.56it/s]
Adding requests:  31%|███       | 1258/4096 [00:04<00:09, 291.71it/s]
Adding requests:  31%|███▏      | 1288/4096 [00:04<00:09, 292.74it/s]
Adding requests:  32%|███▏      | 1319/4096 [00:04<00:09, 295.48it/s]
Adding requests:  33%|███▎      | 1349/4096 [00:04<00:09, 291.27it/s]
Adding requests:  34%|███▎      | 1379/4096 [00:04<00:09, 289.35it/s]
Adding requests:  34%|███▍      | 1411/4096 [00:04<00:09, 296.39it/s]
Adding requests:  35%|███▌      | 1441/4096 [00:04<00:09, 292.47it/s]
Adding requests:  36%|███▌      | 1471/4096 [00:04<00:08, 291.76it/s]
Adding requests:  37%|███▋      | 1502/4096 [00:04<00:08, 295.08it/s]
Adding requests:  37%|███▋      | 1532/4096 [00:05<00:08, 296.50it/s]
Adding requests:  38%|███▊      | 1562/4096 [00:05<00:08, 291.75it/s]
Adding requests:  39%|███▉      | 1593/4096 [00:05<00:08, 294.37it/s]
Adding requests:  40%|███▉      | 1623/4096 [00:05<00:08, 293.96it/s]
Adding requests:  40%|████      | 1653/4096 [00:05<00:08, 294.81it/s]
Adding requests:  41%|████      | 1683/4096 [00:05<00:08, 291.22it/s]
Adding requests:  42%|████▏     | 1714/4096 [00:05<00:08, 294.34it/s]
Adding requests:  43%|████▎     | 1744/4096 [00:05<00:07, 295.70it/s]
Adding requests:  43%|████▎     | 1774/4096 [00:05<00:07, 296.86it/s]
Adding requests:  44%|████▍     | 1805/4096 [00:06<00:07, 300.28it/s]
Adding requests:  45%|████▍     | 1836/4096 [00:06<00:07, 302.84it/s]
Adding requests:  46%|████▌     | 1867/4096 [00:06<00:07, 301.73it/s]
Adding requests:  46%|████▋     | 1899/4096 [00:06<00:07, 307.04it/s]
Adding requests:  47%|████▋     | 1930/4096 [00:06<00:07, 300.11it/s]
Adding requests:  48%|████▊     | 1962/4096 [00:06<00:07, 302.61it/s]
Adding requests:  49%|████▊     | 1993/4096 [00:06<00:07, 299.82it/s]
Adding requests:  49%|████▉     | 2025/4096 [00:06<00:06, 302.73it/s]
Adding requests:  50%|█████     | 2057/4096 [00:06<00:06, 304.88it/s]
Adding requests:  51%|█████     | 2088/4096 [00:06<00:06, 305.52it/s]
Adding requests:  52%|█████▏    | 2120/4096 [00:07<00:06, 306.06it/s]
Adding requests:  53%|█████▎    | 2151/4096 [00:07<00:06, 304.05it/s]
Adding requests:  53%|█████▎    | 2182/4096 [00:07<00:06, 302.38it/s]
Adding requests:  54%|█████▍    | 2213/4096 [00:07<00:06, 299.20it/s]
Adding requests:  55%|█████▍    | 2243/4096 [00:07<00:06, 294.48it/s]
Adding requests:  55%|█████▌    | 2273/4096 [00:07<00:06, 294.88it/s]
Adding requests:  56%|█████▌    | 2303/4096 [00:07<00:06, 291.13it/s]
Adding requests:  57%|█████▋    | 2333/4096 [00:07<00:06, 291.38it/s]
Adding requests:  58%|█████▊    | 2363/4096 [00:07<00:06, 281.97it/s]
Adding requests:  58%|█████▊    | 2392/4096 [00:07<00:05, 284.07it/s]
Adding requests:  59%|█████▉    | 2423/4096 [00:08<00:05, 289.51it/s]
Adding requests:  60%|█████▉    | 2453/4096 [00:08<00:05, 288.45it/s]
Adding requests:  61%|██████    | 2483/4096 [00:08<00:05, 291.28it/s]
Adding requests:  61%|██████▏   | 2514/4096 [00:08<00:05, 293.64it/s]
Adding requests:  62%|██████▏   | 2545/4096 [00:08<00:05, 297.31it/s]
Adding requests:  63%|██████▎   | 2578/4096 [00:08<00:04, 306.71it/s]
Adding requests:  64%|██████▎   | 2609/4096 [00:08<00:04, 306.59it/s]
Adding requests:  65%|██████▍   | 2644/4096 [00:08<00:04, 317.25it/s]
Adding requests:  65%|██████▌   | 2678/4096 [00:08<00:04, 323.05it/s]
Adding requests:  66%|██████▌   | 2711/4096 [00:09<00:04, 320.63it/s]
Adding requests:  67%|██████▋   | 2745/4096 [00:09<00:04, 325.69it/s]
Adding requests:  68%|██████▊   | 2779/4096 [00:09<00:04, 328.16it/s]
Adding requests:  69%|██████▊   | 2812/4096 [00:09<00:03, 326.65it/s]
Adding requests:  70%|██████▉   | 2847/4096 [00:09<00:03, 333.01it/s]
Adding requests:  70%|███████   | 2882/4096 [00:09<00:03, 336.53it/s]
Adding requests:  71%|███████   | 2916/4096 [00:09<00:03, 326.21it/s]
Adding requests:  72%|███████▏  | 2949/4096 [00:09<00:03, 322.18it/s]
Adding requests:  73%|███████▎  | 2984/4096 [00:09<00:03, 329.13it/s]
Adding requests:  74%|███████▎  | 3017/4096 [00:09<00:03, 328.62it/s]
Adding requests:  74%|███████▍  | 3051/4096 [00:10<00:03, 329.59it/s]
Adding requests:  75%|███████▌  | 3084/4096 [00:10<00:03, 325.58it/s]
Adding requests:  76%|███████▌  | 3118/4096 [00:10<00:02, 328.18it/s]
Adding requests:  77%|███████▋  | 3151/4096 [00:10<00:02, 325.69it/s]
Adding requests:  78%|███████▊  | 3186/4096 [00:10<00:02, 330.73it/s]
Adding requests:  79%|███████▊  | 3220/4096 [00:10<00:02, 321.15it/s]
Adding requests:  79%|███████▉  | 3253/4096 [00:10<00:02, 319.17it/s]
Adding requests:  80%|████████  | 3285/4096 [00:10<00:02, 313.29it/s]
Adding requests:  81%|████████  | 3317/4096 [00:10<00:02, 310.76it/s]
Adding requests:  82%|████████▏ | 3350/4096 [00:10<00:02, 313.83it/s]
Adding requests:  83%|████████▎ | 3382/4096 [00:11<00:02, 307.96it/s]
Adding requests:  83%|████████▎ | 3413/4096 [00:11<00:02, 306.40it/s]
Adding requests:  84%|████████▍ | 3444/4096 [00:11<00:02, 299.11it/s]
Adding requests:  85%|████████▍ | 3474/4096 [00:11<00:02, 292.16it/s]
Adding requests:  86%|████████▌ | 3504/4096 [00:11<00:02, 292.09it/s]
Adding requests:  86%|████████▋ | 3534/4096 [00:11<00:01, 286.71it/s]
Adding requests:  87%|████████▋ | 3564/4096 [00:11<00:01, 288.13it/s]
Adding requests:  88%|████████▊ | 3593/4096 [00:11<00:01, 287.18it/s]
Adding requests:  88%|████████▊ | 3622/4096 [00:11<00:01, 285.06it/s]
Adding requests:  89%|████████▉ | 3651/4096 [00:12<00:01, 278.47it/s]
Adding requests:  90%|████████▉ | 3682/4096 [00:12<00:01, 286.16it/s]
Adding requests:  91%|█████████ | 3714/4096 [00:12<00:01, 292.73it/s]
Adding requests:  91%|█████████▏| 3744/4096 [00:12<00:01, 289.93it/s]
Adding requests:  92%|█████████▏| 3776/4096 [00:12<00:01, 298.25it/s]
Adding requests:  93%|█████████▎| 3808/4096 [00:12<00:00, 303.04it/s]
Adding requests:  94%|█████████▎| 3839/4096 [00:12<00:00, 304.06it/s]
Adding requests:  94%|█████████▍| 3870/4096 [00:12<00:00, 301.90it/s]
Adding requests:  95%|█████████▌| 3901/4096 [00:12<00:00, 293.32it/s]
Adding requests:  96%|█████████▌| 3931/4096 [00:12<00:00, 293.36it/s]
Adding requests:  97%|█████████▋| 3962/4096 [00:13<00:00, 295.81it/s]
Adding requests:  97%|█████████▋| 3992/4096 [00:13<00:00, 296.58it/s]
Adding requests:  98%|█████████▊| 4025/4096 [00:13<00:00, 304.93it/s]
Adding requests:  99%|█████████▉| 4056/4096 [00:13<00:00, 298.66it/s]
Adding requests: 100%|█████████▉| 4087/4096 [00:13<00:00, 300.00it/s]
Adding requests: 100%|██████████| 4096/4096 [00:13<00:00, 302.93it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [00:00<00:00, 10655.06it/s, est. speed input: 10913576.63 toks/s, output: 10655.92 toks/s]
Processed prompts:  56%|█████▌    | 2284/4096 [00:09<00:09, 198.50it/s, est. speed input: 241116.80 toks/s, output: 235.47 toks/s]      
Processed prompts:  67%|██████▋   | 2730/4096 [00:14<00:08, 156.23it/s, est. speed input: 194329.85 toks/s, output: 189.78 toks/s]
Processed prompts:  73%|███████▎  | 2977/4096 [00:16<00:07, 142.94it/s, est. speed input: 180827.69 toks/s, output: 176.59 toks/s]
Processed prompts:  76%|███████▋  | 3131/4096 [00:18<00:07, 132.11it/s, est. speed input: 172134.85 toks/s, output: 168.10 toks/s]
Processed prompts:  79%|███████▉  | 3232/4096 [00:19<00:06, 127.86it/s, est. speed input: 168613.69 toks/s, output: 164.66 toks/s]
Processed prompts:  81%|████████  | 3303/4096 [00:20<00:06, 119.05it/s, est. speed input: 164134.99 toks/s, output: 160.29 toks/s]
Processed prompts:  82%|████████▏ | 3353/4096 [00:20<00:06, 121.45it/s, est. speed input: 164020.72 toks/s, output: 160.18 toks/s]
Processed prompts:  83%|████████▎ | 3392/4096 [00:21<00:05, 121.28it/s, est. speed input: 163382.45 toks/s, output: 159.55 toks/s]
Processed prompts:  84%|████████▎ | 3423/4096 [00:21<00:05, 118.24it/s, est. speed input: 162383.01 toks/s, output: 158.58 toks/s]
Processed prompts:  84%|████████▍ | 3447/4096 [00:21<00:05, 110.72it/s, est. speed input: 160904.90 toks/s, output: 157.13 toks/s]
Processed prompts:  85%|████████▍ | 3466/4096 [00:22<00:06, 100.56it/s, est. speed input: 159226.13 toks/s, output: 155.49 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [00:22<00:06, 93.94it/s, est. speed input: 157827.43 toks/s, output: 154.13 toks/s] 
Processed prompts:  86%|████████▌ | 3522/4096 [00:22<00:06, 93.16it/s, est. speed input: 156825.30 toks/s, output: 153.15 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [00:23<00:05, 92.51it/s, est. speed input: 155853.56 toks/s, output: 152.20 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [00:23<00:05, 91.97it/s, est. speed input: 154909.18 toks/s, output: 151.28 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [00:24<00:05, 91.54it/s, est. speed input: 153991.18 toks/s, output: 150.38 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [00:24<00:04, 91.26it/s, est. speed input: 153103.88 toks/s, output: 149.52 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [00:24<00:04, 90.95it/s, est. speed input: 152232.74 toks/s, output: 148.66 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [00:25<00:04, 91.46it/s, est. speed input: 151446.31 toks/s, output: 147.90 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [00:25<00:03, 91.17it/s, est. speed input: 150629.17 toks/s, output: 147.10 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [00:25<00:03, 90.98it/s, est. speed input: 149836.68 toks/s, output: 146.32 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [00:26<00:03, 90.83it/s, est. speed input: 149063.62 toks/s, output: 145.57 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [00:26<00:02, 90.71it/s, est. speed input: 148310.50 toks/s, output: 144.83 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [00:26<00:02, 91.10it/s, est. speed input: 147610.94 toks/s, output: 144.15 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [00:27<00:02, 93.15it/s, est. speed input: 147049.86 toks/s, output: 143.60 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [00:27<00:01, 94.42it/s, est. speed input: 146487.64 toks/s, output: 143.05 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [00:27<00:01, 95.47it/s, est. speed input: 145947.26 toks/s, output: 142.53 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [00:28<00:00, 96.23it/s, est. speed input: 145420.13 toks/s, output: 142.01 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [00:28<00:00, 97.48it/s, est. speed input: 144945.38 toks/s, output: 141.55 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [00:28<00:00, 98.78it/s, est. speed input: 144503.77 toks/s, output: 141.12 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:28<00:00, 98.78it/s, est. speed input: 145566.97 toks/s, output: 142.16 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [00:28<00:00, 142.15it/s, est. speed input: 145566.97 toks/s, output: 142.16 toks/s]
[rank0]:[W125 19:06:29.061111077 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-25 19:06:32
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-1B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 19:07:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 19:07:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=292693) WARNING 01-25 19:07:36 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=292693) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=292693) WARNING 01-25 19:07:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 40.56 requests/s, 41577.23 total tokens/s, 40.56 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-25 19:07:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:07:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:07:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:07:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:07:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:07:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:07:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:07:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:07:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:07:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:07:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:07:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:07:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:07:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 19:07:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 19:07:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-25 19:07:36] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-25 19:07:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:07:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:07:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:07:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:07:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-25 19:07:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-25 19:07:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 19:07:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 19:07:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 19:07:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 19:07:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:37] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=292693) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=292693) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.42it/s]
(EngineCore_DP0 pid=292693) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.42it/s]
(EngineCore_DP0 pid=292693) 
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 2752] -> 1D uint8
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6389760 bytes
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 2752] -> 1D uint8
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4259840 bytes
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 2752] -> 1D uint8
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34078720 bytes
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 10944] -> 1D uint8
(EngineCore_DP0 pid=292693) [2026-01-25 19:07:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16842752 bytes
(EngineCore_DP0 pid=292693) [rank0]:W0125 19:07:50.273000 292693 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=292693) [rank0]:W0125 19:07:50.352000 292693 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=292693) [rank0]:W0125 19:07:51.456000 292693 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=292693) [rank0]:W0125 19:07:51.570000 292693 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=292693) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:01,  9.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:01,  9.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:00<00:01, 10.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:00<00:01, 10.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:00<00:00, 10.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:01<00:00, 10.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:01<00:00, 10.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:01<00:00,  7.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:01<00:00,  7.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:02<00:00,  6.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:02<00:00,  6.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:02<00:00,  7.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:02<00:00,  8.25it/s]
(EngineCore_DP0 pid=292693) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  8.08it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:00,  9.66it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 10.01it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:00<00:00, 10.05it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:00<00:00, 10.13it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00, 10.13it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00, 10.00it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 26/8192 [00:00<00:32, 252.04it/s]
Adding requests:   1%|          | 55/8192 [00:00<00:29, 272.68it/s]
Adding requests:   1%|          | 85/8192 [00:00<00:28, 282.01it/s]
Adding requests:   1%|▏         | 115/8192 [00:00<00:28, 285.81it/s]
Adding requests:   2%|▏         | 145/8192 [00:00<00:27, 288.13it/s]
Adding requests:   2%|▏         | 175/8192 [00:00<00:27, 289.64it/s]
Adding requests:   2%|▏         | 204/8192 [00:00<00:28, 283.08it/s]
Adding requests:   3%|▎         | 233/8192 [00:00<00:27, 284.47it/s]
Adding requests:   3%|▎         | 262/8192 [00:00<00:28, 274.10it/s]
Adding requests:   4%|▎         | 291/8192 [00:01<00:28, 278.39it/s]
Adding requests:   4%|▍         | 319/8192 [00:01<00:28, 276.96it/s]
Adding requests:   4%|▍         | 348/8192 [00:01<00:28, 277.95it/s]
Adding requests:   5%|▍         | 379/8192 [00:01<00:27, 285.94it/s]
Adding requests:   5%|▍         | 408/8192 [00:01<00:27, 286.71it/s]
Adding requests:   5%|▌         | 437/8192 [00:01<00:26, 287.54it/s]
Adding requests:   6%|▌         | 468/8192 [00:01<00:26, 291.50it/s]
Adding requests:   6%|▌         | 498/8192 [00:01<00:26, 286.87it/s]
Adding requests:   6%|▋         | 527/8192 [00:01<00:27, 278.24it/s]
Adding requests:   7%|▋         | 558/8192 [00:01<00:26, 284.95it/s]
Adding requests:   7%|▋         | 588/8192 [00:02<00:26, 288.82it/s]
Adding requests:   8%|▊         | 617/8192 [00:02<00:26, 285.72it/s]
Adding requests:   8%|▊         | 648/8192 [00:02<00:25, 290.46it/s]
Adding requests:   8%|▊         | 679/8192 [00:02<00:25, 295.63it/s]
Adding requests:   9%|▊         | 709/8192 [00:02<00:25, 291.29it/s]
Adding requests:   9%|▉         | 739/8192 [00:02<00:25, 289.96it/s]
Adding requests:   9%|▉         | 769/8192 [00:02<00:25, 291.13it/s]
Adding requests:  10%|▉         | 799/8192 [00:02<00:25, 288.12it/s]
Adding requests:  10%|█         | 828/8192 [00:02<00:26, 282.98it/s]
Adding requests:  10%|█         | 857/8192 [00:03<00:25, 284.01it/s]
Adding requests:  11%|█         | 888/8192 [00:03<00:25, 288.71it/s]
Adding requests:  11%|█         | 918/8192 [00:03<00:24, 291.41it/s]
Adding requests:  12%|█▏        | 948/8192 [00:03<00:24, 292.71it/s]
Adding requests:  12%|█▏        | 978/8192 [00:03<00:24, 294.21it/s]
Adding requests:  12%|█▏        | 1010/8192 [00:03<00:23, 301.27it/s]
Adding requests:  13%|█▎        | 1042/8192 [00:03<00:23, 305.59it/s]
Adding requests:  13%|█▎        | 1073/8192 [00:03<00:23, 305.40it/s]
Adding requests:  13%|█▎        | 1105/8192 [00:03<00:23, 307.24it/s]
Adding requests:  14%|█▍        | 1136/8192 [00:03<00:23, 302.33it/s]
Adding requests:  14%|█▍        | 1168/8192 [00:04<00:22, 307.30it/s]
Adding requests:  15%|█▍        | 1199/8192 [00:04<00:22, 304.58it/s]
Adding requests:  15%|█▌        | 1231/8192 [00:04<00:22, 309.00it/s]
Adding requests:  15%|█▌        | 1262/8192 [00:04<00:22, 307.07it/s]
Adding requests:  16%|█▌        | 1294/8192 [00:04<00:22, 308.24it/s]
Adding requests:  16%|█▌        | 1326/8192 [00:04<00:22, 310.87it/s]
Adding requests:  17%|█▋        | 1358/8192 [00:04<00:21, 313.14it/s]
Adding requests:  17%|█▋        | 1390/8192 [00:04<00:21, 312.85it/s]
Adding requests:  17%|█▋        | 1422/8192 [00:04<00:22, 305.56it/s]
Adding requests:  18%|█▊        | 1454/8192 [00:04<00:21, 309.42it/s]
Adding requests:  18%|█▊        | 1485/8192 [00:05<00:22, 304.73it/s]
Adding requests:  19%|█▊        | 1517/8192 [00:05<00:21, 307.54it/s]
Adding requests:  19%|█▉        | 1548/8192 [00:05<00:22, 301.57it/s]
Adding requests:  19%|█▉        | 1579/8192 [00:05<00:22, 297.16it/s]
Adding requests:  20%|█▉        | 1609/8192 [00:05<00:22, 297.00it/s]
Adding requests:  20%|██        | 1639/8192 [00:05<00:22, 292.52it/s]
Adding requests:  20%|██        | 1669/8192 [00:05<00:23, 282.58it/s]
Adding requests:  21%|██        | 1699/8192 [00:05<00:22, 284.63it/s]
Adding requests:  21%|██        | 1728/8192 [00:05<00:22, 284.02it/s]
Adding requests:  21%|██▏       | 1757/8192 [00:06<00:23, 278.55it/s]
Adding requests:  22%|██▏       | 1785/8192 [00:06<00:23, 276.95it/s]
Adding requests:  22%|██▏       | 1813/8192 [00:06<00:22, 277.69it/s]
Adding requests:  22%|██▏       | 1842/8192 [00:06<00:22, 278.26it/s]
Adding requests:  23%|██▎       | 1870/8192 [00:06<00:24, 262.76it/s]
Adding requests:  23%|██▎       | 1900/8192 [00:06<00:23, 273.26it/s]
Adding requests:  24%|██▎       | 1930/8192 [00:06<00:22, 280.50it/s]
Adding requests:  30%|██▉       | 2444/8192 [00:06<00:03, 1677.12it/s]
Adding requests:  32%|███▏      | 2613/8192 [00:07<00:08, 663.48it/s] 
Adding requests:  33%|███▎      | 2740/8192 [00:07<00:10, 498.59it/s]
Adding requests:  35%|███▍      | 2837/8192 [00:08<00:12, 428.95it/s]
Adding requests:  36%|███▌      | 2914/8192 [00:08<00:13, 397.59it/s]
Adding requests:  36%|███▋      | 2977/8192 [00:08<00:13, 374.95it/s]
Adding requests:  37%|███▋      | 3030/8192 [00:08<00:14, 356.68it/s]
Adding requests:  38%|███▊      | 3076/8192 [00:08<00:14, 341.23it/s]
Adding requests:  38%|███▊      | 3117/8192 [00:09<00:15, 330.11it/s]
Adding requests:  39%|███▊      | 3155/8192 [00:09<00:15, 320.01it/s]
Adding requests:  39%|███▉      | 3190/8192 [00:09<00:16, 300.50it/s]
Adding requests:  39%|███▉      | 3222/8192 [00:09<00:16, 294.78it/s]
Adding requests:  40%|███▉      | 3254/8192 [00:09<00:16, 299.37it/s]
Adding requests:  40%|████      | 3287/8192 [00:09<00:16, 306.42it/s]
Adding requests:  41%|████      | 3320/8192 [00:09<00:15, 311.02it/s]
Adding requests:  41%|████      | 3354/8192 [00:09<00:15, 317.79it/s]
Adding requests:  41%|████▏     | 3387/8192 [00:10<00:15, 312.55it/s]
Adding requests:  42%|████▏     | 3419/8192 [00:10<00:15, 308.56it/s]
Adding requests:  42%|████▏     | 3451/8192 [00:10<00:15, 302.75it/s]
Adding requests:  43%|████▎     | 3482/8192 [00:10<00:15, 299.12it/s]
Adding requests:  43%|████▎     | 3513/8192 [00:10<00:15, 299.99it/s]
Adding requests:  43%|████▎     | 3544/8192 [00:10<00:15, 299.49it/s]
Adding requests:  44%|████▎     | 3575/8192 [00:10<00:15, 302.16it/s]
Adding requests:  44%|████▍     | 3606/8192 [00:10<00:15, 303.64it/s]
Adding requests:  44%|████▍     | 3637/8192 [00:10<00:15, 301.51it/s]
Adding requests:  45%|████▍     | 3668/8192 [00:10<00:14, 302.02it/s]
Adding requests:  45%|████▌     | 3699/8192 [00:11<00:14, 302.88it/s]
Adding requests:  46%|████▌     | 3730/8192 [00:11<00:15, 297.39it/s]
Adding requests:  46%|████▌     | 3762/8192 [00:11<00:14, 302.23it/s]
Adding requests:  46%|████▋     | 3795/8192 [00:11<00:14, 308.68it/s]
Adding requests:  47%|████▋     | 3826/8192 [00:11<00:14, 303.13it/s]
Adding requests:  47%|████▋     | 3857/8192 [00:11<00:14, 302.85it/s]
Adding requests:  47%|████▋     | 3889/8192 [00:11<00:13, 307.84it/s]
Adding requests:  48%|████▊     | 3923/8192 [00:11<00:13, 314.90it/s]
Adding requests:  48%|████▊     | 3955/8192 [00:11<00:13, 315.84it/s]
Adding requests:  49%|████▊     | 3987/8192 [00:11<00:13, 313.90it/s]
Adding requests:  49%|████▉     | 4021/8192 [00:12<00:12, 320.86it/s]
Adding requests:  49%|████▉     | 4054/8192 [00:12<00:12, 319.54it/s]
Adding requests:  50%|████▉     | 4086/8192 [00:12<00:12, 318.90it/s]
Adding requests:  50%|█████     | 4119/8192 [00:12<00:12, 321.94it/s]
Adding requests:  51%|█████     | 4152/8192 [00:12<00:12, 315.33it/s]
Adding requests:  51%|█████     | 4186/8192 [00:12<00:12, 320.44it/s]
Adding requests:  52%|█████▏    | 4219/8192 [00:12<00:12, 318.16it/s]
Adding requests:  52%|█████▏    | 4253/8192 [00:12<00:12, 322.14it/s]
Adding requests:  52%|█████▏    | 4286/8192 [00:12<00:12, 322.32it/s]
Adding requests:  53%|█████▎    | 4319/8192 [00:13<00:12, 317.50it/s]
Adding requests:  53%|█████▎    | 4351/8192 [00:13<00:12, 315.36it/s]
Adding requests:  54%|█████▎    | 4383/8192 [00:13<00:12, 315.24it/s]
Adding requests:  54%|█████▍    | 4415/8192 [00:13<00:12, 302.36it/s]
Adding requests:  54%|█████▍    | 4446/8192 [00:13<00:12, 292.79it/s]
Adding requests:  55%|█████▍    | 4476/8192 [00:13<00:13, 283.22it/s]
Adding requests:  55%|█████▍    | 4505/8192 [00:13<00:13, 279.43it/s]
Adding requests:  55%|█████▌    | 4534/8192 [00:13<00:13, 262.56it/s]
Adding requests:  56%|█████▌    | 4563/8192 [00:13<00:13, 269.59it/s]
Adding requests:  56%|█████▌    | 4592/8192 [00:14<00:13, 274.84it/s]
Adding requests:  56%|█████▋    | 4621/8192 [00:14<00:12, 277.56it/s]
Adding requests:  57%|█████▋    | 4649/8192 [00:14<00:12, 276.99it/s]
Adding requests:  57%|█████▋    | 4677/8192 [00:14<00:12, 277.57it/s]
Adding requests:  57%|█████▋    | 4708/8192 [00:14<00:12, 284.29it/s]
Adding requests:  58%|█████▊    | 4739/8192 [00:14<00:11, 290.12it/s]
Adding requests:  58%|█████▊    | 4769/8192 [00:14<00:11, 292.45it/s]
Adding requests:  59%|█████▊    | 4799/8192 [00:14<00:11, 293.12it/s]
Adding requests:  59%|█████▉    | 4829/8192 [00:14<00:11, 291.03it/s]
Adding requests:  59%|█████▉    | 4859/8192 [00:14<00:11, 292.02it/s]
Adding requests:  60%|█████▉    | 4889/8192 [00:15<00:11, 289.35it/s]
Adding requests:  60%|██████    | 4918/8192 [00:15<00:11, 288.31it/s]
Adding requests:  60%|██████    | 4948/8192 [00:15<00:11, 291.74it/s]
Adding requests:  61%|██████    | 4979/8192 [00:15<00:10, 294.81it/s]
Adding requests:  61%|██████    | 5009/8192 [00:15<00:10, 295.99it/s]
Adding requests:  62%|██████▏   | 5040/8192 [00:15<00:10, 297.80it/s]
Adding requests:  62%|██████▏   | 5070/8192 [00:15<00:10, 292.73it/s]
Adding requests:  62%|██████▏   | 5100/8192 [00:15<00:10, 291.89it/s]
Adding requests:  63%|██████▎   | 5130/8192 [00:15<00:10, 293.63it/s]
Adding requests:  63%|██████▎   | 5160/8192 [00:15<00:10, 290.73it/s]
Adding requests:  63%|██████▎   | 5191/8192 [00:16<00:10, 293.53it/s]
Adding requests:  64%|██████▎   | 5221/8192 [00:16<00:10, 292.52it/s]
Adding requests:  64%|██████▍   | 5251/8192 [00:16<00:10, 282.87it/s]
Adding requests:  64%|██████▍   | 5280/8192 [00:16<00:10, 283.61it/s]
Adding requests:  65%|██████▍   | 5311/8192 [00:16<00:09, 289.41it/s]
Adding requests:  65%|██████▌   | 5340/8192 [00:16<00:09, 286.20it/s]
Adding requests:  66%|██████▌   | 5369/8192 [00:16<00:09, 282.86it/s]
Adding requests:  66%|██████▌   | 5398/8192 [00:16<00:09, 281.89it/s]
Adding requests:  66%|██████▌   | 5427/8192 [00:16<00:09, 282.12it/s]
Adding requests:  67%|██████▋   | 5456/8192 [00:17<00:09, 279.29it/s]
Adding requests:  67%|██████▋   | 5484/8192 [00:17<00:09, 279.33it/s]
Adding requests:  67%|██████▋   | 5512/8192 [00:17<00:09, 278.87it/s]
Adding requests:  68%|██████▊   | 5540/8192 [00:17<00:09, 279.14it/s]
Adding requests:  68%|██████▊   | 5568/8192 [00:17<00:09, 275.66it/s]
Adding requests:  68%|██████▊   | 5596/8192 [00:17<00:09, 275.44it/s]
Adding requests:  69%|██████▊   | 5624/8192 [00:17<00:09, 269.67it/s]
Adding requests:  69%|██████▉   | 5651/8192 [00:17<00:09, 267.71it/s]
Adding requests:  69%|██████▉   | 5680/8192 [00:17<00:09, 274.02it/s]
Adding requests:  70%|██████▉   | 5711/8192 [00:17<00:08, 282.73it/s]
Adding requests:  70%|███████   | 5742/8192 [00:18<00:08, 288.64it/s]
Adding requests:  70%|███████   | 5772/8192 [00:18<00:08, 291.51it/s]
Adding requests:  71%|███████   | 5802/8192 [00:18<00:08, 292.15it/s]
Adding requests:  71%|███████   | 5832/8192 [00:18<00:08, 288.56it/s]
Adding requests:  72%|███████▏  | 5862/8192 [00:18<00:07, 291.76it/s]
Adding requests:  72%|███████▏  | 5892/8192 [00:18<00:08, 279.37it/s]
Adding requests:  72%|███████▏  | 5921/8192 [00:18<00:08, 281.02it/s]
Adding requests:  73%|███████▎  | 5950/8192 [00:18<00:07, 283.05it/s]
Adding requests:  73%|███████▎  | 5979/8192 [00:18<00:07, 283.85it/s]
Adding requests:  73%|███████▎  | 6009/8192 [00:18<00:07, 288.35it/s]
Adding requests:  74%|███████▎  | 6040/8192 [00:19<00:07, 292.93it/s]
Adding requests:  74%|███████▍  | 6070/8192 [00:19<00:07, 290.58it/s]
Adding requests:  74%|███████▍  | 6100/8192 [00:19<00:07, 290.93it/s]
Adding requests:  75%|███████▍  | 6131/8192 [00:19<00:07, 294.40it/s]
Adding requests:  75%|███████▌  | 6161/8192 [00:19<00:06, 290.36it/s]
Adding requests:  76%|███████▌  | 6191/8192 [00:19<00:06, 289.54it/s]
Adding requests:  76%|███████▌  | 6220/8192 [00:19<00:06, 288.92it/s]
Adding requests:  76%|███████▋  | 6249/8192 [00:19<00:06, 286.23it/s]
Adding requests:  77%|███████▋  | 6281/8192 [00:19<00:06, 295.06it/s]
Adding requests:  77%|███████▋  | 6311/8192 [00:20<00:06, 294.75it/s]
Adding requests:  77%|███████▋  | 6342/8192 [00:20<00:06, 296.85it/s]
Adding requests:  78%|███████▊  | 6374/8192 [00:20<00:06, 302.83it/s]
Adding requests:  78%|███████▊  | 6406/8192 [00:20<00:05, 306.60it/s]
Adding requests:  79%|███████▊  | 6438/8192 [00:20<00:05, 308.30it/s]
Adding requests:  79%|███████▉  | 6469/8192 [00:20<00:05, 306.40it/s]
Adding requests:  79%|███████▉  | 6501/8192 [00:20<00:05, 307.77it/s]
Adding requests:  80%|███████▉  | 6533/8192 [00:20<00:05, 311.23it/s]
Adding requests:  80%|████████  | 6565/8192 [00:20<00:05, 313.00it/s]
Adding requests:  81%|████████  | 6597/8192 [00:20<00:05, 314.16it/s]
Adding requests:  81%|████████  | 6629/8192 [00:21<00:04, 314.82it/s]
Adding requests:  81%|████████▏ | 6661/8192 [00:21<00:04, 314.63it/s]
Adding requests:  82%|████████▏ | 6693/8192 [00:21<00:04, 309.73it/s]
Adding requests:  82%|████████▏ | 6725/8192 [00:21<00:04, 310.82it/s]
Adding requests:  82%|████████▏ | 6757/8192 [00:21<00:04, 304.81it/s]
Adding requests:  83%|████████▎ | 6788/8192 [00:21<00:04, 299.38it/s]
Adding requests:  83%|████████▎ | 6819/8192 [00:21<00:04, 299.95it/s]
Adding requests:  84%|████████▎ | 6850/8192 [00:21<00:04, 302.45it/s]
Adding requests:  84%|████████▍ | 6881/8192 [00:21<00:04, 293.92it/s]
Adding requests:  84%|████████▍ | 6911/8192 [00:21<00:04, 295.22it/s]
Adding requests:  85%|████████▍ | 6942/8192 [00:22<00:04, 297.87it/s]
Adding requests:  85%|████████▌ | 6972/8192 [00:22<00:04, 296.21it/s]
Adding requests:  85%|████████▌ | 7002/8192 [00:22<00:04, 290.30it/s]
Adding requests:  86%|████████▌ | 7032/8192 [00:22<00:04, 288.45it/s]
Adding requests:  86%|████████▌ | 7062/8192 [00:22<00:03, 291.55it/s]
Adding requests:  87%|████████▋ | 7092/8192 [00:22<00:03, 291.58it/s]
Adding requests:  87%|████████▋ | 7122/8192 [00:22<00:03, 289.95it/s]
Adding requests:  87%|████████▋ | 7152/8192 [00:22<00:03, 289.77it/s]
Adding requests:  88%|████████▊ | 7181/8192 [00:22<00:03, 284.54it/s]
Adding requests:  88%|████████▊ | 7210/8192 [00:23<00:03, 283.84it/s]
Adding requests:  88%|████████▊ | 7239/8192 [00:23<00:03, 268.46it/s]
Adding requests:  89%|████████▊ | 7269/8192 [00:23<00:03, 276.31it/s]
Adding requests:  89%|████████▉ | 7298/8192 [00:23<00:03, 278.35it/s]
Adding requests:  89%|████████▉ | 7328/8192 [00:23<00:03, 282.29it/s]
Adding requests:  90%|████████▉ | 7357/8192 [00:23<00:02, 278.57it/s]
Adding requests:  90%|█████████ | 7387/8192 [00:23<00:02, 283.18it/s]
Adding requests:  91%|█████████ | 7417/8192 [00:23<00:02, 287.23it/s]
Adding requests:  91%|█████████ | 7446/8192 [00:23<00:02, 276.23it/s]
Adding requests:  91%|█████████ | 7474/8192 [00:23<00:02, 270.92it/s]
Adding requests:  92%|█████████▏| 7505/8192 [00:24<00:02, 280.33it/s]
Adding requests:  92%|█████████▏| 7535/8192 [00:24<00:02, 284.32it/s]
Adding requests:  92%|█████████▏| 7566/8192 [00:24<00:02, 291.48it/s]
Adding requests:  93%|█████████▎| 7596/8192 [00:24<00:02, 292.29it/s]
Adding requests:  93%|█████████▎| 7627/8192 [00:24<00:01, 294.40it/s]
Adding requests:  93%|█████████▎| 7659/8192 [00:24<00:01, 301.56it/s]
Adding requests:  94%|█████████▍| 7690/8192 [00:24<00:01, 301.00it/s]
Adding requests:  94%|█████████▍| 7721/8192 [00:24<00:01, 299.23it/s]
Adding requests:  95%|█████████▍| 7752/8192 [00:24<00:01, 300.04it/s]
Adding requests:  95%|█████████▌| 7783/8192 [00:24<00:01, 296.25it/s]
Adding requests:  95%|█████████▌| 7813/8192 [00:25<00:01, 292.48it/s]
Adding requests:  96%|█████████▌| 7844/8192 [00:25<00:01, 295.35it/s]
Adding requests:  96%|█████████▌| 7874/8192 [00:25<00:01, 295.76it/s]
Adding requests:  96%|█████████▋| 7905/8192 [00:25<00:00, 297.98it/s]
Adding requests:  97%|█████████▋| 7935/8192 [00:25<00:00, 298.07it/s]
Adding requests:  97%|█████████▋| 7966/8192 [00:25<00:00, 298.89it/s]
Adding requests:  98%|█████████▊| 7997/8192 [00:25<00:00, 299.20it/s]
Adding requests:  98%|█████████▊| 8027/8192 [00:25<00:00, 294.16it/s]
Adding requests:  98%|█████████▊| 8057/8192 [00:25<00:00, 290.12it/s]
Adding requests:  99%|█████████▊| 8087/8192 [00:26<00:00, 280.71it/s]
Adding requests:  99%|█████████▉| 8116/8192 [00:26<00:00, 281.72it/s]
Adding requests:  99%|█████████▉| 8145/8192 [00:26<00:00, 274.94it/s]
Adding requests: 100%|█████████▉| 8174/8192 [00:26<00:00, 278.80it/s]
Adding requests: 100%|██████████| 8192/8192 [00:26<00:00, 310.14it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 1127/8192 [00:01<00:07, 930.63it/s, est. speed input: 952989.32 toks/s, output: 930.64 toks/s]
Processed prompts:  15%|█▍        | 1221/8192 [00:02<00:18, 373.03it/s, est. speed input: 457959.89 toks/s, output: 447.23 toks/s]
Processed prompts:  15%|█▌        | 1263/8192 [00:04<00:34, 200.24it/s, est. speed input: 295984.40 toks/s, output: 289.05 toks/s]
Processed prompts:  16%|█▌        | 1319/8192 [00:06<00:52, 131.15it/s, est. speed input: 224658.35 toks/s, output: 219.39 toks/s]
Processed prompts:  17%|█▋        | 1383/8192 [00:07<01:10, 96.72it/s, est. speed input: 184933.63 toks/s, output: 180.60 toks/s] 
Processed prompts:  18%|█▊        | 1447/8192 [00:09<01:25, 78.64it/s, est. speed input: 161380.23 toks/s, output: 157.60 toks/s]
Processed prompts:  18%|█▊        | 1511/8192 [00:10<01:39, 66.94it/s, est. speed input: 144578.94 toks/s, output: 141.19 toks/s]
Processed prompts:  20%|██        | 1639/8192 [00:12<01:32, 70.85it/s, est. speed input: 136170.59 toks/s, output: 132.98 toks/s]
Processed prompts:  21%|██        | 1703/8192 [00:13<01:47, 60.56it/s, est. speed input: 124825.72 toks/s, output: 121.90 toks/s]
Processed prompts:  22%|██▏       | 1767/8192 [00:15<01:58, 54.19it/s, est. speed input: 116199.74 toks/s, output: 113.48 toks/s]
Processed prompts:  22%|██▏       | 1831/8192 [00:16<02:03, 51.60it/s, est. speed input: 110333.67 toks/s, output: 107.75 toks/s]
Processed prompts:  23%|██▎       | 1895/8192 [00:18<02:09, 48.73it/s, est. speed input: 104804.61 toks/s, output: 102.35 toks/s]
Processed prompts:  24%|██▍       | 1959/8192 [00:20<02:12, 46.91it/s, est. speed input: 100217.47 toks/s, output: 97.87 toks/s] 
Processed prompts:  25%|██▍       | 2023/8192 [00:21<02:19, 44.29it/s, est. speed input: 95594.67 toks/s, output: 93.35 toks/s] 
Processed prompts:  25%|██▌       | 2087/8192 [00:23<02:23, 42.58it/s, est. speed input: 91643.32 toks/s, output: 89.50 toks/s]
Processed prompts:  26%|██▋       | 2151/8192 [00:24<02:25, 41.42it/s, est. speed input: 88216.86 toks/s, output: 86.15 toks/s]
Processed prompts:  27%|██▋       | 2215/8192 [00:26<02:19, 42.90it/s, est. speed input: 86140.87 toks/s, output: 84.12 toks/s]
Processed prompts:  28%|██▊       | 2279/8192 [00:27<02:14, 43.92it/s, est. speed input: 84234.71 toks/s, output: 82.26 toks/s]
Processed prompts:  29%|██▊       | 2343/8192 [00:29<02:18, 42.27it/s, est. speed input: 81735.05 toks/s, output: 79.82 toks/s]
Processed prompts:  29%|██▉       | 2407/8192 [00:31<02:20, 41.18it/s, est. speed input: 79502.03 toks/s, output: 77.64 toks/s]
Processed prompts:  30%|███       | 2471/8192 [00:32<02:17, 41.51it/s, est. speed input: 77819.26 toks/s, output: 76.00 toks/s]
Processed prompts:  31%|███       | 2535/8192 [00:34<02:15, 41.65it/s, est. speed input: 76259.87 toks/s, output: 74.47 toks/s]
Processed prompts:  32%|███▏      | 2599/8192 [00:35<02:15, 41.42it/s, est. speed input: 74748.73 toks/s, output: 73.00 toks/s]
Processed prompts:  33%|███▎      | 2663/8192 [00:37<02:16, 40.63it/s, est. speed input: 73204.71 toks/s, output: 71.49 toks/s]
Processed prompts:  33%|███▎      | 2727/8192 [00:38<02:16, 40.08it/s, est. speed input: 71789.79 toks/s, output: 70.11 toks/s]
Processed prompts:  34%|███▍      | 2791/8192 [00:40<02:14, 40.17it/s, est. speed input: 70598.26 toks/s, output: 68.94 toks/s]
Processed prompts:  36%|███▌      | 2919/8192 [00:41<01:36, 54.92it/s, est. speed input: 71484.70 toks/s, output: 69.81 toks/s]
Processed prompts:  36%|███▋      | 2983/8192 [00:43<01:42, 50.82it/s, est. speed input: 70449.09 toks/s, output: 68.80 toks/s]
Processed prompts:  37%|███▋      | 3047/8192 [00:44<01:49, 47.09it/s, est. speed input: 69337.08 toks/s, output: 67.71 toks/s]
Processed prompts:  38%|███▊      | 3111/8192 [00:46<01:51, 45.42it/s, est. speed input: 68445.94 toks/s, output: 66.84 toks/s]
Processed prompts:  39%|███▉      | 3175/8192 [00:48<01:55, 43.30it/s, est. speed input: 67455.38 toks/s, output: 65.87 toks/s]
Processed prompts:  40%|███▉      | 3239/8192 [00:49<01:55, 42.79it/s, est. speed input: 66684.63 toks/s, output: 65.12 toks/s]
Processed prompts:  40%|████      | 3303/8192 [00:51<01:55, 42.40it/s, est. speed input: 65956.10 toks/s, output: 64.41 toks/s]
Processed prompts:  41%|████      | 3367/8192 [00:52<01:57, 41.23it/s, est. speed input: 65130.19 toks/s, output: 63.60 toks/s]
Processed prompts:  42%|████▏     | 3431/8192 [00:54<01:57, 40.44it/s, est. speed input: 64356.10 toks/s, output: 62.85 toks/s]
Processed prompts:  43%|████▎     | 3495/8192 [00:56<01:57, 39.92it/s, est. speed input: 63631.79 toks/s, output: 62.14 toks/s]
Processed prompts:  43%|████▎     | 3559/8192 [00:57<01:54, 40.46it/s, est. speed input: 63079.19 toks/s, output: 61.60 toks/s]
Processed prompts:  44%|████▍     | 3623/8192 [00:59<01:51, 40.81it/s, est. speed input: 62549.97 toks/s, output: 61.08 toks/s]
Processed prompts:  45%|████▌     | 3687/8192 [01:00<01:49, 41.04it/s, est. speed input: 62045.95 toks/s, output: 60.59 toks/s]
Processed prompts:  46%|████▌     | 3751/8192 [01:02<01:50, 40.33it/s, est. speed input: 61455.03 toks/s, output: 60.01 toks/s]
Processed prompts:  47%|████▋     | 3815/8192 [01:04<01:49, 39.92it/s, est. speed input: 60903.46 toks/s, output: 59.48 toks/s]
Processed prompts:  47%|████▋     | 3879/8192 [01:05<01:46, 40.42it/s, est. speed input: 60477.06 toks/s, output: 59.06 toks/s]
Processed prompts:  48%|████▊     | 3943/8192 [01:07<01:44, 40.73it/s, est. speed input: 60063.11 toks/s, output: 58.66 toks/s]
Processed prompts:  49%|████▉     | 4007/8192 [01:08<01:42, 41.02it/s, est. speed input: 59676.24 toks/s, output: 58.28 toks/s]
Processed prompts:  50%|████▉     | 4071/8192 [01:10<01:42, 40.33it/s, est. speed input: 59208.64 toks/s, output: 57.82 toks/s]
Processed prompts:  50%|█████     | 4135/8192 [01:12<01:41, 39.83it/s, est. speed input: 58759.78 toks/s, output: 57.38 toks/s]
Processed prompts:  52%|█████▏    | 4263/8192 [01:13<01:10, 55.61it/s, est. speed input: 59555.84 toks/s, output: 58.16 toks/s]
Processed prompts:  53%|█████▎    | 4327/8192 [01:14<01:13, 52.53it/s, est. speed input: 59298.88 toks/s, output: 57.91 toks/s]
Processed prompts:  54%|█████▎    | 4391/8192 [01:16<01:18, 48.42it/s, est. speed input: 58903.52 toks/s, output: 57.52 toks/s]
Processed prompts:  54%|█████▍    | 4455/8192 [01:17<01:22, 45.34it/s, est. speed input: 58496.54 toks/s, output: 57.13 toks/s]
Processed prompts:  55%|█████▌    | 4519/8192 [01:19<01:24, 43.31it/s, est. speed input: 58108.37 toks/s, output: 56.75 toks/s]
Processed prompts:  56%|█████▌    | 4583/8192 [01:21<01:25, 42.30it/s, est. speed input: 57770.19 toks/s, output: 56.42 toks/s]
Processed prompts:  57%|█████▋    | 4647/8192 [01:22<01:24, 42.17it/s, est. speed input: 57494.34 toks/s, output: 56.15 toks/s]
Processed prompts:  58%|█████▊    | 4711/8192 [01:24<01:24, 41.34it/s, est. speed input: 57165.99 toks/s, output: 55.83 toks/s]
Processed prompts:  58%|█████▊    | 4775/8192 [01:25<01:22, 41.37it/s, est. speed input: 56901.39 toks/s, output: 55.57 toks/s]
Processed prompts:  59%|█████▉    | 4839/8192 [01:27<01:21, 41.38it/s, est. speed input: 56645.52 toks/s, output: 55.32 toks/s]
Processed prompts:  60%|█████▉    | 4903/8192 [01:29<01:20, 40.91it/s, est. speed input: 56359.79 toks/s, output: 55.04 toks/s]
Processed prompts:  61%|██████    | 4967/8192 [01:30<01:16, 42.01it/s, est. speed input: 56195.02 toks/s, output: 54.88 toks/s]
Processed prompts:  61%|██████▏   | 5031/8192 [01:32<01:16, 41.46it/s, est. speed input: 55935.69 toks/s, output: 54.62 toks/s]
Processed prompts:  62%|██████▏   | 5095/8192 [01:33<01:16, 40.61it/s, est. speed input: 55649.73 toks/s, output: 54.35 toks/s]
Processed prompts:  63%|██████▎   | 5159/8192 [01:35<01:15, 40.09it/s, est. speed input: 55377.65 toks/s, output: 54.08 toks/s]
Processed prompts:  64%|██████▍   | 5223/8192 [01:36<01:14, 40.11it/s, est. speed input: 55142.81 toks/s, output: 53.85 toks/s]
Processed prompts:  65%|██████▍   | 5287/8192 [01:38<01:11, 40.65it/s, est. speed input: 54954.93 toks/s, output: 53.67 toks/s]
Processed prompts:  65%|██████▌   | 5351/8192 [01:40<01:10, 40.49it/s, est. speed input: 54733.99 toks/s, output: 53.45 toks/s]
Processed prompts:  66%|██████▌   | 5415/8192 [01:41<01:09, 40.01it/s, est. speed input: 54493.39 toks/s, output: 53.22 toks/s]
Processed prompts:  67%|██████▋   | 5479/8192 [01:43<01:08, 39.62it/s, est. speed input: 54256.63 toks/s, output: 52.98 toks/s]
Processed prompts:  68%|██████▊   | 5607/8192 [01:45<00:49, 51.71it/s, est. speed input: 54681.19 toks/s, output: 53.40 toks/s]
Processed prompts:  69%|██████▉   | 5671/8192 [01:46<00:51, 48.92it/s, est. speed input: 54514.84 toks/s, output: 53.24 toks/s]
Processed prompts:  70%|███████   | 5735/8192 [01:48<00:53, 46.30it/s, est. speed input: 54318.74 toks/s, output: 53.05 toks/s]
Processed prompts:  71%|███████   | 5799/8192 [01:49<00:54, 43.99it/s, est. speed input: 54099.87 toks/s, output: 52.83 toks/s]
Processed prompts:  72%|███████▏  | 5863/8192 [01:51<00:54, 42.40it/s, est. speed input: 53886.63 toks/s, output: 52.62 toks/s]
Processed prompts:  72%|███████▏  | 5927/8192 [01:53<00:54, 41.45it/s, est. speed input: 53689.34 toks/s, output: 52.43 toks/s]
Processed prompts:  73%|███████▎  | 5991/8192 [01:54<00:52, 41.57it/s, est. speed input: 53545.21 toks/s, output: 52.29 toks/s]
Processed prompts:  74%|███████▍  | 6055/8192 [01:56<00:51, 41.17it/s, est. speed input: 53376.02 toks/s, output: 52.13 toks/s]
Processed prompts:  75%|███████▍  | 6119/8192 [01:57<00:51, 40.46it/s, est. speed input: 53186.29 toks/s, output: 51.94 toks/s]
Processed prompts:  75%|███████▌  | 6183/8192 [01:59<00:50, 39.92it/s, est. speed input: 52998.50 toks/s, output: 51.76 toks/s]
Processed prompts:  76%|███████▋  | 6247/8192 [02:01<00:48, 39.90it/s, est. speed input: 52836.53 toks/s, output: 51.60 toks/s]
Processed prompts:  77%|███████▋  | 6311/8192 [02:02<00:46, 40.53it/s, est. speed input: 52715.73 toks/s, output: 51.48 toks/s]
Processed prompts:  78%|███████▊  | 6375/8192 [02:04<00:44, 40.47it/s, est. speed input: 52569.87 toks/s, output: 51.34 toks/s]
Processed prompts:  79%|███████▊  | 6439/8192 [02:05<00:43, 39.88it/s, est. speed input: 52397.44 toks/s, output: 51.17 toks/s]
Processed prompts:  79%|███████▉  | 6503/8192 [02:07<00:42, 39.54it/s, est. speed input: 52232.76 toks/s, output: 51.01 toks/s]
Processed prompts:  80%|████████  | 6567/8192 [02:08<00:40, 40.50it/s, est. speed input: 52137.39 toks/s, output: 50.92 toks/s]
Processed prompts:  81%|████████  | 6631/8192 [02:10<00:37, 41.77it/s, est. speed input: 52072.00 toks/s, output: 50.85 toks/s]
Processed prompts:  82%|████████▏ | 6695/8192 [02:11<00:36, 41.52it/s, est. speed input: 51952.09 toks/s, output: 50.73 toks/s]
Processed prompts:  83%|████████▎ | 6759/8192 [02:13<00:35, 40.68it/s, est. speed input: 51802.13 toks/s, output: 50.59 toks/s]
Processed prompts:  84%|████████▍ | 6887/8192 [02:15<00:24, 52.27it/s, est. speed input: 52144.91 toks/s, output: 50.92 toks/s]
Processed prompts:  85%|████████▍ | 6951/8192 [02:16<00:25, 48.24it/s, est. speed input: 52000.18 toks/s, output: 50.78 toks/s]
Processed prompts:  86%|████████▌ | 7015/8192 [02:18<00:25, 46.48it/s, est. speed input: 51902.88 toks/s, output: 50.69 toks/s]
Processed prompts:  86%|████████▋ | 7079/8192 [02:19<00:24, 44.74it/s, est. speed input: 51787.78 toks/s, output: 50.57 toks/s]
Processed prompts:  87%|████████▋ | 7143/8192 [02:21<00:23, 43.81it/s, est. speed input: 51687.56 toks/s, output: 50.48 toks/s]
Processed prompts:  88%|████████▊ | 7207/8192 [02:23<00:23, 42.24it/s, est. speed input: 51549.11 toks/s, output: 50.34 toks/s]
Processed prompts:  89%|████████▉ | 7271/8192 [02:24<00:21, 42.01it/s, est. speed input: 51452.13 toks/s, output: 50.25 toks/s]
Processed prompts:  90%|████████▉ | 7335/8192 [02:26<00:20, 41.76it/s, est. speed input: 51353.20 toks/s, output: 50.15 toks/s]
Processed prompts:  90%|█████████ | 7399/8192 [02:27<00:19, 41.55it/s, est. speed input: 51255.14 toks/s, output: 50.05 toks/s]
Processed prompts:  91%|█████████ | 7463/8192 [02:29<00:17, 40.68it/s, est. speed input: 51127.46 toks/s, output: 49.93 toks/s]
Processed prompts:  92%|█████████▏| 7527/8192 [02:31<00:16, 40.10it/s, est. speed input: 51002.68 toks/s, output: 49.81 toks/s]
Processed prompts:  93%|█████████▎| 7591/8192 [02:32<00:15, 39.81it/s, est. speed input: 50886.07 toks/s, output: 49.69 toks/s]
Processed prompts:  93%|█████████▎| 7655/8192 [02:34<00:13, 40.46it/s, est. speed input: 50809.02 toks/s, output: 49.62 toks/s]
Processed prompts:  94%|█████████▍| 7719/8192 [02:35<00:11, 40.63it/s, est. speed input: 50721.14 toks/s, output: 49.53 toks/s]
Processed prompts:  95%|█████████▌| 7783/8192 [02:37<00:10, 39.97it/s, est. speed input: 50602.07 toks/s, output: 49.42 toks/s]
Processed prompts:  96%|█████████▌| 7847/8192 [02:39<00:08, 39.61it/s, est. speed input: 50489.00 toks/s, output: 49.31 toks/s]
Processed prompts:  97%|█████████▋| 7911/8192 [02:40<00:07, 39.81it/s, est. speed input: 50397.76 toks/s, output: 49.22 toks/s]
Processed prompts:  97%|█████████▋| 7975/8192 [02:42<00:05, 40.44it/s, est. speed input: 50328.22 toks/s, output: 49.15 toks/s]
Processed prompts:  98%|█████████▊| 8039/8192 [02:43<00:03, 40.67it/s, est. speed input: 50251.30 toks/s, output: 49.07 toks/s]
Processed prompts: 100%|█████████▉| 8167/8192 [02:43<00:00, 72.16it/s, est. speed input: 50998.26 toks/s, output: 49.80 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [02:43<00:00, 72.16it/s, est. speed input: 51154.21 toks/s, output: 49.96 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [02:43<00:00, 49.96it/s, est. speed input: 51154.21 toks/s, output: 49.96 toks/s]
[rank0]:[W125 19:11:11.351127209 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-25 22:12:20
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:12:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:12:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=466670) WARNING 01-25 22:12:38 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=466670) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=466670) WARNING 01-25 22:12:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.71 requests/s, 7547.75 total tokens/s, 14.71 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-25 22:12:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:12:29] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:12:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:12:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:12:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:12:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:12:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:12:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:12:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:12:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:12:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:12:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:12:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:12:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:12:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:12:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:12:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:12:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:12:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:12:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:12:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:12:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:12:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:39] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:39] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:39] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:39] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:39] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=466670) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=466670) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:02<00:00,  2.38s/it]
(EngineCore_DP0 pid=466670) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:02<00:00,  2.38s/it]
(EngineCore_DP0 pid=466670) 
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9437184 bytes
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50331648 bytes
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=466670) [2026-01-25 22:12:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25264128 bytes
(EngineCore_DP0 pid=466670) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.87it/s]
(EngineCore_DP0 pid=466670) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  5.56it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  5.55it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  41%|████      | 52/128 [00:00<00:00, 510.67it/s]
Adding requests:  84%|████████▎ | 107/128 [00:00<00:00, 530.85it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 531.87it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:18,  7.02it/s, est. speed input: 3594.24 toks/s, output: 7.02 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:13,  9.40it/s, est. speed input: 4654.51 toks/s, output: 9.09 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:00<00:01, 94.56it/s, est. speed input: 35961.76 toks/s, output: 70.24 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:01<00:02, 33.28it/s, est. speed input: 18207.81 toks/s, output: 35.56 toks/s]
Processed prompts:  41%|████      | 52/128 [00:01<00:02, 25.57it/s, est. speed input: 15097.85 toks/s, output: 29.49 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:02<00:03, 22.29it/s, est. speed input: 13750.12 toks/s, output: 26.86 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:02<00:03, 20.62it/s, est. speed input: 13090.19 toks/s, output: 25.57 toks/s]
Processed prompts:  52%|█████▏    | 66/128 [00:02<00:03, 19.23it/s, est. speed input: 12557.19 toks/s, output: 24.53 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:03, 18.38it/s, est. speed input: 12228.34 toks/s, output: 23.88 toks/s]
Processed prompts:  56%|█████▋    | 72/128 [00:03<00:03, 17.71it/s, est. speed input: 11956.39 toks/s, output: 23.35 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:03<00:03, 16.89it/s, est. speed input: 11671.65 toks/s, output: 22.80 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:03<00:03, 16.54it/s, est. speed input: 11517.16 toks/s, output: 22.49 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:03<00:03, 16.21it/s, est. speed input: 11373.39 toks/s, output: 22.21 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:03<00:02, 15.98it/s, est. speed input: 11246.27 toks/s, output: 21.97 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:03<00:02, 15.86it/s, est. speed input: 11133.70 toks/s, output: 21.75 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:03<00:02, 15.78it/s, est. speed input: 11030.46 toks/s, output: 21.54 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:04<00:02, 15.74it/s, est. speed input: 10935.64 toks/s, output: 21.36 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:04<00:02, 15.52it/s, est. speed input: 10831.98 toks/s, output: 21.16 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:04<00:02, 15.41it/s, est. speed input: 10737.63 toks/s, output: 20.97 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:04<00:02, 15.27it/s, est. speed input: 10645.35 toks/s, output: 20.79 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:04<00:02, 15.25it/s, est. speed input: 10563.49 toks/s, output: 20.63 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:02, 15.17it/s, est. speed input: 10482.20 toks/s, output: 20.47 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:04<00:01, 15.10it/s, est. speed input: 10404.30 toks/s, output: 20.32 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:05<00:01, 15.03it/s, est. speed input: 10329.30 toks/s, output: 20.17 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:05<00:01, 14.94it/s, est. speed input: 10255.44 toks/s, output: 20.03 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:05<00:01, 14.84it/s, est. speed input: 10183.81 toks/s, output: 19.89 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:05<00:01, 14.91it/s, est. speed input: 10123.47 toks/s, output: 19.77 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:05<00:01, 14.83it/s, est. speed input: 10058.50 toks/s, output: 19.65 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:05<00:01, 14.80it/s, est. speed input: 9998.71 toks/s, output: 19.53 toks/s] 
Processed prompts:  88%|████████▊ | 113/128 [00:05<00:01, 14.80it/s, est. speed input: 9942.35 toks/s, output: 19.42 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:05<00:00, 14.82it/s, est. speed input: 9889.80 toks/s, output: 19.32 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:06<00:00, 14.81it/s, est. speed input: 9838.42 toks/s, output: 19.22 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:06<00:00, 15.13it/s, est. speed input: 9804.30 toks/s, output: 19.15 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:06<00:00, 15.31it/s, est. speed input: 9769.27 toks/s, output: 19.08 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:06<00:00, 15.43it/s, est. speed input: 9735.64 toks/s, output: 19.01 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:06<00:00, 15.59it/s, est. speed input: 9705.94 toks/s, output: 18.96 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:06<00:00, 15.62it/s, est. speed input: 9674.34 toks/s, output: 18.90 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 15.62it/s, est. speed input: 9658.12 toks/s, output: 18.86 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 18.86it/s, est. speed input: 9658.12 toks/s, output: 18.86 toks/s]
[rank0]:[W125 22:13:19.740392383 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-25 22:13:22
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:13:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:13:32 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=467827) WARNING 01-25 22:13:41 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=467827) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=467827) WARNING 01-25 22:13:51 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.43 requests/s, 14791.70 total tokens/s, 14.43 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-25 22:13:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:13:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:13:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:13:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:13:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:13:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:13:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:13:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:13:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:13:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:13:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:13:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:13:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:13:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:13:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:13:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:13:40] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:13:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:13:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:13:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:13:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:13:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:13:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:13:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:13:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:13:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:13:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:13:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:41] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:41] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:41] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:41] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:41] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=467827) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=467827) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.06it/s]
(EngineCore_DP0 pid=467827) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.06it/s]
(EngineCore_DP0 pid=467827) 
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9437184 bytes
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50331648 bytes
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:42] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=467827) [2026-01-25 22:13:42] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25264128 bytes
(EngineCore_DP0 pid=467827) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.17it/s]
(EngineCore_DP0 pid=467827) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  20%|██        | 26/128 [00:00<00:00, 251.82it/s]
Adding requests:  42%|████▏     | 54/128 [00:00<00:00, 262.76it/s]
Adding requests:  64%|██████▍   | 82/128 [00:00<00:00, 268.24it/s]
Adding requests:  85%|████████▌ | 109/128 [00:00<00:00, 267.77it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 268.12it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:05, 23.98it/s, est. speed input: 24565.46 toks/s, output: 23.99 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:07, 17.37it/s, est. speed input: 18556.93 toks/s, output: 18.12 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:07, 16.36it/s, est. speed input: 17580.70 toks/s, output: 17.17 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:00<00:07, 15.74it/s, est. speed input: 16995.38 toks/s, output: 16.60 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:00<00:07, 15.35it/s, est. speed input: 16617.74 toks/s, output: 16.23 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:07, 15.05it/s, est. speed input: 16330.55 toks/s, output: 15.95 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:01<00:07, 15.01it/s, est. speed input: 16189.76 toks/s, output: 15.81 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:01<00:07, 15.06it/s, est. speed input: 16115.82 toks/s, output: 15.74 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:07, 15.03it/s, est. speed input: 16031.74 toks/s, output: 15.66 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:07, 14.92it/s, est. speed input: 15934.10 toks/s, output: 15.56 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:06, 14.92it/s, est. speed input: 15877.98 toks/s, output: 15.51 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:06, 14.90it/s, est. speed input: 15824.70 toks/s, output: 15.45 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:06, 14.90it/s, est. speed input: 15783.92 toks/s, output: 15.41 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:06, 14.87it/s, est. speed input: 15739.33 toks/s, output: 15.37 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:02<00:06, 14.85it/s, est. speed input: 15701.98 toks/s, output: 15.33 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:02<00:06, 14.81it/s, est. speed input: 15663.91 toks/s, output: 15.30 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:02<00:06, 14.85it/s, est. speed input: 15643.28 toks/s, output: 15.28 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:06, 14.80it/s, est. speed input: 15609.42 toks/s, output: 15.24 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 14.72it/s, est. speed input: 15571.27 toks/s, output: 15.21 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:05, 14.62it/s, est. speed input: 15530.04 toks/s, output: 15.17 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:05, 14.59it/s, est. speed input: 15498.74 toks/s, output: 15.14 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:03<00:05, 14.59it/s, est. speed input: 15474.05 toks/s, output: 15.11 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:03<00:05, 14.74it/s, est. speed input: 15472.82 toks/s, output: 15.11 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:03<00:05, 14.78it/s, est. speed input: 15462.65 toks/s, output: 15.10 toks/s]
Processed prompts:  41%|████      | 52/128 [00:03<00:05, 14.80it/s, est. speed input: 15453.04 toks/s, output: 15.09 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:03<00:04, 14.82it/s, est. speed input: 15444.89 toks/s, output: 15.08 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:03<00:04, 14.88it/s, est. speed input: 15442.72 toks/s, output: 15.08 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:03<00:00, 64.48it/s, est. speed input: 21667.05 toks/s, output: 21.16 toks/s]
Processed prompts:  69%|██████▉   | 88/128 [00:04<00:01, 38.32it/s, est. speed input: 21157.08 toks/s, output: 20.66 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:04<00:01, 29.66it/s, est. speed input: 20819.45 toks/s, output: 20.33 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 25.48it/s, est. speed input: 20586.56 toks/s, output: 20.10 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:05<00:01, 22.49it/s, est. speed input: 20360.87 toks/s, output: 19.88 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:05<00:01, 20.90it/s, est. speed input: 20218.51 toks/s, output: 19.74 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:05<00:01, 19.66it/s, est. speed input: 20090.25 toks/s, output: 19.62 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:05<00:00, 18.63it/s, est. speed input: 19961.96 toks/s, output: 19.49 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:05<00:00, 18.13it/s, est. speed input: 19888.69 toks/s, output: 19.42 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:05<00:00, 17.70it/s, est. speed input: 19820.04 toks/s, output: 19.36 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:06<00:00, 17.22it/s, est. speed input: 19741.74 toks/s, output: 19.28 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:06<00:00, 16.91it/s, est. speed input: 19674.50 toks/s, output: 19.21 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:06<00:00, 16.69it/s, est. speed input: 19610.84 toks/s, output: 19.15 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:06<00:00, 16.56it/s, est. speed input: 19553.08 toks/s, output: 19.09 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:06<00:00, 16.42it/s, est. speed input: 19493.96 toks/s, output: 19.04 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:06<00:00, 16.30it/s, est. speed input: 19435.17 toks/s, output: 18.98 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 16.00it/s, est. speed input: 19362.47 toks/s, output: 18.91 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 16.00it/s, est. speed input: 19362.47 toks/s, output: 18.91 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:06<00:00, 18.91it/s, est. speed input: 19362.47 toks/s, output: 18.91 toks/s]
[rank0]:[W125 22:14:17.275719893 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-25 22:14:20
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:14:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:14:32 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=468884) WARNING 01-25 22:14:41 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=468884) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=468884) WARNING 01-25 22:14:51 [backends.py:609] Failed to read file <frozen os>
Throughput: 29.23 requests/s, 29960.15 total tokens/s, 29.23 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-25 22:14:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:14:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:14:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:14:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:14:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:14:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:14:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:14:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:14:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:14:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:14:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:14:39] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:14:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:14:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:14:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:14:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:14:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:14:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:14:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:14:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:14:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:14:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:14:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:41] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:41] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:41] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:41] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:41] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=468884) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=468884) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.01s/it]
(EngineCore_DP0 pid=468884) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.01s/it]
(EngineCore_DP0 pid=468884) 
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9437184 bytes
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50331648 bytes
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=468884) [2026-01-25 22:14:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25264128 bytes
(EngineCore_DP0 pid=468884) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  7.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  7.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  7.49it/s]
(EngineCore_DP0 pid=468884) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  7.96it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  11%|█         | 28/256 [00:00<00:00, 277.65it/s]
Adding requests:  23%|██▎       | 59/256 [00:00<00:00, 293.29it/s]
Adding requests:  36%|███▋      | 93/256 [00:00<00:00, 310.75it/s]
Adding requests:  49%|████▉     | 126/256 [00:00<00:00, 316.24it/s]
Adding requests:  62%|██████▏   | 158/256 [00:00<00:00, 313.86it/s]
Adding requests:  74%|███████▍  | 190/256 [00:00<00:00, 315.00it/s]
Adding requests:  87%|████████▋ | 222/256 [00:00<00:00, 306.48it/s]
Adding requests: 100%|█████████▉| 255/256 [00:00<00:00, 312.01it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 309.66it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   8%|▊         | 20/256 [00:00<00:01, 135.47it/s, est. speed input: 138745.83 toks/s, output: 135.48 toks/s]
Processed prompts:  13%|█▎        | 34/256 [00:00<00:04, 51.75it/s, est. speed input: 59477.15 toks/s, output: 58.08 toks/s]   
Processed prompts:  16%|█▋        | 42/256 [00:00<00:04, 43.99it/s, est. speed input: 51567.14 toks/s, output: 50.36 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:01<00:05, 40.51it/s, est. speed input: 48197.08 toks/s, output: 47.07 toks/s]
Processed prompts:  21%|██        | 53/256 [00:01<00:05, 40.52it/s, est. speed input: 47477.38 toks/s, output: 46.36 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:01<00:05, 36.21it/s, est. speed input: 44723.16 toks/s, output: 43.67 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:01<00:05, 35.19it/s, est. speed input: 43682.83 toks/s, output: 42.66 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:01<00:05, 34.43it/s, est. speed input: 42837.64 toks/s, output: 41.83 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:01<00:05, 33.79it/s, est. speed input: 42099.58 toks/s, output: 41.11 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:01<00:05, 33.19it/s, est. speed input: 41427.62 toks/s, output: 40.46 toks/s]
Processed prompts:  30%|███       | 78/256 [00:01<00:05, 32.76it/s, est. speed input: 40847.08 toks/s, output: 39.89 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:02<00:05, 32.58it/s, est. speed input: 40371.74 toks/s, output: 39.43 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:02<00:05, 32.00it/s, est. speed input: 39840.42 toks/s, output: 38.91 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:02<00:05, 31.37it/s, est. speed input: 39316.20 toks/s, output: 38.39 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:02<00:05, 30.81it/s, est. speed input: 38821.63 toks/s, output: 37.91 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:02<00:05, 30.57it/s, est. speed input: 38407.41 toks/s, output: 37.51 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:02<00:05, 30.42it/s, est. speed input: 38039.55 toks/s, output: 37.15 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:02<00:04, 30.28it/s, est. speed input: 37698.07 toks/s, output: 36.81 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:03<00:04, 30.10it/s, est. speed input: 37371.69 toks/s, output: 36.50 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:03<00:04, 30.02it/s, est. speed input: 37080.65 toks/s, output: 36.21 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:03<00:04, 30.06it/s, est. speed input: 36829.84 toks/s, output: 35.97 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:03<00:04, 30.11it/s, est. speed input: 36602.38 toks/s, output: 35.74 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:03<00:04, 30.06it/s, est. speed input: 36377.83 toks/s, output: 35.52 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:03<00:04, 29.93it/s, est. speed input: 36156.34 toks/s, output: 35.31 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:03<00:04, 29.92it/s, est. speed input: 35962.53 toks/s, output: 35.12 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:03<00:03, 29.81it/s, est. speed input: 35767.93 toks/s, output: 34.93 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:04<00:03, 29.61it/s, est. speed input: 35568.94 toks/s, output: 34.74 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:04<00:03, 29.66it/s, est. speed input: 35407.14 toks/s, output: 34.58 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:04<00:03, 29.64it/s, est. speed input: 35249.63 toks/s, output: 34.42 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:04<00:03, 29.58it/s, est. speed input: 35095.19 toks/s, output: 34.27 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:04<00:03, 29.56it/s, est. speed input: 34951.87 toks/s, output: 34.13 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:04<00:00, 131.66it/s, est. speed input: 45281.06 toks/s, output: 44.22 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:05<00:00, 75.77it/s, est. speed input: 44102.45 toks/s, output: 43.07 toks/s] 
Processed prompts:  91%|█████████▏| 234/256 [00:05<00:00, 57.67it/s, est. speed input: 43269.43 toks/s, output: 42.26 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:05<00:00, 49.11it/s, est. speed input: 42686.54 toks/s, output: 41.69 toks/s]
Processed prompts:  97%|█████████▋| 249/256 [00:06<00:00, 45.46it/s, est. speed input: 42439.91 toks/s, output: 41.45 toks/s]
Processed prompts: 100%|█████████▉| 255/256 [00:06<00:00, 41.25it/s, est. speed input: 42039.67 toks/s, output: 41.05 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:06<00:00, 41.25it/s, est. speed input: 41754.62 toks/s, output: 40.78 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:06<00:00, 40.77it/s, est. speed input: 41754.62 toks/s, output: 40.78 toks/s]
[rank0]:[W125 22:15:18.983797091 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-25 22:15:21
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:15:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:15:33 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=469996) WARNING 01-25 22:15:42 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=469996) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=469996) WARNING 01-25 22:15:52 [backends.py:609] Failed to read file <frozen os>
Throughput: 40.83 requests/s, 41846.79 total tokens/s, 40.83 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-25 22:15:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:15:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:15:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:15:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:15:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:15:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:15:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:15:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:15:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:15:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:15:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:15:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:15:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:15:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:15:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:15:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:15:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:15:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:15:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:15:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:15:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:15:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:15:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:15:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:15:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:15:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:15:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:15:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:43] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:43] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:43] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:43] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:43] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:43] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=469996) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=469996) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.09it/s]
(EngineCore_DP0 pid=469996) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.09it/s]
(EngineCore_DP0 pid=469996) 
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9437184 bytes
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50331648 bytes
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=469996) [2026-01-25 22:15:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25264128 bytes
(EngineCore_DP0 pid=469996) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:01,  1.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  3.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  4.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  3.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:01<00:00,  3.12it/s]
(EngineCore_DP0 pid=469996) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  5.56it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  7.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  7.87it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  7.43it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▌         | 26/512 [00:00<00:01, 255.38it/s]
Adding requests:  11%|█         | 54/512 [00:00<00:01, 266.15it/s]
Adding requests:  16%|█▌        | 81/512 [00:00<00:01, 265.95it/s]
Adding requests:  21%|██▏       | 110/512 [00:00<00:01, 275.17it/s]
Adding requests:  27%|██▋       | 138/512 [00:00<00:01, 276.74it/s]
Adding requests:  32%|███▏      | 166/512 [00:00<00:01, 276.44it/s]
Adding requests:  38%|███▊      | 194/512 [00:00<00:01, 271.21it/s]
Adding requests:  44%|████▎     | 223/512 [00:00<00:01, 274.73it/s]
Adding requests:  49%|████▉     | 251/512 [00:00<00:00, 274.08it/s]
Adding requests:  54%|█████▍    | 279/512 [00:01<00:00, 275.37it/s]
Adding requests:  60%|██████    | 309/512 [00:01<00:00, 280.01it/s]
Adding requests:  66%|██████▌   | 338/512 [00:01<00:00, 275.67it/s]
Adding requests:  72%|███████▏  | 367/512 [00:01<00:00, 279.88it/s]
Adding requests:  77%|███████▋  | 396/512 [00:01<00:00, 279.96it/s]
Adding requests:  83%|████████▎ | 425/512 [00:01<00:00, 282.79it/s]
Adding requests:  89%|████████▊ | 454/512 [00:01<00:00, 283.02it/s]
Adding requests:  94%|█████████▍| 483/512 [00:01<00:00, 281.35it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 281.00it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 277.18it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:00<00:00, 599.32it/s, est. speed input: 613817.09 toks/s, output: 599.35 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:01<00:05, 70.61it/s, est. speed input: 83538.76 toks/s, output: 81.58 toks/s]  
Processed prompts:  29%|██▉       | 150/512 [00:02<00:06, 60.18it/s, est. speed input: 71828.27 toks/s, output: 70.14 toks/s]
Processed prompts:  33%|███▎      | 167/512 [00:02<00:06, 56.91it/s, est. speed input: 68285.99 toks/s, output: 66.69 toks/s]
Processed prompts:  35%|███▍      | 179/512 [00:02<00:06, 54.21it/s, est. speed input: 65956.58 toks/s, output: 64.41 toks/s]
Processed prompts:  37%|███▋      | 189/512 [00:02<00:05, 54.29it/s, est. speed input: 65344.83 toks/s, output: 63.81 toks/s]
Processed prompts:  38%|███▊      | 197/512 [00:03<00:06, 52.28it/s, est. speed input: 64138.65 toks/s, output: 62.64 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:03<00:01, 131.37it/s, est. speed input: 84468.26 toks/s, output: 82.49 toks/s]
Processed prompts:  57%|█████▋    | 293/512 [00:03<00:02, 99.84it/s, est. speed input: 81057.50 toks/s, output: 79.16 toks/s] 
Processed prompts:  60%|██████    | 308/512 [00:04<00:02, 77.69it/s, est. speed input: 77112.12 toks/s, output: 75.30 toks/s]
Processed prompts:  62%|██████▎   | 320/512 [00:04<00:02, 67.56it/s, est. speed input: 74805.89 toks/s, output: 73.05 toks/s]
Processed prompts:  64%|██████▍   | 329/512 [00:04<00:02, 63.16it/s, est. speed input: 73658.14 toks/s, output: 71.93 toks/s]
Processed prompts:  66%|██████▌   | 337/512 [00:04<00:03, 58.13it/s, est. speed input: 72387.71 toks/s, output: 70.69 toks/s]
Processed prompts:  67%|██████▋   | 344/512 [00:04<00:03, 52.65it/s, est. speed input: 70998.57 toks/s, output: 69.33 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:05<00:03, 46.88it/s, est. speed input: 69501.72 toks/s, output: 67.87 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:05<00:03, 45.30it/s, est. speed input: 68503.93 toks/s, output: 66.90 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:05<00:03, 44.14it/s, est. speed input: 67579.41 toks/s, output: 66.00 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:05<00:03, 43.26it/s, est. speed input: 66712.53 toks/s, output: 65.15 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:05<00:03, 42.63it/s, est. speed input: 65904.84 toks/s, output: 64.36 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:06<00:02, 42.22it/s, est. speed input: 65154.56 toks/s, output: 63.63 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:06<00:02, 41.87it/s, est. speed input: 64441.85 toks/s, output: 62.93 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:06<00:02, 41.60it/s, est. speed input: 63767.31 toks/s, output: 62.27 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:06<00:02, 41.38it/s, est. speed input: 63127.95 toks/s, output: 61.65 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:06<00:02, 41.35it/s, est. speed input: 62543.75 toks/s, output: 61.08 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:07<00:01, 41.27it/s, est. speed input: 61982.54 toks/s, output: 60.53 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:07<00:01, 41.21it/s, est. speed input: 61450.77 toks/s, output: 60.01 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:07<00:01, 41.21it/s, est. speed input: 60951.23 toks/s, output: 59.52 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:07<00:01, 41.22it/s, est. speed input: 60480.16 toks/s, output: 59.06 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:07<00:01, 41.26it/s, est. speed input: 60033.95 toks/s, output: 58.63 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:08<00:01, 41.27it/s, est. speed input: 59607.77 toks/s, output: 58.21 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:08<00:00, 41.16it/s, est. speed input: 59188.79 toks/s, output: 57.80 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:08<00:00, 41.11it/s, est. speed input: 58792.70 toks/s, output: 57.41 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:08<00:00, 41.11it/s, est. speed input: 58417.23 toks/s, output: 57.05 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:08<00:00, 41.10it/s, est. speed input: 58057.67 toks/s, output: 56.70 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:09<00:00, 42.23it/s, est. speed input: 57824.88 toks/s, output: 56.47 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:09<00:00, 42.23it/s, est. speed input: 58050.25 toks/s, output: 56.69 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:09<00:00, 56.69it/s, est. speed input: 58050.25 toks/s, output: 56.69 toks/s]
[rank0]:[W125 22:16:23.105850063 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-25 22:16:27
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:16:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:16:43 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=471174) WARNING 01-25 22:16:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=471174) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=471174) WARNING 01-25 22:17:03 [backends.py:609] Failed to read file <frozen os>
Throughput: 39.60 requests/s, 40594.98 total tokens/s, 39.60 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-25 22:16:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:16:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:16:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:16:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:16:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:16:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:16:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:16:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:16:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:16:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:16:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:16:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:16:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:16:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:16:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:16:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:16:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:16:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:16:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:16:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:16:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:16:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:16:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:16:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:16:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:16:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:16:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:16:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:50] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:50] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:50] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:50] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=471174) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=471174) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.02s/it]
(EngineCore_DP0 pid=471174) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.02s/it]
(EngineCore_DP0 pid=471174) 
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9437184 bytes
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50331648 bytes
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:52] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=471174) [2026-01-25 22:16:52] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25264128 bytes
(EngineCore_DP0 pid=471174) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  3.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  5.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  6.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  6.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  5.18it/s]
(EngineCore_DP0 pid=471174) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  5.88it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  5.50it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  3.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  4.41it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  4.36it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   3%|▎         | 28/1024 [00:00<00:03, 274.92it/s]
Adding requests:   6%|▌         | 57/1024 [00:00<00:03, 278.79it/s]
Adding requests:   8%|▊         | 85/1024 [00:00<00:03, 274.15it/s]
Adding requests:  11%|█         | 113/1024 [00:00<00:03, 272.65it/s]
Adding requests:  14%|█▍        | 141/1024 [00:00<00:03, 271.25it/s]
Adding requests:  17%|█▋        | 169/1024 [00:00<00:03, 269.51it/s]
Adding requests:  19%|█▉        | 196/1024 [00:00<00:03, 266.25it/s]
Adding requests:  22%|██▏       | 224/1024 [00:00<00:02, 269.56it/s]
Adding requests:  25%|██▍       | 252/1024 [00:00<00:02, 271.75it/s]
Adding requests:  27%|██▋       | 280/1024 [00:01<00:02, 271.89it/s]
Adding requests:  30%|███       | 308/1024 [00:01<00:02, 271.90it/s]
Adding requests:  33%|███▎      | 336/1024 [00:01<00:02, 270.29it/s]
Adding requests:  36%|███▌      | 365/1024 [00:01<00:02, 275.39it/s]
Adding requests:  38%|███▊      | 393/1024 [00:01<00:02, 275.19it/s]
Adding requests:  41%|████      | 421/1024 [00:01<00:02, 273.84it/s]
Adding requests:  44%|████▍     | 449/1024 [00:01<00:02, 272.36it/s]
Adding requests:  47%|████▋     | 477/1024 [00:01<00:01, 273.77it/s]
Adding requests:  49%|████▉     | 505/1024 [00:01<00:01, 271.19it/s]
Adding requests:  52%|█████▏    | 533/1024 [00:01<00:01, 264.05it/s]
Adding requests:  55%|█████▍    | 561/1024 [00:02<00:01, 267.62it/s]
Adding requests:  58%|█████▊    | 591/1024 [00:02<00:01, 275.26it/s]
Adding requests:  60%|██████    | 619/1024 [00:02<00:01, 274.20it/s]
Adding requests:  63%|██████▎   | 647/1024 [00:02<00:01, 265.59it/s]
Adding requests:  66%|██████▌   | 677/1024 [00:02<00:01, 275.38it/s]
Adding requests:  69%|██████▉   | 706/1024 [00:02<00:01, 277.79it/s]
Adding requests:  72%|███████▏  | 736/1024 [00:02<00:01, 282.92it/s]
Adding requests:  75%|███████▍  | 765/1024 [00:02<00:00, 272.98it/s]
Adding requests:  77%|███████▋  | 793/1024 [00:02<00:00, 261.20it/s]
Adding requests:  80%|████████  | 820/1024 [00:03<00:00, 260.93it/s]
Adding requests:  83%|████████▎ | 850/1024 [00:03<00:00, 270.80it/s]
Adding requests:  86%|████████▌ | 880/1024 [00:03<00:00, 278.45it/s]
Adding requests:  89%|████████▉ | 910/1024 [00:03<00:00, 282.02it/s]
Adding requests:  92%|█████████▏| 939/1024 [00:03<00:00, 275.73it/s]
Adding requests:  95%|█████████▍| 968/1024 [00:03<00:00, 277.04it/s]
Adding requests:  97%|█████████▋| 996/1024 [00:03<00:00, 274.74it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 273.05it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:00<00:01, 641.33it/s, est. speed input: 656821.08 toks/s, output: 641.36 toks/s]
Processed prompts:  20%|█▉        | 203/1024 [00:01<00:09, 90.45it/s, est. speed input: 112295.35 toks/s, output: 109.66 toks/s] 
Processed prompts:  23%|██▎       | 232/1024 [00:02<00:10, 77.81it/s, est. speed input: 97881.92 toks/s, output: 95.59 toks/s]  
Processed prompts:  24%|██▍       | 250/1024 [00:02<00:12, 63.70it/s, est. speed input: 85539.49 toks/s, output: 83.53 toks/s]
Processed prompts:  26%|██▌       | 263/1024 [00:03<00:11, 64.35it/s, est. speed input: 84640.17 toks/s, output: 82.66 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:03<00:13, 54.92it/s, est. speed input: 78816.96 toks/s, output: 76.97 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:03<00:14, 52.92it/s, est. speed input: 77035.13 toks/s, output: 75.23 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:03<00:14, 50.94it/s, est. speed input: 75415.43 toks/s, output: 73.65 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:04<00:14, 49.13it/s, est. speed input: 73948.05 toks/s, output: 72.21 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:04<00:15, 47.57it/s, est. speed input: 72609.35 toks/s, output: 70.91 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:04<00:15, 46.25it/s, est. speed input: 71378.90 toks/s, output: 69.70 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:04<00:15, 44.36it/s, est. speed input: 70038.45 toks/s, output: 68.40 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:04<00:16, 42.88it/s, est. speed input: 68794.54 toks/s, output: 67.18 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:05<00:16, 41.81it/s, est. speed input: 67646.66 toks/s, output: 66.06 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:05<00:16, 41.04it/s, est. speed input: 66592.36 toks/s, output: 65.03 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:05<00:16, 40.45it/s, est. speed input: 65605.40 toks/s, output: 64.07 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:05<00:16, 40.07it/s, est. speed input: 64694.42 toks/s, output: 63.18 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:05<00:16, 39.78it/s, est. speed input: 63844.12 toks/s, output: 62.35 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:06<00:16, 39.54it/s, est. speed input: 63044.90 toks/s, output: 61.57 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:06<00:16, 39.41it/s, est. speed input: 62303.45 toks/s, output: 60.84 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:06<00:16, 39.30it/s, est. speed input: 61603.99 toks/s, output: 60.16 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:06<00:15, 39.22it/s, est. speed input: 60946.99 toks/s, output: 59.52 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:06<00:15, 39.18it/s, est. speed input: 60332.53 toks/s, output: 58.92 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:07<00:15, 39.15it/s, est. speed input: 59751.33 toks/s, output: 58.35 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:07<00:15, 39.12it/s, est. speed input: 59201.57 toks/s, output: 57.81 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:07<00:15, 39.08it/s, est. speed input: 58679.87 toks/s, output: 57.30 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:07<00:14, 39.10it/s, est. speed input: 58191.42 toks/s, output: 56.83 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:07<00:14, 39.09it/s, est. speed input: 57725.14 toks/s, output: 56.37 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:08<00:14, 39.10it/s, est. speed input: 57284.75 toks/s, output: 55.94 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:08<00:14, 39.12it/s, est. speed input: 56865.53 toks/s, output: 55.53 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:08<00:14, 39.10it/s, est. speed input: 56463.58 toks/s, output: 55.14 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:08<00:13, 39.04it/s, est. speed input: 56074.70 toks/s, output: 54.76 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:09<00:13, 39.04it/s, est. speed input: 55708.15 toks/s, output: 54.40 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:09<00:13, 39.01it/s, est. speed input: 55354.91 toks/s, output: 54.06 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:09<00:13, 38.98it/s, est. speed input: 55017.22 toks/s, output: 53.73 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:09<00:13, 38.98it/s, est. speed input: 54694.51 toks/s, output: 53.41 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:09<00:12, 38.97it/s, est. speed input: 54384.83 toks/s, output: 53.11 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:10<00:12, 39.36it/s, est. speed input: 54124.61 toks/s, output: 52.86 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:10<00:12, 40.15it/s, est. speed input: 53921.07 toks/s, output: 52.66 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:10<00:11, 40.75it/s, est. speed input: 53726.58 toks/s, output: 52.47 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:10<00:11, 41.15it/s, est. speed input: 53536.39 toks/s, output: 52.28 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:10<00:11, 41.47it/s, est. speed input: 53355.61 toks/s, output: 52.10 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:10<00:10, 41.66it/s, est. speed input: 53178.67 toks/s, output: 51.93 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:11<00:10, 41.77it/s, est. speed input: 53005.88 toks/s, output: 51.76 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:11<00:10, 41.87it/s, est. speed input: 52840.47 toks/s, output: 51.60 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:11<00:10, 41.96it/s, est. speed input: 52681.44 toks/s, output: 51.45 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:11<00:10, 42.01it/s, est. speed input: 52527.44 toks/s, output: 51.30 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:11<00:09, 42.11it/s, est. speed input: 52381.70 toks/s, output: 51.15 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:12<00:09, 42.12it/s, est. speed input: 52237.63 toks/s, output: 51.01 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:12<00:09, 42.12it/s, est. speed input: 52096.80 toks/s, output: 50.88 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:12<00:09, 42.11it/s, est. speed input: 51960.39 toks/s, output: 50.74 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:12<00:09, 42.04it/s, est. speed input: 51823.33 toks/s, output: 50.61 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:12<00:09, 41.05it/s, est. speed input: 51631.98 toks/s, output: 50.42 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:13<00:09, 40.39it/s, est. speed input: 51447.50 toks/s, output: 50.24 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:13<00:08, 39.94it/s, est. speed input: 51268.90 toks/s, output: 50.07 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:13<00:08, 39.62it/s, est. speed input: 51094.24 toks/s, output: 49.90 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:13<00:08, 39.39it/s, est. speed input: 50924.67 toks/s, output: 49.73 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:13<00:08, 39.24it/s, est. speed input: 50760.85 toks/s, output: 49.57 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:14<00:08, 39.13it/s, est. speed input: 50601.25 toks/s, output: 49.42 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:14<00:08, 39.09it/s, est. speed input: 50448.49 toks/s, output: 49.27 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:14<00:07, 39.02it/s, est. speed input: 50297.38 toks/s, output: 49.12 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:14<00:07, 38.98it/s, est. speed input: 50151.47 toks/s, output: 48.98 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:14<00:07, 38.98it/s, est. speed input: 50010.47 toks/s, output: 48.84 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:15<00:07, 38.93it/s, est. speed input: 49871.31 toks/s, output: 48.70 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:15<00:07, 38.92it/s, est. speed input: 49736.74 toks/s, output: 48.57 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:15<00:06, 38.91it/s, est. speed input: 49605.56 toks/s, output: 48.44 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:15<00:06, 38.87it/s, est. speed input: 49476.25 toks/s, output: 48.32 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:15<00:06, 38.86it/s, est. speed input: 49351.36 toks/s, output: 48.19 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:16<00:06, 38.83it/s, est. speed input: 49228.01 toks/s, output: 48.07 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:16<00:06, 38.84it/s, est. speed input: 49109.66 toks/s, output: 47.96 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:16<00:05, 38.85it/s, est. speed input: 48994.20 toks/s, output: 47.85 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:16<00:05, 38.83it/s, est. speed input: 48879.96 toks/s, output: 47.73 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:17<00:05, 38.82it/s, est. speed input: 48769.29 toks/s, output: 47.63 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:17<00:05, 38.81it/s, est. speed input: 48660.73 toks/s, output: 47.52 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:17<00:05, 38.83it/s, est. speed input: 48556.02 toks/s, output: 47.42 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:17<00:04, 38.84it/s, est. speed input: 48453.74 toks/s, output: 47.32 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:17<00:04, 38.84it/s, est. speed input: 48353.41 toks/s, output: 47.22 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:18<00:04, 39.56it/s, est. speed input: 48288.97 toks/s, output: 47.16 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:18<00:04, 40.29it/s, est. speed input: 48234.78 toks/s, output: 47.10 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:18<00:03, 40.84it/s, est. speed input: 48182.86 toks/s, output: 47.05 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:18<00:03, 41.19it/s, est. speed input: 48130.31 toks/s, output: 47.00 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:18<00:03, 41.42it/s, est. speed input: 48078.14 toks/s, output: 46.95 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:18<00:03, 41.60it/s, est. speed input: 48027.70 toks/s, output: 46.90 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:19<00:03, 41.74it/s, est. speed input: 47978.50 toks/s, output: 46.85 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:19<00:02, 41.84it/s, est. speed input: 47930.32 toks/s, output: 46.81 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:19<00:02, 41.90it/s, est. speed input: 47882.68 toks/s, output: 46.76 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:19<00:02, 41.91it/s, est. speed input: 47835.01 toks/s, output: 46.71 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:19<00:02, 41.92it/s, est. speed input: 47788.65 toks/s, output: 46.67 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:20<00:02, 41.95it/s, est. speed input: 47743.31 toks/s, output: 46.62 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:20<00:01, 41.98it/s, est. speed input: 47699.53 toks/s, output: 46.58 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:20<00:01, 41.99it/s, est. speed input: 47656.07 toks/s, output: 46.54 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:20<00:01, 42.04it/s, est. speed input: 47614.73 toks/s, output: 46.50 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:20<00:01, 41.63it/s, est. speed input: 47558.88 toks/s, output: 46.44 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:21<00:01, 40.75it/s, est. speed input: 47482.86 toks/s, output: 46.37 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:21<00:00, 40.16it/s, est. speed input: 47408.23 toks/s, output: 46.30 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:21<00:00, 39.69it/s, est. speed input: 47333.01 toks/s, output: 46.22 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:21<00:00, 39.42it/s, est. speed input: 47260.54 toks/s, output: 46.15 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:21<00:00, 39.22it/s, est. speed input: 47189.21 toks/s, output: 46.08 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:22<00:00, 40.27it/s, est. speed input: 47162.31 toks/s, output: 46.06 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:22<00:00, 40.27it/s, est. speed input: 47439.57 toks/s, output: 46.33 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:22<00:00, 46.33it/s, est. speed input: 47439.57 toks/s, output: 46.33 toks/s]
[rank0]:[W125 22:17:48.111705657 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-25 22:17:50
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:18:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:18:13 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=472664) WARNING 01-25 22:18:20 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=472664) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=472664) WARNING 01-25 22:18:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 39.57 requests/s, 40557.57 total tokens/s, 39.57 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-25 22:18:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:18:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:18:12] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:18:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:18:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:18:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:18:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:18:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:18:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:18:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:18:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:18:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:18:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:18:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:18:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:18:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:18:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:18:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:18:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:18:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:18:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:18:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:18:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:18:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:18:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:18:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:18:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:18:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:21] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:21] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:21] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:21] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:21] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=472664) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=472664) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.04s/it]
(EngineCore_DP0 pid=472664) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.04s/it]
(EngineCore_DP0 pid=472664) 
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9437184 bytes
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50331648 bytes
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=472664) [2026-01-25 22:18:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25264128 bytes
(EngineCore_DP0 pid=472664) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  8.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  8.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  8.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  9.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  9.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  9.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  8.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  8.72it/s]
(EngineCore_DP0 pid=472664) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  7.64it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  8.66it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  6.86it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  3.79it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  4.76it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  5.12it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|▏         | 26/2048 [00:00<00:07, 257.27it/s]
Adding requests:   3%|▎         | 54/2048 [00:00<00:07, 270.38it/s]
Adding requests:   4%|▍         | 82/2048 [00:00<00:07, 264.71it/s]
Adding requests:   5%|▌         | 110/2048 [00:00<00:07, 268.30it/s]
Adding requests:   7%|▋         | 138/2048 [00:00<00:07, 272.17it/s]
Adding requests:   8%|▊         | 166/2048 [00:00<00:06, 272.69it/s]
Adding requests:   9%|▉         | 194/2048 [00:00<00:06, 271.13it/s]
Adding requests:  11%|█         | 222/2048 [00:00<00:06, 271.72it/s]
Adding requests:  12%|█▏        | 251/2048 [00:00<00:06, 276.91it/s]
Adding requests:  14%|█▎        | 279/2048 [00:01<00:06, 274.64it/s]
Adding requests:  15%|█▍        | 307/2048 [00:01<00:06, 271.94it/s]
Adding requests:  16%|█▋        | 335/2048 [00:01<00:06, 272.75it/s]
Adding requests:  18%|█▊        | 364/2048 [00:01<00:06, 275.98it/s]
Adding requests:  19%|█▉        | 392/2048 [00:01<00:06, 275.11it/s]
Adding requests:  21%|██        | 420/2048 [00:01<00:05, 273.12it/s]
Adding requests:  22%|██▏       | 448/2048 [00:01<00:05, 269.81it/s]
Adding requests:  23%|██▎       | 475/2048 [00:01<00:05, 269.20it/s]
Adding requests:  25%|██▍       | 503/2048 [00:01<00:05, 270.79it/s]
Adding requests:  26%|██▌       | 531/2048 [00:01<00:05, 264.76it/s]
Adding requests:  27%|██▋       | 560/2048 [00:02<00:05, 270.73it/s]
Adding requests:  29%|██▊       | 588/2048 [00:02<00:05, 272.80it/s]
Adding requests:  30%|███       | 616/2048 [00:02<00:05, 271.95it/s]
Adding requests:  31%|███▏      | 645/2048 [00:02<00:05, 276.60it/s]
Adding requests:  33%|███▎      | 675/2048 [00:02<00:04, 283.24it/s]
Adding requests:  34%|███▍      | 705/2048 [00:02<00:04, 286.48it/s]
Adding requests:  36%|███▌      | 736/2048 [00:02<00:04, 290.54it/s]
Adding requests:  37%|███▋      | 766/2048 [00:02<00:04, 276.23it/s]
Adding requests:  39%|███▉      | 794/2048 [00:02<00:04, 275.23it/s]
Adding requests:  40%|████      | 822/2048 [00:02<00:04, 276.20it/s]
Adding requests:  42%|████▏     | 851/2048 [00:03<00:04, 279.01it/s]
Adding requests:  43%|████▎     | 880/2048 [00:03<00:04, 281.31it/s]
Adding requests:  44%|████▍     | 910/2048 [00:03<00:04, 283.66it/s]
Adding requests:  46%|████▌     | 939/2048 [00:03<00:04, 276.41it/s]
Adding requests:  47%|████▋     | 968/2048 [00:03<00:03, 279.46it/s]
Adding requests:  49%|████▊     | 996/2048 [00:03<00:03, 278.65it/s]
Adding requests:  50%|█████     | 1024/2048 [00:03<00:03, 278.30it/s]
Adding requests:  51%|█████▏    | 1052/2048 [00:03<00:03, 276.48it/s]
Adding requests:  53%|█████▎    | 1081/2048 [00:03<00:03, 277.80it/s]
Adding requests:  54%|█████▍    | 1110/2048 [00:04<00:03, 278.68it/s]
Adding requests:  56%|█████▌    | 1140/2048 [00:04<00:03, 283.08it/s]
Adding requests:  57%|█████▋    | 1172/2048 [00:04<00:02, 292.75it/s]
Adding requests:  59%|█████▊    | 1203/2048 [00:04<00:02, 296.40it/s]
Adding requests:  60%|██████    | 1233/2048 [00:04<00:02, 290.02it/s]
Adding requests:  62%|██████▏   | 1263/2048 [00:04<00:02, 291.39it/s]
Adding requests:  63%|██████▎   | 1294/2048 [00:04<00:02, 296.11it/s]
Adding requests:  65%|██████▍   | 1325/2048 [00:04<00:02, 298.57it/s]
Adding requests:  66%|██████▌   | 1355/2048 [00:04<00:02, 295.35it/s]
Adding requests:  68%|██████▊   | 1385/2048 [00:04<00:02, 292.45it/s]
Adding requests:  69%|██████▉   | 1415/2048 [00:05<00:02, 289.05it/s]
Adding requests:  71%|███████   | 1445/2048 [00:05<00:02, 289.64it/s]
Adding requests:  72%|███████▏  | 1477/2048 [00:05<00:01, 297.68it/s]
Adding requests:  74%|███████▍  | 1511/2048 [00:05<00:01, 307.69it/s]
Adding requests:  75%|███████▌  | 1543/2048 [00:05<00:01, 310.06it/s]
Adding requests:  77%|███████▋  | 1576/2048 [00:05<00:01, 313.01it/s]
Adding requests:  79%|███████▊  | 1611/2048 [00:05<00:01, 319.39it/s]
Adding requests:  80%|████████  | 1644/2048 [00:05<00:01, 321.46it/s]
Adding requests:  82%|████████▏ | 1677/2048 [00:05<00:01, 313.04it/s]
Adding requests:  83%|████████▎ | 1709/2048 [00:06<00:01, 308.90it/s]
Adding requests:  85%|████████▌ | 1741/2048 [00:06<00:00, 310.77it/s]
Adding requests:  87%|████████▋ | 1773/2048 [00:06<00:00, 312.54it/s]
Adding requests:  88%|████████▊ | 1805/2048 [00:06<00:00, 312.56it/s]
Adding requests:  90%|████████▉ | 1837/2048 [00:06<00:00, 312.30it/s]
Adding requests:  91%|█████████▏| 1869/2048 [00:06<00:00, 306.62it/s]
Adding requests:  93%|█████████▎| 1900/2048 [00:06<00:00, 300.33it/s]
Adding requests:  94%|█████████▍| 1931/2048 [00:06<00:00, 297.80it/s]
Adding requests:  96%|█████████▌| 1962/2048 [00:06<00:00, 300.79it/s]
Adding requests:  97%|█████████▋| 1993/2048 [00:06<00:00, 300.47it/s]
Adding requests:  99%|█████████▉| 2024/2048 [00:07<00:00, 296.92it/s]
Adding requests: 100%|██████████| 2048/2048 [00:07<00:00, 287.16it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:00<00:01, 962.28it/s, est. speed input: 985476.90 toks/s, output: 962.31 toks/s]
Processed prompts:  18%|█▊        | 371/2048 [00:02<00:15, 107.89it/s, est. speed input: 137532.22 toks/s, output: 134.31 toks/s]
Processed prompts:  20%|██        | 413/2048 [00:03<00:18, 90.43it/s, est. speed input: 117853.03 toks/s, output: 115.09 toks/s] 
Processed prompts:  21%|██▏       | 439/2048 [00:04<00:22, 72.50it/s, est. speed input: 101828.35 toks/s, output: 99.44 toks/s] 
Processed prompts:  22%|██▏       | 456/2048 [00:04<00:23, 66.89it/s, est. speed input: 96712.58 toks/s, output: 94.45 toks/s] 
Processed prompts:  23%|██▎       | 468/2048 [00:05<00:26, 59.20it/s, est. speed input: 91433.75 toks/s, output: 89.29 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:05<00:29, 53.50it/s, est. speed input: 87285.48 toks/s, output: 85.24 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:06<00:31, 50.00it/s, est. speed input: 84085.29 toks/s, output: 82.11 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:06<00:31, 48.03it/s, est. speed input: 81646.35 toks/s, output: 79.73 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:06<00:32, 46.23it/s, est. speed input: 79399.57 toks/s, output: 77.54 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:07<00:33, 45.07it/s, est. speed input: 77468.39 toks/s, output: 75.65 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:07<00:33, 44.18it/s, est. speed input: 75727.17 toks/s, output: 73.95 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:07<00:34, 43.21it/s, est. speed input: 74062.90 toks/s, output: 72.33 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:08<00:34, 41.82it/s, est. speed input: 72363.77 toks/s, output: 70.67 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:08<00:35, 40.86it/s, est. speed input: 70823.74 toks/s, output: 69.16 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:09<00:35, 40.18it/s, est. speed input: 69419.81 toks/s, output: 67.79 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:09<00:35, 39.70it/s, est. speed input: 68135.84 toks/s, output: 66.54 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:10<00:35, 39.37it/s, est. speed input: 66956.59 toks/s, output: 65.39 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:10<00:35, 39.13it/s, est. speed input: 65870.16 toks/s, output: 64.33 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:10<00:34, 38.97it/s, est. speed input: 64866.18 toks/s, output: 63.35 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:11<00:34, 38.85it/s, est. speed input: 63936.70 toks/s, output: 62.44 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:11<00:34, 38.75it/s, est. speed input: 63068.72 toks/s, output: 61.59 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:12<00:33, 38.69it/s, est. speed input: 62261.62 toks/s, output: 60.80 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:12<00:33, 38.64it/s, est. speed input: 61506.80 toks/s, output: 60.07 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:12<00:32, 38.87it/s, est. speed input: 60845.08 toks/s, output: 59.42 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:13<00:31, 39.69it/s, est. speed input: 60324.88 toks/s, output: 58.91 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:13<00:30, 40.28it/s, est. speed input: 59833.07 toks/s, output: 58.43 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:14<00:30, 40.71it/s, est. speed input: 59369.91 toks/s, output: 57.98 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:14<00:29, 41.02it/s, est. speed input: 58930.31 toks/s, output: 57.55 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:14<00:29, 41.22it/s, est. speed input: 58511.05 toks/s, output: 57.14 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:15<00:28, 41.36it/s, est. speed input: 58113.15 toks/s, output: 56.75 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:15<00:28, 41.46it/s, est. speed input: 57735.08 toks/s, output: 56.38 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:16<00:27, 41.14it/s, est. speed input: 57331.24 toks/s, output: 55.99 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:16<00:28, 40.30it/s, est. speed input: 56877.84 toks/s, output: 55.54 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:16<00:28, 39.73it/s, est. speed input: 56446.85 toks/s, output: 55.12 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:17<00:27, 39.37it/s, est. speed input: 56039.76 toks/s, output: 54.73 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:17<00:27, 39.07it/s, est. speed input: 55645.37 toks/s, output: 54.34 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:18<00:27, 38.87it/s, est. speed input: 55270.66 toks/s, output: 53.98 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:18<00:27, 38.74it/s, est. speed input: 54913.53 toks/s, output: 53.63 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:18<00:26, 38.65it/s, est. speed input: 54572.38 toks/s, output: 53.29 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:19<00:26, 38.60it/s, est. speed input: 54246.45 toks/s, output: 52.97 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:19<00:26, 38.55it/s, est. speed input: 53933.38 toks/s, output: 52.67 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:20<00:25, 38.52it/s, est. speed input: 53633.02 toks/s, output: 52.38 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:20<00:25, 38.49it/s, est. speed input: 53344.54 toks/s, output: 52.09 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:21<00:24, 39.29it/s, est. speed input: 53140.76 toks/s, output: 51.90 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:21<00:23, 39.97it/s, est. speed input: 52952.29 toks/s, output: 51.71 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:21<00:22, 40.45it/s, est. speed input: 52769.42 toks/s, output: 51.53 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:22<00:22, 40.79it/s, est. speed input: 52593.31 toks/s, output: 51.36 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:22<00:21, 41.64it/s, est. speed input: 52467.21 toks/s, output: 51.24 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:22<00:21, 41.63it/s, est. speed input: 52301.36 toks/s, output: 51.08 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:23<00:20, 41.61it/s, est. speed input: 52140.60 toks/s, output: 50.92 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:23<00:07, 103.79it/s, est. speed input: 55105.72 toks/s, output: 53.81 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:23<00:09, 83.42it/s, est. speed input: 54903.48 toks/s, output: 53.62 toks/s] 
Processed prompts:  63%|██████▎   | 1298/2048 [00:24<00:10, 68.85it/s, est. speed input: 54659.01 toks/s, output: 53.38 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:24<00:12, 59.39it/s, est. speed input: 54422.92 toks/s, output: 53.15 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:25<00:13, 53.09it/s, est. speed input: 54194.42 toks/s, output: 52.92 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:25<00:14, 48.83it/s, est. speed input: 53972.90 toks/s, output: 52.71 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:25<00:14, 45.92it/s, est. speed input: 53758.20 toks/s, output: 52.50 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:26<00:15, 43.92it/s, est. speed input: 53550.44 toks/s, output: 52.30 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [00:26<00:15, 42.54it/s, est. speed input: 53349.27 toks/s, output: 52.10 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [00:27<00:15, 41.57it/s, est. speed input: 53153.50 toks/s, output: 51.91 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [00:27<00:15, 40.90it/s, est. speed input: 52964.17 toks/s, output: 51.72 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [00:27<00:14, 40.45it/s, est. speed input: 52780.90 toks/s, output: 51.54 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [00:28<00:14, 40.13it/s, est. speed input: 52602.73 toks/s, output: 51.37 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [00:28<00:14, 39.90it/s, est. speed input: 52429.25 toks/s, output: 51.20 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [00:29<00:14, 39.75it/s, est. speed input: 52261.08 toks/s, output: 51.04 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [00:29<00:13, 39.65it/s, est. speed input: 52097.77 toks/s, output: 50.88 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [00:29<00:13, 39.94it/s, est. speed input: 51960.46 toks/s, output: 50.74 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [00:30<00:12, 40.43it/s, est. speed input: 51842.45 toks/s, output: 50.63 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [00:30<00:12, 40.78it/s, est. speed input: 51727.07 toks/s, output: 50.51 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [00:31<00:11, 41.03it/s, est. speed input: 51614.96 toks/s, output: 50.41 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [00:31<00:11, 41.23it/s, est. speed input: 51506.29 toks/s, output: 50.30 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [00:31<00:10, 41.37it/s, est. speed input: 51400.42 toks/s, output: 50.20 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [00:32<00:10, 40.49it/s, est. speed input: 51247.80 toks/s, output: 50.05 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [00:32<00:10, 39.88it/s, est. speed input: 51097.99 toks/s, output: 49.90 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [00:33<00:10, 39.45it/s, est. speed input: 50951.41 toks/s, output: 49.76 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [00:33<00:09, 39.15it/s, est. speed input: 50808.46 toks/s, output: 49.62 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [00:33<00:09, 38.95it/s, est. speed input: 50669.25 toks/s, output: 49.48 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [00:34<00:09, 38.82it/s, est. speed input: 50533.72 toks/s, output: 49.35 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [00:34<00:08, 38.74it/s, est. speed input: 50401.73 toks/s, output: 49.22 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [00:35<00:08, 38.66it/s, est. speed input: 50272.12 toks/s, output: 49.09 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [00:35<00:07, 38.62it/s, est. speed input: 50146.15 toks/s, output: 48.97 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [00:36<00:07, 38.60it/s, est. speed input: 50023.14 toks/s, output: 48.85 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [00:36<00:06, 38.58it/s, est. speed input: 49902.82 toks/s, output: 48.73 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [00:36<00:06, 38.55it/s, est. speed input: 49784.81 toks/s, output: 48.62 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [00:37<00:06, 38.55it/s, est. speed input: 49669.82 toks/s, output: 48.51 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [00:37<00:05, 38.54it/s, est. speed input: 49557.22 toks/s, output: 48.40 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [00:38<00:05, 38.54it/s, est. speed input: 49447.66 toks/s, output: 48.29 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [00:38<00:04, 39.45it/s, est. speed input: 49380.97 toks/s, output: 48.22 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [00:38<00:04, 40.71it/s, est. speed input: 49340.24 toks/s, output: 48.18 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [00:39<00:03, 41.01it/s, est. speed input: 49275.77 toks/s, output: 48.12 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [00:39<00:03, 41.21it/s, est. speed input: 49211.95 toks/s, output: 48.06 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [00:40<00:03, 41.22it/s, est. speed input: 49144.50 toks/s, output: 47.99 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [00:40<00:02, 40.37it/s, est. speed input: 49044.74 toks/s, output: 47.90 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [00:40<00:02, 39.79it/s, est. speed input: 48947.03 toks/s, output: 47.80 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [00:41<00:01, 39.39it/s, est. speed input: 48850.86 toks/s, output: 47.71 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [00:41<00:01, 39.12it/s, est. speed input: 48757.12 toks/s, output: 47.61 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [00:42<00:01, 38.92it/s, est. speed input: 48664.43 toks/s, output: 47.52 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [00:42<00:00, 38.78it/s, est. speed input: 48573.87 toks/s, output: 47.44 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [00:42<00:00, 39.37it/s, est. speed input: 48511.84 toks/s, output: 47.37 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:42<00:00, 39.37it/s, est. speed input: 48845.30 toks/s, output: 47.70 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [00:42<00:00, 47.70it/s, est. speed input: 48845.30 toks/s, output: 47.70 toks/s]
[rank0]:[W125 22:19:42.967488213 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-25 22:19:45
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:20:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:20:20 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=474678) WARNING 01-25 22:20:27 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=474678) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=474678) WARNING 01-25 22:20:40 [backends.py:609] Failed to read file <frozen os>
Throughput: 39.64 requests/s, 40628.10 total tokens/s, 39.64 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-25 22:20:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:20:19] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:20:19] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:20:19] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:20:19] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:20:19] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:20:19] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:20:19] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:20:19] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:20:19] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:20:19] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:20:19] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:20:19] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:20:19] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:20:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:20:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:20:26] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:20:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:20:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:20:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:20:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:20:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:20:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:20:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:20:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:20:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:20:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:20:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:28] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=474678) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=474678) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.05s/it]
(EngineCore_DP0 pid=474678) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.05s/it]
(EngineCore_DP0 pid=474678) 
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9437184 bytes
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50331648 bytes
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=474678) [2026-01-25 22:20:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25264128 bytes
(EngineCore_DP0 pid=474678) [rank0]:W0125 22:20:48.622000 474678 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=474678) [rank0]:W0125 22:20:48.754000 474678 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=474678) [rank0]:W0125 22:20:50.253000 474678 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=474678) [rank0]:W0125 22:20:50.430000 474678 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=474678) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:01,  7.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  7.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:01,  7.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:00,  7.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  7.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  7.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:00<00:00,  8.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  7.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  5.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  4.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  3.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:02<00:00,  5.49it/s]
(EngineCore_DP0 pid=474678) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:02,  2.35it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:01,  3.82it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  5.27it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  6.38it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  7.17it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  7.78it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  8.17it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:01<00:00,  6.31it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 27/4096 [00:00<00:15, 269.20it/s]
Adding requests:   1%|▏         | 59/4096 [00:00<00:13, 295.89it/s]
Adding requests:   2%|▏         | 89/4096 [00:00<00:13, 294.89it/s]
Adding requests:   3%|▎         | 119/4096 [00:00<00:13, 287.40it/s]
Adding requests:   4%|▎         | 148/4096 [00:00<00:13, 282.24it/s]
Adding requests:   4%|▍         | 177/4096 [00:00<00:14, 278.47it/s]
Adding requests:   5%|▌         | 207/4096 [00:00<00:13, 283.79it/s]
Adding requests:   6%|▌         | 236/4096 [00:00<00:13, 284.09it/s]
Adding requests:   6%|▋         | 266/4096 [00:00<00:13, 286.83it/s]
Adding requests:   7%|▋         | 296/4096 [00:01<00:13, 288.89it/s]
Adding requests:   8%|▊         | 326/4096 [00:01<00:12, 290.12it/s]
Adding requests:   9%|▊         | 358/4096 [00:01<00:12, 295.76it/s]
Adding requests:   9%|▉         | 388/4096 [00:01<00:12, 294.02it/s]
Adding requests:  10%|█         | 418/4096 [00:01<00:12, 283.39it/s]
Adding requests:  11%|█         | 448/4096 [00:01<00:12, 286.42it/s]
Adding requests:  12%|█▏        | 479/4096 [00:01<00:12, 292.20it/s]
Adding requests:  12%|█▏        | 509/4096 [00:01<00:12, 292.48it/s]
Adding requests:  13%|█▎        | 539/4096 [00:01<00:12, 287.82it/s]
Adding requests:  14%|█▍        | 569/4096 [00:01<00:12, 291.11it/s]
Adding requests:  15%|█▍        | 599/4096 [00:02<00:12, 284.95it/s]
Adding requests:  15%|█▌        | 628/4096 [00:02<00:12, 284.01it/s]
Adding requests:  16%|█▌        | 657/4096 [00:02<00:12, 282.41it/s]
Adding requests:  17%|█▋        | 687/4096 [00:02<00:11, 284.91it/s]
Adding requests:  17%|█▋        | 716/4096 [00:02<00:11, 283.86it/s]
Adding requests:  18%|█▊        | 745/4096 [00:02<00:11, 282.41it/s]
Adding requests:  19%|█▉        | 774/4096 [00:02<00:11, 282.40it/s]
Adding requests:  20%|█▉        | 803/4096 [00:02<00:11, 278.50it/s]
Adding requests:  20%|██        | 831/4096 [00:02<00:12, 268.27it/s]
Adding requests:  21%|██        | 859/4096 [00:03<00:12, 269.48it/s]
Adding requests:  22%|██▏       | 887/4096 [00:03<00:11, 270.83it/s]
Adding requests:  22%|██▏       | 916/4096 [00:03<00:11, 275.09it/s]
Adding requests:  23%|██▎       | 944/4096 [00:03<00:11, 274.60it/s]
Adding requests:  24%|██▎       | 972/4096 [00:03<00:11, 274.21it/s]
Adding requests:  24%|██▍       | 1000/4096 [00:03<00:11, 273.27it/s]
Adding requests:  25%|██▌       | 1028/4096 [00:03<00:11, 272.84it/s]
Adding requests:  26%|██▌       | 1056/4096 [00:03<00:11, 272.62it/s]
Adding requests:  26%|██▋       | 1084/4096 [00:03<00:11, 270.30it/s]
Adding requests:  27%|██▋       | 1112/4096 [00:03<00:11, 270.85it/s]
Adding requests:  28%|██▊       | 1141/4096 [00:04<00:10, 274.19it/s]
Adding requests:  29%|██▊       | 1173/4096 [00:04<00:10, 287.34it/s]
Adding requests:  29%|██▉       | 1202/4096 [00:04<00:10, 283.06it/s]
Adding requests:  30%|███       | 1233/4096 [00:04<00:09, 288.65it/s]
Adding requests:  31%|███       | 1263/4096 [00:04<00:09, 290.11it/s]
Adding requests:  32%|███▏      | 1293/4096 [00:04<00:09, 292.63it/s]
Adding requests:  32%|███▏      | 1325/4096 [00:04<00:09, 297.83it/s]
Adding requests:  33%|███▎      | 1355/4096 [00:04<00:09, 288.38it/s]
Adding requests:  34%|███▍      | 1384/4096 [00:04<00:09, 288.57it/s]
Adding requests:  35%|███▍      | 1414/4096 [00:04<00:09, 291.13it/s]
Adding requests:  35%|███▌      | 1444/4096 [00:05<00:09, 289.00it/s]
Adding requests:  36%|███▌      | 1476/4096 [00:05<00:08, 296.42it/s]
Adding requests:  37%|███▋      | 1506/4096 [00:05<00:08, 288.62it/s]
Adding requests:  37%|███▋      | 1535/4096 [00:05<00:09, 277.23it/s]
Adding requests:  38%|███▊      | 1563/4096 [00:05<00:09, 265.19it/s]
Adding requests:  39%|███▉      | 1590/4096 [00:05<00:09, 259.97it/s]
Adding requests:  39%|███▉      | 1617/4096 [00:05<00:09, 262.35it/s]
Adding requests:  40%|████      | 1645/4096 [00:05<00:09, 265.80it/s]
Adding requests:  41%|████      | 1674/4096 [00:05<00:08, 272.51it/s]
Adding requests:  42%|████▏     | 1705/4096 [00:06<00:08, 282.60it/s]
Adding requests:  42%|████▏     | 1736/4096 [00:06<00:08, 289.77it/s]
Adding requests:  43%|████▎     | 1766/4096 [00:06<00:08, 289.67it/s]
Adding requests:  44%|████▍     | 1796/4096 [00:06<00:08, 285.89it/s]
Adding requests:  45%|████▍     | 1826/4096 [00:06<00:07, 287.16it/s]
Adding requests:  45%|████▌     | 1857/4096 [00:06<00:07, 293.75it/s]
Adding requests:  46%|████▌     | 1888/4096 [00:06<00:07, 295.97it/s]
Adding requests:  47%|████▋     | 1918/4096 [00:06<00:07, 289.02it/s]
Adding requests:  48%|████▊     | 1947/4096 [00:06<00:07, 286.06it/s]
Adding requests:  48%|████▊     | 1976/4096 [00:06<00:07, 279.97it/s]
Adding requests:  49%|████▉     | 2006/4096 [00:07<00:07, 283.55it/s]
Adding requests:  50%|████▉     | 2037/4096 [00:07<00:07, 291.09it/s]
Adding requests:  50%|█████     | 2068/4096 [00:07<00:06, 296.24it/s]
Adding requests:  51%|█████▏    | 2101/4096 [00:07<00:06, 303.26it/s]
Adding requests:  52%|█████▏    | 2132/4096 [00:07<00:06, 299.46it/s]
Adding requests:  53%|█████▎    | 2162/4096 [00:07<00:06, 296.56it/s]
Adding requests:  54%|█████▎    | 2194/4096 [00:07<00:06, 302.99it/s]
Adding requests:  54%|█████▍    | 2227/4096 [00:07<00:06, 308.10it/s]
Adding requests:  55%|█████▌    | 2258/4096 [00:07<00:05, 308.58it/s]
Adding requests:  56%|█████▌    | 2289/4096 [00:08<00:06, 300.07it/s]
Adding requests:  57%|█████▋    | 2320/4096 [00:08<00:05, 298.80it/s]
Adding requests:  57%|█████▋    | 2352/4096 [00:08<00:05, 302.78it/s]
Adding requests:  58%|█████▊    | 2383/4096 [00:08<00:05, 289.58it/s]
Adding requests:  59%|█████▉    | 2413/4096 [00:08<00:06, 273.72it/s]
Adding requests:  60%|█████▉    | 2443/4096 [00:08<00:05, 279.03it/s]
Adding requests:  60%|██████    | 2472/4096 [00:08<00:05, 277.43it/s]
Adding requests:  61%|██████    | 2501/4096 [00:08<00:05, 279.18it/s]
Adding requests:  62%|██████▏   | 2530/4096 [00:08<00:05, 276.30it/s]
Adding requests:  62%|██████▏   | 2559/4096 [00:08<00:05, 280.21it/s]
Adding requests:  63%|██████▎   | 2588/4096 [00:09<00:05, 280.07it/s]
Adding requests:  64%|██████▍   | 2617/4096 [00:09<00:05, 276.76it/s]
Adding requests:  65%|██████▍   | 2647/4096 [00:09<00:05, 281.79it/s]
Adding requests:  65%|██████▌   | 2676/4096 [00:09<00:05, 279.57it/s]
Adding requests:  66%|██████▌   | 2704/4096 [00:09<00:05, 276.76it/s]
Adding requests:  67%|██████▋   | 2732/4096 [00:09<00:04, 274.13it/s]
Adding requests:  67%|██████▋   | 2761/4096 [00:09<00:04, 276.20it/s]
Adding requests:  68%|██████▊   | 2789/4096 [00:09<00:04, 276.71it/s]
Adding requests:  69%|██████▉   | 2818/4096 [00:09<00:04, 278.52it/s]
Adding requests:  69%|██████▉   | 2846/4096 [00:10<00:04, 278.08it/s]
Adding requests:  70%|███████   | 2874/4096 [00:10<00:04, 274.30it/s]
Adding requests:  71%|███████   | 2906/4096 [00:10<00:04, 285.96it/s]
Adding requests:  72%|███████▏  | 2935/4096 [00:10<00:04, 283.37it/s]
Adding requests:  72%|███████▏  | 2964/4096 [00:10<00:04, 282.60it/s]
Adding requests:  73%|███████▎  | 2995/4096 [00:10<00:03, 289.64it/s]
Adding requests:  74%|███████▍  | 3025/4096 [00:10<00:03, 292.62it/s]
Adding requests:  75%|███████▍  | 3056/4096 [00:10<00:03, 296.31it/s]
Adding requests:  75%|███████▌  | 3086/4096 [00:10<00:03, 293.90it/s]
Adding requests:  76%|███████▌  | 3118/4096 [00:10<00:03, 300.51it/s]
Adding requests:  77%|███████▋  | 3149/4096 [00:11<00:03, 292.89it/s]
Adding requests:  78%|███████▊  | 3179/4096 [00:11<00:03, 284.35it/s]
Adding requests:  78%|███████▊  | 3208/4096 [00:11<00:03, 282.43it/s]
Adding requests:  79%|███████▉  | 3239/4096 [00:11<00:02, 290.08it/s]
Adding requests:  80%|███████▉  | 3269/4096 [00:11<00:02, 283.59it/s]
Adding requests:  81%|████████  | 3298/4096 [00:11<00:02, 285.39it/s]
Adding requests:  81%|████████  | 3327/4096 [00:11<00:02, 277.24it/s]
Adding requests:  82%|████████▏ | 3357/4096 [00:11<00:02, 282.50it/s]
Adding requests:  83%|████████▎ | 3386/4096 [00:11<00:02, 281.90it/s]
Adding requests:  83%|████████▎ | 3415/4096 [00:12<00:02, 280.98it/s]
Adding requests:  84%|████████▍ | 3444/4096 [00:12<00:02, 277.15it/s]
Adding requests:  85%|████████▍ | 3472/4096 [00:12<00:02, 271.00it/s]
Adding requests:  85%|████████▌ | 3501/4096 [00:12<00:02, 275.90it/s]
Adding requests:  86%|████████▌ | 3529/4096 [00:12<00:02, 276.46it/s]
Adding requests:  87%|████████▋ | 3559/4096 [00:12<00:01, 280.61it/s]
Adding requests:  88%|████████▊ | 3588/4096 [00:12<00:01, 281.03it/s]
Adding requests:  88%|████████▊ | 3617/4096 [00:12<00:01, 280.73it/s]
Adding requests:  89%|████████▉ | 3646/4096 [00:12<00:01, 275.24it/s]
Adding requests:  90%|████████▉ | 3675/4096 [00:12<00:01, 277.92it/s]
Adding requests:  90%|█████████ | 3704/4096 [00:13<00:01, 280.27it/s]
Adding requests:  91%|█████████ | 3733/4096 [00:13<00:01, 279.55it/s]
Adding requests:  92%|█████████▏| 3761/4096 [00:13<00:01, 262.96it/s]
Adding requests:  93%|█████████▎| 3789/4096 [00:13<00:01, 266.95it/s]
Adding requests:  93%|█████████▎| 3820/4096 [00:13<00:00, 276.38it/s]
Adding requests:  94%|█████████▍| 3850/4096 [00:13<00:00, 282.12it/s]
Adding requests:  95%|█████████▍| 3881/4096 [00:13<00:00, 290.11it/s]
Adding requests:  96%|█████████▌| 3913/4096 [00:13<00:00, 297.06it/s]
Adding requests:  96%|█████████▋| 3946/4096 [00:13<00:00, 304.58it/s]
Adding requests:  97%|█████████▋| 3979/4096 [00:13<00:00, 309.78it/s]
Adding requests:  98%|█████████▊| 4011/4096 [00:14<00:00, 309.55it/s]
Adding requests:  99%|█████████▊| 4043/4096 [00:14<00:00, 309.81it/s]
Adding requests: 100%|█████████▉| 4077/4096 [00:14<00:00, 317.07it/s]
Adding requests: 100%|██████████| 4096/4096 [00:14<00:00, 285.29it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [00:00<00:04, 792.77it/s, est. speed input: 811832.81 toks/s, output: 792.78 toks/s]
Processed prompts:  15%|█▌        | 626/4096 [00:02<00:15, 227.29it/s, est. speed input: 286152.18 toks/s, output: 279.44 toks/s]
Processed prompts:  16%|█▌        | 662/4096 [00:03<00:21, 159.83it/s, est. speed input: 221080.28 toks/s, output: 215.90 toks/s]
Processed prompts:  17%|█▋        | 684/4096 [00:03<00:29, 113.95it/s, est. speed input: 179902.19 toks/s, output: 175.69 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [00:04<00:39, 85.15it/s, est. speed input: 153154.95 toks/s, output: 149.56 toks/s] 
Processed prompts:  18%|█▊        | 738/4096 [00:05<00:47, 70.26it/s, est. speed input: 136217.67 toks/s, output: 133.02 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [00:06<00:55, 60.34it/s, est. speed input: 123676.82 toks/s, output: 120.78 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [00:07<01:00, 54.31it/s, est. speed input: 114548.55 toks/s, output: 111.86 toks/s]
Processed prompts:  20%|██        | 834/4096 [00:07<01:04, 50.66it/s, est. speed input: 107636.49 toks/s, output: 105.11 toks/s]
Processed prompts:  21%|██        | 866/4096 [00:08<01:07, 48.06it/s, est. speed input: 101939.74 toks/s, output: 99.55 toks/s] 
Processed prompts:  22%|██▏       | 898/4096 [00:09<01:09, 46.21it/s, est. speed input: 97161.72 toks/s, output: 94.88 toks/s] 
Processed prompts:  23%|██▎       | 930/4096 [00:10<01:11, 44.45it/s, est. speed input: 92858.68 toks/s, output: 90.68 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [00:11<01:13, 42.61it/s, est. speed input: 88868.29 toks/s, output: 86.79 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [00:11<01:14, 41.37it/s, est. speed input: 85433.06 toks/s, output: 83.43 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [00:12<00:47, 63.94it/s, est. speed input: 87525.10 toks/s, output: 85.47 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [00:13<00:52, 56.23it/s, est. speed input: 84590.61 toks/s, output: 82.61 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [00:14<00:57, 51.26it/s, est. speed input: 82107.28 toks/s, output: 80.18 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [00:15<01:01, 47.41it/s, est. speed input: 79783.75 toks/s, output: 77.91 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [00:15<01:02, 45.76it/s, est. speed input: 77999.35 toks/s, output: 76.17 toks/s]
Processed prompts:  31%|███       | 1250/4096 [00:16<01:03, 44.60it/s, est. speed input: 76388.00 toks/s, output: 74.60 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [00:17<01:04, 43.78it/s, est. speed input: 74921.77 toks/s, output: 73.17 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [00:18<01:05, 42.73it/s, est. speed input: 73463.15 toks/s, output: 71.74 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [00:19<01:06, 41.44it/s, est. speed input: 71993.04 toks/s, output: 70.31 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [00:19<01:06, 40.58it/s, est. speed input: 70646.92 toks/s, output: 68.99 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [00:20<01:07, 39.98it/s, est. speed input: 69407.92 toks/s, output: 67.78 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [00:21<01:07, 39.56it/s, est. speed input: 68263.57 toks/s, output: 66.66 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [00:22<01:06, 39.28it/s, est. speed input: 67204.74 toks/s, output: 65.63 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [00:23<01:06, 39.09it/s, est. speed input: 66222.57 toks/s, output: 64.67 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [00:24<01:04, 39.44it/s, est. speed input: 65398.76 toks/s, output: 63.87 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [00:24<01:02, 40.14it/s, est. speed input: 64706.83 toks/s, output: 63.19 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [00:25<01:01, 40.65it/s, est. speed input: 64057.12 toks/s, output: 62.56 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [00:26<01:00, 40.51it/s, est. speed input: 63365.00 toks/s, output: 61.88 toks/s]
Processed prompts:  41%|████      | 1666/4096 [00:27<01:00, 39.89it/s, est. speed input: 62635.88 toks/s, output: 61.17 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [00:28<01:00, 39.48it/s, est. speed input: 61951.40 toks/s, output: 60.50 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [00:28<01:00, 39.24it/s, est. speed input: 61311.49 toks/s, output: 59.87 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [00:29<00:59, 39.07it/s, est. speed input: 60708.02 toks/s, output: 59.29 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [00:30<00:59, 38.95it/s, est. speed input: 60136.36 toks/s, output: 58.73 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [00:31<00:58, 39.08it/s, est. speed input: 59623.36 toks/s, output: 58.23 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [00:32<00:55, 40.18it/s, est. speed input: 59261.94 toks/s, output: 57.87 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [00:32<00:54, 40.68it/s, est. speed input: 58881.52 toks/s, output: 57.50 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [00:33<00:52, 41.04it/s, est. speed input: 58518.71 toks/s, output: 57.15 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [00:34<00:52, 40.79it/s, est. speed input: 58118.33 toks/s, output: 56.76 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [00:35<00:52, 40.18it/s, est. speed input: 57689.34 toks/s, output: 56.34 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [00:36<00:52, 39.77it/s, est. speed input: 57279.90 toks/s, output: 55.94 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [00:36<00:51, 39.47it/s, est. speed input: 56887.76 toks/s, output: 55.55 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [00:37<00:51, 39.28it/s, est. speed input: 56513.57 toks/s, output: 55.19 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [00:38<00:50, 39.14it/s, est. speed input: 56155.65 toks/s, output: 54.84 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [00:39<00:48, 39.87it/s, est. speed input: 55892.26 toks/s, output: 54.58 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [00:40<00:47, 40.46it/s, est. speed input: 55644.60 toks/s, output: 54.34 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [00:40<00:46, 40.87it/s, est. speed input: 55405.94 toks/s, output: 54.11 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [00:41<00:45, 41.17it/s, est. speed input: 55175.82 toks/s, output: 53.88 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [00:42<00:44, 40.90it/s, est. speed input: 54915.29 toks/s, output: 53.63 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [00:43<00:27, 63.45it/s, est. speed input: 56090.57 toks/s, output: 54.78 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [00:44<00:30, 55.88it/s, est. speed input: 55780.46 toks/s, output: 54.47 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [00:44<00:32, 50.65it/s, est. speed input: 55482.11 toks/s, output: 54.18 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [00:45<00:34, 47.02it/s, est. speed input: 55194.33 toks/s, output: 53.90 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [00:46<00:35, 44.84it/s, est. speed input: 54942.08 toks/s, output: 53.65 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [00:47<00:36, 43.48it/s, est. speed input: 54711.12 toks/s, output: 53.43 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [00:48<00:35, 43.02it/s, est. speed input: 54523.03 toks/s, output: 53.25 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [00:48<00:35, 42.68it/s, est. speed input: 54340.78 toks/s, output: 53.07 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [00:49<00:34, 42.44it/s, est. speed input: 54164.34 toks/s, output: 52.89 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [00:50<00:34, 41.78it/s, est. speed input: 53960.37 toks/s, output: 52.70 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [00:51<00:34, 40.81it/s, est. speed input: 53728.36 toks/s, output: 52.47 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [00:52<00:34, 40.17it/s, est. speed input: 53505.07 toks/s, output: 52.25 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [00:52<00:33, 39.68it/s, est. speed input: 53285.73 toks/s, output: 52.04 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [00:53<00:33, 39.37it/s, est. speed input: 53074.36 toks/s, output: 51.83 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [00:54<00:32, 39.18it/s, est. speed input: 52871.58 toks/s, output: 51.63 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [00:55<00:31, 38.99it/s, est. speed input: 52670.79 toks/s, output: 51.44 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [00:56<00:31, 38.97it/s, est. speed input: 52483.56 toks/s, output: 51.25 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [00:56<00:29, 39.80it/s, est. speed input: 52354.77 toks/s, output: 51.13 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [00:57<00:28, 40.40it/s, est. speed input: 52229.51 toks/s, output: 51.01 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [00:58<00:27, 40.27it/s, est. speed input: 52075.10 toks/s, output: 50.85 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [00:59<00:27, 39.73it/s, est. speed input: 51898.58 toks/s, output: 50.68 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [01:00<00:26, 39.40it/s, est. speed input: 51729.37 toks/s, output: 50.52 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [01:01<00:26, 39.18it/s, est. speed input: 51564.59 toks/s, output: 50.36 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [01:01<00:25, 39.01it/s, est. speed input: 51403.89 toks/s, output: 50.20 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [01:02<00:24, 38.90it/s, est. speed input: 51247.67 toks/s, output: 50.05 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [01:03<00:23, 39.31it/s, est. speed input: 51122.82 toks/s, output: 49.92 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [01:04<00:22, 40.04it/s, est. speed input: 51024.67 toks/s, output: 49.83 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [01:05<00:21, 40.57it/s, est. speed input: 50928.52 toks/s, output: 49.73 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [01:05<00:20, 40.95it/s, est. speed input: 50834.81 toks/s, output: 49.64 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [01:06<00:19, 40.63it/s, est. speed input: 50714.68 toks/s, output: 49.53 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [01:07<00:19, 40.01it/s, est. speed input: 50577.58 toks/s, output: 49.39 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [01:08<00:18, 39.58it/s, est. speed input: 50443.55 toks/s, output: 49.26 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [01:09<00:17, 39.29it/s, est. speed input: 50313.19 toks/s, output: 49.13 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [01:09<00:17, 39.09it/s, est. speed input: 50185.86 toks/s, output: 49.01 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [01:10<00:16, 38.95it/s, est. speed input: 50061.27 toks/s, output: 48.89 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [01:11<00:15, 39.54it/s, est. speed input: 49972.81 toks/s, output: 48.80 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [01:12<00:14, 40.20it/s, est. speed input: 49897.34 toks/s, output: 48.73 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [01:13<00:13, 40.68it/s, est. speed input: 49823.40 toks/s, output: 48.66 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [01:13<00:12, 41.02it/s, est. speed input: 49751.07 toks/s, output: 48.59 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [01:14<00:06, 68.98it/s, est. speed input: 50634.35 toks/s, output: 49.45 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [01:15<00:06, 59.61it/s, est. speed input: 50525.61 toks/s, output: 49.34 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [01:16<00:06, 53.34it/s, est. speed input: 50419.06 toks/s, output: 49.24 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [01:16<00:06, 49.09it/s, est. speed input: 50314.82 toks/s, output: 49.14 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [01:17<00:06, 46.17it/s, est. speed input: 50212.49 toks/s, output: 49.04 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [01:18<00:05, 44.15it/s, est. speed input: 50112.20 toks/s, output: 48.94 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [01:19<00:05, 42.76it/s, est. speed input: 50014.24 toks/s, output: 48.84 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [01:20<00:04, 41.79it/s, est. speed input: 49918.29 toks/s, output: 48.75 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [01:20<00:03, 41.80it/s, est. speed input: 49851.31 toks/s, output: 48.68 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [01:21<00:03, 41.81it/s, est. speed input: 49785.57 toks/s, output: 48.62 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [01:22<00:02, 41.50it/s, est. speed input: 49709.14 toks/s, output: 48.54 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [01:23<00:01, 40.93it/s, est. speed input: 49620.79 toks/s, output: 48.46 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [01:24<00:00, 40.62it/s, est. speed input: 49537.30 toks/s, output: 48.38 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:24<00:00, 40.62it/s, est. speed input: 49902.42 toks/s, output: 48.73 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [01:24<00:00, 48.73it/s, est. speed input: 49902.42 toks/s, output: 48.73 toks/s]
[rank0]:[W125 22:22:38.543387868 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-25 22:22:42
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Llama3.2-3B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:23:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 22:23:44 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=477848) WARNING 01-25 22:23:52 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=477848) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=477848) WARNING 01-25 22:24:03 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.73 requests/s, 18176.32 total tokens/s, 17.73 output tokens/s
Total num prompt tokens:  8388608
Total num output tokens:  8192

STDERR:
[2026-01-25 22:23:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:23:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:23:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:23:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:23:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:23:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:23:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:23:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:23:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:23:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:23:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:23:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:23:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:23:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:23:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:23:51] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-25 22:23:51] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-25 22:23:51] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:23:51] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:23:51] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:23:51] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:23:51] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-25 22:23:51] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-25 22:23:51] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:23:51] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:23:51] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:23:51] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:23:51] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=477848) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=477848) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.00s/it]
(EngineCore_DP0 pid=477848) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.00s/it]
(EngineCore_DP0 pid=477848) 
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4096] -> 1D uint8
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4096] -> 1D uint8
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9437184 bytes
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4096] -> 1D uint8
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50331648 bytes
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 10944] -> 1D uint8
(EngineCore_DP0 pid=477848) [2026-01-25 22:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25264128 bytes
(EngineCore_DP0 pid=477848) [rank0]:W0125 22:24:12.231000 477848 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=477848) [rank0]:W0125 22:24:12.350000 477848 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=477848) [rank0]:W0125 22:24:14.245000 477848 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=477848) [rank0]:W0125 22:24:14.436000 477848 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=477848) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:07,  2.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:01<00:11,  1.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:01<00:07,  2.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:02<00:07,  2.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:02<00:05,  2.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:02<00:03,  3.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:02<00:02,  4.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:02<00:02,  4.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:02<00:01,  5.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:02<00:01,  5.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:03<00:01,  6.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:03<00:01,  6.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:03<00:00,  7.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:03<00:00,  7.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:03<00:00,  7.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:03<00:00,  7.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:03<00:00,  7.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:03<00:00,  7.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:04<00:00,  5.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:04<00:00,  4.53it/s]
(EngineCore_DP0 pid=477848) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:05,  1.78it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:03,  2.88it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:01<00:02,  2.86it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:01<00:02,  3.20it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:01<00:01,  4.12it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:01<00:01,  4.97it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:01<00:00,  5.86it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:01<00:00,  6.59it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  7.25it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:02<00:00,  7.76it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:02<00:00,  8.17it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:02<00:00,  5.12it/s]

Adding requests:   0%|          | 0/8192 [00:00<?, ?it/s]
Adding requests:   0%|          | 29/8192 [00:00<00:29, 281.24it/s]
Adding requests:   1%|          | 58/8192 [00:00<00:28, 285.72it/s]
Adding requests:   1%|          | 90/8192 [00:00<00:27, 299.48it/s]
Adding requests:   1%|▏         | 121/8192 [00:00<00:26, 299.91it/s]
Adding requests:   2%|▏         | 151/8192 [00:00<00:26, 299.90it/s]
Adding requests:   2%|▏         | 181/8192 [00:00<00:28, 280.91it/s]
Adding requests:   3%|▎         | 210/8192 [00:00<00:28, 280.80it/s]
Adding requests:   3%|▎         | 239/8192 [00:00<00:28, 283.02it/s]
Adding requests:   3%|▎         | 269/8192 [00:00<00:27, 286.82it/s]
Adding requests:   4%|▎         | 298/8192 [00:01<00:27, 285.56it/s]
Adding requests:   4%|▍         | 327/8192 [00:01<00:28, 279.43it/s]
Adding requests:   4%|▍         | 356/8192 [00:01<00:27, 281.03it/s]
Adding requests:   5%|▍         | 385/8192 [00:01<00:27, 279.36it/s]
Adding requests:   5%|▌         | 413/8192 [00:01<00:28, 274.70it/s]
Adding requests:   5%|▌         | 443/8192 [00:01<00:27, 280.21it/s]
Adding requests:   6%|▌         | 472/8192 [00:01<00:27, 278.72it/s]
Adding requests:   6%|▌         | 500/8192 [00:01<00:27, 277.08it/s]
Adding requests:   6%|▋         | 528/8192 [00:01<00:28, 268.97it/s]
Adding requests:   7%|▋         | 558/8192 [00:01<00:27, 277.11it/s]
Adding requests:   7%|▋         | 588/8192 [00:02<00:27, 281.27it/s]
Adding requests:   8%|▊         | 617/8192 [00:02<00:27, 272.50it/s]
Adding requests:   8%|▊         | 645/8192 [00:02<00:27, 272.84it/s]
Adding requests:   8%|▊         | 673/8192 [00:02<00:27, 273.80it/s]
Adding requests:   9%|▊         | 703/8192 [00:02<00:26, 280.62it/s]
Adding requests:   9%|▉         | 732/8192 [00:02<00:26, 283.18it/s]
Adding requests:   9%|▉         | 761/8192 [00:02<00:28, 264.76it/s]
Adding requests:  10%|▉         | 788/8192 [00:02<00:29, 251.12it/s]
Adding requests:  10%|▉         | 814/8192 [00:02<00:29, 249.73it/s]
Adding requests:  10%|█         | 842/8192 [00:03<00:28, 257.94it/s]
Adding requests:  11%|█         | 870/8192 [00:03<00:27, 263.77it/s]
Adding requests:  11%|█         | 899/8192 [00:03<00:27, 270.07it/s]
Adding requests:  17%|█▋        | 1399/8192 [00:03<00:04, 1644.14it/s]
Adding requests:  19%|█▉        | 1568/8192 [00:03<00:09, 674.09it/s] 
Adding requests:  21%|██        | 1695/8192 [00:04<00:12, 507.12it/s]
Adding requests:  22%|██▏       | 1792/8192 [00:04<00:15, 426.31it/s]
Adding requests:  23%|██▎       | 1868/8192 [00:05<00:16, 386.88it/s]
Adding requests:  24%|██▎       | 1930/8192 [00:05<00:17, 356.51it/s]
Adding requests:  24%|██▍       | 1981/8192 [00:05<00:18, 344.67it/s]
Adding requests:  25%|██▍       | 2026/8192 [00:05<00:18, 332.92it/s]
Adding requests:  25%|██▌       | 2066/8192 [00:05<00:18, 329.16it/s]
Adding requests:  26%|██▌       | 2104/8192 [00:05<00:18, 322.11it/s]
Adding requests:  26%|██▌       | 2140/8192 [00:05<00:19, 315.01it/s]
Adding requests:  27%|██▋       | 2174/8192 [00:06<00:19, 312.57it/s]
Adding requests:  27%|██▋       | 2207/8192 [00:06<00:19, 313.07it/s]
Adding requests:  27%|██▋       | 2240/8192 [00:06<00:19, 311.93it/s]
Adding requests:  28%|██▊       | 2272/8192 [00:06<00:18, 311.84it/s]
Adding requests:  28%|██▊       | 2304/8192 [00:06<00:19, 303.16it/s]
Adding requests:  29%|██▊       | 2335/8192 [00:06<00:19, 300.91it/s]
Adding requests:  29%|██▉       | 2367/8192 [00:06<00:19, 305.89it/s]
Adding requests:  29%|██▉       | 2399/8192 [00:06<00:18, 309.16it/s]
Adding requests:  30%|██▉       | 2431/8192 [00:06<00:18, 311.83it/s]
Adding requests:  30%|███       | 2463/8192 [00:07<00:18, 307.99it/s]
Adding requests:  30%|███       | 2494/8192 [00:07<00:18, 307.98it/s]
Adding requests:  31%|███       | 2525/8192 [00:07<00:18, 301.18it/s]
Adding requests:  31%|███       | 2557/8192 [00:07<00:18, 304.28it/s]
Adding requests:  32%|███▏      | 2589/8192 [00:07<00:18, 307.98it/s]
Adding requests:  32%|███▏      | 2620/8192 [00:07<00:18, 306.65it/s]
Adding requests:  32%|███▏      | 2653/8192 [00:07<00:17, 311.43it/s]
Adding requests:  33%|███▎      | 2685/8192 [00:07<00:17, 313.31it/s]
Adding requests:  33%|███▎      | 2717/8192 [00:07<00:17, 307.40it/s]
Adding requests:  34%|███▎      | 2749/8192 [00:07<00:17, 309.57it/s]
Adding requests:  34%|███▍      | 2780/8192 [00:08<00:17, 306.59it/s]
Adding requests:  34%|███▍      | 2811/8192 [00:08<00:17, 307.38it/s]
Adding requests:  35%|███▍      | 2842/8192 [00:08<00:17, 306.05it/s]
Adding requests:  35%|███▌      | 2874/8192 [00:08<00:17, 308.54it/s]
Adding requests:  35%|███▌      | 2905/8192 [00:08<00:17, 307.83it/s]
Adding requests:  36%|███▌      | 2936/8192 [00:08<00:17, 302.45it/s]
Adding requests:  36%|███▋      | 2970/8192 [00:08<00:16, 310.92it/s]
Adding requests:  37%|███▋      | 3002/8192 [00:08<00:16, 305.47it/s]
Adding requests:  37%|███▋      | 3033/8192 [00:08<00:17, 302.36it/s]
Adding requests:  37%|███▋      | 3064/8192 [00:09<00:17, 297.87it/s]
Adding requests:  38%|███▊      | 3095/8192 [00:09<00:17, 299.27it/s]
Adding requests:  38%|███▊      | 3125/8192 [00:09<00:17, 289.25it/s]
Adding requests:  39%|███▊      | 3154/8192 [00:09<00:19, 258.02it/s]
Adding requests:  39%|███▉      | 3185/8192 [00:09<00:18, 269.77it/s]
Adding requests:  39%|███▉      | 3213/8192 [00:09<00:18, 270.12it/s]
Adding requests:  40%|███▉      | 3243/8192 [00:09<00:17, 275.52it/s]
Adding requests:  40%|███▉      | 3271/8192 [00:09<00:17, 276.47it/s]
Adding requests:  40%|████      | 3300/8192 [00:09<00:17, 279.13it/s]
Adding requests:  41%|████      | 3329/8192 [00:09<00:17, 280.64it/s]
Adding requests:  41%|████      | 3358/8192 [00:10<00:17, 281.53it/s]
Adding requests:  41%|████▏     | 3388/8192 [00:10<00:16, 285.21it/s]
Adding requests:  42%|████▏     | 3419/8192 [00:10<00:16, 290.01it/s]
Adding requests:  42%|████▏     | 3449/8192 [00:10<00:16, 284.25it/s]
Adding requests:  42%|████▏     | 3478/8192 [00:10<00:16, 282.71it/s]
Adding requests:  43%|████▎     | 3507/8192 [00:10<00:16, 283.84it/s]
Adding requests:  43%|████▎     | 3536/8192 [00:10<00:16, 282.19it/s]
Adding requests:  44%|████▎     | 3565/8192 [00:10<00:16, 282.95it/s]
Adding requests:  44%|████▍     | 3595/8192 [00:10<00:16, 285.06it/s]
Adding requests:  44%|████▍     | 3624/8192 [00:11<00:16, 283.52it/s]
Adding requests:  45%|████▍     | 3653/8192 [00:11<00:15, 284.49it/s]
Adding requests:  45%|████▍     | 3682/8192 [00:11<00:16, 281.72it/s]
Adding requests:  45%|████▌     | 3711/8192 [00:11<00:15, 283.64it/s]
Adding requests:  46%|████▌     | 3740/8192 [00:11<00:16, 266.58it/s]
Adding requests:  46%|████▌     | 3769/8192 [00:11<00:16, 271.83it/s]
Adding requests:  46%|████▋     | 3800/8192 [00:11<00:15, 281.10it/s]
Adding requests:  47%|████▋     | 3829/8192 [00:11<00:15, 283.47it/s]
Adding requests:  47%|████▋     | 3861/8192 [00:11<00:14, 291.28it/s]
Adding requests:  47%|████▋     | 3891/8192 [00:11<00:14, 290.37it/s]
Adding requests:  48%|████▊     | 3922/8192 [00:12<00:14, 296.09it/s]
Adding requests:  48%|████▊     | 3953/8192 [00:12<00:14, 299.62it/s]
Adding requests:  49%|████▊     | 3984/8192 [00:12<00:14, 298.91it/s]
Adding requests:  49%|████▉     | 4015/8192 [00:12<00:13, 301.73it/s]
Adding requests:  49%|████▉     | 4046/8192 [00:12<00:14, 291.20it/s]
Adding requests:  50%|████▉     | 4077/8192 [00:12<00:13, 294.31it/s]
Adding requests:  50%|█████     | 4107/8192 [00:12<00:13, 294.52it/s]
Adding requests:  51%|█████     | 4137/8192 [00:12<00:13, 291.76it/s]
Adding requests:  51%|█████     | 4167/8192 [00:12<00:13, 288.15it/s]
Adding requests:  51%|█████     | 4196/8192 [00:12<00:13, 287.72it/s]
Adding requests:  52%|█████▏    | 4226/8192 [00:13<00:13, 288.31it/s]
Adding requests:  52%|█████▏    | 4256/8192 [00:13<00:13, 289.46it/s]
Adding requests:  52%|█████▏    | 4285/8192 [00:13<00:13, 284.91it/s]
Adding requests:  53%|█████▎    | 4314/8192 [00:13<00:13, 286.02it/s]
Adding requests:  53%|█████▎    | 4343/8192 [00:13<00:13, 281.46it/s]
Adding requests:  53%|█████▎    | 4372/8192 [00:13<00:13, 283.74it/s]
Adding requests:  54%|█████▎    | 4401/8192 [00:13<00:13, 285.37it/s]
Adding requests:  54%|█████▍    | 4430/8192 [00:13<00:13, 280.92it/s]
Adding requests:  54%|█████▍    | 4460/8192 [00:13<00:13, 283.39it/s]
Adding requests:  55%|█████▍    | 4489/8192 [00:14<00:13, 265.57it/s]
Adding requests:  55%|█████▌    | 4517/8192 [00:14<00:13, 266.96it/s]
Adding requests:  56%|█████▌    | 4547/8192 [00:14<00:13, 276.06it/s]
Adding requests:  56%|█████▌    | 4575/8192 [00:14<00:13, 276.58it/s]
Adding requests:  56%|█████▌    | 4603/8192 [00:14<00:12, 276.98it/s]
Adding requests:  57%|█████▋    | 4631/8192 [00:14<00:13, 273.88it/s]
Adding requests:  57%|█████▋    | 4661/8192 [00:14<00:12, 281.05it/s]
Adding requests:  57%|█████▋    | 4690/8192 [00:14<00:12, 282.62it/s]
Adding requests:  58%|█████▊    | 4719/8192 [00:14<00:12, 281.96it/s]
Adding requests:  58%|█████▊    | 4752/8192 [00:14<00:11, 295.93it/s]
Adding requests:  58%|█████▊    | 4786/8192 [00:15<00:11, 307.26it/s]
Adding requests:  59%|█████▉    | 4817/8192 [00:15<00:11, 299.94it/s]
Adding requests:  59%|█████▉    | 4849/8192 [00:15<00:10, 304.96it/s]
Adding requests:  60%|█████▉    | 4881/8192 [00:15<00:10, 308.75it/s]
Adding requests:  60%|█████▉    | 4914/8192 [00:15<00:10, 312.04it/s]
Adding requests:  60%|██████    | 4946/8192 [00:15<00:10, 306.68it/s]
Adding requests:  61%|██████    | 4980/8192 [00:15<00:10, 315.03it/s]
Adding requests:  61%|██████    | 5012/8192 [00:15<00:10, 316.23it/s]
Adding requests:  62%|██████▏   | 5045/8192 [00:15<00:09, 318.56it/s]
Adding requests:  62%|██████▏   | 5077/8192 [00:15<00:09, 314.93it/s]
Adding requests:  62%|██████▏   | 5109/8192 [00:16<00:09, 313.13it/s]
Adding requests:  63%|██████▎   | 5141/8192 [00:16<00:09, 314.30it/s]
Adding requests:  63%|██████▎   | 5173/8192 [00:16<00:09, 311.20it/s]
Adding requests:  64%|██████▎   | 5206/8192 [00:16<00:09, 315.10it/s]
Adding requests:  64%|██████▍   | 5238/8192 [00:16<00:09, 310.14it/s]
Adding requests:  64%|██████▍   | 5270/8192 [00:16<00:09, 309.14it/s]
Adding requests:  65%|██████▍   | 5302/8192 [00:16<00:09, 312.16it/s]
Adding requests:  65%|██████▌   | 5334/8192 [00:16<00:09, 305.64it/s]
Adding requests:  65%|██████▌   | 5365/8192 [00:16<00:09, 306.46it/s]
Adding requests:  66%|██████▌   | 5396/8192 [00:17<00:09, 295.86it/s]
Adding requests:  66%|██████▌   | 5426/8192 [00:17<00:09, 292.81it/s]
Adding requests:  67%|██████▋   | 5456/8192 [00:17<00:09, 287.59it/s]
Adding requests:  67%|██████▋   | 5485/8192 [00:17<00:09, 284.24it/s]
Adding requests:  67%|██████▋   | 5514/8192 [00:17<00:09, 282.01it/s]
Adding requests:  68%|██████▊   | 5543/8192 [00:17<00:09, 275.14it/s]
Adding requests:  68%|██████▊   | 5571/8192 [00:17<00:09, 268.25it/s]
Adding requests:  68%|██████▊   | 5601/8192 [00:17<00:09, 274.71it/s]
Adding requests:  69%|██████▊   | 5629/8192 [00:17<00:09, 270.61it/s]
Adding requests:  69%|██████▉   | 5658/8192 [00:18<00:09, 273.06it/s]
Adding requests:  69%|██████▉   | 5689/8192 [00:18<00:08, 282.92it/s]
Adding requests:  70%|██████▉   | 5720/8192 [00:18<00:08, 290.27it/s]
Adding requests:  70%|███████   | 5750/8192 [00:18<00:08, 292.18it/s]
Adding requests:  71%|███████   | 5781/8192 [00:18<00:08, 294.57it/s]
Adding requests:  71%|███████   | 5811/8192 [00:18<00:08, 295.69it/s]
Adding requests:  71%|███████▏  | 5841/8192 [00:18<00:08, 279.49it/s]
Adding requests:  72%|███████▏  | 5872/8192 [00:18<00:08, 286.81it/s]
Adding requests:  72%|███████▏  | 5903/8192 [00:18<00:07, 291.23it/s]
Adding requests:  72%|███████▏  | 5933/8192 [00:18<00:07, 287.18it/s]
Adding requests:  73%|███████▎  | 5963/8192 [00:19<00:07, 288.76it/s]
Adding requests:  73%|███████▎  | 5992/8192 [00:19<00:07, 287.15it/s]
Adding requests:  73%|███████▎  | 6021/8192 [00:19<00:07, 285.94it/s]
Adding requests:  74%|███████▍  | 6052/8192 [00:19<00:07, 291.24it/s]
Adding requests:  74%|███████▍  | 6082/8192 [00:19<00:07, 283.12it/s]
Adding requests:  75%|███████▍  | 6111/8192 [00:19<00:07, 283.61it/s]
Adding requests:  75%|███████▍  | 6140/8192 [00:19<00:07, 279.10it/s]
Adding requests:  75%|███████▌  | 6168/8192 [00:19<00:07, 276.04it/s]
Adding requests:  76%|███████▌  | 6198/8192 [00:19<00:07, 282.22it/s]
Adding requests:  76%|███████▌  | 6229/8192 [00:19<00:06, 288.27it/s]
Adding requests:  76%|███████▋  | 6259/8192 [00:20<00:06, 290.05it/s]
Adding requests:  77%|███████▋  | 6289/8192 [00:20<00:06, 288.79it/s]
Adding requests:  77%|███████▋  | 6318/8192 [00:20<00:06, 285.59it/s]
Adding requests:  77%|███████▋  | 6347/8192 [00:20<00:06, 286.01it/s]
Adding requests:  78%|███████▊  | 6376/8192 [00:20<00:06, 283.79it/s]
Adding requests:  78%|███████▊  | 6406/8192 [00:20<00:06, 288.03it/s]
Adding requests:  79%|███████▊  | 6436/8192 [00:20<00:06, 291.01it/s]
Adding requests:  79%|███████▉  | 6466/8192 [00:20<00:05, 288.11it/s]
Adding requests:  79%|███████▉  | 6496/8192 [00:20<00:05, 291.55it/s]
Adding requests:  80%|███████▉  | 6526/8192 [00:21<00:05, 287.31it/s]
Adding requests:  80%|████████  | 6556/8192 [00:21<00:05, 290.66it/s]
Adding requests:  80%|████████  | 6586/8192 [00:21<00:05, 291.30it/s]
Adding requests:  81%|████████  | 6616/8192 [00:21<00:05, 290.06it/s]
Adding requests:  81%|████████  | 6647/8192 [00:21<00:05, 294.24it/s]
Adding requests:  82%|████████▏ | 6677/8192 [00:21<00:05, 293.84it/s]
Adding requests:  82%|████████▏ | 6708/8192 [00:21<00:04, 297.11it/s]
Adding requests:  82%|████████▏ | 6738/8192 [00:21<00:04, 293.30it/s]
Adding requests:  83%|████████▎ | 6768/8192 [00:21<00:04, 285.21it/s]
Adding requests:  83%|████████▎ | 6800/8192 [00:21<00:04, 292.85it/s]
Adding requests:  83%|████████▎ | 6832/8192 [00:22<00:04, 300.07it/s]
Adding requests:  84%|████████▍ | 6865/8192 [00:22<00:04, 307.02it/s]
Adding requests:  84%|████████▍ | 6900/8192 [00:22<00:04, 318.28it/s]
Adding requests:  85%|████████▍ | 6932/8192 [00:22<00:04, 313.68it/s]
Adding requests:  85%|████████▌ | 6965/8192 [00:22<00:03, 317.81it/s]
Adding requests:  85%|████████▌ | 6997/8192 [00:22<00:03, 311.36it/s]
Adding requests:  86%|████████▌ | 7029/8192 [00:22<00:03, 312.55it/s]
Adding requests:  86%|████████▌ | 7062/8192 [00:22<00:03, 315.75it/s]
Adding requests:  87%|████████▋ | 7094/8192 [00:22<00:03, 311.49it/s]
Adding requests:  87%|████████▋ | 7128/8192 [00:22<00:03, 318.52it/s]
Adding requests:  87%|████████▋ | 7160/8192 [00:23<00:03, 314.33it/s]
Adding requests:  88%|████████▊ | 7192/8192 [00:23<00:03, 314.50it/s]
Adding requests:  88%|████████▊ | 7224/8192 [00:23<00:03, 302.83it/s]
Adding requests:  89%|████████▊ | 7256/8192 [00:23<00:03, 306.40it/s]
Adding requests:  89%|████████▉ | 7290/8192 [00:23<00:02, 313.64it/s]
Adding requests:  89%|████████▉ | 7322/8192 [00:23<00:02, 312.28it/s]
Adding requests:  90%|████████▉ | 7354/8192 [00:23<00:02, 313.82it/s]
Adding requests:  90%|█████████ | 7386/8192 [00:23<00:02, 301.44it/s]
Adding requests:  91%|█████████ | 7419/8192 [00:23<00:02, 308.88it/s]
Adding requests:  91%|█████████ | 7452/8192 [00:24<00:02, 312.94it/s]
Adding requests:  91%|█████████▏| 7484/8192 [00:24<00:02, 311.13it/s]
Adding requests:  92%|█████████▏| 7517/8192 [00:24<00:02, 314.19it/s]
Adding requests:  92%|█████████▏| 7549/8192 [00:24<00:02, 307.55it/s]
Adding requests:  93%|█████████▎| 7580/8192 [00:24<00:02, 305.77it/s]
Adding requests:  93%|█████████▎| 7612/8192 [00:24<00:01, 308.05it/s]
Adding requests:  93%|█████████▎| 7646/8192 [00:24<00:01, 316.52it/s]
Adding requests:  94%|█████████▍| 7680/8192 [00:24<00:01, 321.56it/s]
Adding requests:  94%|█████████▍| 7713/8192 [00:24<00:01, 312.81it/s]
Adding requests:  95%|█████████▍| 7745/8192 [00:24<00:01, 309.59it/s]
Adding requests:  95%|█████████▍| 7777/8192 [00:25<00:01, 303.18it/s]
Adding requests:  95%|█████████▌| 7808/8192 [00:25<00:01, 302.02it/s]
Adding requests:  96%|█████████▌| 7840/8192 [00:25<00:01, 307.07it/s]
Adding requests:  96%|█████████▌| 7871/8192 [00:25<00:01, 292.78it/s]
Adding requests:  96%|█████████▋| 7901/8192 [00:25<00:01, 289.85it/s]
Adding requests:  97%|█████████▋| 7931/8192 [00:25<00:00, 288.03it/s]
Adding requests:  97%|█████████▋| 7960/8192 [00:25<00:00, 288.25it/s]
Adding requests:  98%|█████████▊| 7989/8192 [00:25<00:00, 274.86it/s]
Adding requests:  98%|█████████▊| 8017/8192 [00:25<00:00, 264.04it/s]
Adding requests:  98%|█████████▊| 8045/8192 [00:26<00:00, 266.87it/s]
Adding requests:  99%|█████████▊| 8074/8192 [00:26<00:00, 270.61it/s]
Adding requests:  99%|█████████▉| 8102/8192 [00:26<00:00, 270.10it/s]
Adding requests:  99%|█████████▉| 8130/8192 [00:26<00:00, 266.24it/s]
Adding requests: 100%|█████████▉| 8157/8192 [00:26<00:00, 261.08it/s]
Adding requests: 100%|█████████▉| 8184/8192 [00:26<00:00, 262.67it/s]
Adding requests: 100%|██████████| 8192/8192 [00:26<00:00, 307.93it/s]

Processed prompts:   0%|          | 0/8192 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   5%|▌         | 450/8192 [00:01<00:25, 306.28it/s, est. speed input: 313637.20 toks/s, output: 306.28 toks/s]
Processed prompts:   6%|▋         | 514/8192 [00:04<01:32, 83.27it/s, est. speed input: 105431.41 toks/s, output: 102.96 toks/s] 
Processed prompts:   7%|▋         | 578/8192 [00:06<01:59, 63.67it/s, est. speed input: 84814.39 toks/s, output: 82.83 toks/s]  
Processed prompts:   8%|▊         | 642/8192 [00:10<03:07, 40.16it/s, est. speed input: 61492.90 toks/s, output: 60.05 toks/s]
Processed prompts:   9%|▊         | 706/8192 [00:14<03:58, 31.41it/s, est. speed input: 51062.96 toks/s, output: 49.87 toks/s]
Processed prompts:   9%|▉         | 770/8192 [00:17<04:45, 26.02it/s, est. speed input: 44135.51 toks/s, output: 43.10 toks/s]
Processed prompts:  10%|█         | 834/8192 [00:21<05:18, 23.13it/s, est. speed input: 39751.03 toks/s, output: 38.82 toks/s]
Processed prompts:  11%|█         | 898/8192 [00:25<05:42, 21.27it/s, est. speed input: 36591.69 toks/s, output: 35.73 toks/s]
Processed prompts:  12%|█▏        | 962/8192 [00:28<05:58, 20.17it/s, est. speed input: 34297.64 toks/s, output: 33.49 toks/s]
Processed prompts:  13%|█▎        | 1026/8192 [00:32<06:08, 19.46it/s, est. speed input: 32528.56 toks/s, output: 31.77 toks/s]
Processed prompts:  13%|█▎        | 1090/8192 [00:35<06:16, 18.87it/s, est. speed input: 31056.62 toks/s, output: 30.33 toks/s]
Processed prompts:  14%|█▍        | 1154/8192 [00:37<05:23, 21.76it/s, est. speed input: 31265.28 toks/s, output: 30.53 toks/s]
Processed prompts:  15%|█▍        | 1218/8192 [00:41<05:45, 20.21it/s, est. speed input: 30052.77 toks/s, output: 29.35 toks/s]
Processed prompts:  16%|█▌        | 1282/8192 [00:45<05:52, 19.58it/s, est. speed input: 29165.16 toks/s, output: 28.48 toks/s]
Processed prompts:  16%|█▋        | 1346/8192 [00:48<06:00, 19.01it/s, est. speed input: 28354.46 toks/s, output: 27.69 toks/s]
Processed prompts:  17%|█▋        | 1410/8192 [00:52<06:07, 18.45it/s, est. speed input: 27597.13 toks/s, output: 26.95 toks/s]
Processed prompts:  18%|█▊        | 1474/8192 [00:55<06:07, 18.28it/s, est. speed input: 27004.47 toks/s, output: 26.37 toks/s]
Processed prompts:  19%|█▉        | 1538/8192 [00:59<06:10, 17.97it/s, est. speed input: 26424.58 toks/s, output: 25.81 toks/s]
Processed prompts:  20%|█▉        | 1602/8192 [01:03<06:04, 18.08it/s, est. speed input: 26003.80 toks/s, output: 25.39 toks/s]
Processed prompts:  20%|██        | 1666/8192 [01:06<06:06, 17.81it/s, est. speed input: 25537.26 toks/s, output: 24.94 toks/s]
Processed prompts:  21%|██        | 1730/8192 [01:08<05:07, 21.01it/s, est. speed input: 25834.24 toks/s, output: 25.23 toks/s]
Processed prompts:  22%|██▏       | 1794/8192 [01:12<05:20, 19.99it/s, est. speed input: 25465.34 toks/s, output: 24.87 toks/s]
Processed prompts:  23%|██▎       | 1858/8192 [01:15<05:28, 19.26it/s, est. speed input: 25118.92 toks/s, output: 24.53 toks/s]
Processed prompts:  23%|██▎       | 1922/8192 [01:19<05:30, 18.99it/s, est. speed input: 24842.50 toks/s, output: 24.26 toks/s]
Processed prompts:  24%|██▍       | 1986/8192 [01:22<05:36, 18.44it/s, est. speed input: 24522.69 toks/s, output: 23.95 toks/s]
Processed prompts:  25%|██▌       | 2050/8192 [01:26<05:33, 18.41it/s, est. speed input: 24290.93 toks/s, output: 23.72 toks/s]
Processed prompts:  26%|██▌       | 2114/8192 [01:30<05:36, 18.04it/s, est. speed input: 24016.52 toks/s, output: 23.45 toks/s]
Processed prompts:  27%|██▋       | 2178/8192 [01:33<05:33, 18.04it/s, est. speed input: 23806.85 toks/s, output: 23.25 toks/s]
Processed prompts:  27%|██▋       | 2242/8192 [01:37<05:32, 17.90it/s, est. speed input: 23589.06 toks/s, output: 23.04 toks/s]
Processed prompts:  28%|██▊       | 2306/8192 [01:39<04:45, 20.62it/s, est. speed input: 23774.11 toks/s, output: 23.22 toks/s]
Processed prompts:  29%|██▉       | 2370/8192 [01:42<04:51, 19.96it/s, est. speed input: 23614.01 toks/s, output: 23.06 toks/s]
Processed prompts:  30%|██▉       | 2434/8192 [01:46<05:02, 19.06it/s, est. speed input: 23406.69 toks/s, output: 22.86 toks/s]
Processed prompts:  30%|███       | 2498/8192 [01:49<05:01, 18.91it/s, est. speed input: 23269.23 toks/s, output: 22.72 toks/s]
Processed prompts:  31%|███▏      | 2562/8192 [01:53<05:05, 18.46it/s, est. speed input: 23096.19 toks/s, output: 22.55 toks/s]
Processed prompts:  32%|███▏      | 2626/8192 [01:57<05:05, 18.24it/s, est. speed input: 22945.14 toks/s, output: 22.41 toks/s]
Processed prompts:  33%|███▎      | 2690/8192 [02:00<05:04, 18.09it/s, est. speed input: 22802.77 toks/s, output: 22.27 toks/s]
Processed prompts:  34%|███▎      | 2754/8192 [02:04<05:03, 17.92it/s, est. speed input: 22660.12 toks/s, output: 22.13 toks/s]
Processed prompts:  34%|███▍      | 2818/8192 [02:07<04:59, 17.97it/s, est. speed input: 22545.46 toks/s, output: 22.02 toks/s]
Processed prompts:  35%|███▌      | 2882/8192 [02:10<04:20, 20.38it/s, est. speed input: 22675.19 toks/s, output: 22.14 toks/s]
Processed prompts:  36%|███▌      | 2946/8192 [02:13<04:27, 19.58it/s, est. speed input: 22560.39 toks/s, output: 22.03 toks/s]
Processed prompts:  37%|███▋      | 3010/8192 [02:17<04:33, 18.95it/s, est. speed input: 22441.23 toks/s, output: 21.92 toks/s]
Processed prompts:  38%|███▊      | 3074/8192 [02:20<04:36, 18.51it/s, est. speed input: 22326.15 toks/s, output: 21.80 toks/s]
Processed prompts:  38%|███▊      | 3138/8192 [02:24<04:35, 18.33it/s, est. speed input: 22228.08 toks/s, output: 21.71 toks/s]
Processed prompts:  39%|███▉      | 3202/8192 [02:28<04:36, 18.02it/s, est. speed input: 22116.38 toks/s, output: 21.60 toks/s]
Processed prompts:  40%|███▉      | 3266/8192 [02:31<04:32, 18.08it/s, est. speed input: 22036.62 toks/s, output: 21.52 toks/s]
Processed prompts:  41%|████      | 3330/8192 [02:35<04:33, 17.80it/s, est. speed input: 21930.15 toks/s, output: 21.42 toks/s]
Processed prompts:  41%|████▏     | 3394/8192 [02:38<04:26, 18.02it/s, est. speed input: 21866.04 toks/s, output: 21.35 toks/s]
Processed prompts:  42%|████▏     | 3458/8192 [02:40<03:49, 20.65it/s, est. speed input: 21995.59 toks/s, output: 21.48 toks/s]
Processed prompts:  43%|████▎     | 3522/8192 [02:44<03:58, 19.58it/s, est. speed input: 21904.28 toks/s, output: 21.39 toks/s]
Processed prompts:  44%|████▍     | 3586/8192 [02:48<04:01, 19.08it/s, est. speed input: 21830.87 toks/s, output: 21.32 toks/s]
Processed prompts:  45%|████▍     | 3650/8192 [02:51<04:05, 18.50it/s, est. speed input: 21741.46 toks/s, output: 21.23 toks/s]
Processed prompts:  45%|████▌     | 3714/8192 [02:55<04:03, 18.42it/s, est. speed input: 21679.93 toks/s, output: 21.17 toks/s]
Processed prompts:  46%|████▌     | 3778/8192 [02:59<04:04, 18.04it/s, est. speed input: 21595.92 toks/s, output: 21.09 toks/s]
Processed prompts:  47%|████▋     | 3842/8192 [03:02<03:59, 18.14it/s, est. speed input: 21542.96 toks/s, output: 21.04 toks/s]
Processed prompts:  48%|████▊     | 3906/8192 [03:06<03:59, 17.90it/s, est. speed input: 21468.56 toks/s, output: 20.97 toks/s]
Processed prompts:  48%|████▊     | 3970/8192 [03:09<03:54, 18.01it/s, est. speed input: 21417.66 toks/s, output: 20.92 toks/s]
Processed prompts:  49%|████▉     | 4034/8192 [03:11<03:18, 20.92it/s, est. speed input: 21546.32 toks/s, output: 21.04 toks/s]
Processed prompts:  50%|█████     | 4098/8192 [03:15<03:28, 19.68it/s, est. speed input: 21473.45 toks/s, output: 20.97 toks/s]
Processed prompts:  51%|█████     | 4162/8192 [03:18<03:29, 19.26it/s, est. speed input: 21426.78 toks/s, output: 20.92 toks/s]
Processed prompts:  52%|█████▏    | 4226/8192 [03:22<03:31, 18.79it/s, est. speed input: 21369.03 toks/s, output: 20.87 toks/s]
Processed prompts:  52%|█████▏    | 4290/8192 [03:26<03:31, 18.47it/s, est. speed input: 21313.39 toks/s, output: 20.81 toks/s]
Processed prompts:  53%|█████▎    | 4354/8192 [03:29<03:31, 18.16it/s, est. speed input: 21254.18 toks/s, output: 20.76 toks/s]
Processed prompts:  54%|█████▍    | 4418/8192 [03:33<03:28, 18.06it/s, est. speed input: 21203.89 toks/s, output: 20.71 toks/s]
Processed prompts:  55%|█████▍    | 4482/8192 [03:36<03:26, 18.00it/s, est. speed input: 21155.64 toks/s, output: 20.66 toks/s]
Processed prompts:  55%|█████▌    | 4546/8192 [03:40<03:24, 17.87it/s, est. speed input: 21103.48 toks/s, output: 20.61 toks/s]
Processed prompts:  56%|█████▋    | 4610/8192 [03:42<02:51, 20.88it/s, est. speed input: 21221.61 toks/s, output: 20.72 toks/s]
Processed prompts:  57%|█████▋    | 4674/8192 [03:46<02:59, 19.62it/s, est. speed input: 21161.91 toks/s, output: 20.67 toks/s]
Processed prompts:  58%|█████▊    | 4738/8192 [03:49<03:00, 19.16it/s, est. speed input: 21122.96 toks/s, output: 20.63 toks/s]
Processed prompts:  59%|█████▊    | 4802/8192 [03:53<03:01, 18.71it/s, est. speed input: 21077.07 toks/s, output: 20.58 toks/s]
Processed prompts:  59%|█████▉    | 4866/8192 [03:57<03:02, 18.23it/s, est. speed input: 21022.84 toks/s, output: 20.53 toks/s]
Processed prompts:  60%|██████    | 4930/8192 [04:00<02:59, 18.15it/s, est. speed input: 20984.16 toks/s, output: 20.49 toks/s]
Processed prompts:  61%|██████    | 4994/8192 [04:04<02:57, 18.04it/s, est. speed input: 20943.34 toks/s, output: 20.45 toks/s]
Processed prompts:  62%|██████▏   | 5058/8192 [04:07<02:52, 18.14it/s, est. speed input: 20913.32 toks/s, output: 20.42 toks/s]
Processed prompts:  63%|██████▎   | 5122/8192 [04:11<02:51, 17.87it/s, est. speed input: 20865.71 toks/s, output: 20.38 toks/s]
Processed prompts:  63%|██████▎   | 5186/8192 [04:13<02:23, 21.01it/s, est. speed input: 20976.45 toks/s, output: 20.48 toks/s]
Processed prompts:  64%|██████▍   | 5250/8192 [04:16<02:27, 19.99it/s, est. speed input: 20940.39 toks/s, output: 20.45 toks/s]
Processed prompts:  65%|██████▍   | 5314/8192 [04:20<02:30, 19.07it/s, est. speed input: 20893.27 toks/s, output: 20.40 toks/s]
Processed prompts:  66%|██████▌   | 5378/8192 [04:23<02:29, 18.83it/s, est. speed input: 20864.73 toks/s, output: 20.38 toks/s]
Processed prompts:  66%|██████▋   | 5442/8192 [04:27<02:30, 18.31it/s, est. speed input: 20819.32 toks/s, output: 20.33 toks/s]
Processed prompts:  67%|██████▋   | 5506/8192 [04:31<02:26, 18.32it/s, est. speed input: 20793.14 toks/s, output: 20.31 toks/s]
Processed prompts:  68%|██████▊   | 5570/8192 [04:34<02:25, 17.98it/s, est. speed input: 20750.49 toks/s, output: 20.26 toks/s]
Processed prompts:  69%|██████▉   | 5634/8192 [04:38<02:21, 18.01it/s, est. speed input: 20722.44 toks/s, output: 20.24 toks/s]
Processed prompts:  70%|██████▉   | 5698/8192 [04:42<02:19, 17.86it/s, est. speed input: 20686.10 toks/s, output: 20.20 toks/s]
Processed prompts:  70%|███████   | 5762/8192 [04:44<01:57, 20.63it/s, est. speed input: 20772.69 toks/s, output: 20.29 toks/s]
Processed prompts:  71%|███████   | 5826/8192 [04:47<01:58, 19.95it/s, est. speed input: 20751.26 toks/s, output: 20.26 toks/s]
Processed prompts:  72%|███████▏  | 5890/8192 [04:51<02:00, 19.05it/s, est. speed input: 20711.77 toks/s, output: 20.23 toks/s]
Processed prompts:  73%|███████▎  | 5954/8192 [04:54<01:59, 18.77it/s, est. speed input: 20686.36 toks/s, output: 20.20 toks/s]
Processed prompts:  73%|███████▎  | 6018/8192 [04:58<01:58, 18.34it/s, est. speed input: 20651.10 toks/s, output: 20.17 toks/s]
Processed prompts:  74%|███████▍  | 6082/8192 [05:02<01:56, 18.18it/s, est. speed input: 20622.21 toks/s, output: 20.14 toks/s]
Processed prompts:  75%|███████▌  | 6146/8192 [05:05<01:53, 18.03it/s, est. speed input: 20592.60 toks/s, output: 20.11 toks/s]
Processed prompts:  76%|███████▌  | 6210/8192 [05:09<01:50, 17.89it/s, est. speed input: 20561.99 toks/s, output: 20.08 toks/s]
Processed prompts:  77%|███████▋  | 6274/8192 [05:12<01:47, 17.92it/s, est. speed input: 20537.53 toks/s, output: 20.06 toks/s]
Processed prompts:  77%|███████▋  | 6338/8192 [05:14<01:30, 20.38it/s, est. speed input: 20606.54 toks/s, output: 20.12 toks/s]
Processed prompts:  78%|███████▊  | 6402/8192 [05:18<01:31, 19.60it/s, est. speed input: 20582.17 toks/s, output: 20.10 toks/s]
Processed prompts:  79%|███████▉  | 6466/8192 [05:22<01:31, 18.92it/s, est. speed input: 20552.12 toks/s, output: 20.07 toks/s]
Processed prompts:  80%|███████▉  | 6530/8192 [05:25<01:29, 18.51it/s, est. speed input: 20524.02 toks/s, output: 20.04 toks/s]
Processed prompts:  80%|████████  | 6594/8192 [05:29<01:26, 18.46it/s, est. speed input: 20505.60 toks/s, output: 20.02 toks/s]
Processed prompts:  81%|████████▏ | 6658/8192 [05:32<01:23, 18.29it/s, est. speed input: 20482.48 toks/s, output: 20.00 toks/s]
Processed prompts:  82%|████████▏ | 6722/8192 [05:36<01:20, 18.27it/s, est. speed input: 20463.23 toks/s, output: 19.98 toks/s]
Processed prompts:  83%|████████▎ | 6786/8192 [05:40<01:18, 17.94it/s, est. speed input: 20432.35 toks/s, output: 19.95 toks/s]
Processed prompts:  84%|████████▎ | 6850/8192 [05:43<01:14, 18.11it/s, est. speed input: 20417.64 toks/s, output: 19.94 toks/s]
Processed prompts:  84%|████████▍ | 6914/8192 [05:45<01:01, 20.70it/s, est. speed input: 20485.53 toks/s, output: 20.01 toks/s]
Processed prompts:  85%|████████▌ | 6978/8192 [05:49<01:01, 19.58it/s, est. speed input: 20457.38 toks/s, output: 19.98 toks/s]
Processed prompts:  86%|████████▌ | 7042/8192 [05:52<01:00, 19.09it/s, est. speed input: 20437.45 toks/s, output: 19.96 toks/s]
Processed prompts:  87%|████████▋ | 7106/8192 [05:56<00:58, 18.50it/s, est. speed input: 20408.50 toks/s, output: 19.93 toks/s]
Processed prompts:  88%|████████▊ | 7170/8192 [06:00<00:55, 18.45it/s, est. speed input: 20392.55 toks/s, output: 19.91 toks/s]
Processed prompts:  88%|████████▊ | 7234/8192 [06:03<00:53, 18.07it/s, est. speed input: 20364.59 toks/s, output: 19.89 toks/s]
Processed prompts:  89%|████████▉ | 7298/8192 [06:07<00:49, 18.16it/s, est. speed input: 20349.81 toks/s, output: 19.87 toks/s]
Processed prompts:  90%|████████▉ | 7362/8192 [06:10<00:46, 17.95it/s, est. speed input: 20325.69 toks/s, output: 19.85 toks/s]
Processed prompts:  91%|█████████ | 7426/8192 [06:14<00:42, 18.01it/s, est. speed input: 20309.34 toks/s, output: 19.83 toks/s]
Processed prompts:  91%|█████████▏| 7490/8192 [06:16<00:33, 20.68it/s, est. speed input: 20374.22 toks/s, output: 19.90 toks/s]
Processed prompts:  92%|█████████▏| 7554/8192 [06:20<00:32, 19.52it/s, est. speed input: 20347.90 toks/s, output: 19.87 toks/s]
Processed prompts:  93%|█████████▎| 7618/8192 [06:23<00:30, 19.13it/s, est. speed input: 20333.01 toks/s, output: 19.86 toks/s]
Processed prompts:  94%|█████████▍| 7682/8192 [06:27<00:27, 18.51it/s, est. speed input: 20307.03 toks/s, output: 19.83 toks/s]
Processed prompts:  95%|█████████▍| 7746/8192 [06:30<00:24, 18.34it/s, est. speed input: 20289.41 toks/s, output: 19.81 toks/s]
Processed prompts:  95%|█████████▌| 7810/8192 [06:34<00:21, 18.05it/s, est. speed input: 20266.61 toks/s, output: 19.79 toks/s]
Processed prompts:  96%|█████████▌| 7874/8192 [06:38<00:17, 18.02it/s, est. speed input: 20249.78 toks/s, output: 19.78 toks/s]
Processed prompts:  97%|█████████▋| 7938/8192 [06:41<00:14, 17.94it/s, est. speed input: 20231.27 toks/s, output: 19.76 toks/s]
Processed prompts:  98%|█████████▊| 8002/8192 [06:45<00:10, 17.84it/s, est. speed input: 20211.58 toks/s, output: 19.74 toks/s]
Processed prompts:  98%|█████████▊| 8066/8192 [06:48<00:06, 18.08it/s, est. speed input: 20202.22 toks/s, output: 19.73 toks/s]
Processed prompts:  99%|█████████▉| 8130/8192 [06:50<00:02, 20.93it/s, est. speed input: 20266.75 toks/s, output: 19.79 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [06:50<00:00, 20.93it/s, est. speed input: 20421.25 toks/s, output: 19.94 toks/s]
Processed prompts: 100%|██████████| 8192/8192 [06:50<00:00, 19.94it/s, est. speed input: 20421.25 toks/s, output: 19.94 toks/s]
[rank0]:[W125 22:31:46.686956350 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 03:57:55
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:58:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:58:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=146318) WARNING 01-26 03:58:11 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=146318) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=146318) WARNING 01-26 03:58:29 [backends.py:609] Failed to read file <frozen os>
Throughput: 16.37 requests/s, 8399.53 total tokens/s, 16.37 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 03:58:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:58:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 03:58:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 03:58:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:58:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:58:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:58:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:58:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:58:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:58:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 03:58:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:58:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 03:58:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:58:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:58:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:58:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:58:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:12] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:12] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:12] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:12] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:12] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=146318) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=146318) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:02<00:02,  2.31s/it]
(EngineCore_DP0 pid=146318) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.69s/it]
(EngineCore_DP0 pid=146318) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.48s/it]
(EngineCore_DP0 pid=146318) 
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16662528 bytes
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12959744 bytes
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 137003008 bytes
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=146318) [2026-01-26 03:58:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 68009984 bytes
(EngineCore_DP0 pid=146318) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.31it/s]
(EngineCore_DP0 pid=146318) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.74it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  35%|███▌      | 45/128 [00:00<00:00, 444.99it/s]
Adding requests:  72%|███████▏  | 92/128 [00:00<00:00, 456.72it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 459.20it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:15,  8.24it/s, est. speed input: 4221.54 toks/s, output: 8.24 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:12, 10.02it/s, est. speed input: 5022.92 toks/s, output: 9.81 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:09, 12.70it/s, est. speed input: 6045.49 toks/s, output: 11.81 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:08, 14.25it/s, est. speed input: 6631.55 toks/s, output: 12.95 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:07, 15.19it/s, est. speed input: 7004.35 toks/s, output: 13.68 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:07, 15.85it/s, est. speed input: 7278.15 toks/s, output: 14.21 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:07, 16.25it/s, est. speed input: 7472.33 toks/s, output: 14.59 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:06, 16.54it/s, est. speed input: 7626.58 toks/s, output: 14.90 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:06, 16.79it/s, est. speed input: 7755.30 toks/s, output: 15.15 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:06, 16.90it/s, est. speed input: 7852.20 toks/s, output: 15.34 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:06, 16.97it/s, est. speed input: 7931.52 toks/s, output: 15.49 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:01<00:06, 17.04it/s, est. speed input: 8000.97 toks/s, output: 15.63 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:05, 17.21it/s, est. speed input: 8073.24 toks/s, output: 15.77 toks/s]
Processed prompts:  21%|██        | 27/128 [00:01<00:05, 17.06it/s, est. speed input: 8107.84 toks/s, output: 15.84 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:05, 17.17it/s, est. speed input: 8158.83 toks/s, output: 15.94 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:01<00:05, 16.99it/s, est. speed input: 8180.15 toks/s, output: 15.98 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:02<00:05, 17.04it/s, est. speed input: 8214.54 toks/s, output: 16.04 toks/s]
Processed prompts:  27%|██▋       | 35/128 [00:02<00:05, 17.23it/s, est. speed input: 8258.22 toks/s, output: 16.13 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:02<00:05, 17.37it/s, est. speed input: 8297.92 toks/s, output: 16.21 toks/s]
Processed prompts:  30%|███       | 39/128 [00:02<00:05, 17.46it/s, est. speed input: 8333.38 toks/s, output: 16.28 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:02<00:04, 17.54it/s, est. speed input: 8366.84 toks/s, output: 16.34 toks/s]
Processed prompts:  34%|███▎      | 43/128 [00:02<00:04, 17.56it/s, est. speed input: 8394.73 toks/s, output: 16.40 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:02<00:04, 17.45it/s, est. speed input: 8412.60 toks/s, output: 16.43 toks/s]
Processed prompts:  37%|███▋      | 47/128 [00:02<00:04, 17.43it/s, est. speed input: 8432.38 toks/s, output: 16.47 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:02<00:04, 17.47it/s, est. speed input: 8453.45 toks/s, output: 16.51 toks/s]
Processed prompts:  40%|███▉      | 51/128 [00:03<00:04, 17.48it/s, est. speed input: 8472.49 toks/s, output: 16.55 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:03<00:04, 17.52it/s, est. speed input: 8491.85 toks/s, output: 16.59 toks/s]
Processed prompts:  43%|████▎     | 55/128 [00:03<00:04, 17.56it/s, est. speed input: 8510.57 toks/s, output: 16.62 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:03<00:04, 17.61it/s, est. speed input: 8529.04 toks/s, output: 16.66 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:03<00:03, 17.51it/s, est. speed input: 8539.80 toks/s, output: 16.68 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:03<00:03, 17.53it/s, est. speed input: 8553.80 toks/s, output: 16.71 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:03<00:03, 17.40it/s, est. speed input: 8560.23 toks/s, output: 16.72 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:03<00:03, 17.33it/s, est. speed input: 8567.10 toks/s, output: 16.73 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:04<00:03, 17.32it/s, est. speed input: 8575.53 toks/s, output: 16.75 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:04<00:03, 17.25it/s, est. speed input: 8580.42 toks/s, output: 16.76 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:04<00:03, 17.32it/s, est. speed input: 8590.51 toks/s, output: 16.78 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:04<00:03, 17.34it/s, est. speed input: 8598.80 toks/s, output: 16.79 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:04<00:03, 17.32it/s, est. speed input: 8605.23 toks/s, output: 16.81 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:04<00:02, 17.36it/s, est. speed input: 8613.34 toks/s, output: 16.82 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:04<00:02, 17.45it/s, est. speed input: 8623.75 toks/s, output: 16.84 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:04<00:02, 17.45it/s, est. speed input: 8631.37 toks/s, output: 16.86 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:04<00:02, 17.41it/s, est. speed input: 8636.58 toks/s, output: 16.87 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:05<00:02, 17.31it/s, est. speed input: 8639.16 toks/s, output: 16.87 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:05<00:02, 17.21it/s, est. speed input: 8640.39 toks/s, output: 16.88 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:05<00:02, 17.20it/s, est. speed input: 8643.88 toks/s, output: 16.88 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:05<00:02, 17.23it/s, est. speed input: 8648.30 toks/s, output: 16.89 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:05<00:02, 17.21it/s, est. speed input: 8651.28 toks/s, output: 16.90 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:05<00:01, 17.05it/s, est. speed input: 8648.93 toks/s, output: 16.89 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:05<00:01, 17.20it/s, est. speed input: 8655.94 toks/s, output: 16.91 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:05<00:01, 17.31it/s, est. speed input: 8662.53 toks/s, output: 16.92 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:05<00:01, 17.18it/s, est. speed input: 8661.99 toks/s, output: 16.92 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:06<00:01, 17.26it/s, est. speed input: 8667.27 toks/s, output: 16.93 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:06<00:01, 17.29it/s, est. speed input: 8671.41 toks/s, output: 16.94 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:06<00:01, 17.39it/s, est. speed input: 8677.76 toks/s, output: 16.95 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:06<00:01, 17.50it/s, est. speed input: 8685.10 toks/s, output: 16.96 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:06<00:00, 17.62it/s, est. speed input: 8693.27 toks/s, output: 16.98 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:06<00:00, 17.67it/s, est. speed input: 8700.42 toks/s, output: 16.99 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:06<00:00, 17.67it/s, est. speed input: 8706.11 toks/s, output: 17.00 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:06<00:00, 17.58it/s, est. speed input: 8709.30 toks/s, output: 17.01 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:06<00:00, 17.24it/s, est. speed input: 8704.68 toks/s, output: 17.00 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:07<00:00, 17.08it/s, est. speed input: 8702.40 toks/s, output: 17.00 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:07<00:00, 17.01it/s, est. speed input: 8700.99 toks/s, output: 16.99 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:07<00:00, 16.94it/s, est. speed input: 8699.21 toks/s, output: 16.99 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:07<00:00, 16.85it/s, est. speed input: 8696.46 toks/s, output: 16.99 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 16.85it/s, est. speed input: 8695.14 toks/s, output: 16.98 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:07<00:00, 16.98it/s, est. speed input: 8695.14 toks/s, output: 16.98 toks/s]
[rank0]:[W126 03:58:54.185286823 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 03:58:56
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:59:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 03:59:06 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=147479) WARNING 01-26 03:59:14 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=147479) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=147479) WARNING 01-26 03:59:25 [backends.py:609] Failed to read file <frozen os>
Throughput: 16.34 requests/s, 16745.61 total tokens/s, 16.34 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 03:59:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:59:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 03:59:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 03:59:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:59:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:59:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:59:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:59:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:59:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:59:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 03:59:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 03:59:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 03:59:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:59:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:59:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:59:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:59:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:14] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:14] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:14] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:14] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:14] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=147479) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=147479) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.44it/s]
(EngineCore_DP0 pid=147479) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.44it/s]
(EngineCore_DP0 pid=147479) 
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16662528 bytes
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12959744 bytes
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 137003008 bytes
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=147479) [2026-01-26 03:59:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 68009984 bytes
(EngineCore_DP0 pid=147479) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  8.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.42it/s]
(EngineCore_DP0 pid=147479) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  7.28it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  19%|█▉        | 24/128 [00:00<00:00, 233.03it/s]
Adding requests:  38%|███▊      | 49/128 [00:00<00:00, 240.93it/s]
Adding requests:  60%|██████    | 77/128 [00:00<00:00, 256.11it/s]
Adding requests:  80%|████████  | 103/128 [00:00<00:00, 255.11it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 253.72it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:03, 32.18it/s, est. speed input: 32964.04 toks/s, output: 32.19 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:00<00:05, 21.38it/s, est. speed input: 23054.61 toks/s, output: 22.51 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:05, 19.62it/s, est. speed input: 21329.57 toks/s, output: 20.83 toks/s]
Processed prompts:  11%|█         | 14/128 [00:00<00:06, 18.77it/s, est. speed input: 20465.38 toks/s, output: 19.99 toks/s]
Processed prompts:  12%|█▎        | 16/128 [00:00<00:06, 18.39it/s, est. speed input: 20082.59 toks/s, output: 19.61 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:06, 18.15it/s, est. speed input: 19819.96 toks/s, output: 19.36 toks/s]
Processed prompts:  16%|█▌        | 20/128 [00:01<00:06, 18.00it/s, est. speed input: 19624.17 toks/s, output: 19.16 toks/s]
Processed prompts:  17%|█▋        | 22/128 [00:01<00:05, 17.82it/s, est. speed input: 19445.04 toks/s, output: 18.99 toks/s]
Processed prompts:  19%|█▉        | 24/128 [00:01<00:05, 17.70it/s, est. speed input: 19297.89 toks/s, output: 18.85 toks/s]
Processed prompts:  20%|██        | 26/128 [00:01<00:05, 17.59it/s, est. speed input: 19168.86 toks/s, output: 18.72 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:01<00:05, 17.47it/s, est. speed input: 19046.27 toks/s, output: 18.60 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:01<00:05, 17.23it/s, est. speed input: 18902.32 toks/s, output: 18.46 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:01<00:05, 17.21it/s, est. speed input: 18815.99 toks/s, output: 18.37 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:01<00:05, 17.18it/s, est. speed input: 18731.95 toks/s, output: 18.29 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:01<00:05, 17.05it/s, est. speed input: 18636.87 toks/s, output: 18.20 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:02<00:05, 16.95it/s, est. speed input: 18551.88 toks/s, output: 18.12 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:02<00:05, 16.96it/s, est. speed input: 18489.21 toks/s, output: 18.06 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:02<00:05, 16.96it/s, est. speed input: 18432.24 toks/s, output: 18.00 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:02<00:04, 16.99it/s, est. speed input: 18386.69 toks/s, output: 17.96 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:02<00:04, 17.03it/s, est. speed input: 18346.77 toks/s, output: 17.92 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:02<00:04, 16.92it/s, est. speed input: 18289.71 toks/s, output: 17.86 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:02<00:04, 16.87it/s, est. speed input: 18242.43 toks/s, output: 17.81 toks/s]
Processed prompts:  59%|█████▉    | 76/128 [00:02<00:00, 79.59it/s, est. speed input: 26694.88 toks/s, output: 26.07 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:03<00:01, 38.32it/s, est. speed input: 25297.15 toks/s, output: 24.70 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:03<00:01, 29.21it/s, est. speed input: 24445.26 toks/s, output: 23.87 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:04<00:01, 25.51it/s, est. speed input: 23943.98 toks/s, output: 23.38 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:04<00:01, 23.27it/s, est. speed input: 23580.42 toks/s, output: 23.03 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:04<00:01, 21.56it/s, est. speed input: 23260.45 toks/s, output: 22.72 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:04<00:00, 20.54it/s, est. speed input: 23044.81 toks/s, output: 22.50 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:04<00:00, 19.69it/s, est. speed input: 22845.99 toks/s, output: 22.31 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:05<00:00, 19.20it/s, est. speed input: 22690.88 toks/s, output: 22.16 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:05<00:00, 18.82it/s, est. speed input: 22547.22 toks/s, output: 22.02 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:05<00:00, 18.47it/s, est. speed input: 22404.13 toks/s, output: 21.88 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:05<00:00, 18.19it/s, est. speed input: 22303.73 toks/s, output: 21.78 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:05<00:00, 18.05it/s, est. speed input: 22217.86 toks/s, output: 21.70 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:05<00:00, 18.01it/s, est. speed input: 22142.27 toks/s, output: 21.62 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 17.99it/s, est. speed input: 22071.64 toks/s, output: 21.55 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 17.99it/s, est. speed input: 22071.64 toks/s, output: 21.55 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 21.55it/s, est. speed input: 22071.64 toks/s, output: 21.55 toks/s]
[rank0]:[W126 03:59:49.170529361 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 03:59:52
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:00:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:00:02 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=148515) WARNING 01-26 04:00:10 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=148515) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=148515) WARNING 01-26 04:00:21 [backends.py:609] Failed to read file <frozen os>
Throughput: 19.14 requests/s, 19620.28 total tokens/s, 19.14 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 04:00:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:00:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:00:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:00:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:00:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:00:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:00:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:00:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:00:09] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:00:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:00:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:00:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:00:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:00:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:00:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:00:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:00:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:11] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:11] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:11] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:11] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:11] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=148515) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=148515) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.20it/s]
(EngineCore_DP0 pid=148515) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.06s/it]
(EngineCore_DP0 pid=148515) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.03s/it]
(EngineCore_DP0 pid=148515) 
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16662528 bytes
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12959744 bytes
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 137003008 bytes
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:13] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=148515) [2026-01-26 04:00:13] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 68009984 bytes
(EngineCore_DP0 pid=148515) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  8.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  8.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  8.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  8.24it/s]
(EngineCore_DP0 pid=148515) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  7.49it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.54it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  8.36it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  10%|▉         | 25/256 [00:00<00:00, 240.90it/s]
Adding requests:  20%|█▉        | 51/256 [00:00<00:00, 251.33it/s]
Adding requests:  30%|███       | 78/256 [00:00<00:00, 258.44it/s]
Adding requests:  41%|████      | 104/256 [00:00<00:00, 254.51it/s]
Adding requests:  51%|█████     | 130/256 [00:00<00:00, 255.72it/s]
Adding requests:  61%|██████▏   | 157/256 [00:00<00:00, 257.75it/s]
Adding requests:  73%|███████▎  | 187/256 [00:00<00:00, 268.07it/s]
Adding requests:  84%|████████▎ | 214/256 [00:00<00:00, 267.03it/s]
Adding requests:  94%|█████████▍| 241/256 [00:00<00:00, 267.82it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 261.11it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 16/256 [00:00<00:02, 83.42it/s, est. speed input: 85439.57 toks/s, output: 83.43 toks/s]
Processed prompts:  10%|▉         | 25/256 [00:00<00:06, 37.25it/s, est. speed input: 42679.49 toks/s, output: 41.68 toks/s]
Processed prompts:  12%|█▏        | 30/256 [00:00<00:08, 27.93it/s, est. speed input: 33928.74 toks/s, output: 33.13 toks/s]
Processed prompts:  13%|█▎        | 34/256 [00:01<00:08, 25.41it/s, est. speed input: 31351.49 toks/s, output: 30.62 toks/s]
Processed prompts:  14%|█▍        | 37/256 [00:01<00:08, 26.09it/s, est. speed input: 31236.50 toks/s, output: 30.50 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:01<00:09, 22.27it/s, est. speed input: 28893.28 toks/s, output: 28.22 toks/s]
Processed prompts:  17%|█▋        | 43/256 [00:01<00:09, 23.64it/s, est. speed input: 28974.10 toks/s, output: 28.29 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:01<00:10, 20.47it/s, est. speed input: 27327.21 toks/s, output: 26.69 toks/s]
Processed prompts:  19%|█▉        | 49/256 [00:01<00:09, 22.24it/s, est. speed input: 27470.70 toks/s, output: 26.83 toks/s]
Processed prompts:  20%|██        | 52/256 [00:02<00:10, 19.43it/s, est. speed input: 26204.92 toks/s, output: 25.59 toks/s]
Processed prompts:  21%|██▏       | 55/256 [00:02<00:09, 21.45it/s, est. speed input: 26379.07 toks/s, output: 25.76 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:02<00:10, 18.94it/s, est. speed input: 25387.76 toks/s, output: 24.79 toks/s]
Processed prompts:  24%|██▍       | 61/256 [00:02<00:09, 21.09it/s, est. speed input: 25575.61 toks/s, output: 24.98 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:02<00:10, 18.66it/s, est. speed input: 24751.88 toks/s, output: 24.17 toks/s]
Processed prompts:  26%|██▌       | 67/256 [00:02<00:09, 20.92it/s, est. speed input: 24951.60 toks/s, output: 24.37 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:02<00:10, 18.56it/s, est. speed input: 24261.18 toks/s, output: 23.69 toks/s]
Processed prompts:  29%|██▊       | 73/256 [00:03<00:08, 20.82it/s, est. speed input: 24451.78 toks/s, output: 23.88 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:03<00:09, 18.53it/s, est. speed input: 23866.13 toks/s, output: 23.31 toks/s]
Processed prompts:  31%|███       | 79/256 [00:03<00:08, 20.84it/s, est. speed input: 24055.84 toks/s, output: 23.49 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:03<00:09, 18.53it/s, est. speed input: 23543.13 toks/s, output: 22.99 toks/s]
Processed prompts:  33%|███▎      | 85/256 [00:03<00:08, 20.84it/s, est. speed input: 23724.90 toks/s, output: 23.17 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:03<00:09, 18.53it/s, est. speed input: 23269.80 toks/s, output: 22.72 toks/s]
Processed prompts:  36%|███▌      | 91/256 [00:03<00:07, 20.82it/s, est. speed input: 23442.98 toks/s, output: 22.89 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:04<00:08, 18.49it/s, est. speed input: 23029.19 toks/s, output: 22.49 toks/s]
Processed prompts:  38%|███▊      | 97/256 [00:04<00:07, 20.80it/s, est. speed input: 23197.82 toks/s, output: 22.65 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:04<00:08, 18.50it/s, est. speed input: 22827.20 toks/s, output: 22.29 toks/s]
Processed prompts:  40%|████      | 103/256 [00:04<00:07, 20.82it/s, est. speed input: 22989.68 toks/s, output: 22.45 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:04<00:08, 18.52it/s, est. speed input: 22653.95 toks/s, output: 22.12 toks/s]
Processed prompts:  43%|████▎     | 109/256 [00:04<00:07, 20.84it/s, est. speed input: 22809.29 toks/s, output: 22.27 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:05<00:07, 18.48it/s, est. speed input: 22493.73 toks/s, output: 21.97 toks/s]
Processed prompts:  45%|████▍     | 115/256 [00:05<00:06, 20.79it/s, est. speed input: 22642.19 toks/s, output: 22.11 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:05<00:07, 18.46it/s, est. speed input: 22352.26 toks/s, output: 21.83 toks/s]
Processed prompts:  47%|████▋     | 121/256 [00:05<00:06, 20.78it/s, est. speed input: 22495.70 toks/s, output: 21.97 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:05<00:07, 18.45it/s, est. speed input: 22225.42 toks/s, output: 21.70 toks/s]
Processed prompts:  50%|████▉     | 127/256 [00:05<00:06, 20.77it/s, est. speed input: 22364.00 toks/s, output: 21.84 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:06<00:06, 18.49it/s, est. speed input: 22116.83 toks/s, output: 21.60 toks/s]
Processed prompts:  52%|█████▏    | 133/256 [00:06<00:05, 20.77it/s, est. speed input: 22247.13 toks/s, output: 21.73 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:06<00:06, 18.46it/s, est. speed input: 22013.37 toks/s, output: 21.50 toks/s]
Processed prompts:  54%|█████▍    | 139/256 [00:06<00:05, 20.76it/s, est. speed input: 22139.77 toks/s, output: 21.62 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:06<00:06, 18.46it/s, est. speed input: 21920.23 toks/s, output: 21.41 toks/s]
Processed prompts:  57%|█████▋    | 145/256 [00:06<00:05, 20.77it/s, est. speed input: 22043.44 toks/s, output: 21.53 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:06<00:05, 18.49it/s, est. speed input: 21838.44 toks/s, output: 21.33 toks/s]
Processed prompts:  59%|█████▉    | 151/256 [00:07<00:05, 20.81it/s, est. speed input: 21958.66 toks/s, output: 21.44 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:07<00:05, 18.48it/s, est. speed input: 21762.10 toks/s, output: 21.25 toks/s]
Processed prompts:  61%|██████▏   | 157/256 [00:07<00:04, 20.79it/s, est. speed input: 21877.30 toks/s, output: 21.36 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:07<00:05, 18.48it/s, est. speed input: 21692.31 toks/s, output: 21.18 toks/s]
Processed prompts:  64%|██████▎   | 163/256 [00:07<00:04, 20.79it/s, est. speed input: 21803.87 toks/s, output: 21.29 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:07<00:04, 18.48it/s, est. speed input: 21627.53 toks/s, output: 21.12 toks/s]
Processed prompts:  66%|██████▌   | 169/256 [00:07<00:04, 20.78it/s, est. speed input: 21735.23 toks/s, output: 21.23 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:08<00:00, 74.98it/s, est. speed input: 25014.83 toks/s, output: 24.43 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:08<00:01, 47.08it/s, est. speed input: 24892.10 toks/s, output: 24.31 toks/s]
Processed prompts:  83%|████████▎ | 213/256 [00:08<00:01, 37.81it/s, est. speed input: 24840.56 toks/s, output: 24.26 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:09<00:01, 30.17it/s, est. speed input: 24563.45 toks/s, output: 23.99 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:09<00:01, 27.47it/s, est. speed input: 24461.53 toks/s, output: 23.89 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:09<00:01, 25.37it/s, est. speed input: 24365.36 toks/s, output: 23.79 toks/s]
Processed prompts:  89%|████████▉ | 229/256 [00:09<00:01, 26.01it/s, est. speed input: 24426.46 toks/s, output: 23.85 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:09<00:01, 22.47it/s, est. speed input: 24230.73 toks/s, output: 23.66 toks/s]
Processed prompts:  92%|█████████▏| 235/256 [00:09<00:00, 23.69it/s, est. speed input: 24288.50 toks/s, output: 23.72 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:10<00:00, 20.56it/s, est. speed input: 24098.31 toks/s, output: 23.53 toks/s]
Processed prompts:  94%|█████████▍| 241/256 [00:10<00:00, 22.27it/s, est. speed input: 24156.99 toks/s, output: 23.59 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:10<00:00, 19.52it/s, est. speed input: 23976.10 toks/s, output: 23.41 toks/s]
Processed prompts:  96%|█████████▋| 247/256 [00:10<00:00, 21.51it/s, est. speed input: 24034.40 toks/s, output: 23.47 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:10<00:00, 18.95it/s, est. speed input: 23860.24 toks/s, output: 23.30 toks/s]
Processed prompts:  99%|█████████▉| 253/256 [00:10<00:00, 21.12it/s, est. speed input: 23919.07 toks/s, output: 23.36 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:10<00:00, 20.26it/s, est. speed input: 23844.29 toks/s, output: 23.29 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:10<00:00, 20.26it/s, est. speed input: 23844.29 toks/s, output: 23.29 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:10<00:00, 23.28it/s, est. speed input: 23844.29 toks/s, output: 23.29 toks/s]
[rank0]:[W126 04:00:51.975940442 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 04:00:54
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:01:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:01:06 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=149637) WARNING 01-26 04:01:13 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=149637) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=149637) WARNING 01-26 04:01:24 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.05 requests/s, 20550.78 total tokens/s, 20.05 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 04:01:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:01:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:01:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:01:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:01:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:01:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:01:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:01:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:01:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:01:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:01:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:01:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:01:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:01:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:01:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:01:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:01:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:14] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:14] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:14] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:14] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:14] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=149637) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=149637) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.15it/s]
(EngineCore_DP0 pid=149637) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.10s/it]
(EngineCore_DP0 pid=149637) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.06s/it]
(EngineCore_DP0 pid=149637) 
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16662528 bytes
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12959744 bytes
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 137003008 bytes
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=149637) [2026-01-26 04:01:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 68009984 bytes
(EngineCore_DP0 pid=149637) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  8.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  8.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  8.32it/s]
(EngineCore_DP0 pid=149637) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  7.43it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  8.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.99it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  8.72it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   5%|▍         | 24/512 [00:00<00:02, 239.60it/s]
Adding requests:  10%|▉         | 50/512 [00:00<00:01, 250.08it/s]
Adding requests:  15%|█▌        | 78/512 [00:00<00:01, 260.99it/s]
Adding requests:  21%|██        | 105/512 [00:00<00:01, 262.52it/s]
Adding requests:  26%|██▌       | 132/512 [00:00<00:01, 260.44it/s]
Adding requests:  31%|███▏      | 160/512 [00:00<00:01, 263.77it/s]
Adding requests:  37%|███▋      | 189/512 [00:00<00:01, 269.26it/s]
Adding requests:  42%|████▏     | 217/512 [00:00<00:01, 271.34it/s]
Adding requests:  48%|████▊     | 245/512 [00:00<00:00, 268.10it/s]
Adding requests:  53%|█████▎    | 272/512 [00:01<00:00, 266.21it/s]
Adding requests:  59%|█████▊    | 300/512 [00:01<00:00, 268.46it/s]
Adding requests:  64%|██████▍   | 327/512 [00:01<00:00, 268.15it/s]
Adding requests:  70%|██████▉   | 356/512 [00:01<00:00, 274.41it/s]
Adding requests:  75%|███████▌  | 384/512 [00:01<00:00, 275.19it/s]
Adding requests:  81%|████████  | 413/512 [00:01<00:00, 279.27it/s]
Adding requests:  86%|████████▌ | 441/512 [00:01<00:00, 279.05it/s]
Adding requests:  92%|█████████▏| 470/512 [00:01<00:00, 280.62it/s]
Adding requests:  98%|█████████▊| 500/512 [00:01<00:00, 285.90it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 272.44it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 34/512 [00:00<00:02, 170.97it/s, est. speed input: 175101.10 toks/s, output: 170.98 toks/s]
Processed prompts:  10%|█         | 52/512 [00:00<00:10, 45.17it/s, est. speed input: 54061.53 toks/s, output: 52.79 toks/s]   
Processed prompts:  12%|█▏        | 61/512 [00:01<00:12, 36.76it/s, est. speed input: 45327.83 toks/s, output: 44.27 toks/s]
Processed prompts:  13%|█▎        | 67/512 [00:01<00:15, 29.21it/s, est. speed input: 38726.55 toks/s, output: 37.82 toks/s]
Processed prompts:  14%|█▍        | 71/512 [00:01<00:16, 27.45it/s, est. speed input: 36946.98 toks/s, output: 36.08 toks/s]
Processed prompts:  15%|█▍        | 75/512 [00:02<00:16, 25.87it/s, est. speed input: 35483.09 toks/s, output: 34.65 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:02<00:18, 23.31it/s, est. speed input: 33830.51 toks/s, output: 33.04 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:02<00:19, 22.55it/s, est. speed input: 32830.71 toks/s, output: 32.06 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:02<00:19, 21.97it/s, est. speed input: 31979.64 toks/s, output: 31.23 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:02<00:19, 21.54it/s, est. speed input: 31243.95 toks/s, output: 30.51 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:03<00:19, 21.22it/s, est. speed input: 30599.03 toks/s, output: 29.88 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:03<00:19, 20.98it/s, est. speed input: 30028.00 toks/s, output: 29.32 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:03<00:19, 20.79it/s, est. speed input: 29515.77 toks/s, output: 28.82 toks/s]
Processed prompts:  21%|██        | 106/512 [00:03<00:19, 20.64it/s, est. speed input: 29055.19 toks/s, output: 28.37 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:03<00:19, 20.54it/s, est. speed input: 28641.13 toks/s, output: 27.97 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:04<00:19, 20.47it/s, est. speed input: 28265.82 toks/s, output: 27.60 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:04<00:19, 20.43it/s, est. speed input: 27927.74 toks/s, output: 27.27 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:04<00:19, 20.39it/s, est. speed input: 27616.69 toks/s, output: 26.97 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:04<00:18, 20.37it/s, est. speed input: 27332.37 toks/s, output: 26.69 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:04<00:18, 20.36it/s, est. speed input: 27072.17 toks/s, output: 26.44 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:05<00:18, 20.36it/s, est. speed input: 26833.07 toks/s, output: 26.20 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:05<00:18, 20.35it/s, est. speed input: 26609.62 toks/s, output: 25.99 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:05<00:18, 20.34it/s, est. speed input: 26402.60 toks/s, output: 25.78 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:05<00:18, 20.33it/s, est. speed input: 26208.88 toks/s, output: 25.59 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:05<00:17, 20.33it/s, est. speed input: 26029.58 toks/s, output: 25.42 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:06<00:05, 65.25it/s, est. speed input: 30676.81 toks/s, output: 29.96 toks/s]
Processed prompts:  37%|███▋      | 189/512 [00:06<00:05, 56.09it/s, est. speed input: 30854.84 toks/s, output: 30.13 toks/s]
Processed prompts:  38%|███▊      | 195/512 [00:06<00:08, 37.00it/s, est. speed input: 29954.99 toks/s, output: 29.25 toks/s]
Processed prompts:  39%|███▉      | 200/512 [00:06<00:09, 34.09it/s, est. speed input: 29840.88 toks/s, output: 29.14 toks/s]
Processed prompts:  40%|███▉      | 204/512 [00:07<00:09, 31.92it/s, est. speed input: 29732.84 toks/s, output: 29.04 toks/s]
Processed prompts:  41%|████      | 208/512 [00:07<00:10, 28.65it/s, est. speed input: 29490.89 toks/s, output: 28.80 toks/s]
Processed prompts:  41%|████▏     | 212/512 [00:07<00:11, 26.26it/s, est. speed input: 29261.46 toks/s, output: 28.58 toks/s]
Processed prompts:  42%|████▏     | 215/512 [00:07<00:12, 23.04it/s, est. speed input: 28907.36 toks/s, output: 28.23 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:07<00:14, 20.75it/s, est. speed input: 28572.38 toks/s, output: 27.90 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:08<00:14, 20.61it/s, est. speed input: 28380.59 toks/s, output: 27.72 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:08<00:13, 20.52it/s, est. speed input: 28197.75 toks/s, output: 27.54 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:08<00:13, 20.43it/s, est. speed input: 28021.94 toks/s, output: 27.37 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:08<00:13, 20.39it/s, est. speed input: 27856.05 toks/s, output: 27.20 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:08<00:13, 20.35it/s, est. speed input: 27696.14 toks/s, output: 27.05 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:08<00:13, 20.32it/s, est. speed input: 27543.37 toks/s, output: 26.90 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:09<00:13, 20.30it/s, est. speed input: 27397.24 toks/s, output: 26.76 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:09<00:12, 20.30it/s, est. speed input: 27258.28 toks/s, output: 26.62 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:09<00:12, 20.28it/s, est. speed input: 27123.66 toks/s, output: 26.49 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:09<00:12, 20.28it/s, est. speed input: 26995.55 toks/s, output: 26.36 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:09<00:12, 20.26it/s, est. speed input: 26870.78 toks/s, output: 26.24 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:10<00:12, 20.26it/s, est. speed input: 26751.72 toks/s, output: 26.12 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:10<00:11, 20.25it/s, est. speed input: 26636.55 toks/s, output: 26.01 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:10<00:11, 20.25it/s, est. speed input: 26526.18 toks/s, output: 25.90 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:10<00:11, 20.24it/s, est. speed input: 26419.73 toks/s, output: 25.80 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:10<00:11, 20.25it/s, est. speed input: 26317.38 toks/s, output: 25.70 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:11<00:11, 20.24it/s, est. speed input: 26218.35 toks/s, output: 25.60 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:11<00:10, 20.24it/s, est. speed input: 26122.83 toks/s, output: 25.51 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:11<00:10, 20.23it/s, est. speed input: 26029.59 toks/s, output: 25.42 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:11<00:10, 20.22it/s, est. speed input: 25939.46 toks/s, output: 25.33 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:11<00:10, 20.21it/s, est. speed input: 25852.00 toks/s, output: 25.25 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:12<00:10, 20.20it/s, est. speed input: 25767.90 toks/s, output: 25.16 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:12<00:10, 20.20it/s, est. speed input: 25686.13 toks/s, output: 25.08 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:12<00:09, 20.19it/s, est. speed input: 25606.66 toks/s, output: 25.01 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:12<00:09, 20.19it/s, est. speed input: 25530.16 toks/s, output: 24.93 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:12<00:09, 20.19it/s, est. speed input: 25455.71 toks/s, output: 24.86 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:13<00:09, 20.20it/s, est. speed input: 25384.69 toks/s, output: 24.79 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:13<00:08, 20.22it/s, est. speed input: 25316.16 toks/s, output: 24.72 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:13<00:08, 20.22it/s, est. speed input: 25248.52 toks/s, output: 24.66 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:13<00:08, 20.19it/s, est. speed input: 25181.43 toks/s, output: 24.59 toks/s]
Processed prompts:  67%|██████▋   | 342/512 [00:13<00:08, 20.18it/s, est. speed input: 25117.04 toks/s, output: 24.53 toks/s]
Processed prompts:  68%|██████▊   | 346/512 [00:14<00:08, 20.18it/s, est. speed input: 25054.50 toks/s, output: 24.47 toks/s]
Processed prompts:  68%|██████▊   | 350/512 [00:14<00:08, 20.17it/s, est. speed input: 24993.10 toks/s, output: 24.41 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:14<00:07, 20.16it/s, est. speed input: 24933.52 toks/s, output: 24.35 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:14<00:07, 20.15it/s, est. speed input: 24875.37 toks/s, output: 24.29 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:14<00:07, 20.15it/s, est. speed input: 24818.76 toks/s, output: 24.24 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:15<00:07, 20.13it/s, est. speed input: 24763.09 toks/s, output: 24.18 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:15<00:07, 20.13it/s, est. speed input: 24709.27 toks/s, output: 24.13 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:15<00:06, 20.12it/s, est. speed input: 24656.38 toks/s, output: 24.08 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:15<00:06, 20.12it/s, est. speed input: 24605.53 toks/s, output: 24.03 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:15<00:06, 20.12it/s, est. speed input: 24555.22 toks/s, output: 23.98 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:16<00:06, 20.13it/s, est. speed input: 24507.04 toks/s, output: 23.93 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:16<00:06, 20.13it/s, est. speed input: 24459.53 toks/s, output: 23.89 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:16<00:05, 20.12it/s, est. speed input: 24412.76 toks/s, output: 23.84 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:16<00:05, 20.12it/s, est. speed input: 24367.74 toks/s, output: 23.80 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:16<00:05, 20.12it/s, est. speed input: 24323.47 toks/s, output: 23.75 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:17<00:05, 20.12it/s, est. speed input: 24280.07 toks/s, output: 23.71 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:17<00:05, 20.12it/s, est. speed input: 24237.86 toks/s, output: 23.67 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:17<00:04, 20.12it/s, est. speed input: 24196.54 toks/s, output: 23.63 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:17<00:04, 20.11it/s, est. speed input: 24155.91 toks/s, output: 23.59 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:17<00:04, 20.12it/s, est. speed input: 24116.62 toks/s, output: 23.55 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:18<00:04, 20.11it/s, est. speed input: 24077.76 toks/s, output: 23.51 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:18<00:04, 20.10it/s, est. speed input: 24039.49 toks/s, output: 23.48 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:18<00:03, 20.09it/s, est. speed input: 24002.03 toks/s, output: 23.44 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:18<00:03, 20.08it/s, est. speed input: 23965.27 toks/s, output: 23.40 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:18<00:03, 20.08it/s, est. speed input: 23929.04 toks/s, output: 23.37 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:19<00:03, 20.07it/s, est. speed input: 23893.77 toks/s, output: 23.33 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:19<00:03, 20.09it/s, est. speed input: 23860.08 toks/s, output: 23.30 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:19<00:02, 20.09it/s, est. speed input: 23826.48 toks/s, output: 23.27 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:19<00:02, 20.10it/s, est. speed input: 23794.02 toks/s, output: 23.24 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:19<00:02, 20.11it/s, est. speed input: 23762.53 toks/s, output: 23.21 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:20<00:02, 20.12it/s, est. speed input: 23731.23 toks/s, output: 23.17 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:20<00:02, 20.10it/s, est. speed input: 23699.95 toks/s, output: 23.14 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:20<00:01, 20.10it/s, est. speed input: 23669.62 toks/s, output: 23.11 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:20<00:01, 20.10it/s, est. speed input: 23640.09 toks/s, output: 23.09 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:20<00:01, 20.10it/s, est. speed input: 23610.95 toks/s, output: 23.06 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:21<00:01, 20.11it/s, est. speed input: 23582.93 toks/s, output: 23.03 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:21<00:01, 20.10it/s, est. speed input: 23554.65 toks/s, output: 23.00 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:21<00:00, 20.12it/s, est. speed input: 23527.72 toks/s, output: 22.98 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:21<00:00, 20.09it/s, est. speed input: 23499.79 toks/s, output: 22.95 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:21<00:00, 20.06it/s, est. speed input: 23472.25 toks/s, output: 22.92 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:22<00:00, 20.08it/s, est. speed input: 23446.40 toks/s, output: 22.90 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:22<00:00, 21.46it/s, est. speed input: 23465.75 toks/s, output: 22.92 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:22<00:00, 21.46it/s, est. speed input: 23557.54 toks/s, output: 23.01 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:22<00:00, 23.01it/s, est. speed input: 23557.54 toks/s, output: 23.01 toks/s]
[rank0]:[W126 04:02:07.378637935 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 04:02:09
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:02:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:02:24 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=150979) WARNING 01-26 04:02:31 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=150979) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=150979) WARNING 01-26 04:02:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.26 requests/s, 20767.35 total tokens/s, 20.26 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 04:02:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:02:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:02:23] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:02:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:02:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:02:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:02:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:02:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:02:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:02:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:02:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:02:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:02:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:02:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:02:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:02:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:02:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:32] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:32] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:32] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:32] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:32] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=150979) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=150979) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.15it/s]
(EngineCore_DP0 pid=150979) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.06s/it]
(EngineCore_DP0 pid=150979) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.03s/it]
(EngineCore_DP0 pid=150979) 
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16662528 bytes
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12959744 bytes
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 137003008 bytes
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:35] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=150979) [2026-01-26 04:02:35] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 68009984 bytes
(EngineCore_DP0 pid=150979) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  4.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  5.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  6.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  6.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:00<00:00,  5.74it/s]
(EngineCore_DP0 pid=150979) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:00,  7.03it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  8.14it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  8.59it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.89it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:00<00:00,  8.57it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 25/1024 [00:00<00:04, 240.47it/s]
Adding requests:   5%|▌         | 52/1024 [00:00<00:03, 252.89it/s]
Adding requests:   8%|▊         | 80/1024 [00:00<00:03, 262.02it/s]
Adding requests:  10%|█         | 107/1024 [00:00<00:03, 255.84it/s]
Adding requests:  13%|█▎        | 133/1024 [00:00<00:03, 252.84it/s]
Adding requests:  16%|█▌        | 161/1024 [00:00<00:03, 260.17it/s]
Adding requests:  19%|█▊        | 190/1024 [00:00<00:03, 269.37it/s]
Adding requests:  21%|██▏       | 218/1024 [00:00<00:02, 271.11it/s]
Adding requests:  24%|██▍       | 246/1024 [00:00<00:02, 271.23it/s]
Adding requests:  27%|██▋       | 274/1024 [00:01<00:02, 270.43it/s]
Adding requests:  30%|██▉       | 303/1024 [00:01<00:02, 274.00it/s]
Adding requests:  32%|███▏      | 331/1024 [00:01<00:02, 273.10it/s]
Adding requests:  35%|███▌      | 359/1024 [00:01<00:02, 270.88it/s]
Adding requests:  38%|███▊      | 387/1024 [00:01<00:02, 272.45it/s]
Adding requests:  41%|████      | 415/1024 [00:01<00:02, 273.04it/s]
Adding requests:  43%|████▎     | 443/1024 [00:01<00:02, 270.21it/s]
Adding requests:  46%|████▌     | 472/1024 [00:01<00:02, 273.28it/s]
Adding requests:  49%|████▉     | 502/1024 [00:01<00:01, 277.83it/s]
Adding requests:  52%|█████▏    | 532/1024 [00:01<00:01, 283.15it/s]
Adding requests:  55%|█████▍    | 561/1024 [00:02<00:01, 283.33it/s]
Adding requests:  58%|█████▊    | 590/1024 [00:02<00:01, 277.41it/s]
Adding requests:  60%|██████    | 618/1024 [00:02<00:01, 275.76it/s]
Adding requests:  63%|██████▎   | 646/1024 [00:02<00:01, 267.26it/s]
Adding requests:  66%|██████▌   | 673/1024 [00:02<00:01, 267.52it/s]
Adding requests:  69%|██████▊   | 703/1024 [00:02<00:01, 276.24it/s]
Adding requests:  71%|███████▏  | 731/1024 [00:02<00:01, 268.48it/s]
Adding requests:  74%|███████▍  | 758/1024 [00:02<00:00, 268.72it/s]
Adding requests:  77%|███████▋  | 787/1024 [00:02<00:00, 273.43it/s]
Adding requests:  80%|███████▉  | 815/1024 [00:03<00:00, 272.92it/s]
Adding requests:  82%|████████▏ | 844/1024 [00:03<00:00, 277.10it/s]
Adding requests:  85%|████████▌ | 873/1024 [00:03<00:00, 279.67it/s]
Adding requests:  88%|████████▊ | 901/1024 [00:03<00:00, 279.62it/s]
Adding requests:  91%|█████████ | 929/1024 [00:03<00:00, 267.56it/s]
Adding requests:  94%|█████████▎| 958/1024 [00:03<00:00, 270.75it/s]
Adding requests:  96%|█████████▋| 986/1024 [00:03<00:00, 270.53it/s]
Adding requests:  99%|█████████▉| 1014/1024 [00:03<00:00, 266.30it/s]
Adding requests: 100%|██████████| 1024/1024 [00:03<00:00, 270.62it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 74/1024 [00:00<00:05, 182.25it/s, est. speed input: 186635.95 toks/s, output: 182.25 toks/s]
Processed prompts:   9%|▉         | 93/1024 [00:01<00:13, 66.59it/s, est. speed input: 80360.49 toks/s, output: 78.48 toks/s]   
Processed prompts:  10%|▉         | 102/1024 [00:01<00:17, 51.64it/s, est. speed input: 66329.74 toks/s, output: 64.77 toks/s]
Processed prompts:  11%|█         | 108/1024 [00:01<00:23, 39.70it/s, est. speed input: 56289.26 toks/s, output: 54.97 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:02<00:28, 31.92it/s, est. speed input: 49580.58 toks/s, output: 48.42 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:02<00:31, 28.34it/s, est. speed input: 45516.25 toks/s, output: 44.45 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:03<00:34, 25.92it/s, est. speed input: 42466.37 toks/s, output: 41.47 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:03<00:36, 24.25it/s, est. speed input: 40089.00 toks/s, output: 39.15 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:03<00:37, 23.11it/s, est. speed input: 38182.87 toks/s, output: 37.29 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:04<00:38, 22.31it/s, est. speed input: 36623.03 toks/s, output: 35.76 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:04<00:39, 21.75it/s, est. speed input: 35319.06 toks/s, output: 34.49 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:05<00:39, 21.36it/s, est. speed input: 34215.25 toks/s, output: 33.41 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:05<00:40, 21.09it/s, est. speed input: 33268.64 toks/s, output: 32.49 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:05<00:40, 20.90it/s, est. speed input: 32448.75 toks/s, output: 31.69 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:06<00:39, 20.77it/s, est. speed input: 31730.42 toks/s, output: 30.99 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:06<00:38, 21.21it/s, est. speed input: 31251.77 toks/s, output: 30.52 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:07<00:38, 20.97it/s, est. speed input: 30674.64 toks/s, output: 29.96 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:07<00:38, 20.81it/s, est. speed input: 30158.60 toks/s, output: 29.45 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:07<00:38, 20.69it/s, est. speed input: 29694.21 toks/s, output: 29.00 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:08<00:38, 20.61it/s, est. speed input: 29273.05 toks/s, output: 28.59 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:08<00:38, 20.55it/s, est. speed input: 28891.01 toks/s, output: 28.21 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:08<00:37, 20.50it/s, est. speed input: 28541.04 toks/s, output: 27.87 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:09<00:37, 20.47it/s, est. speed input: 28219.70 toks/s, output: 27.56 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:09<00:37, 20.44it/s, est. speed input: 27923.96 toks/s, output: 27.27 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:10<00:36, 20.42it/s, est. speed input: 27649.99 toks/s, output: 27.00 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:10<00:36, 20.41it/s, est. speed input: 27398.03 toks/s, output: 26.76 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:10<00:35, 20.39it/s, est. speed input: 27162.52 toks/s, output: 26.53 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:11<00:35, 20.39it/s, est. speed input: 26943.75 toks/s, output: 26.31 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:11<00:35, 20.38it/s, est. speed input: 26740.18 toks/s, output: 26.11 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:12<00:34, 20.38it/s, est. speed input: 26548.94 toks/s, output: 25.93 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:12<00:34, 20.36it/s, est. speed input: 26368.90 toks/s, output: 25.75 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:12<00:34, 20.35it/s, est. speed input: 26199.44 toks/s, output: 25.59 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:13<00:33, 20.34it/s, est. speed input: 26039.74 toks/s, output: 25.43 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:13<00:33, 20.33it/s, est. speed input: 25888.55 toks/s, output: 25.28 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:14<00:32, 20.32it/s, est. speed input: 25746.07 toks/s, output: 25.14 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:14<00:32, 20.31it/s, est. speed input: 25610.53 toks/s, output: 25.01 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:14<00:32, 20.30it/s, est. speed input: 25481.95 toks/s, output: 24.88 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:15<00:31, 20.30it/s, est. speed input: 25360.34 toks/s, output: 24.77 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:15<00:31, 20.29it/s, est. speed input: 25244.44 toks/s, output: 24.65 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:16<00:31, 20.29it/s, est. speed input: 25134.53 toks/s, output: 24.55 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:16<00:30, 20.27it/s, est. speed input: 25028.52 toks/s, output: 24.44 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:16<00:30, 20.27it/s, est. speed input: 24928.31 toks/s, output: 24.34 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:17<00:29, 20.27it/s, est. speed input: 24832.74 toks/s, output: 24.25 toks/s]
Processed prompts:  42%|████▏     | 426/1024 [00:17<00:29, 20.27it/s, est. speed input: 24741.14 toks/s, output: 24.16 toks/s]
Processed prompts:  42%|████▏     | 434/1024 [00:18<00:29, 20.26it/s, est. speed input: 24653.28 toks/s, output: 24.08 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:18<00:28, 20.26it/s, est. speed input: 24569.56 toks/s, output: 23.99 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:18<00:28, 20.26it/s, est. speed input: 24489.07 toks/s, output: 23.92 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:19<00:11, 45.45it/s, est. speed input: 25963.79 toks/s, output: 25.36 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:19<00:14, 36.98it/s, est. speed input: 25857.20 toks/s, output: 25.25 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:19<00:16, 31.55it/s, est. speed input: 25754.94 toks/s, output: 25.15 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:20<00:18, 27.97it/s, est. speed input: 25656.60 toks/s, output: 25.06 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:20<00:19, 25.57it/s, est. speed input: 25562.49 toks/s, output: 24.96 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:20<00:20, 23.93it/s, est. speed input: 25471.79 toks/s, output: 24.87 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:21<00:21, 22.80it/s, est. speed input: 25383.90 toks/s, output: 24.79 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:21<00:22, 22.02it/s, est. speed input: 25298.87 toks/s, output: 24.71 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:22<00:22, 21.47it/s, est. speed input: 25217.03 toks/s, output: 24.63 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:22<00:22, 21.10it/s, est. speed input: 25138.42 toks/s, output: 24.55 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:22<00:22, 20.84it/s, est. speed input: 25062.58 toks/s, output: 24.48 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:23<00:21, 20.67it/s, est. speed input: 24989.54 toks/s, output: 24.40 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:23<00:21, 20.55it/s, est. speed input: 24918.99 toks/s, output: 24.33 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:24<00:21, 20.46it/s, est. speed input: 24850.59 toks/s, output: 24.27 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:24<00:21, 20.39it/s, est. speed input: 24784.19 toks/s, output: 24.20 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:24<00:20, 20.35it/s, est. speed input: 24720.09 toks/s, output: 24.14 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:25<00:20, 20.32it/s, est. speed input: 24658.20 toks/s, output: 24.08 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:25<00:19, 20.30it/s, est. speed input: 24598.06 toks/s, output: 24.02 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:26<00:19, 20.29it/s, est. speed input: 24539.98 toks/s, output: 23.96 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:26<00:19, 20.28it/s, est. speed input: 24483.58 toks/s, output: 23.91 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:26<00:18, 20.28it/s, est. speed input: 24428.87 toks/s, output: 23.86 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:27<00:18, 20.28it/s, est. speed input: 24375.81 toks/s, output: 23.80 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:27<00:18, 20.27it/s, est. speed input: 24324.19 toks/s, output: 23.75 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:28<00:17, 20.27it/s, est. speed input: 24273.91 toks/s, output: 23.70 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:28<00:17, 20.27it/s, est. speed input: 24225.46 toks/s, output: 23.66 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:28<00:16, 20.27it/s, est. speed input: 24178.00 toks/s, output: 23.61 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:29<00:16, 20.27it/s, est. speed input: 24131.84 toks/s, output: 23.57 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:29<00:16, 20.27it/s, est. speed input: 24087.04 toks/s, output: 23.52 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [00:30<00:15, 20.27it/s, est. speed input: 24043.49 toks/s, output: 23.48 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [00:30<00:15, 20.28it/s, est. speed input: 24001.26 toks/s, output: 23.44 toks/s]
Processed prompts:  71%|███████   | 722/1024 [00:30<00:14, 20.28it/s, est. speed input: 23960.06 toks/s, output: 23.40 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [00:31<00:14, 20.28it/s, est. speed input: 23919.78 toks/s, output: 23.36 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [00:31<00:14, 20.29it/s, est. speed input: 23880.68 toks/s, output: 23.32 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [00:32<00:13, 20.29it/s, est. speed input: 23842.69 toks/s, output: 23.28 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [00:32<00:13, 20.29it/s, est. speed input: 23805.47 toks/s, output: 23.25 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [00:32<00:12, 20.29it/s, est. speed input: 23769.22 toks/s, output: 23.21 toks/s]
Processed prompts:  75%|███████▌  | 770/1024 [00:33<00:12, 20.29it/s, est. speed input: 23733.78 toks/s, output: 23.18 toks/s]
Processed prompts:  76%|███████▌  | 778/1024 [00:33<00:12, 20.29it/s, est. speed input: 23699.13 toks/s, output: 23.14 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [00:33<00:11, 20.85it/s, est. speed input: 23689.83 toks/s, output: 23.13 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [00:34<00:11, 20.68it/s, est. speed input: 23656.59 toks/s, output: 23.10 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [00:34<00:10, 20.57it/s, est. speed input: 23623.98 toks/s, output: 23.07 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [00:35<00:10, 20.48it/s, est. speed input: 23592.06 toks/s, output: 23.04 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [00:35<00:10, 20.43it/s, est. speed input: 23560.96 toks/s, output: 23.01 toks/s]
Processed prompts:  81%|████████  | 826/1024 [00:35<00:09, 20.39it/s, est. speed input: 23530.67 toks/s, output: 22.98 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [00:36<00:09, 20.36it/s, est. speed input: 23500.81 toks/s, output: 22.95 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [00:36<00:08, 20.34it/s, est. speed input: 23471.65 toks/s, output: 22.92 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [00:37<00:08, 20.33it/s, est. speed input: 23443.18 toks/s, output: 22.89 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [00:37<00:08, 20.31it/s, est. speed input: 23415.14 toks/s, output: 22.87 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [00:37<00:07, 20.31it/s, est. speed input: 23387.82 toks/s, output: 22.84 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [00:38<00:07, 20.30it/s, est. speed input: 23360.78 toks/s, output: 22.81 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [00:38<00:06, 20.30it/s, est. speed input: 23334.52 toks/s, output: 22.79 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [00:39<00:06, 20.30it/s, est. speed input: 23308.82 toks/s, output: 22.76 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [00:39<00:06, 20.30it/s, est. speed input: 23283.59 toks/s, output: 22.74 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [00:39<00:05, 20.30it/s, est. speed input: 23258.93 toks/s, output: 22.71 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [00:40<00:05, 20.29it/s, est. speed input: 23234.56 toks/s, output: 22.69 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [00:40<00:05, 20.29it/s, est. speed input: 23210.70 toks/s, output: 22.67 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [00:41<00:04, 20.29it/s, est. speed input: 23187.44 toks/s, output: 22.64 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [00:41<00:04, 20.29it/s, est. speed input: 23164.57 toks/s, output: 22.62 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [00:41<00:03, 20.29it/s, est. speed input: 23142.02 toks/s, output: 22.60 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [00:42<00:03, 20.29it/s, est. speed input: 23120.02 toks/s, output: 22.58 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [00:42<00:03, 20.29it/s, est. speed input: 23098.43 toks/s, output: 22.56 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [00:43<00:02, 20.29it/s, est. speed input: 23077.05 toks/s, output: 22.54 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [00:43<00:02, 20.29it/s, est. speed input: 23056.35 toks/s, output: 22.52 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [00:43<00:01, 20.29it/s, est. speed input: 23035.71 toks/s, output: 22.50 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [00:44<00:01, 20.29it/s, est. speed input: 23015.53 toks/s, output: 22.48 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [00:44<00:01, 20.29it/s, est. speed input: 22995.85 toks/s, output: 22.46 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [00:45<00:00, 20.29it/s, est. speed input: 22976.42 toks/s, output: 22.44 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [00:45<00:00, 20.93it/s, est. speed input: 22977.67 toks/s, output: 22.44 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:45<00:00, 20.93it/s, est. speed input: 23112.94 toks/s, output: 22.57 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [00:45<00:00, 22.57it/s, est. speed input: 23112.94 toks/s, output: 22.57 toks/s]
[rank0]:[W126 04:03:50.132033601 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 04:03:53
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:04:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:04:15 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=152785) WARNING 01-26 04:04:22 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=152785) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=152785) WARNING 01-26 04:04:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.25 requests/s, 20759.31 total tokens/s, 20.25 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 04:04:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:04:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:04:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:04:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:04:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:04:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:04:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:04:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:04:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:04:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:04:22] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:04:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:04:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:04:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:04:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:04:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:04:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:23] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:23] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:23] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:23] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:23] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:23] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=152785) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=152785) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.20it/s]
(EngineCore_DP0 pid=152785) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.06s/it]
(EngineCore_DP0 pid=152785) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.03s/it]
(EngineCore_DP0 pid=152785) 
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16662528 bytes
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12959744 bytes
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 137003008 bytes
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=152785) [2026-01-26 04:04:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 68009984 bytes
(EngineCore_DP0 pid=152785) [rank0]:W0126 04:04:42.063000 152785 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=152785) [rank0]:W0126 04:04:42.176000 152785 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=152785) [rank0]:W0126 04:04:43.842000 152785 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=152785) [rank0]:W0126 04:04:44.017000 152785 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=152785) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  7.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  8.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  8.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  8.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  8.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  8.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  8.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00,  8.39it/s]
(EngineCore_DP0 pid=152785) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  7.10it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  8.15it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  8.54it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  8.82it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  9.03it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  8.69it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 25/2048 [00:00<00:08, 242.80it/s]
Adding requests:   3%|▎         | 52/2048 [00:00<00:07, 256.29it/s]
Adding requests:   4%|▍         | 79/2048 [00:00<00:07, 260.93it/s]
Adding requests:   5%|▌         | 106/2048 [00:00<00:07, 262.29it/s]
Adding requests:   6%|▋         | 133/2048 [00:00<00:07, 262.70it/s]
Adding requests:   8%|▊         | 161/2048 [00:00<00:07, 267.03it/s]
Adding requests:   9%|▉         | 190/2048 [00:00<00:06, 273.88it/s]
Adding requests:  11%|█         | 218/2048 [00:00<00:06, 271.48it/s]
Adding requests:  12%|█▏        | 246/2048 [00:00<00:06, 272.89it/s]
Adding requests:  13%|█▎        | 274/2048 [00:01<00:06, 269.72it/s]
Adding requests:  15%|█▍        | 303/2048 [00:01<00:06, 273.48it/s]
Adding requests:  16%|█▌        | 332/2048 [00:01<00:06, 276.26it/s]
Adding requests:  18%|█▊        | 362/2048 [00:01<00:06, 280.45it/s]
Adding requests:  19%|█▉        | 391/2048 [00:01<00:05, 282.62it/s]
Adding requests:  21%|██        | 421/2048 [00:01<00:05, 285.57it/s]
Adding requests:  22%|██▏       | 450/2048 [00:01<00:05, 279.66it/s]
Adding requests:  23%|██▎       | 481/2048 [00:01<00:05, 287.62it/s]
Adding requests:  25%|██▍       | 510/2048 [00:01<00:05, 282.46it/s]
Adding requests:  26%|██▋       | 539/2048 [00:01<00:05, 279.49it/s]
Adding requests:  28%|██▊       | 568/2048 [00:02<00:05, 279.51it/s]
Adding requests:  29%|██▉       | 596/2048 [00:02<00:05, 269.33it/s]
Adding requests:  30%|███       | 624/2048 [00:02<00:05, 268.31it/s]
Adding requests:  32%|███▏      | 651/2048 [00:02<00:05, 265.88it/s]
Adding requests:  33%|███▎      | 678/2048 [00:02<00:05, 265.20it/s]
Adding requests:  34%|███▍      | 706/2048 [00:02<00:05, 266.22it/s]
Adding requests:  36%|███▌      | 733/2048 [00:02<00:04, 266.13it/s]
Adding requests:  37%|███▋      | 760/2048 [00:02<00:04, 266.09it/s]
Adding requests:  39%|███▊      | 789/2048 [00:02<00:04, 271.20it/s]
Adding requests:  40%|███▉      | 817/2048 [00:03<00:04, 271.45it/s]
Adding requests:  41%|████▏     | 847/2048 [00:03<00:04, 270.92it/s]
Adding requests:  43%|████▎     | 875/2048 [00:03<00:04, 273.34it/s]
Adding requests:  44%|████▍     | 904/2048 [00:03<00:04, 277.77it/s]
Adding requests:  46%|████▌     | 932/2048 [00:03<00:04, 269.95it/s]
Adding requests:  47%|████▋     | 960/2048 [00:03<00:04, 271.69it/s]
Adding requests:  48%|████▊     | 988/2048 [00:03<00:03, 271.66it/s]
Adding requests:  50%|████▉     | 1016/2048 [00:03<00:03, 268.67it/s]
Adding requests:  51%|█████     | 1044/2048 [00:03<00:03, 270.27it/s]
Adding requests:  52%|█████▏    | 1072/2048 [00:03<00:03, 266.54it/s]
Adding requests:  54%|█████▎    | 1099/2048 [00:04<00:03, 266.94it/s]
Adding requests:  55%|█████▌    | 1128/2048 [00:04<00:03, 272.76it/s]
Adding requests:  56%|█████▋    | 1156/2048 [00:04<00:03, 269.07it/s]
Adding requests:  58%|█████▊    | 1184/2048 [00:04<00:03, 269.90it/s]
Adding requests:  59%|█████▉    | 1213/2048 [00:04<00:03, 272.85it/s]
Adding requests:  61%|██████    | 1241/2048 [00:04<00:02, 274.20it/s]
Adding requests:  62%|██████▏   | 1269/2048 [00:04<00:02, 271.27it/s]
Adding requests:  81%|████████▏ | 1669/2048 [00:04<00:00, 1353.42it/s]
Adding requests:  88%|████████▊ | 1806/2048 [00:05<00:00, 631.68it/s] 
Adding requests:  93%|█████████▎| 1911/2048 [00:05<00:00, 482.46it/s]
Adding requests:  97%|█████████▋| 1993/2048 [00:05<00:00, 417.77it/s]
Adding requests: 100%|██████████| 2048/2048 [00:06<00:00, 332.92it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:00<00:07, 251.31it/s, est. speed input: 257349.70 toks/s, output: 251.31 toks/s]
Processed prompts:   8%|▊         | 172/2048 [00:01<00:17, 107.77it/s, est. speed input: 129144.96 toks/s, output: 126.12 toks/s]
Processed prompts:   9%|▉         | 185/2048 [00:02<00:29, 63.63it/s, est. speed input: 88281.51 toks/s, output: 86.21 toks/s]   
Processed prompts:   9%|▉         | 194/2048 [00:02<00:43, 42.32it/s, est. speed input: 67857.43 toks/s, output: 66.27 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:03<00:53, 34.24it/s, est. speed input: 57948.21 toks/s, output: 56.59 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:04<01:01, 29.47it/s, est. speed input: 51492.84 toks/s, output: 50.29 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:05<01:08, 26.46it/s, est. speed input: 46939.66 toks/s, output: 45.84 toks/s]
Processed prompts:  13%|█▎        | 258/2048 [00:06<01:13, 24.52it/s, est. speed input: 43569.11 toks/s, output: 42.55 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:06<01:16, 23.22it/s, est. speed input: 40969.14 toks/s, output: 40.01 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:07<01:18, 22.33it/s, est. speed input: 38898.20 toks/s, output: 37.99 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:08<01:20, 21.73it/s, est. speed input: 37212.99 toks/s, output: 36.34 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:09<01:21, 21.31it/s, est. speed input: 35814.45 toks/s, output: 34.97 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:09<01:21, 21.01it/s, est. speed input: 34635.79 toks/s, output: 33.82 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:10<01:21, 20.81it/s, est. speed input: 33627.64 toks/s, output: 32.84 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:11<01:21, 20.66it/s, est. speed input: 32755.56 toks/s, output: 31.99 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:12<01:20, 20.56it/s, est. speed input: 31994.37 toks/s, output: 31.24 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:13<01:20, 20.44it/s, est. speed input: 31307.86 toks/s, output: 30.57 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:13<01:19, 20.40it/s, est. speed input: 30713.60 toks/s, output: 29.99 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:14<01:19, 20.37it/s, est. speed input: 30181.80 toks/s, output: 29.47 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:15<01:18, 20.34it/s, est. speed input: 29703.06 toks/s, output: 29.01 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:16<01:17, 20.33it/s, est. speed input: 29271.80 toks/s, output: 28.59 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:17<01:17, 20.32it/s, est. speed input: 28881.38 toks/s, output: 28.20 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:17<01:16, 20.31it/s, est. speed input: 28522.75 toks/s, output: 27.85 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:18<01:15, 20.29it/s, est. speed input: 28193.78 toks/s, output: 27.53 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:19<01:14, 20.29it/s, est. speed input: 27892.30 toks/s, output: 27.24 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:20<01:14, 20.28it/s, est. speed input: 27614.21 toks/s, output: 26.97 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:21<01:13, 20.27it/s, est. speed input: 27355.67 toks/s, output: 26.71 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:21<01:12, 20.27it/s, est. speed input: 27116.70 toks/s, output: 26.48 toks/s]
Processed prompts:  29%|██▉       | 594/2048 [00:22<01:11, 20.26it/s, est. speed input: 26893.21 toks/s, output: 26.26 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:23<01:10, 20.26it/s, est. speed input: 26686.20 toks/s, output: 26.06 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:24<01:10, 20.26it/s, est. speed input: 26492.32 toks/s, output: 25.87 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:24<01:09, 20.25it/s, est. speed input: 26309.71 toks/s, output: 25.69 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:25<01:08, 20.25it/s, est. speed input: 26138.42 toks/s, output: 25.53 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:26<01:07, 20.25it/s, est. speed input: 25977.64 toks/s, output: 25.37 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:27<01:07, 20.25it/s, est. speed input: 25826.95 toks/s, output: 25.22 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:28<01:06, 20.25it/s, est. speed input: 25683.45 toks/s, output: 25.08 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:28<01:05, 20.25it/s, est. speed input: 25548.75 toks/s, output: 24.95 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [00:29<00:37, 34.31it/s, est. speed input: 26518.62 toks/s, output: 25.90 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [00:29<00:43, 29.29it/s, est. speed input: 26367.20 toks/s, output: 25.75 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [00:30<00:47, 26.64it/s, est. speed input: 26253.34 toks/s, output: 25.64 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [00:31<00:50, 24.54it/s, est. speed input: 26115.09 toks/s, output: 25.50 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [00:32<00:53, 23.19it/s, est. speed input: 25985.13 toks/s, output: 25.38 toks/s]
Processed prompts:  41%|████      | 834/2048 [00:33<00:54, 22.28it/s, est. speed input: 25861.19 toks/s, output: 25.26 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [00:33<00:55, 21.65it/s, est. speed input: 25741.47 toks/s, output: 25.14 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [00:34<00:55, 21.24it/s, est. speed input: 25628.42 toks/s, output: 25.03 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [00:35<00:55, 20.96it/s, est. speed input: 25521.46 toks/s, output: 24.92 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [00:36<00:55, 20.75it/s, est. speed input: 25417.74 toks/s, output: 24.82 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [00:36<00:55, 20.60it/s, est. speed input: 25317.75 toks/s, output: 24.72 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [00:37<00:54, 20.51it/s, est. speed input: 25222.89 toks/s, output: 24.63 toks/s]
Processed prompts:  46%|████▌     | 946/2048 [00:38<00:53, 20.45it/s, est. speed input: 25132.20 toks/s, output: 24.54 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [00:39<00:53, 20.40it/s, est. speed input: 25045.13 toks/s, output: 24.46 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [00:40<00:52, 20.36it/s, est. speed input: 24960.34 toks/s, output: 24.38 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [00:40<00:51, 20.33it/s, est. speed input: 24879.19 toks/s, output: 24.30 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [00:41<00:51, 20.32it/s, est. speed input: 24801.62 toks/s, output: 24.22 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [00:42<00:50, 20.31it/s, est. speed input: 24726.65 toks/s, output: 24.15 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [00:43<00:49, 20.28it/s, est. speed input: 24653.31 toks/s, output: 24.08 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [00:44<00:48, 20.28it/s, est. speed input: 24583.90 toks/s, output: 24.01 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [00:44<00:48, 20.29it/s, est. speed input: 24516.99 toks/s, output: 23.94 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [00:45<00:47, 20.27it/s, est. speed input: 24451.19 toks/s, output: 23.88 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [00:46<00:46, 20.27it/s, est. speed input: 24388.67 toks/s, output: 23.82 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [00:47<00:45, 20.28it/s, est. speed input: 24328.30 toks/s, output: 23.76 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [00:48<00:44, 20.27it/s, est. speed input: 24269.21 toks/s, output: 23.70 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [00:48<00:44, 20.28it/s, est. speed input: 24212.93 toks/s, output: 23.65 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [00:49<00:43, 20.27it/s, est. speed input: 24157.85 toks/s, output: 23.59 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [00:50<00:42, 20.27it/s, est. speed input: 24104.66 toks/s, output: 23.54 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [00:51<00:41, 20.27it/s, est. speed input: 24052.53 toks/s, output: 23.49 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [00:51<00:40, 20.27it/s, est. speed input: 24002.86 toks/s, output: 23.44 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [00:52<00:40, 20.28it/s, est. speed input: 23954.53 toks/s, output: 23.39 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [00:53<00:39, 20.27it/s, est. speed input: 23907.00 toks/s, output: 23.35 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [00:54<00:38, 20.27it/s, est. speed input: 23861.45 toks/s, output: 23.30 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [00:55<00:37, 20.28it/s, est. speed input: 23817.34 toks/s, output: 23.26 toks/s]
Processed prompts:  63%|██████▎   | 1298/2048 [00:55<00:36, 20.28it/s, est. speed input: 23774.54 toks/s, output: 23.22 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [00:56<00:36, 20.27it/s, est. speed input: 23732.08 toks/s, output: 23.18 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [00:57<00:35, 20.27it/s, est. speed input: 23691.35 toks/s, output: 23.14 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [00:58<00:34, 20.28it/s, est. speed input: 23652.01 toks/s, output: 23.10 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [00:59<00:33, 20.27it/s, est. speed input: 23612.84 toks/s, output: 23.06 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [00:59<00:33, 20.27it/s, est. speed input: 23575.25 toks/s, output: 23.02 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [01:00<00:32, 20.28it/s, est. speed input: 23538.89 toks/s, output: 22.99 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [01:00<00:18, 34.39it/s, est. speed input: 24010.02 toks/s, output: 23.45 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [01:01<00:20, 29.35it/s, est. speed input: 23968.99 toks/s, output: 23.41 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [01:02<00:22, 26.28it/s, est. speed input: 23928.77 toks/s, output: 23.37 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [01:03<00:23, 24.31it/s, est. speed input: 23888.83 toks/s, output: 23.33 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [01:03<00:24, 23.04it/s, est. speed input: 23850.58 toks/s, output: 23.29 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [01:04<00:24, 22.18it/s, est. speed input: 23813.28 toks/s, output: 23.26 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [01:05<00:24, 21.59it/s, est. speed input: 23776.23 toks/s, output: 23.22 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [01:06<00:24, 21.20it/s, est. speed input: 23740.79 toks/s, output: 23.18 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [01:07<00:23, 20.92it/s, est. speed input: 23705.95 toks/s, output: 23.15 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [01:07<00:23, 20.72it/s, est. speed input: 23671.60 toks/s, output: 23.12 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [01:08<00:22, 20.59it/s, est. speed input: 23638.52 toks/s, output: 23.08 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [01:09<00:21, 20.48it/s, est. speed input: 23605.21 toks/s, output: 23.05 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [01:10<00:20, 20.70it/s, est. speed input: 23584.97 toks/s, output: 23.03 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [01:11<00:20, 20.57it/s, est. speed input: 23553.52 toks/s, output: 23.00 toks/s]
Processed prompts:  81%|████████  | 1650/2048 [01:11<00:19, 20.47it/s, est. speed input: 23522.43 toks/s, output: 22.97 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [01:12<00:18, 20.40it/s, est. speed input: 23491.95 toks/s, output: 22.94 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [01:13<00:17, 20.35it/s, est. speed input: 23462.12 toks/s, output: 22.91 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [01:14<00:17, 20.32it/s, est. speed input: 23433.04 toks/s, output: 22.88 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [01:14<00:16, 20.30it/s, est. speed input: 23404.59 toks/s, output: 22.86 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [01:15<00:15, 20.28it/s, est. speed input: 23376.66 toks/s, output: 22.83 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [01:16<00:14, 20.27it/s, est. speed input: 23349.46 toks/s, output: 22.80 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [01:17<00:14, 20.27it/s, est. speed input: 23322.89 toks/s, output: 22.78 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [01:18<00:13, 20.25it/s, est. speed input: 23296.17 toks/s, output: 22.75 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [01:18<00:12, 20.25it/s, est. speed input: 23270.49 toks/s, output: 22.73 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [01:19<00:11, 20.24it/s, est. speed input: 23245.08 toks/s, output: 22.70 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [01:20<00:10, 20.24it/s, est. speed input: 23220.25 toks/s, output: 22.68 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [01:21<00:10, 20.24it/s, est. speed input: 23196.09 toks/s, output: 22.65 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [01:22<00:09, 20.23it/s, est. speed input: 23171.90 toks/s, output: 22.63 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [01:22<00:08, 20.24it/s, est. speed input: 23148.68 toks/s, output: 22.61 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [01:23<00:07, 20.24it/s, est. speed input: 23125.89 toks/s, output: 22.58 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [01:24<00:07, 20.24it/s, est. speed input: 23103.31 toks/s, output: 22.56 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [01:25<00:06, 20.24it/s, est. speed input: 23081.32 toks/s, output: 22.54 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [01:26<00:05, 20.24it/s, est. speed input: 23059.58 toks/s, output: 22.52 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [01:26<00:04, 20.25it/s, est. speed input: 23038.63 toks/s, output: 22.50 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [01:27<00:03, 20.26it/s, est. speed input: 23018.19 toks/s, output: 22.48 toks/s]
Processed prompts:  97%|█████████▋| 1986/2048 [01:28<00:03, 20.25it/s, est. speed input: 22997.59 toks/s, output: 22.46 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [01:29<00:02, 20.25it/s, est. speed input: 22977.72 toks/s, output: 22.44 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [01:30<00:01, 20.26it/s, est. speed input: 22958.27 toks/s, output: 22.42 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [01:30<00:00, 20.59it/s, est. speed input: 22949.75 toks/s, output: 22.41 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:30<00:00, 20.59it/s, est. speed input: 23107.61 toks/s, output: 22.57 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [01:30<00:00, 22.57it/s, est. speed input: 23107.61 toks/s, output: 22.57 toks/s]
[rank0]:[W126 04:06:29.171597667 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 04:06:31
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:07:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:07:07 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=155502) WARNING 01-26 04:07:15 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=155502) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=155502) WARNING 01-26 04:07:27 [backends.py:609] Failed to read file <frozen os>
Throughput: 6.05 requests/s, 6201.87 total tokens/s, 6.05 output tokens/s
Total num prompt tokens:  4194304
Total num output tokens:  4096

STDERR:
[2026-01-26 04:07:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:07:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:07:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:07:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:07:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:07:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:07:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:07:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:07:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:07:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:07:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:07:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:07:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:07:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:07:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:07:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:07:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:15] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:15] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:15] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:15] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:15] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:15] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=155502) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=155502) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.21it/s]
(EngineCore_DP0 pid=155502) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.04s/it]
(EngineCore_DP0 pid=155502) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.01s/it]
(EngineCore_DP0 pid=155502) 
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16662528 bytes
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12959744 bytes
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 137003008 bytes
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:18] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=155502) [2026-01-26 04:07:18] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 68009984 bytes
(EngineCore_DP0 pid=155502) [rank0]:W0126 04:07:34.465000 155502 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=155502) [rank0]:W0126 04:07:34.574000 155502 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=155502) [rank0]:W0126 04:07:36.070000 155502 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=155502) [rank0]:W0126 04:07:36.255000 155502 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=155502) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 1/11 [00:00<00:02,  3.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 2/11 [00:00<00:01,  5.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 3/11 [00:00<00:01,  5.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▋      | 4/11 [00:00<00:01,  6.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 5/11 [00:00<00:00,  7.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 6/11 [00:00<00:00,  7.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▎   | 7/11 [00:01<00:00,  7.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 8/11 [00:01<00:00,  8.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 9/11 [00:01<00:00,  8.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 10/11 [00:01<00:00,  8.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 11/11 [00:01<00:00,  7.26it/s]
(EngineCore_DP0 pid=155502) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 1/7 [00:00<00:00,  6.98it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 2/7 [00:00<00:00,  7.98it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 3/7 [00:00<00:00,  8.42it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 4/7 [00:00<00:00,  8.78it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 5/7 [00:00<00:00,  8.89it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 6/7 [00:00<00:00,  8.95it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  8.95it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 7/7 [00:00<00:00,  8.69it/s]

Adding requests:   0%|          | 0/4096 [00:00<?, ?it/s]
Adding requests:   1%|          | 24/4096 [00:00<00:17, 235.53it/s]
Adding requests:   1%|          | 50/4096 [00:00<00:16, 246.06it/s]
Adding requests:   2%|▏         | 78/4096 [00:00<00:15, 256.47it/s]
Adding requests:   3%|▎         | 104/4096 [00:00<00:15, 251.91it/s]
Adding requests:   3%|▎         | 130/4096 [00:00<00:15, 248.75it/s]
Adding requests:   4%|▍         | 156/4096 [00:00<00:15, 251.37it/s]
Adding requests:   4%|▍         | 182/4096 [00:00<00:15, 246.91it/s]
Adding requests:   5%|▌         | 207/4096 [00:00<00:15, 245.93it/s]
Adding requests:   6%|▌         | 234/4096 [00:00<00:15, 252.10it/s]
Adding requests:   6%|▋         | 261/4096 [00:01<00:14, 257.17it/s]
Adding requests:   7%|▋         | 287/4096 [00:01<00:15, 248.30it/s]
Adding requests:   8%|▊         | 315/4096 [00:01<00:14, 257.54it/s]
Adding requests:   8%|▊         | 342/4096 [00:01<00:14, 260.51it/s]
Adding requests:   9%|▉         | 369/4096 [00:01<00:14, 261.94it/s]
Adding requests:  10%|▉         | 396/4096 [00:01<00:14, 257.94it/s]
Adding requests:  10%|█         | 424/4096 [00:01<00:13, 264.14it/s]
Adding requests:  11%|█         | 451/4096 [00:01<00:13, 263.83it/s]
Adding requests:  12%|█▏        | 478/4096 [00:01<00:13, 259.25it/s]
Adding requests:  12%|█▏        | 504/4096 [00:01<00:13, 256.79it/s]
Adding requests:  13%|█▎        | 534/4096 [00:02<00:13, 267.91it/s]
Adding requests:  14%|█▎        | 562/4096 [00:02<00:13, 270.44it/s]
Adding requests:  14%|█▍        | 590/4096 [00:02<00:14, 248.41it/s]
Adding requests:  15%|█▌        | 616/4096 [00:02<00:14, 245.06it/s]
Adding requests:  16%|█▌        | 643/4096 [00:02<00:13, 250.03it/s]
Adding requests:  16%|█▋        | 669/4096 [00:02<00:14, 235.98it/s]
Adding requests:  17%|█▋        | 696/4096 [00:02<00:13, 244.08it/s]
Adding requests:  18%|█▊        | 721/4096 [00:02<00:13, 244.54it/s]
Adding requests:  18%|█▊        | 746/4096 [00:02<00:13, 243.00it/s]
Adding requests:  19%|█▉        | 771/4096 [00:03<00:14, 236.27it/s]
Adding requests:  19%|█▉        | 798/4096 [00:03<00:13, 245.53it/s]
Adding requests:  20%|██        | 826/4096 [00:03<00:12, 254.79it/s]
Adding requests:  21%|██        | 852/4096 [00:03<00:13, 249.51it/s]
Adding requests:  21%|██▏       | 878/4096 [00:03<00:12, 248.02it/s]
Adding requests:  22%|██▏       | 908/4096 [00:03<00:12, 260.83it/s]
Adding requests:  23%|██▎       | 935/4096 [00:03<00:12, 254.22it/s]
Adding requests:  23%|██▎       | 961/4096 [00:03<00:12, 248.84it/s]
Adding requests:  24%|██▍       | 988/4096 [00:03<00:12, 252.39it/s]
Adding requests:  25%|██▍       | 1014/4096 [00:04<00:12, 252.52it/s]
Adding requests:  25%|██▌       | 1040/4096 [00:04<00:12, 249.15it/s]
Adding requests:  26%|██▌       | 1065/4096 [00:04<00:12, 243.68it/s]
Adding requests:  27%|██▋       | 1092/4096 [00:04<00:12, 249.75it/s]
Adding requests:  27%|██▋       | 1119/4096 [00:04<00:11, 254.36it/s]
Adding requests:  28%|██▊       | 1145/4096 [00:04<00:11, 248.52it/s]
Adding requests:  29%|██▊       | 1171/4096 [00:04<00:11, 250.95it/s]
Adding requests:  29%|██▉       | 1199/4096 [00:04<00:11, 258.56it/s]
Adding requests:  30%|██▉       | 1225/4096 [00:04<00:11, 253.09it/s]
Adding requests:  31%|███       | 1251/4096 [00:04<00:11, 249.41it/s]
Adding requests:  31%|███       | 1276/4096 [00:05<00:11, 248.87it/s]
Adding requests:  32%|███▏      | 1303/4096 [00:05<00:11, 252.38it/s]
Adding requests:  32%|███▏      | 1329/4096 [00:05<00:11, 238.47it/s]
Adding requests:  33%|███▎      | 1356/4096 [00:05<00:11, 245.23it/s]
Adding requests:  34%|███▍      | 1383/4096 [00:05<00:10, 250.61it/s]
Adding requests:  34%|███▍      | 1409/4096 [00:05<00:10, 245.31it/s]
Adding requests:  35%|███▌      | 1434/4096 [00:05<00:11, 241.97it/s]
Adding requests:  36%|███▌      | 1461/4096 [00:05<00:10, 248.15it/s]
Adding requests:  36%|███▋      | 1488/4096 [00:05<00:10, 253.25it/s]
Adding requests:  37%|███▋      | 1514/4096 [00:06<00:10, 243.31it/s]
Adding requests:  38%|███▊      | 1539/4096 [00:06<00:10, 243.37it/s]
Adding requests:  38%|███▊      | 1566/4096 [00:06<00:10, 244.61it/s]
Adding requests:  39%|███▉      | 1592/4096 [00:06<00:10, 247.59it/s]
Adding requests:  39%|███▉      | 1617/4096 [00:06<00:10, 236.44it/s]
Adding requests:  40%|████      | 1642/4096 [00:06<00:10, 240.25it/s]
Adding requests:  41%|████      | 1668/4096 [00:06<00:09, 244.85it/s]
Adding requests:  41%|████▏     | 1693/4096 [00:06<00:09, 245.49it/s]
Adding requests:  42%|████▏     | 1719/4096 [00:06<00:09, 249.00it/s]
Adding requests:  43%|████▎     | 1747/4096 [00:06<00:09, 256.33it/s]
Adding requests:  43%|████▎     | 1777/4096 [00:07<00:08, 267.63it/s]
Adding requests:  44%|████▍     | 1804/4096 [00:07<00:09, 253.74it/s]
Adding requests:  45%|████▍     | 1831/4096 [00:07<00:08, 256.35it/s]
Adding requests:  45%|████▌     | 1859/4096 [00:07<00:08, 261.12it/s]
Adding requests:  46%|████▌     | 1886/4096 [00:07<00:08, 259.61it/s]
Adding requests:  47%|████▋     | 1913/4096 [00:07<00:08, 255.05it/s]
Adding requests:  47%|████▋     | 1942/4096 [00:07<00:08, 262.48it/s]
Adding requests:  48%|████▊     | 1970/4096 [00:07<00:08, 265.29it/s]
Adding requests:  49%|████▉     | 1997/4096 [00:07<00:08, 251.23it/s]
Adding requests:  49%|████▉     | 2023/4096 [00:08<00:08, 247.90it/s]
Adding requests:  50%|█████     | 2051/4096 [00:08<00:07, 255.81it/s]
Adding requests:  51%|█████     | 2077/4096 [00:08<00:08, 246.01it/s]
Adding requests:  51%|█████▏    | 2102/4096 [00:08<00:08, 243.18it/s]
Adding requests:  52%|█████▏    | 2129/4096 [00:08<00:07, 249.78it/s]
Adding requests:  53%|█████▎    | 2156/4096 [00:08<00:07, 252.98it/s]
Adding requests:  53%|█████▎    | 2182/4096 [00:08<00:08, 234.90it/s]
Adding requests:  54%|█████▍    | 2208/4096 [00:08<00:07, 239.96it/s]
Adding requests:  55%|█████▍    | 2235/4096 [00:08<00:07, 248.32it/s]
Adding requests:  55%|█████▌    | 2261/4096 [00:09<00:07, 246.51it/s]
Adding requests:  56%|█████▌    | 2286/4096 [00:09<00:07, 243.05it/s]
Adding requests:  56%|█████▋    | 2314/4096 [00:09<00:07, 251.67it/s]
Adding requests:  57%|█████▋    | 2343/4096 [00:09<00:06, 262.07it/s]
Adding requests:  58%|█████▊    | 2370/4096 [00:09<00:06, 251.50it/s]
Adding requests:  59%|█████▊    | 2399/4096 [00:09<00:06, 261.24it/s]
Adding requests:  59%|█████▉    | 2428/4096 [00:09<00:06, 268.41it/s]
Adding requests:  60%|█████▉    | 2455/4096 [00:09<00:06, 254.20it/s]
Adding requests:  61%|██████    | 2481/4096 [00:09<00:06, 249.80it/s]
Adding requests:  61%|██████▏   | 2509/4096 [00:09<00:06, 258.13it/s]
Adding requests:  62%|██████▏   | 2537/4096 [00:10<00:05, 263.38it/s]
Adding requests:  63%|██████▎   | 2564/4096 [00:10<00:05, 261.22it/s]
Adding requests:  63%|██████▎   | 2592/4096 [00:10<00:05, 264.20it/s]
Adding requests:  64%|██████▍   | 2620/4096 [00:10<00:05, 267.82it/s]
Adding requests:  65%|██████▍   | 2647/4096 [00:10<00:05, 263.92it/s]
Adding requests:  65%|██████▌   | 2674/4096 [00:10<00:05, 253.47it/s]
Adding requests:  66%|██████▌   | 2701/4096 [00:10<00:05, 257.27it/s]
Adding requests:  67%|██████▋   | 2729/4096 [00:10<00:05, 262.04it/s]
Adding requests:  67%|██████▋   | 2756/4096 [00:10<00:05, 262.48it/s]
Adding requests:  68%|██████▊   | 2783/4096 [00:11<00:05, 261.46it/s]
Adding requests:  69%|██████▊   | 2812/4096 [00:11<00:04, 265.96it/s]
Adding requests:  69%|██████▉   | 2841/4096 [00:11<00:04, 270.82it/s]
Adding requests:  70%|███████   | 2869/4096 [00:11<00:04, 258.38it/s]
Adding requests:  71%|███████   | 2896/4096 [00:11<00:04, 259.84it/s]
Adding requests:  71%|███████▏  | 2923/4096 [00:11<00:04, 262.01it/s]
Adding requests:  72%|███████▏  | 2952/4096 [00:11<00:04, 264.86it/s]
Adding requests:  73%|███████▎  | 2979/4096 [00:11<00:04, 253.44it/s]
Adding requests:  73%|███████▎  | 3008/4096 [00:11<00:04, 262.25it/s]
Adding requests:  74%|███████▍  | 3036/4096 [00:11<00:03, 266.74it/s]
Adding requests:  75%|███████▍  | 3063/4096 [00:12<00:04, 254.77it/s]
Adding requests:  75%|███████▌  | 3089/4096 [00:12<00:03, 253.94it/s]
Adding requests:  76%|███████▌  | 3118/4096 [00:12<00:03, 261.39it/s]
Adding requests:  77%|███████▋  | 3145/4096 [00:12<00:03, 263.52it/s]
Adding requests:  77%|███████▋  | 3172/4096 [00:12<00:03, 250.57it/s]
Adding requests:  78%|███████▊  | 3200/4096 [00:12<00:03, 257.08it/s]
Adding requests:  79%|███████▉  | 3230/4096 [00:12<00:03, 268.20it/s]
Adding requests:  80%|███████▉  | 3257/4096 [00:12<00:03, 258.40it/s]
Adding requests:  80%|████████  | 3283/4096 [00:12<00:03, 252.65it/s]
Adding requests:  81%|████████  | 3309/4096 [00:13<00:03, 252.83it/s]
Adding requests:  81%|████████▏ | 3336/4096 [00:13<00:02, 255.61it/s]
Adding requests:  82%|████████▏ | 3362/4096 [00:13<00:02, 249.96it/s]
Adding requests:  83%|████████▎ | 3390/4096 [00:13<00:02, 257.98it/s]
Adding requests:  83%|████████▎ | 3418/4096 [00:13<00:02, 263.05it/s]
Adding requests:  84%|████████▍ | 3445/4096 [00:13<00:02, 263.47it/s]
Adding requests:  85%|████████▍ | 3472/4096 [00:13<00:02, 260.08it/s]
Adding requests:  85%|████████▌ | 3499/4096 [00:13<00:02, 261.20it/s]
Adding requests:  86%|████████▌ | 3530/4096 [00:13<00:02, 272.83it/s]
Adding requests:  87%|████████▋ | 3558/4096 [00:14<00:02, 266.27it/s]
Adding requests:  88%|████████▊ | 3585/4096 [00:14<00:01, 263.97it/s]
Adding requests:  88%|████████▊ | 3614/4096 [00:14<00:01, 268.57it/s]
Adding requests:  89%|████████▉ | 3641/4096 [00:14<00:01, 265.47it/s]
Adding requests:  90%|████████▉ | 3668/4096 [00:14<00:01, 254.22it/s]
Adding requests:  90%|█████████ | 3694/4096 [00:14<00:01, 255.81it/s]
Adding requests:  91%|█████████ | 3722/4096 [00:14<00:01, 262.27it/s]
Adding requests:  92%|█████████▏| 3749/4096 [00:14<00:01, 242.88it/s]
Adding requests:  92%|█████████▏| 3774/4096 [00:14<00:01, 244.04it/s]
Adding requests:  93%|█████████▎| 3799/4096 [00:14<00:01, 243.12it/s]
Adding requests:  93%|█████████▎| 3824/4096 [00:15<00:01, 229.95it/s]
Adding requests:  94%|█████████▍| 3848/4096 [00:15<00:01, 230.29it/s]
Adding requests:  95%|█████████▍| 3876/4096 [00:15<00:00, 243.69it/s]
Adding requests:  95%|█████████▌| 3901/4096 [00:15<00:00, 243.57it/s]
Adding requests:  96%|█████████▌| 3926/4096 [00:15<00:00, 232.17it/s]
Adding requests:  96%|█████████▋| 3952/4096 [00:15<00:00, 239.33it/s]
Adding requests:  97%|█████████▋| 3978/4096 [00:15<00:00, 244.72it/s]
Adding requests:  98%|█████████▊| 4004/4096 [00:15<00:00, 247.29it/s]
Adding requests:  98%|█████████▊| 4029/4096 [00:15<00:00, 243.21it/s]
Adding requests:  99%|█████████▉| 4055/4096 [00:16<00:00, 246.59it/s]
Adding requests: 100%|█████████▉| 4083/4096 [00:16<00:00, 254.55it/s]
Adding requests: 100%|██████████| 4096/4096 [00:16<00:00, 252.99it/s]

Processed prompts:   0%|          | 0/4096 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 66/4096 [00:00<00:15, 265.73it/s, est. speed input: 272136.09 toks/s, output: 265.74 toks/s]
Processed prompts:   2%|▏         | 98/4096 [00:04<03:27, 19.31it/s, est. speed input: 24334.12 toks/s, output: 23.76 toks/s]   
Processed prompts:   3%|▎         | 130/4096 [00:09<06:11, 10.68it/s, est. speed input: 14144.05 toks/s, output: 13.81 toks/s]
Processed prompts:   4%|▍         | 162/4096 [00:14<07:45,  8.45it/s, est. speed input: 11284.49 toks/s, output: 11.02 toks/s]
Processed prompts:   5%|▍         | 194/4096 [00:19<08:42,  7.47it/s, est. speed input: 9937.99 toks/s, output: 9.71 toks/s]  
Processed prompts:   6%|▌         | 226/4096 [00:25<09:17,  6.95it/s, est. speed input: 9154.88 toks/s, output: 8.94 toks/s]
Processed prompts:   6%|▋         | 258/4096 [00:30<09:38,  6.64it/s, est. speed input: 8642.61 toks/s, output: 8.44 toks/s]
Processed prompts:   7%|▋         | 290/4096 [00:34<08:58,  7.06it/s, est. speed input: 8619.45 toks/s, output: 8.42 toks/s]
Processed prompts:   8%|▊         | 322/4096 [00:39<09:21,  6.72it/s, est. speed input: 8295.94 toks/s, output: 8.10 toks/s]
Processed prompts:   9%|▊         | 354/4096 [00:45<09:35,  6.50it/s, est. speed input: 8048.84 toks/s, output: 7.86 toks/s]
Processed prompts:   9%|▉         | 386/4096 [00:50<09:43,  6.35it/s, est. speed input: 7853.72 toks/s, output: 7.67 toks/s]
Processed prompts:  10%|█         | 418/4096 [00:55<09:47,  6.26it/s, est. speed input: 7695.11 toks/s, output: 7.51 toks/s]
Processed prompts:  11%|█         | 450/4096 [01:00<09:48,  6.19it/s, est. speed input: 7564.14 toks/s, output: 7.39 toks/s]
Processed prompts:  12%|█▏        | 482/4096 [01:04<09:00,  6.69it/s, est. speed input: 7615.85 toks/s, output: 7.44 toks/s]
Processed prompts:  13%|█▎        | 514/4096 [01:10<09:12,  6.48it/s, est. speed input: 7508.20 toks/s, output: 7.33 toks/s]
Processed prompts:  13%|█▎        | 546/4096 [01:15<09:19,  6.34it/s, est. speed input: 7415.35 toks/s, output: 7.24 toks/s]
Processed prompts:  14%|█▍        | 578/4096 [01:20<09:22,  6.25it/s, est. speed input: 7334.77 toks/s, output: 7.16 toks/s]
Processed prompts:  15%|█▍        | 610/4096 [01:25<09:23,  6.19it/s, est. speed input: 7263.96 toks/s, output: 7.09 toks/s]
Processed prompts:  16%|█▌        | 642/4096 [01:31<09:22,  6.14it/s, est. speed input: 7201.65 toks/s, output: 7.03 toks/s]
Processed prompts:  16%|█▋        | 674/4096 [01:35<08:34,  6.65it/s, est. speed input: 7251.67 toks/s, output: 7.08 toks/s]
Processed prompts:  17%|█▋        | 706/4096 [01:40<08:45,  6.46it/s, est. speed input: 7195.94 toks/s, output: 7.03 toks/s]
Processed prompts:  18%|█▊        | 738/4096 [01:45<08:50,  6.33it/s, est. speed input: 7145.39 toks/s, output: 6.98 toks/s]
Processed prompts:  19%|█▉        | 770/4096 [01:50<08:46,  6.31it/s, est. speed input: 7112.64 toks/s, output: 6.95 toks/s]
Processed prompts:  20%|█▉        | 802/4096 [01:56<08:49,  6.23it/s, est. speed input: 7069.87 toks/s, output: 6.90 toks/s]
Processed prompts:  20%|██        | 834/4096 [02:01<08:48,  6.17it/s, est. speed input: 7031.07 toks/s, output: 6.87 toks/s]
Processed prompts:  21%|██        | 866/4096 [02:05<08:04,  6.67it/s, est. speed input: 7074.85 toks/s, output: 6.91 toks/s]
Processed prompts:  22%|██▏       | 898/4096 [02:10<08:13,  6.48it/s, est. speed input: 7039.79 toks/s, output: 6.87 toks/s]
Processed prompts:  23%|██▎       | 930/4096 [02:15<08:19,  6.34it/s, est. speed input: 7007.13 toks/s, output: 6.84 toks/s]
Processed prompts:  23%|██▎       | 962/4096 [02:21<08:22,  6.24it/s, est. speed input: 6974.73 toks/s, output: 6.81 toks/s]
Processed prompts:  24%|██▍       | 994/4096 [02:26<08:22,  6.17it/s, est. speed input: 6945.26 toks/s, output: 6.78 toks/s]
Processed prompts:  25%|██▌       | 1026/4096 [02:31<08:21,  6.13it/s, est. speed input: 6918.19 toks/s, output: 6.76 toks/s]
Processed prompts:  26%|██▌       | 1058/4096 [02:37<08:17,  6.10it/s, est. speed input: 6893.61 toks/s, output: 6.73 toks/s]
Processed prompts:  27%|██▋       | 1090/4096 [02:40<07:32,  6.65it/s, est. speed input: 6933.93 toks/s, output: 6.77 toks/s]
Processed prompts:  27%|██▋       | 1122/4096 [02:46<07:38,  6.49it/s, est. speed input: 6914.14 toks/s, output: 6.75 toks/s]
Processed prompts:  28%|██▊       | 1154/4096 [02:51<07:43,  6.35it/s, est. speed input: 6891.71 toks/s, output: 6.73 toks/s]
Processed prompts:  29%|██▉       | 1186/4096 [02:56<07:45,  6.25it/s, est. speed input: 6870.25 toks/s, output: 6.71 toks/s]
Processed prompts:  30%|██▉       | 1218/4096 [03:02<07:45,  6.18it/s, est. speed input: 6849.27 toks/s, output: 6.69 toks/s]
Processed prompts:  31%|███       | 1250/4096 [03:07<07:43,  6.13it/s, est. speed input: 6830.49 toks/s, output: 6.67 toks/s]
Processed prompts:  31%|███▏      | 1282/4096 [03:11<07:06,  6.60it/s, est. speed input: 6859.39 toks/s, output: 6.70 toks/s]
Processed prompts:  32%|███▏      | 1314/4096 [03:16<07:13,  6.42it/s, est. speed input: 6841.29 toks/s, output: 6.68 toks/s]
Processed prompts:  33%|███▎      | 1346/4096 [03:21<07:16,  6.30it/s, est. speed input: 6824.17 toks/s, output: 6.66 toks/s]
Processed prompts:  34%|███▎      | 1378/4096 [03:27<07:16,  6.22it/s, est. speed input: 6808.03 toks/s, output: 6.65 toks/s]
Processed prompts:  34%|███▍      | 1410/4096 [03:32<07:15,  6.17it/s, est. speed input: 6792.64 toks/s, output: 6.63 toks/s]
Processed prompts:  35%|███▌      | 1442/4096 [03:37<07:12,  6.13it/s, est. speed input: 6777.98 toks/s, output: 6.62 toks/s]
Processed prompts:  36%|███▌      | 1474/4096 [03:41<06:35,  6.63it/s, est. speed input: 6806.46 toks/s, output: 6.65 toks/s]
Processed prompts:  37%|███▋      | 1506/4096 [03:47<06:41,  6.44it/s, est. speed input: 6792.06 toks/s, output: 6.63 toks/s]
Processed prompts:  38%|███▊      | 1538/4096 [03:52<06:44,  6.32it/s, est. speed input: 6778.30 toks/s, output: 6.62 toks/s]
Processed prompts:  38%|███▊      | 1570/4096 [03:57<06:45,  6.23it/s, est. speed input: 6765.19 toks/s, output: 6.61 toks/s]
Processed prompts:  39%|███▉      | 1602/4096 [04:02<06:38,  6.25it/s, est. speed input: 6758.39 toks/s, output: 6.60 toks/s]
Processed prompts:  40%|███▉      | 1634/4096 [04:08<06:37,  6.19it/s, est. speed input: 6746.25 toks/s, output: 6.59 toks/s]
Processed prompts:  41%|████      | 1666/4096 [04:11<06:03,  6.68it/s, est. speed input: 6771.94 toks/s, output: 6.61 toks/s]
Processed prompts:  41%|████▏     | 1698/4096 [04:17<06:10,  6.48it/s, est. speed input: 6759.94 toks/s, output: 6.60 toks/s]
Processed prompts:  42%|████▏     | 1730/4096 [04:22<06:13,  6.34it/s, est. speed input: 6748.41 toks/s, output: 6.59 toks/s]
Processed prompts:  43%|████▎     | 1762/4096 [04:27<06:13,  6.25it/s, est. speed input: 6737.34 toks/s, output: 6.58 toks/s]
Processed prompts:  44%|████▍     | 1794/4096 [04:33<06:12,  6.19it/s, est. speed input: 6726.74 toks/s, output: 6.57 toks/s]
Processed prompts:  45%|████▍     | 1826/4096 [04:38<06:09,  6.14it/s, est. speed input: 6716.50 toks/s, output: 6.56 toks/s]
Processed prompts:  45%|████▌     | 1858/4096 [04:42<05:36,  6.64it/s, est. speed input: 6739.86 toks/s, output: 6.58 toks/s]
Processed prompts:  46%|████▌     | 1890/4096 [04:47<05:41,  6.45it/s, est. speed input: 6729.71 toks/s, output: 6.57 toks/s]
Processed prompts:  47%|████▋     | 1922/4096 [04:52<05:43,  6.32it/s, est. speed input: 6719.94 toks/s, output: 6.56 toks/s]
Processed prompts:  48%|████▊     | 1954/4096 [04:58<05:43,  6.24it/s, est. speed input: 6710.51 toks/s, output: 6.55 toks/s]
Processed prompts:  48%|████▊     | 1986/4096 [05:03<05:41,  6.18it/s, est. speed input: 6701.43 toks/s, output: 6.54 toks/s]
Processed prompts:  49%|████▉     | 2018/4096 [05:08<05:38,  6.14it/s, est. speed input: 6692.65 toks/s, output: 6.54 toks/s]
Processed prompts:  50%|█████     | 2050/4096 [05:12<05:08,  6.64it/s, est. speed input: 6713.99 toks/s, output: 6.56 toks/s]
Processed prompts:  51%|█████     | 2082/4096 [05:17<05:12,  6.45it/s, est. speed input: 6705.27 toks/s, output: 6.55 toks/s]
Processed prompts:  52%|█████▏    | 2114/4096 [05:23<05:13,  6.32it/s, est. speed input: 6696.80 toks/s, output: 6.54 toks/s]
Processed prompts:  52%|█████▏    | 2146/4096 [05:28<05:12,  6.24it/s, est. speed input: 6688.60 toks/s, output: 6.53 toks/s]
Processed prompts:  53%|█████▎    | 2178/4096 [05:33<05:06,  6.25it/s, est. speed input: 6684.82 toks/s, output: 6.53 toks/s]
Processed prompts:  54%|█████▍    | 2210/4096 [05:38<05:04,  6.19it/s, est. speed input: 6677.08 toks/s, output: 6.52 toks/s]
Processed prompts:  55%|█████▍    | 2242/4096 [05:42<04:37,  6.68it/s, est. speed input: 6696.80 toks/s, output: 6.54 toks/s]
Processed prompts:  56%|█████▌    | 2274/4096 [05:48<04:41,  6.48it/s, est. speed input: 6689.15 toks/s, output: 6.53 toks/s]
Processed prompts:  56%|█████▋    | 2306/4096 [05:53<04:42,  6.34it/s, est. speed input: 6681.71 toks/s, output: 6.53 toks/s]
Processed prompts:  57%|█████▋    | 2338/4096 [05:58<04:41,  6.25it/s, est. speed input: 6674.40 toks/s, output: 6.52 toks/s]
Processed prompts:  58%|█████▊    | 2370/4096 [06:03<04:39,  6.19it/s, est. speed input: 6667.29 toks/s, output: 6.51 toks/s]
Processed prompts:  59%|█████▊    | 2402/4096 [06:09<04:35,  6.14it/s, est. speed input: 6660.39 toks/s, output: 6.50 toks/s]
Processed prompts:  59%|█████▉    | 2434/4096 [06:14<04:31,  6.11it/s, est. speed input: 6653.69 toks/s, output: 6.50 toks/s]
Processed prompts:  60%|██████    | 2466/4096 [06:18<04:06,  6.62it/s, est. speed input: 6671.89 toks/s, output: 6.52 toks/s]
Processed prompts:  61%|██████    | 2498/4096 [06:23<04:08,  6.44it/s, est. speed input: 6665.40 toks/s, output: 6.51 toks/s]
Processed prompts:  62%|██████▏   | 2530/4096 [06:29<04:08,  6.31it/s, est. speed input: 6658.68 toks/s, output: 6.50 toks/s]
Processed prompts:  63%|██████▎   | 2562/4096 [06:34<04:06,  6.22it/s, est. speed input: 6652.12 toks/s, output: 6.50 toks/s]
Processed prompts:  63%|██████▎   | 2594/4096 [06:39<04:03,  6.16it/s, est. speed input: 6645.75 toks/s, output: 6.49 toks/s]
Processed prompts:  64%|██████▍   | 2626/4096 [06:44<03:59,  6.13it/s, est. speed input: 6639.78 toks/s, output: 6.48 toks/s]
Processed prompts:  65%|██████▍   | 2658/4096 [06:48<03:36,  6.65it/s, est. speed input: 6657.33 toks/s, output: 6.50 toks/s]
Processed prompts:  66%|██████▌   | 2690/4096 [06:54<03:36,  6.48it/s, est. speed input: 6652.52 toks/s, output: 6.50 toks/s]
Processed prompts:  66%|██████▋   | 2722/4096 [06:59<03:37,  6.32it/s, est. speed input: 6645.68 toks/s, output: 6.49 toks/s]
Processed prompts:  67%|██████▋   | 2754/4096 [07:04<03:35,  6.22it/s, est. speed input: 6639.14 toks/s, output: 6.48 toks/s]
Processed prompts:  68%|██████▊   | 2786/4096 [07:10<03:32,  6.16it/s, est. speed input: 6633.60 toks/s, output: 6.48 toks/s]
Processed prompts:  69%|██████▉   | 2818/4096 [07:15<03:28,  6.13it/s, est. speed input: 6628.50 toks/s, output: 6.47 toks/s]
Processed prompts:  70%|██████▉   | 2850/4096 [07:19<03:07,  6.65it/s, est. speed input: 6644.67 toks/s, output: 6.49 toks/s]
Processed prompts:  70%|███████   | 2882/4096 [07:24<03:08,  6.46it/s, est. speed input: 6639.29 toks/s, output: 6.48 toks/s]
Processed prompts:  71%|███████   | 2914/4096 [07:29<03:06,  6.33it/s, est. speed input: 6634.01 toks/s, output: 6.48 toks/s]
Processed prompts:  72%|███████▏  | 2946/4096 [07:35<03:04,  6.24it/s, est. speed input: 6628.89 toks/s, output: 6.47 toks/s]
Processed prompts:  73%|███████▎  | 2978/4096 [07:40<03:00,  6.18it/s, est. speed input: 6623.85 toks/s, output: 6.47 toks/s]
Processed prompts:  73%|███████▎  | 3010/4096 [07:45<02:56,  6.14it/s, est. speed input: 6618.93 toks/s, output: 6.46 toks/s]
Processed prompts:  74%|███████▍  | 3042/4096 [07:49<02:38,  6.63it/s, est. speed input: 6633.33 toks/s, output: 6.48 toks/s]
Processed prompts:  75%|███████▌  | 3074/4096 [07:54<02:38,  6.44it/s, est. speed input: 6628.39 toks/s, output: 6.47 toks/s]
Processed prompts:  76%|███████▌  | 3106/4096 [08:00<02:36,  6.32it/s, est. speed input: 6623.55 toks/s, output: 6.47 toks/s]
Processed prompts:  77%|███████▋  | 3138/4096 [08:05<02:33,  6.23it/s, est. speed input: 6618.81 toks/s, output: 6.46 toks/s]
Processed prompts:  77%|███████▋  | 3170/4096 [08:10<02:29,  6.17it/s, est. speed input: 6614.17 toks/s, output: 6.46 toks/s]
Processed prompts:  78%|███████▊  | 3202/4096 [08:16<02:25,  6.14it/s, est. speed input: 6609.65 toks/s, output: 6.45 toks/s]
Processed prompts:  79%|███████▉  | 3234/4096 [08:19<02:09,  6.64it/s, est. speed input: 6623.60 toks/s, output: 6.47 toks/s]
Processed prompts:  80%|███████▉  | 3266/4096 [08:25<02:08,  6.45it/s, est. speed input: 6619.05 toks/s, output: 6.46 toks/s]
Processed prompts:  81%|████████  | 3298/4096 [08:30<02:06,  6.32it/s, est. speed input: 6614.58 toks/s, output: 6.46 toks/s]
Processed prompts:  81%|████████▏ | 3330/4096 [08:35<02:02,  6.24it/s, est. speed input: 6610.22 toks/s, output: 6.46 toks/s]
Processed prompts:  82%|████████▏ | 3362/4096 [08:41<01:58,  6.18it/s, est. speed input: 6605.92 toks/s, output: 6.45 toks/s]
Processed prompts:  83%|████████▎ | 3394/4096 [08:46<01:54,  6.14it/s, est. speed input: 6601.73 toks/s, output: 6.45 toks/s]
Processed prompts:  84%|████████▎ | 3426/4096 [08:50<01:40,  6.64it/s, est. speed input: 6614.96 toks/s, output: 6.46 toks/s]
Processed prompts:  84%|████████▍ | 3458/4096 [08:55<01:38,  6.45it/s, est. speed input: 6610.74 toks/s, output: 6.46 toks/s]
Processed prompts:  85%|████████▌ | 3490/4096 [09:00<01:35,  6.32it/s, est. speed input: 6606.61 toks/s, output: 6.45 toks/s]
Processed prompts:  86%|████████▌ | 3522/4096 [09:06<01:32,  6.23it/s, est. speed input: 6602.56 toks/s, output: 6.45 toks/s]
Processed prompts:  87%|████████▋ | 3554/4096 [09:11<01:27,  6.18it/s, est. speed input: 6598.57 toks/s, output: 6.44 toks/s]
Processed prompts:  88%|████████▊ | 3586/4096 [09:16<01:23,  6.14it/s, est. speed input: 6594.67 toks/s, output: 6.44 toks/s]
Processed prompts:  88%|████████▊ | 3618/4096 [09:20<01:12,  6.64it/s, est. speed input: 6607.22 toks/s, output: 6.45 toks/s]
Processed prompts:  89%|████████▉ | 3650/4096 [09:26<01:09,  6.45it/s, est. speed input: 6603.31 toks/s, output: 6.45 toks/s]
Processed prompts:  90%|████████▉ | 3682/4096 [09:31<01:04,  6.40it/s, est. speed input: 6601.85 toks/s, output: 6.45 toks/s]
Processed prompts:  91%|█████████ | 3714/4096 [09:36<01:00,  6.29it/s, est. speed input: 6598.06 toks/s, output: 6.44 toks/s]
Processed prompts:  91%|█████████▏| 3746/4096 [09:41<00:56,  6.21it/s, est. speed input: 6594.32 toks/s, output: 6.44 toks/s]
Processed prompts:  92%|█████████▏| 3778/4096 [09:46<00:51,  6.16it/s, est. speed input: 6590.64 toks/s, output: 6.44 toks/s]
Processed prompts:  93%|█████████▎| 3810/4096 [09:52<00:46,  6.12it/s, est. speed input: 6587.04 toks/s, output: 6.43 toks/s]
Processed prompts:  94%|█████████▍| 3842/4096 [09:56<00:38,  6.63it/s, est. speed input: 6598.94 toks/s, output: 6.44 toks/s]
Processed prompts:  95%|█████████▍| 3874/4096 [10:01<00:34,  6.44it/s, est. speed input: 6595.34 toks/s, output: 6.44 toks/s]
Processed prompts:  95%|█████████▌| 3906/4096 [10:06<00:29,  6.40it/s, est. speed input: 6594.02 toks/s, output: 6.44 toks/s]
Processed prompts:  96%|█████████▌| 3938/4096 [10:11<00:25,  6.28it/s, est. speed input: 6590.49 toks/s, output: 6.44 toks/s]
Processed prompts:  97%|█████████▋| 3970/4096 [10:17<00:20,  6.21it/s, est. speed input: 6587.02 toks/s, output: 6.43 toks/s]
Processed prompts:  98%|█████████▊| 4002/4096 [10:22<00:15,  6.16it/s, est. speed input: 6583.63 toks/s, output: 6.43 toks/s]
Processed prompts:  98%|█████████▊| 4034/4096 [10:26<00:09,  6.66it/s, est. speed input: 6595.00 toks/s, output: 6.44 toks/s]
Processed prompts:  99%|█████████▉| 4066/4096 [10:31<00:04,  6.55it/s, est. speed input: 6593.92 toks/s, output: 6.44 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [10:31<00:00,  6.55it/s, est. speed input: 6642.56 toks/s, output: 6.49 toks/s]
Processed prompts: 100%|██████████| 4096/4096 [10:31<00:00,  6.49it/s, est. speed input: 6642.56 toks/s, output: 6.49 toks/s]
[rank0]:[W126 04:18:33.772020070 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=65536 ==========
Time: 2026-01-26 04:18:36
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-7B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:19:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:19:43 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=166712) WARNING 01-26 04:19:58 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=166712) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=166712) WARNING 01-26 04:20:12 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     def forward(
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     raise e
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return compiled_fn(full_args)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     outs = compiled_fn(args)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/tmp/torchinductor_root/ss/csshv4l3lmhqprl2ob6nwekt2ruwfci2u7gsirottxbkuatuadsn.py", line 1093, in call
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     buf17 = torch.ops.slidesparse.quant_slide_fp8.default(buf16, 'Qwen2.5-7B-FP8', 6)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return fn(input, L)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]            ^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 263, in quant_slide_fp8_triton
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     self._init_handles()
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) ERROR 01-26 04:20:22 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered

STDERR:
[2026-01-26 04:19:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:19:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:19:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:19:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:19:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:19:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:19:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:19:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:19:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:19:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:19:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 04:19:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 04:19:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:19:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:19:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:19:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:19:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[W126 04:19:58.687727550 socket.cpp:209] [c10d] The hostname of the client socket cannot be retrieved. err=-3
(EngineCore_DP0 pid=166712) [2026-01-26 04:19:59] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=166712) [2026-01-26 04:19:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=166712) [2026-01-26 04:19:59] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=166712) [2026-01-26 04:19:59] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=166712) [2026-01-26 04:19:59] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=166712) [2026-01-26 04:19:59] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=166712) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=166712) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.21it/s]
(EngineCore_DP0 pid=166712) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.04s/it]
(EngineCore_DP0 pid=166712) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.01s/it]
(EngineCore_DP0 pid=166712) 
(EngineCore_DP0 pid=166712) [2026-01-26 04:20:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 4800] -> 1D uint8
(EngineCore_DP0 pid=166712) [2026-01-26 04:20:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16662528 bytes
(EngineCore_DP0 pid=166712) [2026-01-26 04:20:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 4800] -> 1D uint8
(EngineCore_DP0 pid=166712) [2026-01-26 04:20:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12959744 bytes
(EngineCore_DP0 pid=166712) [2026-01-26 04:20:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 4800] -> 1D uint8
(EngineCore_DP0 pid=166712) [2026-01-26 04:20:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 137003008 bytes
(EngineCore_DP0 pid=166712) [2026-01-26 04:20:02] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 25280] -> 1D uint8
(EngineCore_DP0 pid=166712) [2026-01-26 04:20:02] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 68009984 bytes
(EngineCore_DP0 pid=166712) [rank0]:W0126 04:20:20.385000 166712 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=166712) [rank0]:W0126 04:20:20.496000 166712 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=166712) [rank0]:W0126 04:20:21.991000 166712 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=166712) [rank0]:W0126 04:20:22.165000 166712 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=166712) Process EngineCore_DP0:
(EngineCore_DP0 pid=166712) Traceback (most recent call last):
(EngineCore_DP0 pid=166712)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=166712)     self.run()
(EngineCore_DP0 pid=166712)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=166712)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=166712)     raise e
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=166712)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=166712)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=166712)     super().__init__(
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=166712)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=166712)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=166712)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=166712)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=166712)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=166712)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=166712)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=166712)     return func(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=166712)     return func(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=166712)     self.model_runner.profile_run()
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=166712)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=166712)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=166712)     return func(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=166712)     outputs = self.model(
(EngineCore_DP0 pid=166712)               ^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=166712)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=166712)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=166712)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=166712)     hidden_states = self.model(
(EngineCore_DP0 pid=166712)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=166712)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=166712)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=166712)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=166712)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
(EngineCore_DP0 pid=166712)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=166712)     def forward(
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=166712)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=166712)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=166712)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=166712)     raise e
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=166712)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=166712)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=166712)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "<eval_with_key>.58", line 325, in forward
(EngineCore_DP0 pid=166712)     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=166712)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=166712)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=166712)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=166712)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=166712)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
(EngineCore_DP0 pid=166712)     return compiled_fn(full_args)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=166712)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=166712)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=166712)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=166712)                             ^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 724, in inner_fn
(EngineCore_DP0 pid=166712)     outs = compiled_fn(args)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=166712)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=166712)     return self.current_callable(inputs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=166712)     out = model(new_inputs)
(EngineCore_DP0 pid=166712)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/tmp/torchinductor_root/ss/csshv4l3lmhqprl2ob6nwekt2ruwfci2u7gsirottxbkuatuadsn.py", line 1093, in call
(EngineCore_DP0 pid=166712)     buf17 = torch.ops.slidesparse.quant_slide_fp8.default(buf16, 'Qwen2.5-7B-FP8', 6)
(EngineCore_DP0 pid=166712)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=166712)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/slidesparse/core/kernels.py", line 521, in _quant_slide_fp8_impl
(EngineCore_DP0 pid=166712)     return fn(input, L)
(EngineCore_DP0 pid=166712)            ^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/build/RTX4090_cc89_py312_cu129_x86_64/quant_slide_tuned_Qwen2.5-7B.py", line 263, in quant_slide_fp8_triton
(EngineCore_DP0 pid=166712)     _quant_slide_fp8_kernel[(M,)](
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
(EngineCore_DP0 pid=166712)     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
(EngineCore_DP0 pid=166712)                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
(EngineCore_DP0 pid=166712)     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
(EngineCore_DP0 pid=166712)                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
(EngineCore_DP0 pid=166712)     self._init_handles()
(EngineCore_DP0 pid=166712)   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
(EngineCore_DP0 pid=166712)     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
(EngineCore_DP0 pid=166712)                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=166712) RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 04:20:23.074343812 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=512 ==========
Time: 2026-01-26 07:40:12
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=512, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 512 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 513 --max-num-batched-tokens 513 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:40:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:40:21 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=357482) WARNING 01-26 07:40:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=357482) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=357482) WARNING 01-26 07:40:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.44 requests/s, 4843.75 total tokens/s, 9.44 output tokens/s
Total num prompt tokens:  65536
Total num output tokens:  128

STDERR:
[2026-01-26 07:40:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:40:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:40:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:40:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:40:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:40:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:40:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:40:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:40:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:40:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:40:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:40:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:40:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:40:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:40:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:40:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:40:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:05<00:15,  5.04s/it]
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:09<00:09,  4.91s/it]
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:11<00:03,  3.23s/it]
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:15<00:00,  3.82s/it]
(EngineCore_DP0 pid=357482) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:15<00:00,  3.96s/it]
(EngineCore_DP0 pid=357482) 
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=357482) [2026-01-26 07:40:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=357482) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  1.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:01<00:00,  1.44it/s]
(EngineCore_DP0 pid=357482) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  3.76it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  34%|███▎      | 43/128 [00:00<00:00, 426.42it/s]
Adding requests:  69%|██████▉   | 88/128 [00:00<00:00, 438.92it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 429.67it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:45,  2.77it/s, est. speed input: 1419.95 toks/s, output: 2.77 toks/s]
Processed prompts:   2%|▏         | 2/128 [00:00<00:26,  4.78it/s, est. speed input: 2209.18 toks/s, output: 4.31 toks/s]
Processed prompts:   2%|▏         | 3/128 [00:00<00:19,  6.25it/s, est. speed input: 2718.16 toks/s, output: 5.31 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:17,  7.29it/s, est. speed input: 3068.63 toks/s, output: 5.99 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:15,  8.05it/s, est. speed input: 3331.60 toks/s, output: 6.51 toks/s]
Processed prompts:   5%|▍         | 6/128 [00:00<00:14,  8.62it/s, est. speed input: 3535.93 toks/s, output: 6.91 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:13,  9.01it/s, est. speed input: 3696.74 toks/s, output: 7.22 toks/s]
Processed prompts:   6%|▋         | 8/128 [00:01<00:12,  9.26it/s, est. speed input: 3825.11 toks/s, output: 7.47 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:01<00:12,  9.45it/s, est. speed input: 3931.90 toks/s, output: 7.68 toks/s]
Processed prompts:   8%|▊         | 10/128 [00:01<00:12,  9.56it/s, est. speed input: 4019.90 toks/s, output: 7.85 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:01<00:12,  9.69it/s, est. speed input: 4099.93 toks/s, output: 8.01 toks/s]
Processed prompts:   9%|▉         | 12/128 [00:01<00:11,  9.78it/s, est. speed input: 4169.12 toks/s, output: 8.14 toks/s]
Processed prompts:  11%|█         | 14/128 [00:01<00:11,  9.88it/s, est. speed input: 4282.45 toks/s, output: 8.36 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:11,  9.88it/s, est. speed input: 4327.09 toks/s, output: 8.45 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:11,  9.92it/s, est. speed input: 4405.83 toks/s, output: 8.60 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:02<00:11,  9.83it/s, est. speed input: 4430.50 toks/s, output: 8.65 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:02<00:11,  9.85it/s, est. speed input: 4459.83 toks/s, output: 8.71 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:02<00:10,  9.95it/s, est. speed input: 4518.76 toks/s, output: 8.83 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:02<00:10,  9.97it/s, est. speed input: 4566.15 toks/s, output: 8.92 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:10, 10.00it/s, est. speed input: 4607.68 toks/s, output: 9.00 toks/s]
Processed prompts:  20%|██        | 26/128 [00:02<00:10, 10.00it/s, est. speed input: 4625.06 toks/s, output: 9.03 toks/s]
Processed prompts:  22%|██▏       | 28/128 [00:03<00:09, 10.01it/s, est. speed input: 4658.30 toks/s, output: 9.10 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:03<00:09,  9.99it/s, est. speed input: 4671.39 toks/s, output: 9.12 toks/s]
Processed prompts:  23%|██▎       | 30/128 [00:03<00:09,  9.99it/s, est. speed input: 4684.73 toks/s, output: 9.15 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:03<00:09,  9.98it/s, est. speed input: 4697.37 toks/s, output: 9.17 toks/s]
Processed prompts:  25%|██▌       | 32/128 [00:03<00:09,  9.99it/s, est. speed input: 4709.39 toks/s, output: 9.20 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:03<00:09,  9.99it/s, est. speed input: 4731.77 toks/s, output: 9.24 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:03<00:09,  9.98it/s, est. speed input: 4751.07 toks/s, output: 9.28 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:03<00:09,  9.96it/s, est. speed input: 4758.88 toks/s, output: 9.29 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:04<00:09,  9.85it/s, est. speed input: 4761.64 toks/s, output: 9.30 toks/s]
Processed prompts:  30%|███       | 39/128 [00:04<00:09,  9.78it/s, est. speed input: 4764.91 toks/s, output: 9.31 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:04<00:09,  9.76it/s, est. speed input: 4769.82 toks/s, output: 9.32 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:04<00:08,  9.72it/s, est. speed input: 4773.44 toks/s, output: 9.32 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:04<00:01, 44.59it/s, est. speed input: 6413.77 toks/s, output: 12.53 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:04<00:02, 24.20it/s, est. speed input: 6295.61 toks/s, output: 12.30 toks/s]
Processed prompts:  50%|█████     | 64/128 [00:05<00:03, 18.60it/s, est. speed input: 6217.40 toks/s, output: 12.14 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:05<00:03, 15.50it/s, est. speed input: 6152.21 toks/s, output: 12.02 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:05<00:04, 14.03it/s, est. speed input: 6110.16 toks/s, output: 11.93 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:05<00:04, 12.90it/s, est. speed input: 6072.22 toks/s, output: 11.86 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:06<00:04, 12.02it/s, est. speed input: 6035.68 toks/s, output: 11.79 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:06<00:04, 11.40it/s, est. speed input: 6003.27 toks/s, output: 11.73 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:06<00:04, 10.97it/s, est. speed input: 5974.37 toks/s, output: 11.67 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:06<00:04, 10.62it/s, est. speed input: 5944.93 toks/s, output: 11.61 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:07<00:04, 10.39it/s, est. speed input: 5918.37 toks/s, output: 11.56 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:07<00:04, 10.19it/s, est. speed input: 5891.73 toks/s, output: 11.51 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:07<00:04, 10.10it/s, est. speed input: 5868.92 toks/s, output: 11.46 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:07<00:04, 10.05it/s, est. speed input: 5848.03 toks/s, output: 11.42 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:07<00:03,  9.99it/s, est. speed input: 5827.48 toks/s, output: 11.38 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:08<00:03,  9.93it/s, est. speed input: 5806.40 toks/s, output: 11.34 toks/s]
Processed prompts:  72%|███████▏  | 92/128 [00:08<00:03,  9.89it/s, est. speed input: 5796.04 toks/s, output: 11.32 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:08<00:03,  9.85it/s, est. speed input: 5785.45 toks/s, output: 11.30 toks/s]
Processed prompts:  73%|███████▎  | 94/128 [00:08<00:03,  9.83it/s, est. speed input: 5775.68 toks/s, output: 11.28 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:08<00:03,  9.82it/s, est. speed input: 5766.36 toks/s, output: 11.26 toks/s]
Processed prompts:  75%|███████▌  | 96/128 [00:08<00:03,  9.81it/s, est. speed input: 5757.47 toks/s, output: 11.25 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:08<00:03,  9.80it/s, est. speed input: 5748.48 toks/s, output: 11.23 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:08<00:03,  9.76it/s, est. speed input: 5739.06 toks/s, output: 11.21 toks/s]
Processed prompts:  77%|███████▋  | 99/128 [00:08<00:03,  9.59it/s, est. speed input: 5726.17 toks/s, output: 11.18 toks/s]
Processed prompts:  78%|███████▊  | 100/128 [00:08<00:02,  9.62it/s, est. speed input: 5717.41 toks/s, output: 11.17 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:09<00:02,  9.66it/s, est. speed input: 5709.29 toks/s, output: 11.15 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:09<00:02,  9.67it/s, est. speed input: 5700.83 toks/s, output: 11.13 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:09<00:02,  9.67it/s, est. speed input: 5692.59 toks/s, output: 11.12 toks/s]
Processed prompts:  81%|████████▏ | 104/128 [00:09<00:02,  9.71it/s, est. speed input: 5685.16 toks/s, output: 11.10 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:09<00:02,  9.76it/s, est. speed input: 5678.50 toks/s, output: 11.09 toks/s]
Processed prompts:  83%|████████▎ | 106/128 [00:09<00:02,  9.81it/s, est. speed input: 5672.24 toks/s, output: 11.08 toks/s]
Processed prompts:  84%|████████▎ | 107/128 [00:09<00:02,  9.81it/s, est. speed input: 5665.35 toks/s, output: 11.07 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:09<00:02,  9.77it/s, est. speed input: 5657.79 toks/s, output: 11.05 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:09<00:01,  9.79it/s, est. speed input: 5651.41 toks/s, output: 11.04 toks/s]
Processed prompts:  86%|████████▌ | 110/128 [00:09<00:01,  9.84it/s, est. speed input: 5645.87 toks/s, output: 11.03 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:10<00:01,  9.83it/s, est. speed input: 5639.62 toks/s, output: 11.01 toks/s]
Processed prompts:  88%|████████▊ | 112/128 [00:10<00:01,  9.81it/s, est. speed input: 5633.14 toks/s, output: 11.00 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:10<00:01,  9.80it/s, est. speed input: 5626.88 toks/s, output: 10.99 toks/s]
Processed prompts:  89%|████████▉ | 114/128 [00:10<00:01,  9.83it/s, est. speed input: 5621.44 toks/s, output: 10.98 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:10<00:01,  9.85it/s, est. speed input: 5616.18 toks/s, output: 10.97 toks/s]
Processed prompts:  91%|█████████ | 116/128 [00:10<00:01,  9.87it/s, est. speed input: 5611.01 toks/s, output: 10.96 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:10<00:01,  9.88it/s, est. speed input: 5605.93 toks/s, output: 10.95 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:10<00:01,  9.82it/s, est. speed input: 5599.68 toks/s, output: 10.94 toks/s]
Processed prompts:  93%|█████████▎| 119/128 [00:10<00:00,  9.77it/s, est. speed input: 5593.36 toks/s, output: 10.92 toks/s]
Processed prompts:  94%|█████████▍| 120/128 [00:10<00:00,  9.74it/s, est. speed input: 5587.46 toks/s, output: 10.91 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:11<00:00,  9.74it/s, est. speed input: 5581.80 toks/s, output: 10.90 toks/s]
Processed prompts:  95%|█████████▌| 122/128 [00:11<00:00,  9.74it/s, est. speed input: 5576.36 toks/s, output: 10.89 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:11<00:00,  9.76it/s, est. speed input: 5571.43 toks/s, output: 10.88 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:11<00:00,  9.77it/s, est. speed input: 5566.38 toks/s, output: 10.87 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:11<00:00,  9.78it/s, est. speed input: 5561.55 toks/s, output: 10.86 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:11<00:00,  9.79it/s, est. speed input: 5556.82 toks/s, output: 10.85 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:11<00:00,  9.78it/s, est. speed input: 5551.97 toks/s, output: 10.84 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00,  9.76it/s, est. speed input: 5546.91 toks/s, output: 10.83 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00,  9.76it/s, est. speed input: 5546.91 toks/s, output: 10.83 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00, 10.83it/s, est. speed input: 5546.91 toks/s, output: 10.83 toks/s]
[rank0]:[W126 07:41:36.981997239 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=1024 ==========
Time: 2026-01-26 07:41:39
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=128, max_num_seqs=1
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 128 --max-num-seqs 1 --max-model-len 1025 --max-num-batched-tokens 1025 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M1024.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:41:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:41:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=358979) WARNING 01-26 07:41:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=358979) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=358979) WARNING 01-26 07:42:30 [backends.py:609] Failed to read file <frozen os>
Throughput: 9.76 requests/s, 10001.06 total tokens/s, 9.76 output tokens/s
Total num prompt tokens:  131072
Total num output tokens:  128

STDERR:
[2026-01-26 07:41:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:41:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:41:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:41:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:41:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:41:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:41:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:41:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:41:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:41:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:41:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:41:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:41:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:41:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:41:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:41:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:41:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=358979) [2026-01-26 07:41:57] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:03<00:10,  3.65s/it]
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:08<00:09,  4.51s/it]
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:10<00:03,  3.03s/it]
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:15<00:00,  3.80s/it]
(EngineCore_DP0 pid=358979) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:15<00:00,  3.75s/it]
(EngineCore_DP0 pid=358979) 
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=358979) [2026-01-26 07:42:14] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=358979) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  3.23it/s]
(EngineCore_DP0 pid=358979) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.49it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00,  4.48it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  16%|█▋        | 21/128 [00:00<00:00, 209.32it/s]
Adding requests:  36%|███▌      | 46/128 [00:00<00:00, 230.61it/s]
Adding requests:  56%|█████▋    | 72/128 [00:00<00:00, 238.14it/s]
Adding requests:  75%|███████▌  | 96/128 [00:00<00:00, 237.33it/s]
Adding requests:  95%|█████████▌| 122/128 [00:00<00:00, 241.83it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 238.24it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 4/128 [00:00<00:05, 20.97it/s, est. speed input: 21480.48 toks/s, output: 20.97 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:00<00:09, 13.34it/s, est. speed input: 14566.22 toks/s, output: 14.22 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:09, 12.00it/s, est. speed input: 13303.46 toks/s, output: 12.99 toks/s]
Processed prompts:   9%|▊         | 11/128 [00:00<00:10, 11.25it/s, est. speed input: 12598.36 toks/s, output: 12.30 toks/s]
Processed prompts:  10%|█         | 13/128 [00:01<00:10, 10.82it/s, est. speed input: 12164.15 toks/s, output: 11.88 toks/s]
Processed prompts:  12%|█▏        | 15/128 [00:01<00:10, 10.58it/s, est. speed input: 11880.89 toks/s, output: 11.60 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:01<00:10, 10.40it/s, est. speed input: 11664.33 toks/s, output: 11.39 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:01<00:10, 10.27it/s, est. speed input: 11494.97 toks/s, output: 11.23 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:01<00:10, 10.18it/s, est. speed input: 11358.84 toks/s, output: 11.09 toks/s]
Processed prompts:  18%|█▊        | 23/128 [00:02<00:10, 10.13it/s, est. speed input: 11253.01 toks/s, output: 10.99 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:02<00:10, 10.11it/s, est. speed input: 11171.38 toks/s, output: 10.91 toks/s]
Processed prompts:  21%|██        | 27/128 [00:02<00:10, 10.06it/s, est. speed input: 11091.94 toks/s, output: 10.83 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:02<00:09, 10.03it/s, est. speed input: 11025.93 toks/s, output: 10.77 toks/s]
Processed prompts:  24%|██▍       | 31/128 [00:02<00:09, 10.00it/s, est. speed input: 10965.58 toks/s, output: 10.71 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:03<00:09,  9.97it/s, est. speed input: 10912.40 toks/s, output: 10.66 toks/s]
Processed prompts:  27%|██▋       | 34/128 [00:03<00:09,  9.96it/s, est. speed input: 10887.87 toks/s, output: 10.63 toks/s]
Processed prompts:  28%|██▊       | 36/128 [00:03<00:09, 10.01it/s, est. speed input: 10856.16 toks/s, output: 10.60 toks/s]
Processed prompts:  30%|██▉       | 38/128 [00:03<00:08, 10.04it/s, est. speed input: 10827.54 toks/s, output: 10.57 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:03<00:08, 10.03it/s, est. speed input: 10798.11 toks/s, output: 10.54 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:03<00:08, 10.02it/s, est. speed input: 10768.98 toks/s, output: 10.52 toks/s]
Processed prompts:  34%|███▍      | 44/128 [00:04<00:08, 10.05it/s, est. speed input: 10749.50 toks/s, output: 10.50 toks/s]
Processed prompts:  36%|███▌      | 46/128 [00:04<00:08, 10.07it/s, est. speed input: 10732.02 toks/s, output: 10.48 toks/s]
Processed prompts:  38%|███▊      | 48/128 [00:04<00:07, 10.03it/s, est. speed input: 10707.27 toks/s, output: 10.46 toks/s]
Processed prompts:  39%|███▉      | 50/128 [00:04<00:07,  9.93it/s, est. speed input: 10674.89 toks/s, output: 10.42 toks/s]
Processed prompts:  41%|████      | 52/128 [00:04<00:07,  9.96it/s, est. speed input: 10659.18 toks/s, output: 10.41 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:05<00:07,  9.91it/s, est. speed input: 10644.09 toks/s, output: 10.39 toks/s]
Processed prompts:  42%|████▏     | 54/128 [00:05<00:07,  9.92it/s, est. speed input: 10635.75 toks/s, output: 10.39 toks/s]
Processed prompts:  44%|████▍     | 56/128 [00:05<00:07,  9.97it/s, est. speed input: 10623.31 toks/s, output: 10.37 toks/s]
Processed prompts:  45%|████▌     | 58/128 [00:05<00:07, 10.00it/s, est. speed input: 10611.44 toks/s, output: 10.36 toks/s]
Processed prompts:  46%|████▌     | 59/128 [00:05<00:06,  9.98it/s, est. speed input: 10603.16 toks/s, output: 10.35 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:05<00:06,  9.97it/s, est. speed input: 10595.46 toks/s, output: 10.35 toks/s]
Processed prompts:  48%|████▊     | 62/128 [00:05<00:06,  9.98it/s, est. speed input: 10583.79 toks/s, output: 10.34 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:06<00:06,  9.97it/s, est. speed input: 10577.15 toks/s, output: 10.33 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:06<00:06, 10.02it/s, est. speed input: 10569.97 toks/s, output: 10.32 toks/s]
Processed prompts:  52%|█████▏    | 67/128 [00:06<00:06, 10.07it/s, est. speed input: 10565.18 toks/s, output: 10.32 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:06<00:05, 10.10it/s, est. speed input: 10560.07 toks/s, output: 10.31 toks/s]
Processed prompts:  55%|█████▌    | 71/128 [00:06<00:05, 10.09it/s, est. speed input: 10552.80 toks/s, output: 10.31 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:07<00:05, 10.10it/s, est. speed input: 10548.00 toks/s, output: 10.30 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:07<00:05, 10.05it/s, est. speed input: 10537.96 toks/s, output: 10.29 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:07<00:05, 10.09it/s, est. speed input: 10534.51 toks/s, output: 10.29 toks/s]
Processed prompts:  62%|██████▏   | 79/128 [00:07<00:04, 10.11it/s, est. speed input: 10530.88 toks/s, output: 10.28 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:07<00:04, 10.09it/s, est. speed input: 10525.16 toks/s, output: 10.28 toks/s]
Processed prompts:  65%|██████▍   | 83/128 [00:08<00:04, 10.07it/s, est. speed input: 10518.73 toks/s, output: 10.27 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:08<00:04, 10.04it/s, est. speed input: 10510.90 toks/s, output: 10.26 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:08<00:04, 10.04it/s, est. speed input: 10505.40 toks/s, output: 10.26 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:08<00:03, 10.03it/s, est. speed input: 10499.40 toks/s, output: 10.25 toks/s]
Processed prompts:  71%|███████   | 91/128 [00:08<00:03, 10.03it/s, est. speed input: 10494.23 toks/s, output: 10.25 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:09<00:03, 10.03it/s, est. speed input: 10489.16 toks/s, output: 10.24 toks/s]
Processed prompts:  74%|███████▍  | 95/128 [00:09<00:03,  9.89it/s, est. speed input: 10473.77 toks/s, output: 10.23 toks/s]
Processed prompts:  87%|████████▋ | 111/128 [00:09<00:00, 32.15it/s, est. speed input: 12016.45 toks/s, output: 11.73 toks/s]
Processed prompts:  90%|████████▉ | 115/128 [00:09<00:00, 21.72it/s, est. speed input: 11944.12 toks/s, output: 11.66 toks/s]
Processed prompts:  92%|█████████▏| 118/128 [00:10<00:00, 17.79it/s, est. speed input: 11893.95 toks/s, output: 11.62 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:10<00:00, 15.26it/s, est. speed input: 11845.83 toks/s, output: 11.57 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:10<00:00, 14.01it/s, est. speed input: 11815.09 toks/s, output: 11.54 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:10<00:00, 13.01it/s, est. speed input: 11786.68 toks/s, output: 11.51 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:11<00:00, 12.22it/s, est. speed input: 11758.95 toks/s, output: 11.48 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00, 12.22it/s, est. speed input: 11742.99 toks/s, output: 11.47 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:11<00:00, 11.47it/s, est. speed input: 11742.99 toks/s, output: 11.47 toks/s]
[rank0]:[W126 07:43:03.855798979 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=2048 ==========
Time: 2026-01-26 07:43:06
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=256, max_num_seqs=2
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 256 --max-num-seqs 2 --max-model-len 1025 --max-num-batched-tokens 2048 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M2048.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:43:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:43:17 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=360442) WARNING 01-26 07:43:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=360442) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=360442) WARNING 01-26 07:43:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.78 requests/s, 11049.35 total tokens/s, 10.78 output tokens/s
Total num prompt tokens:  262144
Total num output tokens:  256

STDERR:
[2026-01-26 07:43:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:43:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:43:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:43:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:43:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:43:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:43:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:43:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:43:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:43:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:43:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:43:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:43:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:43:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:43:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:43:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:43:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.31s/it]
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.31s/it]
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.11it/s]
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.05s/it]
(EngineCore_DP0 pid=360442) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.08s/it]
(EngineCore_DP0 pid=360442) 
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=360442) [2026-01-26 07:43:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=360442) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 1/3 [00:00<00:00,  3.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 2/3 [00:00<00:00,  4.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  4.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 3/3 [00:00<00:00,  4.09it/s]
(EngineCore_DP0 pid=360442) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 1/2 [00:00<00:00,  4.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  4.85it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 2/2 [00:00<00:00,  4.80it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   8%|▊         | 21/256 [00:00<00:01, 203.93it/s]
Adding requests:  19%|█▉        | 48/256 [00:00<00:00, 236.79it/s]
Adding requests:  29%|██▉       | 75/256 [00:00<00:00, 248.93it/s]
Adding requests:  39%|███▉      | 100/256 [00:00<00:00, 246.22it/s]
Adding requests:  50%|████▉     | 127/256 [00:00<00:00, 251.53it/s]
Adding requests:  60%|█████▉    | 153/256 [00:00<00:00, 246.64it/s]
Adding requests:  70%|██████▉   | 179/256 [00:00<00:00, 249.89it/s]
Adding requests:  80%|████████  | 205/256 [00:00<00:00, 251.45it/s]
Adding requests:  91%|█████████ | 232/256 [00:00<00:00, 254.47it/s]
Adding requests: 100%|██████████| 256/256 [00:01<00:00, 246.22it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 10/256 [00:00<00:04, 51.75it/s, est. speed input: 52997.98 toks/s, output: 51.75 toks/s]
Processed prompts:   6%|▋         | 16/256 [00:00<00:12, 19.03it/s, est. speed input: 22111.25 toks/s, output: 21.59 toks/s]
Processed prompts:   7%|▋         | 19/256 [00:00<00:12, 18.31it/s, est. speed input: 21059.42 toks/s, output: 20.57 toks/s]
Processed prompts:   9%|▊         | 22/256 [00:01<00:16, 13.85it/s, est. speed input: 17472.70 toks/s, output: 17.06 toks/s]
Processed prompts:   9%|▉         | 24/256 [00:01<00:17, 13.17it/s, est. speed input: 16703.28 toks/s, output: 16.31 toks/s]
Processed prompts:  10%|█         | 26/256 [00:01<00:18, 12.61it/s, est. speed input: 16104.34 toks/s, output: 15.73 toks/s]
Processed prompts:  11%|█         | 28/256 [00:01<00:18, 12.16it/s, est. speed input: 15614.91 toks/s, output: 15.25 toks/s]
Processed prompts:  12%|█▏        | 30/256 [00:02<00:19, 11.83it/s, est. speed input: 15218.86 toks/s, output: 14.86 toks/s]
Processed prompts:  12%|█▎        | 32/256 [00:02<00:19, 11.59it/s, est. speed input: 14889.73 toks/s, output: 14.54 toks/s]
Processed prompts:  13%|█▎        | 34/256 [00:02<00:19, 11.41it/s, est. speed input: 14610.52 toks/s, output: 14.27 toks/s]
Processed prompts:  14%|█▍        | 36/256 [00:02<00:19, 11.29it/s, est. speed input: 14370.56 toks/s, output: 14.03 toks/s]
Processed prompts:  15%|█▍        | 38/256 [00:02<00:19, 11.18it/s, est. speed input: 14159.94 toks/s, output: 13.83 toks/s]
Processed prompts:  16%|█▌        | 40/256 [00:02<00:19, 11.12it/s, est. speed input: 13976.85 toks/s, output: 13.65 toks/s]
Processed prompts:  16%|█▋        | 42/256 [00:03<00:19, 11.06it/s, est. speed input: 13813.81 toks/s, output: 13.49 toks/s]
Processed prompts:  17%|█▋        | 44/256 [00:03<00:19, 11.04it/s, est. speed input: 13671.21 toks/s, output: 13.35 toks/s]
Processed prompts:  18%|█▊        | 46/256 [00:03<00:19, 11.01it/s, est. speed input: 13542.17 toks/s, output: 13.22 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:03<00:18, 10.99it/s, est. speed input: 13425.60 toks/s, output: 13.11 toks/s]
Processed prompts:  20%|█▉        | 50/256 [00:03<00:18, 10.97it/s, est. speed input: 13319.27 toks/s, output: 13.01 toks/s]
Processed prompts:  20%|██        | 52/256 [00:04<00:18, 10.96it/s, est. speed input: 13221.88 toks/s, output: 12.91 toks/s]
Processed prompts:  21%|██        | 54/256 [00:04<00:18, 10.96it/s, est. speed input: 13134.91 toks/s, output: 12.83 toks/s]
Processed prompts:  22%|██▏       | 56/256 [00:04<00:18, 10.95it/s, est. speed input: 13054.22 toks/s, output: 12.75 toks/s]
Processed prompts:  23%|██▎       | 58/256 [00:04<00:18, 10.96it/s, est. speed input: 12982.14 toks/s, output: 12.68 toks/s]
Processed prompts:  23%|██▎       | 60/256 [00:04<00:17, 10.97it/s, est. speed input: 12915.65 toks/s, output: 12.61 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:04<00:17, 10.97it/s, est. speed input: 12853.34 toks/s, output: 12.55 toks/s]
Processed prompts:  25%|██▌       | 64/256 [00:05<00:17, 10.96it/s, est. speed input: 12794.08 toks/s, output: 12.49 toks/s]
Processed prompts:  26%|██▌       | 66/256 [00:05<00:17, 10.96it/s, est. speed input: 12740.06 toks/s, output: 12.44 toks/s]
Processed prompts:  27%|██▋       | 68/256 [00:05<00:17, 10.95it/s, est. speed input: 12688.10 toks/s, output: 12.39 toks/s]
Processed prompts:  27%|██▋       | 70/256 [00:05<00:16, 10.95it/s, est. speed input: 12640.36 toks/s, output: 12.34 toks/s]
Processed prompts:  28%|██▊       | 72/256 [00:05<00:16, 10.95it/s, est. speed input: 12596.65 toks/s, output: 12.30 toks/s]
Processed prompts:  29%|██▉       | 74/256 [00:06<00:16, 10.94it/s, est. speed input: 12553.48 toks/s, output: 12.26 toks/s]
Processed prompts:  30%|██▉       | 76/256 [00:06<00:16, 10.94it/s, est. speed input: 12513.42 toks/s, output: 12.22 toks/s]
Processed prompts:  30%|███       | 78/256 [00:06<00:16, 10.93it/s, est. speed input: 12474.88 toks/s, output: 12.18 toks/s]
Processed prompts:  31%|███▏      | 80/256 [00:06<00:16, 10.93it/s, est. speed input: 12439.10 toks/s, output: 12.15 toks/s]
Processed prompts:  32%|███▏      | 82/256 [00:06<00:15, 10.93it/s, est. speed input: 12405.52 toks/s, output: 12.11 toks/s]
Processed prompts:  33%|███▎      | 84/256 [00:06<00:15, 10.92it/s, est. speed input: 12372.50 toks/s, output: 12.08 toks/s]
Processed prompts:  34%|███▎      | 86/256 [00:07<00:15, 10.92it/s, est. speed input: 12342.07 toks/s, output: 12.05 toks/s]
Processed prompts:  34%|███▍      | 88/256 [00:07<00:15, 10.92it/s, est. speed input: 12312.88 toks/s, output: 12.02 toks/s]
Processed prompts:  35%|███▌      | 90/256 [00:07<00:15, 10.92it/s, est. speed input: 12285.50 toks/s, output: 12.00 toks/s]
Processed prompts:  36%|███▌      | 92/256 [00:07<00:15, 10.92it/s, est. speed input: 12259.19 toks/s, output: 11.97 toks/s]
Processed prompts:  37%|███▋      | 94/256 [00:07<00:14, 10.93it/s, est. speed input: 12234.51 toks/s, output: 11.95 toks/s]
Processed prompts:  38%|███▊      | 96/256 [00:08<00:14, 10.91it/s, est. speed input: 12209.65 toks/s, output: 11.92 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:08<00:14, 10.92it/s, est. speed input: 12187.12 toks/s, output: 11.90 toks/s]
Processed prompts:  39%|███▉      | 100/256 [00:08<00:14, 10.93it/s, est. speed input: 12165.74 toks/s, output: 11.88 toks/s]
Processed prompts:  40%|███▉      | 102/256 [00:08<00:14, 10.93it/s, est. speed input: 12145.59 toks/s, output: 11.86 toks/s]
Processed prompts:  41%|████      | 104/256 [00:08<00:13, 10.94it/s, est. speed input: 12125.97 toks/s, output: 11.84 toks/s]
Processed prompts:  41%|████▏     | 106/256 [00:08<00:13, 10.93it/s, est. speed input: 12106.91 toks/s, output: 11.82 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:09<00:13, 10.93it/s, est. speed input: 12088.67 toks/s, output: 11.81 toks/s]
Processed prompts:  43%|████▎     | 110/256 [00:09<00:13, 10.93it/s, est. speed input: 12070.76 toks/s, output: 11.79 toks/s]
Processed prompts:  44%|████▍     | 112/256 [00:09<00:13, 10.92it/s, est. speed input: 12053.33 toks/s, output: 11.77 toks/s]
Processed prompts:  45%|████▍     | 114/256 [00:09<00:13, 10.92it/s, est. speed input: 12036.99 toks/s, output: 11.75 toks/s]
Processed prompts:  45%|████▌     | 116/256 [00:09<00:12, 10.92it/s, est. speed input: 12021.28 toks/s, output: 11.74 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:10<00:12, 10.91it/s, est. speed input: 12005.37 toks/s, output: 11.72 toks/s]
Processed prompts:  47%|████▋     | 120/256 [00:10<00:12, 10.91it/s, est. speed input: 11990.17 toks/s, output: 11.71 toks/s]
Processed prompts:  48%|████▊     | 122/256 [00:10<00:12, 10.90it/s, est. speed input: 11975.47 toks/s, output: 11.69 toks/s]
Processed prompts:  48%|████▊     | 124/256 [00:10<00:12, 10.90it/s, est. speed input: 11961.21 toks/s, output: 11.68 toks/s]
Processed prompts:  49%|████▉     | 126/256 [00:10<00:11, 10.90it/s, est. speed input: 11947.56 toks/s, output: 11.67 toks/s]
Processed prompts:  50%|█████     | 128/256 [00:10<00:11, 10.90it/s, est. speed input: 11934.40 toks/s, output: 11.65 toks/s]
Processed prompts:  51%|█████     | 130/256 [00:11<00:11, 10.90it/s, est. speed input: 11921.70 toks/s, output: 11.64 toks/s]
Processed prompts:  52%|█████▏    | 132/256 [00:11<00:11, 10.91it/s, est. speed input: 11909.75 toks/s, output: 11.63 toks/s]
Processed prompts:  52%|█████▏    | 134/256 [00:11<00:11, 10.91it/s, est. speed input: 11898.11 toks/s, output: 11.62 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:11<00:11, 10.90it/s, est. speed input: 11886.28 toks/s, output: 11.61 toks/s]
Processed prompts:  54%|█████▍    | 138/256 [00:11<00:10, 10.91it/s, est. speed input: 11875.51 toks/s, output: 11.60 toks/s]
Processed prompts:  55%|█████▍    | 140/256 [00:12<00:10, 10.90it/s, est. speed input: 11864.51 toks/s, output: 11.59 toks/s]
Processed prompts:  55%|█████▌    | 142/256 [00:12<00:10, 10.90it/s, est. speed input: 11853.63 toks/s, output: 11.58 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:12<00:10, 10.89it/s, est. speed input: 11842.91 toks/s, output: 11.57 toks/s]
Processed prompts:  57%|█████▋    | 146/256 [00:12<00:10, 10.88it/s, est. speed input: 11832.40 toks/s, output: 11.56 toks/s]
Processed prompts:  58%|█████▊    | 148/256 [00:12<00:09, 10.88it/s, est. speed input: 11822.38 toks/s, output: 11.55 toks/s]
Processed prompts:  59%|█████▊    | 150/256 [00:13<00:09, 10.87it/s, est. speed input: 11812.49 toks/s, output: 11.54 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:13<00:09, 10.86it/s, est. speed input: 11802.60 toks/s, output: 11.53 toks/s]
Processed prompts:  60%|██████    | 154/256 [00:13<00:09, 10.86it/s, est. speed input: 11793.28 toks/s, output: 11.52 toks/s]
Processed prompts:  61%|██████    | 156/256 [00:13<00:09, 10.87it/s, est. speed input: 11784.31 toks/s, output: 11.51 toks/s]
Processed prompts:  62%|██████▏   | 158/256 [00:13<00:09, 10.86it/s, est. speed input: 11775.29 toks/s, output: 11.50 toks/s]
Processed prompts:  62%|██████▎   | 160/256 [00:13<00:08, 10.86it/s, est. speed input: 11766.74 toks/s, output: 11.49 toks/s]
Processed prompts:  63%|██████▎   | 162/256 [00:14<00:08, 10.87it/s, est. speed input: 11758.50 toks/s, output: 11.48 toks/s]
Processed prompts:  64%|██████▍   | 164/256 [00:14<00:08, 10.86it/s, est. speed input: 11749.95 toks/s, output: 11.47 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:14<00:08, 10.85it/s, est. speed input: 11741.75 toks/s, output: 11.47 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:14<00:08, 10.86it/s, est. speed input: 11734.34 toks/s, output: 11.46 toks/s]
Processed prompts:  66%|██████▋   | 170/256 [00:14<00:07, 10.87it/s, est. speed input: 11726.92 toks/s, output: 11.45 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:15<00:07, 10.87it/s, est. speed input: 11719.60 toks/s, output: 11.44 toks/s]
Processed prompts:  68%|██████▊   | 174/256 [00:15<00:07, 10.86it/s, est. speed input: 11712.14 toks/s, output: 11.44 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:15<00:07, 10.85it/s, est. speed input: 11704.81 toks/s, output: 11.43 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:15<00:07, 10.85it/s, est. speed input: 11697.73 toks/s, output: 11.42 toks/s]
Processed prompts:  70%|███████   | 180/256 [00:15<00:07, 10.85it/s, est. speed input: 11690.87 toks/s, output: 11.42 toks/s]
Processed prompts:  71%|███████   | 182/256 [00:15<00:06, 10.85it/s, est. speed input: 11684.14 toks/s, output: 11.41 toks/s]
Processed prompts:  72%|███████▏  | 184/256 [00:16<00:06, 10.85it/s, est. speed input: 11677.72 toks/s, output: 11.40 toks/s]
Processed prompts:  73%|███████▎  | 186/256 [00:16<00:06, 10.84it/s, est. speed input: 11670.91 toks/s, output: 11.40 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:16<00:06, 10.84it/s, est. speed input: 11664.33 toks/s, output: 11.39 toks/s]
Processed prompts:  74%|███████▍  | 190/256 [00:16<00:06, 10.83it/s, est. speed input: 11657.84 toks/s, output: 11.38 toks/s]
Processed prompts:  75%|███████▌  | 192/256 [00:16<00:05, 10.83it/s, est. speed input: 11651.72 toks/s, output: 11.38 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:17<00:05, 10.83it/s, est. speed input: 11645.56 toks/s, output: 11.37 toks/s]
Processed prompts:  77%|███████▋  | 196/256 [00:17<00:05, 10.83it/s, est. speed input: 11639.66 toks/s, output: 11.37 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:17<00:05, 10.84it/s, est. speed input: 11634.05 toks/s, output: 11.36 toks/s]
Processed prompts:  78%|███████▊  | 200/256 [00:17<00:05, 10.84it/s, est. speed input: 11628.68 toks/s, output: 11.36 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:17<00:04, 10.84it/s, est. speed input: 11623.11 toks/s, output: 11.35 toks/s]
Processed prompts:  80%|███████▉  | 204/256 [00:17<00:04, 10.84it/s, est. speed input: 11617.66 toks/s, output: 11.35 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:18<00:04, 10.85it/s, est. speed input: 11612.65 toks/s, output: 11.34 toks/s]
Processed prompts:  81%|████████▏ | 208/256 [00:18<00:04, 10.84it/s, est. speed input: 11607.29 toks/s, output: 11.34 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:18<00:04, 10.84it/s, est. speed input: 11602.36 toks/s, output: 11.33 toks/s]
Processed prompts:  83%|████████▎ | 212/256 [00:18<00:04, 10.84it/s, est. speed input: 11597.43 toks/s, output: 11.33 toks/s]
Processed prompts:  84%|████████▎ | 214/256 [00:18<00:03, 10.84it/s, est. speed input: 11592.35 toks/s, output: 11.32 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:19<00:03, 10.82it/s, est. speed input: 11587.08 toks/s, output: 11.32 toks/s]
Processed prompts:  85%|████████▌ | 218/256 [00:19<00:03, 10.82it/s, est. speed input: 11582.00 toks/s, output: 11.31 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:19<00:03, 10.81it/s, est. speed input: 11576.98 toks/s, output: 11.31 toks/s]
Processed prompts:  87%|████████▋ | 222/256 [00:19<00:03, 10.81it/s, est. speed input: 11572.19 toks/s, output: 11.30 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:19<00:02, 10.81it/s, est. speed input: 11567.42 toks/s, output: 11.30 toks/s]
Processed prompts:  88%|████████▊ | 226/256 [00:20<00:02, 10.81it/s, est. speed input: 11562.78 toks/s, output: 11.29 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:20<00:02, 10.81it/s, est. speed input: 11558.33 toks/s, output: 11.29 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:20<00:02, 10.81it/s, est. speed input: 11554.01 toks/s, output: 11.28 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:20<00:02, 10.81it/s, est. speed input: 11549.48 toks/s, output: 11.28 toks/s]
Processed prompts:  91%|█████████▏| 234/256 [00:20<00:02, 10.81it/s, est. speed input: 11545.42 toks/s, output: 11.27 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:20<00:01, 10.82it/s, est. speed input: 11541.36 toks/s, output: 11.27 toks/s]
Processed prompts:  93%|█████████▎| 238/256 [00:21<00:01, 10.82it/s, est. speed input: 11537.26 toks/s, output: 11.27 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:21<00:01, 10.81it/s, est. speed input: 11532.99 toks/s, output: 11.26 toks/s]
Processed prompts:  95%|█████████▍| 242/256 [00:21<00:01, 10.82it/s, est. speed input: 11529.24 toks/s, output: 11.26 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:21<00:01, 10.81it/s, est. speed input: 11525.07 toks/s, output: 11.25 toks/s]
Processed prompts:  96%|█████████▌| 246/256 [00:21<00:00, 10.80it/s, est. speed input: 11521.08 toks/s, output: 11.25 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:22<00:00, 10.80it/s, est. speed input: 11517.07 toks/s, output: 11.25 toks/s]
Processed prompts:  98%|█████████▊| 250/256 [00:22<00:00, 10.80it/s, est. speed input: 11513.26 toks/s, output: 11.24 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:22<00:00, 10.80it/s, est. speed input: 11509.65 toks/s, output: 11.24 toks/s]
Processed prompts:  99%|█████████▉| 254/256 [00:22<00:00, 10.82it/s, est. speed input: 11506.41 toks/s, output: 11.24 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:22<00:00, 12.50it/s, est. speed input: 11544.90 toks/s, output: 11.27 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:22<00:00, 12.50it/s, est. speed input: 11544.90 toks/s, output: 11.27 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:22<00:00, 11.27it/s, est. speed input: 11544.90 toks/s, output: 11.27 toks/s]
[rank0]:[W126 07:44:31.284669797 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=4096 ==========
Time: 2026-01-26 07:44:34
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=512, max_num_seqs=4
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 512 --max-num-seqs 4 --max-model-len 1025 --max-num-batched-tokens 4096 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M4096.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:44:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:44:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=361907) WARNING 01-26 07:44:53 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=361907) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=361907) WARNING 01-26 07:45:13 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.86 requests/s, 11130.08 total tokens/s, 10.86 output tokens/s
Total num prompt tokens:  524288
Total num output tokens:  512

STDERR:
[2026-01-26 07:44:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:44:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:44:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:44:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:44:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:44:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:44:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:44:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:44:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:44:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:44:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:44:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:44:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:44:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:44:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:44:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:44:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.24s/it]
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.26s/it]
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.16it/s]
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.01s/it]
(EngineCore_DP0 pid=361907) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.03s/it]
(EngineCore_DP0 pid=361907) 
(EngineCore_DP0 pid=361907) [2026-01-26 07:44:59] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=361907) [2026-01-26 07:45:00] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=361907) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 1/4 [00:00<00:00,  4.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 2/4 [00:00<00:00,  3.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 3/4 [00:00<00:00,  4.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 4/4 [00:00<00:00,  4.40it/s]
(EngineCore_DP0 pid=361907) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/3 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 1/3 [00:00<00:00,  4.64it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 2/3 [00:00<00:00,  5.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  5.35it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 3/3 [00:00<00:00,  5.23it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:   4%|▍         | 22/512 [00:00<00:02, 219.87it/s]
Adding requests:   9%|▉         | 47/512 [00:00<00:01, 234.95it/s]
Adding requests:  14%|█▍        | 74/512 [00:00<00:01, 246.69it/s]
Adding requests:  19%|█▉        | 99/512 [00:00<00:01, 245.79it/s]
Adding requests:  24%|██▍       | 125/512 [00:00<00:01, 250.30it/s]
Adding requests:  29%|██▉       | 151/512 [00:00<00:01, 249.64it/s]
Adding requests:  35%|███▍      | 177/512 [00:00<00:01, 249.80it/s]
Adding requests:  40%|███▉      | 204/512 [00:00<00:01, 253.10it/s]
Adding requests:  45%|████▌     | 232/512 [00:00<00:01, 259.79it/s]
Adding requests:  50%|█████     | 258/512 [00:01<00:00, 256.36it/s]
Adding requests:  55%|█████▌    | 284/512 [00:01<00:00, 257.38it/s]
Adding requests:  61%|██████    | 310/512 [00:01<00:00, 257.76it/s]
Adding requests:  66%|██████▌   | 338/512 [00:01<00:00, 263.11it/s]
Adding requests:  71%|███████▏  | 366/512 [00:01<00:00, 265.16it/s]
Adding requests:  77%|███████▋  | 393/512 [00:01<00:00, 262.57it/s]
Adding requests:  82%|████████▏ | 421/512 [00:01<00:00, 265.03it/s]
Adding requests:  88%|████████▊ | 448/512 [00:01<00:00, 260.72it/s]
Adding requests:  93%|█████████▎| 475/512 [00:01<00:00, 263.32it/s]
Adding requests:  98%|█████████▊| 503/512 [00:01<00:00, 266.96it/s]
Adding requests: 100%|██████████| 512/512 [00:01<00:00, 258.08it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▎         | 18/512 [00:00<00:05, 95.01it/s, est. speed input: 97301.82 toks/s, output: 95.01 toks/s]
Processed prompts:   5%|▌         | 28/512 [00:00<00:18, 26.53it/s, est. speed input: 31554.41 toks/s, output: 30.81 toks/s]
Processed prompts:   6%|▋         | 33/512 [00:01<00:22, 21.77it/s, est. speed input: 26636.27 toks/s, output: 26.01 toks/s]
Processed prompts:   7%|▋         | 37/512 [00:01<00:26, 18.05it/s, est. speed input: 23269.39 toks/s, output: 22.72 toks/s]
Processed prompts:   8%|▊         | 40/512 [00:01<00:31, 14.81it/s, est. speed input: 20602.60 toks/s, output: 20.12 toks/s]
Processed prompts:   8%|▊         | 42/512 [00:02<00:39, 11.83it/s, est. speed input: 18317.21 toks/s, output: 17.89 toks/s]
Processed prompts:   9%|▉         | 46/512 [00:02<00:40, 11.60it/s, est. speed input: 17392.86 toks/s, output: 16.99 toks/s]
Processed prompts:  10%|▉         | 50/512 [00:03<00:40, 11.45it/s, est. speed input: 16685.60 toks/s, output: 16.29 toks/s]
Processed prompts:  11%|█         | 54/512 [00:03<00:40, 11.34it/s, est. speed input: 16128.13 toks/s, output: 15.75 toks/s]
Processed prompts:  11%|█▏        | 58/512 [00:03<00:40, 11.27it/s, est. speed input: 15675.64 toks/s, output: 15.31 toks/s]
Processed prompts:  12%|█▏        | 62/512 [00:04<00:40, 11.22it/s, est. speed input: 15302.21 toks/s, output: 14.94 toks/s]
Processed prompts:  13%|█▎        | 66/512 [00:04<00:39, 11.18it/s, est. speed input: 14987.22 toks/s, output: 14.64 toks/s]
Processed prompts:  14%|█▎        | 70/512 [00:04<00:39, 11.15it/s, est. speed input: 14718.44 toks/s, output: 14.37 toks/s]
Processed prompts:  14%|█▍        | 74/512 [00:05<00:39, 11.13it/s, est. speed input: 14486.26 toks/s, output: 14.15 toks/s]
Processed prompts:  15%|█▌        | 78/512 [00:05<00:39, 11.12it/s, est. speed input: 14283.57 toks/s, output: 13.95 toks/s]
Processed prompts:  16%|█▌        | 82/512 [00:05<00:38, 11.11it/s, est. speed input: 14105.22 toks/s, output: 13.77 toks/s]
Processed prompts:  17%|█▋        | 86/512 [00:06<00:38, 11.10it/s, est. speed input: 13947.67 toks/s, output: 13.62 toks/s]
Processed prompts:  18%|█▊        | 90/512 [00:06<00:38, 11.09it/s, est. speed input: 13806.59 toks/s, output: 13.48 toks/s]
Processed prompts:  18%|█▊        | 94/512 [00:07<00:37, 11.08it/s, est. speed input: 13679.60 toks/s, output: 13.36 toks/s]
Processed prompts:  19%|█▉        | 98/512 [00:07<00:37, 11.08it/s, est. speed input: 13565.23 toks/s, output: 13.25 toks/s]
Processed prompts:  20%|█▉        | 102/512 [00:07<00:37, 11.08it/s, est. speed input: 13462.05 toks/s, output: 13.15 toks/s]
Processed prompts:  21%|██        | 106/512 [00:08<00:36, 11.03it/s, est. speed input: 13358.23 toks/s, output: 13.05 toks/s]
Processed prompts:  21%|██▏       | 110/512 [00:08<00:36, 10.98it/s, est. speed input: 13262.75 toks/s, output: 12.95 toks/s]
Processed prompts:  22%|██▏       | 114/512 [00:08<00:36, 10.96it/s, est. speed input: 13175.41 toks/s, output: 12.87 toks/s]
Processed prompts:  23%|██▎       | 118/512 [00:09<00:36, 10.93it/s, est. speed input: 13094.35 toks/s, output: 12.79 toks/s]
Processed prompts:  24%|██▍       | 122/512 [00:09<00:35, 10.92it/s, est. speed input: 13019.25 toks/s, output: 12.71 toks/s]
Processed prompts:  25%|██▍       | 126/512 [00:09<00:35, 10.90it/s, est. speed input: 12949.73 toks/s, output: 12.65 toks/s]
Processed prompts:  25%|██▌       | 130/512 [00:10<00:35, 10.89it/s, est. speed input: 12885.13 toks/s, output: 12.58 toks/s]
Processed prompts:  26%|██▌       | 134/512 [00:10<00:34, 10.89it/s, est. speed input: 12824.86 toks/s, output: 12.52 toks/s]
Processed prompts:  27%|██▋       | 138/512 [00:11<00:34, 10.88it/s, est. speed input: 12768.67 toks/s, output: 12.47 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:11<00:34, 10.88it/s, est. speed input: 12715.56 toks/s, output: 12.42 toks/s]
Processed prompts:  29%|██▊       | 146/512 [00:11<00:33, 10.87it/s, est. speed input: 12665.69 toks/s, output: 12.37 toks/s]
Processed prompts:  29%|██▉       | 150/512 [00:12<00:33, 10.87it/s, est. speed input: 12618.87 toks/s, output: 12.32 toks/s]
Processed prompts:  30%|███       | 154/512 [00:12<00:32, 10.86it/s, est. speed input: 12574.77 toks/s, output: 12.28 toks/s]
Processed prompts:  31%|███       | 158/512 [00:12<00:32, 10.86it/s, est. speed input: 12532.95 toks/s, output: 12.24 toks/s]
Processed prompts:  32%|███▏      | 162/512 [00:13<00:32, 10.85it/s, est. speed input: 12493.16 toks/s, output: 12.20 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:13<00:31, 10.85it/s, est. speed input: 12455.58 toks/s, output: 12.16 toks/s]
Processed prompts:  33%|███▎      | 170/512 [00:14<00:31, 10.85it/s, est. speed input: 12419.82 toks/s, output: 12.13 toks/s]
Processed prompts:  34%|███▍      | 174/512 [00:14<00:31, 10.84it/s, est. speed input: 12385.92 toks/s, output: 12.10 toks/s]
Processed prompts:  35%|███▍      | 178/512 [00:14<00:30, 10.84it/s, est. speed input: 12353.84 toks/s, output: 12.06 toks/s]
Processed prompts:  36%|███▌      | 182/512 [00:15<00:30, 10.84it/s, est. speed input: 12323.21 toks/s, output: 12.03 toks/s]
Processed prompts:  36%|███▋      | 186/512 [00:15<00:30, 10.84it/s, est. speed input: 12293.77 toks/s, output: 12.01 toks/s]
Processed prompts:  37%|███▋      | 190/512 [00:15<00:29, 10.84it/s, est. speed input: 12266.11 toks/s, output: 11.98 toks/s]
Processed prompts:  38%|███▊      | 194/512 [00:16<00:29, 10.85it/s, est. speed input: 12240.68 toks/s, output: 11.95 toks/s]
Processed prompts:  39%|███▊      | 198/512 [00:16<00:28, 10.86it/s, est. speed input: 12216.34 toks/s, output: 11.93 toks/s]
Processed prompts:  39%|███▉      | 202/512 [00:16<00:28, 10.87it/s, est. speed input: 12193.31 toks/s, output: 11.91 toks/s]
Processed prompts:  40%|████      | 206/512 [00:17<00:28, 10.88it/s, est. speed input: 12171.33 toks/s, output: 11.89 toks/s]
Processed prompts:  41%|████      | 210/512 [00:17<00:27, 10.88it/s, est. speed input: 12150.00 toks/s, output: 11.87 toks/s]
Processed prompts:  42%|████▏     | 214/512 [00:18<00:27, 10.88it/s, est. speed input: 12129.50 toks/s, output: 11.85 toks/s]
Processed prompts:  43%|████▎     | 218/512 [00:18<00:27, 10.88it/s, est. speed input: 12109.83 toks/s, output: 11.83 toks/s]
Processed prompts:  43%|████▎     | 222/512 [00:18<00:26, 10.88it/s, est. speed input: 12090.83 toks/s, output: 11.81 toks/s]
Processed prompts:  44%|████▍     | 226/512 [00:19<00:26, 10.88it/s, est. speed input: 12072.50 toks/s, output: 11.79 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:19<00:25, 10.88it/s, est. speed input: 12054.78 toks/s, output: 11.77 toks/s]
Processed prompts:  46%|████▌     | 234/512 [00:19<00:25, 10.88it/s, est. speed input: 12037.87 toks/s, output: 11.76 toks/s]
Processed prompts:  46%|████▋     | 238/512 [00:20<00:25, 10.88it/s, est. speed input: 12021.57 toks/s, output: 11.74 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:20<00:24, 10.87it/s, est. speed input: 12005.53 toks/s, output: 11.72 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:21<00:24, 10.87it/s, est. speed input: 11990.24 toks/s, output: 11.71 toks/s]
Processed prompts:  49%|████▉     | 250/512 [00:21<00:24, 10.87it/s, est. speed input: 11975.52 toks/s, output: 11.69 toks/s]
Processed prompts:  50%|████▉     | 254/512 [00:21<00:23, 10.87it/s, est. speed input: 11960.95 toks/s, output: 11.68 toks/s]
Processed prompts:  50%|█████     | 258/512 [00:22<00:23, 10.86it/s, est. speed input: 11946.85 toks/s, output: 11.67 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:22<00:23, 10.86it/s, est. speed input: 11933.34 toks/s, output: 11.65 toks/s]
Processed prompts:  52%|█████▏    | 266/512 [00:22<00:22, 10.86it/s, est. speed input: 11920.20 toks/s, output: 11.64 toks/s]
Processed prompts:  53%|█████▎    | 270/512 [00:23<00:22, 10.86it/s, est. speed input: 11907.41 toks/s, output: 11.63 toks/s]
Processed prompts:  54%|█████▎    | 274/512 [00:23<00:21, 10.86it/s, est. speed input: 11895.03 toks/s, output: 11.62 toks/s]
Processed prompts:  54%|█████▍    | 278/512 [00:23<00:21, 10.86it/s, est. speed input: 11883.17 toks/s, output: 11.60 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:24<00:21, 10.87it/s, est. speed input: 11872.42 toks/s, output: 11.59 toks/s]
Processed prompts:  56%|█████▌    | 286/512 [00:24<00:20, 10.88it/s, est. speed input: 11861.71 toks/s, output: 11.58 toks/s]
Processed prompts:  57%|█████▋    | 290/512 [00:25<00:20, 10.89it/s, est. speed input: 11851.52 toks/s, output: 11.57 toks/s]
Processed prompts:  57%|█████▋    | 294/512 [00:25<00:20, 10.89it/s, est. speed input: 11841.61 toks/s, output: 11.56 toks/s]
Processed prompts:  58%|█████▊    | 298/512 [00:25<00:19, 10.89it/s, est. speed input: 11831.78 toks/s, output: 11.55 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:26<00:19, 10.89it/s, est. speed input: 11822.17 toks/s, output: 11.55 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:26<00:18, 10.89it/s, est. speed input: 11812.98 toks/s, output: 11.54 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:26<00:18, 10.90it/s, est. speed input: 11804.17 toks/s, output: 11.53 toks/s]
Processed prompts:  61%|██████▏   | 314/512 [00:27<00:18, 10.90it/s, est. speed input: 11795.84 toks/s, output: 11.52 toks/s]
Processed prompts:  62%|██████▏   | 318/512 [00:27<00:17, 10.90it/s, est. speed input: 11787.50 toks/s, output: 11.51 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:27<00:17, 10.91it/s, est. speed input: 11779.46 toks/s, output: 11.50 toks/s]
Processed prompts:  64%|██████▎   | 326/512 [00:28<00:17, 10.91it/s, est. speed input: 11771.54 toks/s, output: 11.50 toks/s]
Processed prompts:  64%|██████▍   | 330/512 [00:28<00:16, 10.91it/s, est. speed input: 11763.95 toks/s, output: 11.49 toks/s]
Processed prompts:  65%|██████▌   | 334/512 [00:29<00:16, 10.91it/s, est. speed input: 11756.52 toks/s, output: 11.48 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:29<00:15, 10.91it/s, est. speed input: 11749.23 toks/s, output: 11.47 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:29<00:06, 23.81it/s, est. speed input: 12287.34 toks/s, output: 12.00 toks/s]
Processed prompts:  71%|███████   | 362/512 [00:30<00:07, 19.96it/s, est. speed input: 12273.84 toks/s, output: 11.99 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:30<00:08, 17.25it/s, est. speed input: 12260.49 toks/s, output: 11.97 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:30<00:09, 15.36it/s, est. speed input: 12247.57 toks/s, output: 11.96 toks/s]
Processed prompts:  73%|███████▎  | 374/512 [00:31<00:09, 14.02it/s, est. speed input: 12234.98 toks/s, output: 11.95 toks/s]
Processed prompts:  74%|███████▍  | 378/512 [00:31<00:10, 13.09it/s, est. speed input: 12222.58 toks/s, output: 11.94 toks/s]
Processed prompts:  75%|███████▍  | 382/512 [00:32<00:10, 12.43it/s, est. speed input: 12210.42 toks/s, output: 11.92 toks/s]
Processed prompts:  75%|███████▌  | 386/512 [00:32<00:10, 11.97it/s, est. speed input: 12198.46 toks/s, output: 11.91 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:32<00:10, 11.64it/s, est. speed input: 12186.66 toks/s, output: 11.90 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:33<00:10, 11.42it/s, est. speed input: 12175.28 toks/s, output: 11.89 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:33<00:10, 11.27it/s, est. speed input: 12164.21 toks/s, output: 11.88 toks/s]
Processed prompts:  79%|███████▊  | 402/512 [00:33<00:09, 11.15it/s, est. speed input: 12153.17 toks/s, output: 11.87 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:34<00:09, 11.08it/s, est. speed input: 12142.51 toks/s, output: 11.86 toks/s]
Processed prompts:  80%|████████  | 410/512 [00:34<00:09, 11.02it/s, est. speed input: 12131.98 toks/s, output: 11.85 toks/s]
Processed prompts:  81%|████████  | 414/512 [00:34<00:08, 10.98it/s, est. speed input: 12121.72 toks/s, output: 11.84 toks/s]
Processed prompts:  82%|████████▏ | 418/512 [00:35<00:08, 10.95it/s, est. speed input: 12111.67 toks/s, output: 11.83 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:35<00:08, 10.93it/s, est. speed input: 12101.76 toks/s, output: 11.82 toks/s]
Processed prompts:  83%|████████▎ | 426/512 [00:36<00:07, 10.92it/s, est. speed input: 12092.06 toks/s, output: 11.81 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:36<00:07, 10.91it/s, est. speed input: 12082.59 toks/s, output: 11.80 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:36<00:07, 10.90it/s, est. speed input: 12073.24 toks/s, output: 11.79 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:37<00:06, 10.90it/s, est. speed input: 12064.05 toks/s, output: 11.78 toks/s]
Processed prompts:  86%|████████▋ | 442/512 [00:37<00:06, 10.89it/s, est. speed input: 12055.06 toks/s, output: 11.77 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:37<00:06, 10.89it/s, est. speed input: 12046.15 toks/s, output: 11.76 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:38<00:05, 10.89it/s, est. speed input: 12037.53 toks/s, output: 11.76 toks/s]
Processed prompts:  89%|████████▊ | 454/512 [00:38<00:05, 10.89it/s, est. speed input: 12029.05 toks/s, output: 11.75 toks/s]
Processed prompts:  89%|████████▉ | 458/512 [00:39<00:04, 10.89it/s, est. speed input: 12020.77 toks/s, output: 11.74 toks/s]
Processed prompts:  90%|█████████ | 462/512 [00:39<00:04, 10.88it/s, est. speed input: 12012.55 toks/s, output: 11.73 toks/s]
Processed prompts:  91%|█████████ | 466/512 [00:39<00:04, 10.89it/s, est. speed input: 12004.63 toks/s, output: 11.72 toks/s]
Processed prompts:  92%|█████████▏| 470/512 [00:40<00:03, 10.89it/s, est. speed input: 11996.74 toks/s, output: 11.72 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:40<00:03, 10.89it/s, est. speed input: 11989.07 toks/s, output: 11.71 toks/s]
Processed prompts:  93%|█████████▎| 478/512 [00:40<00:03, 10.89it/s, est. speed input: 11981.48 toks/s, output: 11.70 toks/s]
Processed prompts:  94%|█████████▍| 482/512 [00:41<00:02, 10.88it/s, est. speed input: 11973.96 toks/s, output: 11.69 toks/s]
Processed prompts:  95%|█████████▍| 486/512 [00:41<00:02, 10.89it/s, est. speed input: 11966.80 toks/s, output: 11.69 toks/s]
Processed prompts:  96%|█████████▌| 490/512 [00:41<00:02, 10.89it/s, est. speed input: 11959.63 toks/s, output: 11.68 toks/s]
Processed prompts:  96%|█████████▋| 494/512 [00:42<00:01, 10.88it/s, est. speed input: 11952.48 toks/s, output: 11.67 toks/s]
Processed prompts:  97%|█████████▋| 498/512 [00:42<00:01, 10.88it/s, est. speed input: 11945.47 toks/s, output: 11.67 toks/s]
Processed prompts:  98%|█████████▊| 502/512 [00:43<00:00, 10.88it/s, est. speed input: 11938.58 toks/s, output: 11.66 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:43<00:00, 10.89it/s, est. speed input: 11931.99 toks/s, output: 11.65 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:43<00:00, 11.68it/s, est. speed input: 11948.06 toks/s, output: 11.67 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:43<00:00, 11.68it/s, est. speed input: 11994.85 toks/s, output: 11.71 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:43<00:00, 11.71it/s, est. speed input: 11994.85 toks/s, output: 11.71 toks/s]
[rank0]:[W126 07:46:22.185431347 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=8192 ==========
Time: 2026-01-26 07:46:25
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=1024, max_num_seqs=8
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 1024 --max-num-seqs 8 --max-model-len 1025 --max-num-batched-tokens 8192 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M8192.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:46:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:46:41 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=363758) WARNING 01-26 07:46:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=363758) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=363758) WARNING 01-26 07:47:09 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.63 requests/s, 10894.74 total tokens/s, 10.63 output tokens/s
Total num prompt tokens:  1048576
Total num output tokens:  1024

STDERR:
[2026-01-26 07:46:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:46:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:46:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:46:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:46:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:46:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:46:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:46:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:46:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:46:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:46:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:46:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:46:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:46:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:46:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:46:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:46:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:50] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.33s/it]
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.33s/it]
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.09it/s]
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.05s/it]
(EngineCore_DP0 pid=363758) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.09s/it]
(EngineCore_DP0 pid=363758) 
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=363758) [2026-01-26 07:46:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=363758) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 1/5 [00:00<00:01,  2.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 2/5 [00:00<00:00,  3.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 3/5 [00:00<00:00,  4.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 4/5 [00:00<00:00,  4.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 5/5 [00:01<00:00,  4.13it/s]
(EngineCore_DP0 pid=363758) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/4 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 1/4 [00:00<00:01,  2.42it/s]
Capturing CUDA graphs (decode, FULL):  50%|█████     | 2/4 [00:00<00:00,  3.34it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▌  | 3/4 [00:00<00:00,  3.56it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:01<00:00,  4.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 4/4 [00:01<00:00,  3.71it/s]

Adding requests:   0%|          | 0/1024 [00:00<?, ?it/s]
Adding requests:   2%|▏         | 22/1024 [00:00<00:04, 218.43it/s]
Adding requests:   5%|▍         | 48/1024 [00:00<00:04, 236.18it/s]
Adding requests:   7%|▋         | 74/1024 [00:00<00:03, 245.83it/s]
Adding requests:  10%|▉         | 99/1024 [00:00<00:03, 245.91it/s]
Adding requests:  12%|█▏        | 124/1024 [00:00<00:03, 246.76it/s]
Adding requests:  15%|█▍        | 149/1024 [00:00<00:03, 237.83it/s]
Adding requests:  17%|█▋        | 173/1024 [00:00<00:03, 237.17it/s]
Adding requests:  19%|█▉        | 199/1024 [00:00<00:03, 241.81it/s]
Adding requests:  22%|██▏       | 225/1024 [00:00<00:03, 245.28it/s]
Adding requests:  24%|██▍       | 250/1024 [00:01<00:03, 244.34it/s]
Adding requests:  27%|██▋       | 275/1024 [00:01<00:03, 245.08it/s]
Adding requests:  29%|██▉       | 301/1024 [00:01<00:02, 247.94it/s]
Adding requests:  32%|███▏      | 327/1024 [00:01<00:02, 251.09it/s]
Adding requests:  35%|███▍      | 356/1024 [00:01<00:02, 261.49it/s]
Adding requests:  38%|███▊      | 384/1024 [00:01<00:02, 265.41it/s]
Adding requests:  40%|████      | 413/1024 [00:01<00:02, 269.78it/s]
Adding requests:  43%|████▎     | 440/1024 [00:01<00:02, 264.44it/s]
Adding requests:  46%|████▌     | 467/1024 [00:01<00:02, 262.48it/s]
Adding requests:  49%|████▊     | 497/1024 [00:01<00:01, 270.36it/s]
Adding requests:  52%|█████▏    | 528/1024 [00:02<00:01, 279.36it/s]
Adding requests:  54%|█████▍    | 556/1024 [00:02<00:01, 269.62it/s]
Adding requests:  57%|█████▋    | 584/1024 [00:02<00:01, 266.38it/s]
Adding requests:  60%|█████▉    | 611/1024 [00:02<00:01, 261.73it/s]
Adding requests:  62%|██████▏   | 638/1024 [00:02<00:01, 262.70it/s]
Adding requests:  65%|██████▍   | 665/1024 [00:02<00:01, 259.18it/s]
Adding requests:  68%|██████▊   | 693/1024 [00:02<00:01, 264.63it/s]
Adding requests:  70%|███████   | 720/1024 [00:02<00:01, 259.67it/s]
Adding requests:  73%|███████▎  | 747/1024 [00:02<00:01, 257.76it/s]
Adding requests:  76%|███████▌  | 774/1024 [00:03<00:00, 258.92it/s]
Adding requests:  78%|███████▊  | 800/1024 [00:03<00:00, 257.81it/s]
Adding requests:  81%|████████  | 827/1024 [00:03<00:00, 260.23it/s]
Adding requests:  83%|████████▎ | 854/1024 [00:03<00:00, 258.64it/s]
Adding requests:  86%|████████▌ | 880/1024 [00:03<00:00, 258.64it/s]
Adding requests:  89%|████████▊ | 908/1024 [00:03<00:00, 262.65it/s]
Adding requests:  91%|█████████▏| 935/1024 [00:03<00:00, 252.89it/s]
Adding requests:  94%|█████████▍| 961/1024 [00:03<00:00, 252.15it/s]
Adding requests:  96%|█████████▋| 987/1024 [00:03<00:00, 251.14it/s]
Adding requests:  99%|█████████▉| 1013/1024 [00:03<00:00, 244.82it/s]
Adding requests: 100%|██████████| 1024/1024 [00:04<00:00, 255.11it/s]

Processed prompts:   0%|          | 0/1024 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   3%|▎         | 34/1024 [00:00<00:19, 51.66it/s, est. speed input: 52897.63 toks/s, output: 51.66 toks/s]
Processed prompts:   4%|▍         | 42/1024 [00:01<00:36, 26.62it/s, est. speed input: 30892.76 toks/s, output: 30.17 toks/s]
Processed prompts:   5%|▍         | 50/1024 [00:02<00:50, 19.11it/s, est. speed input: 23932.28 toks/s, output: 23.37 toks/s]
Processed prompts:   6%|▌         | 58/1024 [00:02<01:01, 15.83it/s, est. speed input: 20666.72 toks/s, output: 20.18 toks/s]
Processed prompts:   6%|▋         | 66/1024 [00:03<01:08, 14.04it/s, est. speed input: 18727.78 toks/s, output: 18.29 toks/s]
Processed prompts:   9%|▉         | 90/1024 [00:04<00:46, 20.12it/s, est. speed input: 21074.06 toks/s, output: 20.58 toks/s]
Processed prompts:  10%|▉         | 98/1024 [00:05<00:54, 17.11it/s, est. speed input: 19642.23 toks/s, output: 19.18 toks/s]
Processed prompts:  10%|█         | 106/1024 [00:05<01:01, 15.05it/s, est. speed input: 18529.61 toks/s, output: 18.10 toks/s]
Processed prompts:  11%|█         | 114/1024 [00:06<01:06, 13.75it/s, est. speed input: 17702.26 toks/s, output: 17.29 toks/s]
Processed prompts:  12%|█▏        | 122/1024 [00:07<01:10, 12.86it/s, est. speed input: 17039.39 toks/s, output: 16.64 toks/s]
Processed prompts:  13%|█▎        | 130/1024 [00:08<01:13, 12.24it/s, est. speed input: 16496.95 toks/s, output: 16.11 toks/s]
Processed prompts:  13%|█▎        | 138/1024 [00:08<01:14, 11.82it/s, est. speed input: 16045.46 toks/s, output: 15.67 toks/s]
Processed prompts:  14%|█▍        | 146/1024 [00:09<01:16, 11.52it/s, est. speed input: 15662.44 toks/s, output: 15.30 toks/s]
Processed prompts:  15%|█▌        | 154/1024 [00:10<01:16, 11.31it/s, est. speed input: 15333.74 toks/s, output: 14.97 toks/s]
Processed prompts:  16%|█▌        | 162/1024 [00:11<01:17, 11.11it/s, est. speed input: 15032.06 toks/s, output: 14.68 toks/s]
Processed prompts:  17%|█▋        | 170/1024 [00:11<01:17, 11.02it/s, est. speed input: 14784.05 toks/s, output: 14.44 toks/s]
Processed prompts:  17%|█▋        | 178/1024 [00:12<01:17, 10.96it/s, est. speed input: 14564.56 toks/s, output: 14.22 toks/s]
Processed prompts:  18%|█▊        | 186/1024 [00:13<01:16, 10.91it/s, est. speed input: 14369.37 toks/s, output: 14.03 toks/s]
Processed prompts:  19%|█▉        | 194/1024 [00:13<01:16, 10.88it/s, est. speed input: 14194.83 toks/s, output: 13.86 toks/s]
Processed prompts:  20%|█▉        | 202/1024 [00:14<01:15, 10.86it/s, est. speed input: 14037.29 toks/s, output: 13.71 toks/s]
Processed prompts:  21%|██        | 210/1024 [00:15<01:15, 10.84it/s, est. speed input: 13894.82 toks/s, output: 13.57 toks/s]
Processed prompts:  21%|██▏       | 218/1024 [00:16<01:14, 10.78it/s, est. speed input: 13755.16 toks/s, output: 13.43 toks/s]
Processed prompts:  22%|██▏       | 226/1024 [00:16<01:13, 10.78it/s, est. speed input: 13637.53 toks/s, output: 13.32 toks/s]
Processed prompts:  23%|██▎       | 234/1024 [00:17<01:13, 10.78it/s, est. speed input: 13529.06 toks/s, output: 13.21 toks/s]
Processed prompts:  24%|██▎       | 242/1024 [00:18<01:12, 10.79it/s, est. speed input: 13429.16 toks/s, output: 13.11 toks/s]
Processed prompts:  24%|██▍       | 250/1024 [00:19<01:11, 10.78it/s, est. speed input: 13336.90 toks/s, output: 13.02 toks/s]
Processed prompts:  25%|██▌       | 258/1024 [00:19<01:11, 10.78it/s, est. speed input: 13251.36 toks/s, output: 12.94 toks/s]
Processed prompts:  26%|██▌       | 266/1024 [00:20<01:10, 10.78it/s, est. speed input: 13171.89 toks/s, output: 12.86 toks/s]
Processed prompts:  27%|██▋       | 274/1024 [00:21<01:09, 10.73it/s, est. speed input: 13090.60 toks/s, output: 12.78 toks/s]
Processed prompts:  28%|██▊       | 282/1024 [00:22<01:09, 10.74it/s, est. speed input: 13021.98 toks/s, output: 12.72 toks/s]
Processed prompts:  28%|██▊       | 290/1024 [00:22<01:08, 10.75it/s, est. speed input: 12957.35 toks/s, output: 12.65 toks/s]
Processed prompts:  29%|██▉       | 298/1024 [00:23<01:07, 10.76it/s, est. speed input: 12896.93 toks/s, output: 12.59 toks/s]
Processed prompts:  30%|██▉       | 306/1024 [00:24<01:06, 10.76it/s, est. speed input: 12840.17 toks/s, output: 12.54 toks/s]
Processed prompts:  31%|███       | 314/1024 [00:25<01:05, 10.76it/s, est. speed input: 12786.67 toks/s, output: 12.49 toks/s]
Processed prompts:  31%|███▏      | 322/1024 [00:25<01:05, 10.76it/s, est. speed input: 12735.91 toks/s, output: 12.44 toks/s]
Processed prompts:  32%|███▏      | 330/1024 [00:26<01:04, 10.70it/s, est. speed input: 12681.42 toks/s, output: 12.38 toks/s]
Processed prompts:  33%|███▎      | 338/1024 [00:27<01:03, 10.72it/s, est. speed input: 12636.46 toks/s, output: 12.34 toks/s]
Processed prompts:  34%|███▍      | 346/1024 [00:28<01:03, 10.73it/s, est. speed input: 12593.45 toks/s, output: 12.30 toks/s]
Processed prompts:  35%|███▍      | 354/1024 [00:28<01:02, 10.74it/s, est. speed input: 12552.76 toks/s, output: 12.26 toks/s]
Processed prompts:  35%|███▌      | 362/1024 [00:29<01:01, 10.75it/s, est. speed input: 12514.33 toks/s, output: 12.22 toks/s]
Processed prompts:  36%|███▌      | 370/1024 [00:30<01:00, 10.75it/s, est. speed input: 12477.80 toks/s, output: 12.19 toks/s]
Processed prompts:  37%|███▋      | 378/1024 [00:31<01:00, 10.75it/s, est. speed input: 12442.80 toks/s, output: 12.15 toks/s]
Processed prompts:  38%|███▊      | 386/1024 [00:31<00:59, 10.70it/s, est. speed input: 12404.65 toks/s, output: 12.11 toks/s]
Processed prompts:  38%|███▊      | 394/1024 [00:32<00:58, 10.72it/s, est. speed input: 12373.41 toks/s, output: 12.08 toks/s]
Processed prompts:  39%|███▉      | 402/1024 [00:33<00:57, 10.73it/s, est. speed input: 12343.13 toks/s, output: 12.05 toks/s]
Processed prompts:  40%|████      | 410/1024 [00:34<00:57, 10.74it/s, est. speed input: 12314.01 toks/s, output: 12.03 toks/s]
Processed prompts:  41%|████      | 418/1024 [00:34<00:56, 10.75it/s, est. speed input: 12286.47 toks/s, output: 12.00 toks/s]
Processed prompts:  43%|████▎     | 442/1024 [00:35<00:34, 16.81it/s, est. speed input: 12700.08 toks/s, output: 12.40 toks/s]
Processed prompts:  44%|████▍     | 450/1024 [00:36<00:38, 15.03it/s, est. speed input: 12666.07 toks/s, output: 12.37 toks/s]
Processed prompts:  45%|████▍     | 458/1024 [00:37<00:41, 13.76it/s, est. speed input: 12632.66 toks/s, output: 12.34 toks/s]
Processed prompts:  46%|████▌     | 466/1024 [00:37<00:43, 12.86it/s, est. speed input: 12600.81 toks/s, output: 12.31 toks/s]
Processed prompts:  46%|████▋     | 474/1024 [00:38<00:44, 12.23it/s, est. speed input: 12569.91 toks/s, output: 12.28 toks/s]
Processed prompts:  47%|████▋     | 482/1024 [00:39<00:45, 11.79it/s, est. speed input: 12540.46 toks/s, output: 12.25 toks/s]
Processed prompts:  48%|████▊     | 490/1024 [00:40<00:46, 11.48it/s, est. speed input: 12511.91 toks/s, output: 12.22 toks/s]
Processed prompts:  49%|████▊     | 498/1024 [00:40<00:46, 11.26it/s, est. speed input: 12484.45 toks/s, output: 12.19 toks/s]
Processed prompts:  49%|████▉     | 506/1024 [00:41<00:47, 10.92it/s, est. speed input: 12445.43 toks/s, output: 12.15 toks/s]
Processed prompts:  50%|█████     | 514/1024 [00:42<00:46, 10.86it/s, est. speed input: 12419.55 toks/s, output: 12.13 toks/s]
Processed prompts:  51%|█████     | 522/1024 [00:43<00:46, 10.83it/s, est. speed input: 12395.03 toks/s, output: 12.10 toks/s]
Processed prompts:  52%|█████▏    | 530/1024 [00:43<00:45, 10.80it/s, est. speed input: 12371.58 toks/s, output: 12.08 toks/s]
Processed prompts:  53%|█████▎    | 538/1024 [00:44<00:45, 10.78it/s, est. speed input: 12348.27 toks/s, output: 12.06 toks/s]
Processed prompts:  53%|█████▎    | 546/1024 [00:45<00:44, 10.77it/s, est. speed input: 12326.18 toks/s, output: 12.04 toks/s]
Processed prompts:  54%|█████▍    | 554/1024 [00:46<00:43, 10.76it/s, est. speed input: 12304.46 toks/s, output: 12.02 toks/s]
Processed prompts:  55%|█████▍    | 562/1024 [00:46<00:43, 10.71it/s, est. speed input: 12280.92 toks/s, output: 11.99 toks/s]
Processed prompts:  56%|█████▌    | 570/1024 [00:47<00:42, 10.71it/s, est. speed input: 12260.66 toks/s, output: 11.97 toks/s]
Processed prompts:  56%|█████▋    | 578/1024 [00:48<00:41, 10.72it/s, est. speed input: 12241.10 toks/s, output: 11.95 toks/s]
Processed prompts:  57%|█████▋    | 586/1024 [00:49<00:40, 10.72it/s, est. speed input: 12222.14 toks/s, output: 11.94 toks/s]
Processed prompts:  58%|█████▊    | 594/1024 [00:49<00:40, 10.72it/s, est. speed input: 12203.60 toks/s, output: 11.92 toks/s]
Processed prompts:  59%|█████▉    | 602/1024 [00:50<00:39, 10.73it/s, est. speed input: 12185.66 toks/s, output: 11.90 toks/s]
Processed prompts:  60%|█████▉    | 610/1024 [00:51<00:38, 10.73it/s, est. speed input: 12168.26 toks/s, output: 11.88 toks/s]
Processed prompts:  60%|██████    | 618/1024 [00:52<00:37, 10.69it/s, est. speed input: 12149.04 toks/s, output: 11.86 toks/s]
Processed prompts:  61%|██████    | 626/1024 [00:52<00:37, 10.70it/s, est. speed input: 12132.51 toks/s, output: 11.85 toks/s]
Processed prompts:  62%|██████▏   | 634/1024 [00:53<00:36, 10.71it/s, est. speed input: 12116.78 toks/s, output: 11.83 toks/s]
Processed prompts:  63%|██████▎   | 642/1024 [00:54<00:35, 10.72it/s, est. speed input: 12101.24 toks/s, output: 11.82 toks/s]
Processed prompts:  63%|██████▎   | 650/1024 [00:55<00:34, 10.72it/s, est. speed input: 12085.94 toks/s, output: 11.80 toks/s]
Processed prompts:  64%|██████▍   | 658/1024 [00:55<00:34, 10.71it/s, est. speed input: 12070.85 toks/s, output: 11.79 toks/s]
Processed prompts:  65%|██████▌   | 666/1024 [00:56<00:33, 10.71it/s, est. speed input: 12056.16 toks/s, output: 11.77 toks/s]
Processed prompts:  66%|██████▌   | 674/1024 [00:57<00:33, 10.54it/s, est. speed input: 12033.74 toks/s, output: 11.75 toks/s]
Processed prompts:  67%|██████▋   | 682/1024 [00:58<00:32, 10.59it/s, est. speed input: 12019.87 toks/s, output: 11.74 toks/s]
Processed prompts:  67%|██████▋   | 690/1024 [00:58<00:31, 10.63it/s, est. speed input: 12006.75 toks/s, output: 11.73 toks/s]
Processed prompts:  68%|██████▊   | 698/1024 [00:59<00:30, 10.66it/s, est. speed input: 11993.91 toks/s, output: 11.71 toks/s]
Processed prompts:  69%|██████▉   | 706/1024 [01:00<00:29, 10.67it/s, est. speed input: 11981.15 toks/s, output: 11.70 toks/s]
Processed prompts:  70%|██████▉   | 714/1024 [01:01<00:29, 10.69it/s, est. speed input: 11968.82 toks/s, output: 11.69 toks/s]
Processed prompts:  71%|███████   | 722/1024 [01:01<00:28, 10.70it/s, est. speed input: 11956.92 toks/s, output: 11.68 toks/s]
Processed prompts:  71%|███████▏  | 730/1024 [01:02<00:27, 10.66it/s, est. speed input: 11943.26 toks/s, output: 11.66 toks/s]
Processed prompts:  72%|███████▏  | 738/1024 [01:03<00:26, 10.68it/s, est. speed input: 11931.93 toks/s, output: 11.65 toks/s]
Processed prompts:  73%|███████▎  | 746/1024 [01:04<00:25, 10.69it/s, est. speed input: 11920.94 toks/s, output: 11.64 toks/s]
Processed prompts:  74%|███████▎  | 754/1024 [01:04<00:25, 10.70it/s, est. speed input: 11910.09 toks/s, output: 11.63 toks/s]
Processed prompts:  74%|███████▍  | 762/1024 [01:05<00:24, 10.71it/s, est. speed input: 11899.39 toks/s, output: 11.62 toks/s]
Processed prompts:  77%|███████▋  | 786/1024 [01:06<00:14, 16.76it/s, est. speed input: 12125.95 toks/s, output: 11.84 toks/s]
Processed prompts:  78%|███████▊  | 794/1024 [01:07<00:15, 14.98it/s, est. speed input: 12113.28 toks/s, output: 11.83 toks/s]
Processed prompts:  78%|███████▊  | 802/1024 [01:07<00:16, 13.72it/s, est. speed input: 12100.99 toks/s, output: 11.82 toks/s]
Processed prompts:  79%|███████▉  | 810/1024 [01:08<00:16, 12.83it/s, est. speed input: 12088.89 toks/s, output: 11.81 toks/s]
Processed prompts:  80%|███████▉  | 818/1024 [01:09<00:16, 12.21it/s, est. speed input: 12077.02 toks/s, output: 11.79 toks/s]
Processed prompts:  81%|████████  | 826/1024 [01:10<00:16, 11.77it/s, est. speed input: 12065.46 toks/s, output: 11.78 toks/s]
Processed prompts:  81%|████████▏ | 834/1024 [01:10<00:16, 11.45it/s, est. speed input: 12054.07 toks/s, output: 11.77 toks/s]
Processed prompts:  82%|████████▏ | 842/1024 [01:11<00:16, 11.19it/s, est. speed input: 12041.09 toks/s, output: 11.76 toks/s]
Processed prompts:  83%|████████▎ | 850/1024 [01:12<00:15, 11.05it/s, est. speed input: 12030.14 toks/s, output: 11.75 toks/s]
Processed prompts:  84%|████████▍ | 858/1024 [01:13<00:15, 10.95it/s, est. speed input: 12019.45 toks/s, output: 11.74 toks/s]
Processed prompts:  85%|████████▍ | 866/1024 [01:13<00:14, 10.89it/s, est. speed input: 12009.06 toks/s, output: 11.73 toks/s]
Processed prompts:  85%|████████▌ | 874/1024 [01:14<00:13, 10.83it/s, est. speed input: 11998.52 toks/s, output: 11.72 toks/s]
Processed prompts:  86%|████████▌ | 882/1024 [01:15<00:13, 10.80it/s, est. speed input: 11988.33 toks/s, output: 11.71 toks/s]
Processed prompts:  87%|████████▋ | 890/1024 [01:16<00:12, 10.77it/s, est. speed input: 11978.31 toks/s, output: 11.70 toks/s]
Processed prompts:  88%|████████▊ | 898/1024 [01:16<00:11, 10.70it/s, est. speed input: 11966.74 toks/s, output: 11.69 toks/s]
Processed prompts:  88%|████████▊ | 906/1024 [01:17<00:11, 10.70it/s, est. speed input: 11956.87 toks/s, output: 11.68 toks/s]
Processed prompts:  89%|████████▉ | 914/1024 [01:18<00:10, 10.70it/s, est. speed input: 11947.51 toks/s, output: 11.67 toks/s]
Processed prompts:  90%|█████████ | 922/1024 [01:19<00:09, 10.70it/s, est. speed input: 11938.20 toks/s, output: 11.66 toks/s]
Processed prompts:  91%|█████████ | 930/1024 [01:19<00:08, 10.71it/s, est. speed input: 11929.12 toks/s, output: 11.65 toks/s]
Processed prompts:  92%|█████████▏| 938/1024 [01:20<00:08, 10.70it/s, est. speed input: 11920.10 toks/s, output: 11.64 toks/s]
Processed prompts:  92%|█████████▏| 946/1024 [01:21<00:07, 10.71it/s, est. speed input: 11911.31 toks/s, output: 11.63 toks/s]
Processed prompts:  93%|█████████▎| 954/1024 [01:22<00:06, 10.66it/s, est. speed input: 11901.13 toks/s, output: 11.62 toks/s]
Processed prompts:  94%|█████████▍| 962/1024 [01:22<00:05, 10.67it/s, est. speed input: 11892.44 toks/s, output: 11.61 toks/s]
Processed prompts:  95%|█████████▍| 970/1024 [01:23<00:05, 10.68it/s, est. speed input: 11884.05 toks/s, output: 11.61 toks/s]
Processed prompts:  96%|█████████▌| 978/1024 [01:24<00:04, 10.68it/s, est. speed input: 11875.84 toks/s, output: 11.60 toks/s]
Processed prompts:  96%|█████████▋| 986/1024 [01:25<00:03, 10.69it/s, est. speed input: 11867.66 toks/s, output: 11.59 toks/s]
Processed prompts:  97%|█████████▋| 994/1024 [01:25<00:02, 10.68it/s, est. speed input: 11859.54 toks/s, output: 11.58 toks/s]
Processed prompts:  98%|█████████▊| 1002/1024 [01:26<00:02, 10.69it/s, est. speed input: 11851.65 toks/s, output: 11.57 toks/s]
Processed prompts:  99%|█████████▊| 1010/1024 [01:27<00:01, 10.65it/s, est. speed input: 11842.57 toks/s, output: 11.57 toks/s]
Processed prompts:  99%|█████████▉| 1018/1024 [01:27<00:00, 11.04it/s, est. speed input: 11846.57 toks/s, output: 11.57 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [01:27<00:00, 11.04it/s, est. speed input: 11916.35 toks/s, output: 11.64 toks/s]
Processed prompts: 100%|██████████| 1024/1024 [01:27<00:00, 11.64it/s, est. speed input: 11916.35 toks/s, output: 11.64 toks/s]
[rank0]:[W126 07:49:05.368082117 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16384 ==========
Time: 2026-01-26 07:49:08
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=2048, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 2048 --max-num-seqs 16 --max-model-len 1025 --max-num-batched-tokens 16384 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M16384.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:49:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:49:31 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=366367) WARNING 01-26 07:49:39 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=366367) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=366367) WARNING 01-26 07:49:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.68 requests/s, 10948.65 total tokens/s, 10.68 output tokens/s
Total num prompt tokens:  2097152
Total num output tokens:  2048

STDERR:
[2026-01-26 07:49:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:49:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:49:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:49:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:49:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:49:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:49:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:49:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:49:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:49:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:49:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:49:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:49:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:49:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:49:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:49:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:49:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.28s/it]
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.30s/it]
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:00,  1.12it/s]
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.04s/it]
(EngineCore_DP0 pid=366367) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.07s/it]
(EngineCore_DP0 pid=366367) 
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=366367) [2026-01-26 07:49:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=366367) [rank0]:W0126 07:50:12.900000 366367 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=366367) [rank0]:W0126 07:50:12.979000 366367 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=366367) [rank0]:W0126 07:50:14.157000 366367 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=366367) [rank0]:W0126 07:50:14.275000 366367 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=366367) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:01,  4.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:01,  4.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  4.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  5.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  5.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:01<00:00,  5.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  3.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  3.97it/s]
(EngineCore_DP0 pid=366367) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:01,  3.59it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  3.53it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  4.15it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  4.53it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  4.75it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:01<00:00,  4.39it/s]

Adding requests:   0%|          | 0/2048 [00:00<?, ?it/s]
Adding requests:   1%|          | 21/2048 [00:00<00:09, 207.10it/s]
Adding requests:   2%|▏         | 47/2048 [00:00<00:08, 237.08it/s]
Adding requests:   4%|▎         | 73/2048 [00:00<00:08, 242.58it/s]
Adding requests:   5%|▍         | 98/2048 [00:00<00:08, 242.88it/s]
Adding requests:   6%|▌         | 124/2048 [00:00<00:07, 247.01it/s]
Adding requests:   7%|▋         | 150/2048 [00:00<00:07, 250.09it/s]
Adding requests:   9%|▊         | 176/2048 [00:00<00:07, 250.49it/s]
Adding requests:  10%|▉         | 203/2048 [00:00<00:07, 253.93it/s]
Adding requests:  11%|█▏        | 231/2048 [00:00<00:07, 259.12it/s]
Adding requests:  13%|█▎        | 257/2048 [00:01<00:07, 255.68it/s]
Adding requests:  14%|█▍        | 284/2048 [00:01<00:06, 257.03it/s]
Adding requests:  15%|█▌        | 312/2048 [00:01<00:06, 262.04it/s]
Adding requests:  17%|█▋        | 340/2048 [00:01<00:06, 266.20it/s]
Adding requests:  18%|█▊        | 367/2048 [00:01<00:06, 266.95it/s]
Adding requests:  19%|█▉        | 395/2048 [00:01<00:06, 268.13it/s]
Adding requests:  21%|██        | 424/2048 [00:01<00:05, 271.45it/s]
Adding requests:  22%|██▏       | 452/2048 [00:01<00:05, 267.08it/s]
Adding requests:  23%|██▎       | 481/2048 [00:01<00:05, 273.25it/s]
Adding requests:  25%|██▍       | 510/2048 [00:01<00:05, 276.16it/s]
Adding requests:  26%|██▋       | 538/2048 [00:02<00:05, 276.57it/s]
Adding requests:  28%|██▊       | 566/2048 [00:02<00:05, 275.34it/s]
Adding requests:  29%|██▉       | 594/2048 [00:02<00:05, 261.40it/s]
Adding requests:  30%|███       | 621/2048 [00:02<00:05, 260.63it/s]
Adding requests:  32%|███▏      | 648/2048 [00:02<00:05, 257.08it/s]
Adding requests:  33%|███▎      | 674/2048 [00:02<00:05, 254.99it/s]
Adding requests:  34%|███▍      | 702/2048 [00:02<00:05, 261.14it/s]
Adding requests:  36%|███▌      | 729/2048 [00:02<00:05, 256.23it/s]
Adding requests:  37%|███▋      | 755/2048 [00:02<00:05, 256.56it/s]
Adding requests:  38%|███▊      | 782/2048 [00:03<00:04, 257.67it/s]
Adding requests:  39%|███▉      | 808/2048 [00:03<00:04, 256.39it/s]
Adding requests:  41%|████      | 835/2048 [00:03<00:04, 259.44it/s]
Adding requests:  42%|████▏     | 861/2048 [00:03<00:04, 252.35it/s]
Adding requests:  43%|████▎     | 888/2048 [00:03<00:04, 256.87it/s]
Adding requests:  45%|████▍     | 914/2048 [00:03<00:04, 254.00it/s]
Adding requests:  46%|████▌     | 940/2048 [00:03<00:04, 253.53it/s]
Adding requests:  47%|████▋     | 966/2048 [00:03<00:04, 252.08it/s]
Adding requests:  48%|████▊     | 992/2048 [00:03<00:04, 248.91it/s]
Adding requests:  50%|████▉     | 1017/2048 [00:03<00:04, 248.26it/s]
Adding requests:  51%|█████     | 1044/2048 [00:04<00:03, 252.57it/s]
Adding requests:  52%|█████▏    | 1070/2048 [00:04<00:03, 250.96it/s]
Adding requests:  54%|█████▎    | 1096/2048 [00:04<00:03, 248.33it/s]
Adding requests:  55%|█████▍    | 1124/2048 [00:04<00:03, 254.58it/s]
Adding requests:  56%|█████▌    | 1151/2048 [00:04<00:03, 257.40it/s]
Adding requests:  58%|█████▊    | 1178/2048 [00:04<00:03, 258.60it/s]
Adding requests:  59%|█████▉    | 1205/2048 [00:04<00:03, 261.02it/s]
Adding requests:  60%|██████    | 1233/2048 [00:04<00:03, 265.06it/s]
Adding requests:  62%|██████▏   | 1260/2048 [00:04<00:03, 261.06it/s]
Adding requests:  63%|██████▎   | 1287/2048 [00:04<00:02, 259.28it/s]
Adding requests:  64%|██████▍   | 1314/2048 [00:05<00:02, 261.30it/s]
Adding requests:  65%|██████▌   | 1341/2048 [00:05<00:02, 258.67it/s]
Adding requests:  67%|██████▋   | 1369/2048 [00:05<00:02, 263.35it/s]
Adding requests:  68%|██████▊   | 1396/2048 [00:05<00:02, 261.97it/s]
Adding requests:  69%|██████▉   | 1423/2048 [00:05<00:02, 261.97it/s]
Adding requests:  71%|███████   | 1450/2048 [00:05<00:02, 262.98it/s]
Adding requests:  72%|███████▏  | 1477/2048 [00:05<00:02, 264.88it/s]
Adding requests:  73%|███████▎  | 1505/2048 [00:05<00:02, 266.62it/s]
Adding requests:  75%|███████▍  | 1532/2048 [00:05<00:01, 262.98it/s]
Adding requests:  76%|███████▌  | 1559/2048 [00:06<00:01, 256.63it/s]
Adding requests:  77%|███████▋  | 1585/2048 [00:06<00:01, 253.61it/s]
Adding requests:  79%|███████▊  | 1611/2048 [00:06<00:01, 248.96it/s]
Adding requests:  80%|███████▉  | 1636/2048 [00:06<00:01, 241.29it/s]
Adding requests:  81%|████████  | 1661/2048 [00:06<00:01, 232.85it/s]
Adding requests:  82%|████████▏ | 1688/2048 [00:06<00:01, 240.93it/s]
Adding requests:  84%|████████▎ | 1715/2048 [00:06<00:01, 247.77it/s]
Adding requests:  85%|████████▍ | 1740/2048 [00:06<00:01, 246.34it/s]
Adding requests:  86%|████████▋ | 1769/2048 [00:06<00:01, 256.69it/s]
Adding requests:  88%|████████▊ | 1795/2048 [00:06<00:01, 252.21it/s]
Adding requests:  89%|████████▉ | 1821/2048 [00:07<00:00, 251.08it/s]
Adding requests:  90%|█████████ | 1847/2048 [00:07<00:00, 243.76it/s]
Adding requests:  91%|█████████▏| 1872/2048 [00:07<00:00, 222.60it/s]
Adding requests:  93%|█████████▎| 1896/2048 [00:07<00:00, 225.12it/s]
Adding requests:  94%|█████████▍| 1924/2048 [00:07<00:00, 239.41it/s]
Adding requests:  95%|█████████▌| 1952/2048 [00:07<00:00, 250.73it/s]
Adding requests:  97%|█████████▋| 1979/2048 [00:07<00:00, 254.65it/s]
Adding requests:  98%|█████████▊| 2005/2048 [00:07<00:00, 253.89it/s]
Adding requests:  99%|█████████▉| 2031/2048 [00:07<00:00, 250.90it/s]
Adding requests: 100%|██████████| 2048/2048 [00:08<00:00, 254.80it/s]

Processed prompts:   0%|          | 0/2048 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   4%|▍         | 82/2048 [00:00<00:19, 103.41it/s, est. speed input: 105900.81 toks/s, output: 103.42 toks/s]
Processed prompts:   5%|▍         | 93/2048 [00:01<00:36, 52.96it/s, est. speed input: 62266.05 toks/s, output: 60.81 toks/s]   
Processed prompts:   5%|▍         | 99/2048 [00:02<00:59, 32.83it/s, est. speed input: 44729.05 toks/s, output: 43.68 toks/s]
Processed prompts:   5%|▌         | 106/2048 [00:03<01:21, 23.70it/s, est. speed input: 36124.51 toks/s, output: 35.28 toks/s]
Processed prompts:   6%|▌         | 114/2048 [00:03<01:41, 19.09it/s, est. speed input: 31191.79 toks/s, output: 30.46 toks/s]
Processed prompts:   6%|▌         | 122/2048 [00:04<01:58, 16.30it/s, est. speed input: 27883.51 toks/s, output: 27.23 toks/s]
Processed prompts:   6%|▋         | 130/2048 [00:05<02:12, 14.51it/s, est. speed input: 25507.42 toks/s, output: 24.91 toks/s]
Processed prompts:   7%|▋         | 138/2048 [00:05<02:23, 13.34it/s, est. speed input: 23719.96 toks/s, output: 23.16 toks/s]
Processed prompts:   7%|▋         | 146/2048 [00:06<02:31, 12.56it/s, est. speed input: 22326.21 toks/s, output: 21.80 toks/s]
Processed prompts:   8%|▊         | 154/2048 [00:07<02:37, 12.02it/s, est. speed input: 21208.22 toks/s, output: 20.71 toks/s]
Processed prompts:   8%|▊         | 162/2048 [00:08<02:41, 11.65it/s, est. speed input: 20292.27 toks/s, output: 19.82 toks/s]
Processed prompts:   8%|▊         | 170/2048 [00:08<02:44, 11.40it/s, est. speed input: 19527.43 toks/s, output: 19.07 toks/s]
Processed prompts:   9%|▊         | 178/2048 [00:09<02:46, 11.22it/s, est. speed input: 18879.22 toks/s, output: 18.44 toks/s]
Processed prompts:   9%|▉         | 186/2048 [00:10<02:47, 11.10it/s, est. speed input: 18323.42 toks/s, output: 17.89 toks/s]
Processed prompts:   9%|▉         | 194/2048 [00:11<02:48, 11.01it/s, est. speed input: 17840.66 toks/s, output: 17.42 toks/s]
Processed prompts:  10%|▉         | 202/2048 [00:11<02:48, 10.94it/s, est. speed input: 17416.94 toks/s, output: 17.01 toks/s]
Processed prompts:  10%|█         | 210/2048 [00:12<02:48, 10.89it/s, est. speed input: 17041.43 toks/s, output: 16.64 toks/s]
Processed prompts:  11%|█         | 218/2048 [00:13<02:48, 10.86it/s, est. speed input: 16707.95 toks/s, output: 16.32 toks/s]
Processed prompts:  11%|█         | 226/2048 [00:14<02:48, 10.83it/s, est. speed input: 16409.23 toks/s, output: 16.02 toks/s]
Processed prompts:  11%|█▏        | 234/2048 [00:14<02:47, 10.81it/s, est. speed input: 16140.03 toks/s, output: 15.76 toks/s]
Processed prompts:  12%|█▏        | 242/2048 [00:15<02:47, 10.80it/s, est. speed input: 15896.35 toks/s, output: 15.52 toks/s]
Processed prompts:  13%|█▎        | 266/2048 [00:16<01:45, 16.91it/s, est. speed input: 16626.46 toks/s, output: 16.24 toks/s]
Processed prompts:  13%|█▎        | 274/2048 [00:17<01:57, 15.09it/s, est. speed input: 16382.94 toks/s, output: 16.00 toks/s]
Processed prompts:  14%|█▍        | 282/2048 [00:17<02:07, 13.80it/s, est. speed input: 16159.42 toks/s, output: 15.78 toks/s]
Processed prompts:  14%|█▍        | 290/2048 [00:18<02:16, 12.89it/s, est. speed input: 15953.67 toks/s, output: 15.58 toks/s]
Processed prompts:  15%|█▍        | 298/2048 [00:19<02:22, 12.25it/s, est. speed input: 15763.99 toks/s, output: 15.39 toks/s]
Processed prompts:  15%|█▍        | 306/2048 [00:20<02:27, 11.80it/s, est. speed input: 15587.16 toks/s, output: 15.22 toks/s]
Processed prompts:  15%|█▌        | 314/2048 [00:20<02:31, 11.48it/s, est. speed input: 15423.17 toks/s, output: 15.06 toks/s]
Processed prompts:  16%|█▌        | 322/2048 [00:21<02:33, 11.23it/s, est. speed input: 15265.60 toks/s, output: 14.91 toks/s]
Processed prompts:  16%|█▌        | 330/2048 [00:22<02:35, 11.08it/s, est. speed input: 15122.96 toks/s, output: 14.77 toks/s]
Processed prompts:  17%|█▋        | 338/2048 [00:23<02:35, 10.98it/s, est. speed input: 14989.60 toks/s, output: 14.64 toks/s]
Processed prompts:  17%|█▋        | 346/2048 [00:23<02:36, 10.90it/s, est. speed input: 14864.67 toks/s, output: 14.52 toks/s]
Processed prompts:  17%|█▋        | 354/2048 [00:24<02:36, 10.86it/s, est. speed input: 14747.56 toks/s, output: 14.40 toks/s]
Processed prompts:  18%|█▊        | 362/2048 [00:25<02:35, 10.82it/s, est. speed input: 14636.97 toks/s, output: 14.29 toks/s]
Processed prompts:  18%|█▊        | 370/2048 [00:26<02:35, 10.79it/s, est. speed input: 14532.90 toks/s, output: 14.19 toks/s]
Processed prompts:  18%|█▊        | 378/2048 [00:26<02:34, 10.78it/s, est. speed input: 14434.69 toks/s, output: 14.10 toks/s]
Processed prompts:  19%|█▉        | 386/2048 [00:27<02:34, 10.76it/s, est. speed input: 14341.58 toks/s, output: 14.01 toks/s]
Processed prompts:  19%|█▉        | 394/2048 [00:28<02:33, 10.76it/s, est. speed input: 14254.00 toks/s, output: 13.92 toks/s]
Processed prompts:  20%|█▉        | 402/2048 [00:29<02:32, 10.76it/s, est. speed input: 14171.11 toks/s, output: 13.84 toks/s]
Processed prompts:  20%|██        | 410/2048 [00:29<02:32, 10.76it/s, est. speed input: 14092.02 toks/s, output: 13.76 toks/s]
Processed prompts:  20%|██        | 418/2048 [00:30<02:31, 10.75it/s, est. speed input: 14016.38 toks/s, output: 13.69 toks/s]
Processed prompts:  21%|██        | 426/2048 [00:31<02:30, 10.75it/s, est. speed input: 13944.62 toks/s, output: 13.62 toks/s]
Processed prompts:  21%|██        | 434/2048 [00:32<02:30, 10.75it/s, est. speed input: 13876.41 toks/s, output: 13.55 toks/s]
Processed prompts:  22%|██▏       | 442/2048 [00:32<02:29, 10.74it/s, est. speed input: 13810.83 toks/s, output: 13.49 toks/s]
Processed prompts:  22%|██▏       | 450/2048 [00:33<02:28, 10.73it/s, est. speed input: 13747.45 toks/s, output: 13.43 toks/s]
Processed prompts:  22%|██▏       | 458/2048 [00:34<02:28, 10.73it/s, est. speed input: 13686.84 toks/s, output: 13.37 toks/s]
Processed prompts:  23%|██▎       | 466/2048 [00:35<02:27, 10.72it/s, est. speed input: 13628.82 toks/s, output: 13.31 toks/s]
Processed prompts:  23%|██▎       | 474/2048 [00:35<02:26, 10.72it/s, est. speed input: 13573.52 toks/s, output: 13.26 toks/s]
Processed prompts:  24%|██▎       | 482/2048 [00:36<02:26, 10.71it/s, est. speed input: 13519.82 toks/s, output: 13.20 toks/s]
Processed prompts:  24%|██▍       | 490/2048 [00:37<02:25, 10.71it/s, est. speed input: 13468.56 toks/s, output: 13.15 toks/s]
Processed prompts:  24%|██▍       | 498/2048 [00:38<02:24, 10.71it/s, est. speed input: 13419.14 toks/s, output: 13.10 toks/s]
Processed prompts:  25%|██▍       | 506/2048 [00:38<02:24, 10.71it/s, est. speed input: 13371.59 toks/s, output: 13.06 toks/s]
Processed prompts:  25%|██▌       | 514/2048 [00:39<02:23, 10.71it/s, est. speed input: 13326.08 toks/s, output: 13.01 toks/s]
Processed prompts:  25%|██▌       | 522/2048 [00:40<02:22, 10.71it/s, est. speed input: 13282.20 toks/s, output: 12.97 toks/s]
Processed prompts:  26%|██▌       | 530/2048 [00:40<02:21, 10.71it/s, est. speed input: 13239.91 toks/s, output: 12.93 toks/s]
Processed prompts:  26%|██▋       | 538/2048 [00:41<02:21, 10.70it/s, est. speed input: 13198.99 toks/s, output: 12.89 toks/s]
Processed prompts:  27%|██▋       | 546/2048 [00:42<02:20, 10.71it/s, est. speed input: 13159.83 toks/s, output: 12.85 toks/s]
Processed prompts:  27%|██▋       | 554/2048 [00:43<02:19, 10.71it/s, est. speed input: 13121.79 toks/s, output: 12.81 toks/s]
Processed prompts:  27%|██▋       | 562/2048 [00:43<02:18, 10.70it/s, est. speed input: 13085.00 toks/s, output: 12.78 toks/s]
Processed prompts:  28%|██▊       | 570/2048 [00:44<02:18, 10.71it/s, est. speed input: 13049.61 toks/s, output: 12.74 toks/s]
Processed prompts:  28%|██▊       | 578/2048 [00:45<02:17, 10.71it/s, est. speed input: 13015.28 toks/s, output: 12.71 toks/s]
Processed prompts:  29%|██▊       | 586/2048 [00:46<02:16, 10.71it/s, est. speed input: 12982.30 toks/s, output: 12.68 toks/s]
Processed prompts:  30%|██▉       | 610/2048 [00:47<01:25, 16.91it/s, est. speed input: 13289.68 toks/s, output: 12.98 toks/s]
Processed prompts:  30%|███       | 618/2048 [00:47<01:34, 15.07it/s, est. speed input: 13253.48 toks/s, output: 12.94 toks/s]
Processed prompts:  31%|███       | 626/2048 [00:48<01:43, 13.77it/s, est. speed input: 13218.11 toks/s, output: 12.91 toks/s]
Processed prompts:  31%|███       | 634/2048 [00:49<01:50, 12.85it/s, est. speed input: 13183.68 toks/s, output: 12.87 toks/s]
Processed prompts:  31%|███▏      | 642/2048 [00:49<01:55, 12.21it/s, est. speed input: 13150.48 toks/s, output: 12.84 toks/s]
Processed prompts:  32%|███▏      | 650/2048 [00:50<01:58, 11.76it/s, est. speed input: 13118.16 toks/s, output: 12.81 toks/s]
Processed prompts:  32%|███▏      | 658/2048 [00:51<02:01, 11.44it/s, est. speed input: 13086.83 toks/s, output: 12.78 toks/s]
Processed prompts:  33%|███▎      | 666/2048 [00:52<02:03, 11.22it/s, est. speed input: 13056.34 toks/s, output: 12.75 toks/s]
Processed prompts:  33%|███▎      | 674/2048 [00:52<02:04, 11.07it/s, est. speed input: 13026.95 toks/s, output: 12.72 toks/s]
Processed prompts:  33%|███▎      | 682/2048 [00:53<02:04, 10.96it/s, est. speed input: 12998.33 toks/s, output: 12.69 toks/s]
Processed prompts:  34%|███▎      | 690/2048 [00:54<02:04, 10.88it/s, est. speed input: 12970.21 toks/s, output: 12.67 toks/s]
Processed prompts:  34%|███▍      | 698/2048 [00:55<02:04, 10.83it/s, est. speed input: 12943.02 toks/s, output: 12.64 toks/s]
Processed prompts:  34%|███▍      | 706/2048 [00:55<02:04, 10.79it/s, est. speed input: 12916.42 toks/s, output: 12.61 toks/s]
Processed prompts:  35%|███▍      | 714/2048 [00:56<02:03, 10.76it/s, est. speed input: 12890.48 toks/s, output: 12.59 toks/s]
Processed prompts:  35%|███▌      | 722/2048 [00:57<02:03, 10.74it/s, est. speed input: 12865.34 toks/s, output: 12.56 toks/s]
Processed prompts:  36%|███▌      | 730/2048 [00:58<02:02, 10.73it/s, est. speed input: 12840.96 toks/s, output: 12.54 toks/s]
Processed prompts:  36%|███▌      | 738/2048 [00:58<02:02, 10.72it/s, est. speed input: 12817.06 toks/s, output: 12.52 toks/s]
Processed prompts:  36%|███▋      | 746/2048 [00:59<02:01, 10.72it/s, est. speed input: 12793.76 toks/s, output: 12.49 toks/s]
Processed prompts:  37%|███▋      | 754/2048 [01:00<02:00, 10.71it/s, est. speed input: 12771.02 toks/s, output: 12.47 toks/s]
Processed prompts:  37%|███▋      | 762/2048 [01:01<02:00, 10.71it/s, est. speed input: 12748.85 toks/s, output: 12.45 toks/s]
Processed prompts:  38%|███▊      | 770/2048 [01:01<01:59, 10.71it/s, est. speed input: 12727.44 toks/s, output: 12.43 toks/s]
Processed prompts:  38%|███▊      | 778/2048 [01:02<01:58, 10.70it/s, est. speed input: 12706.17 toks/s, output: 12.41 toks/s]
Processed prompts:  38%|███▊      | 786/2048 [01:03<01:57, 10.70it/s, est. speed input: 12685.58 toks/s, output: 12.39 toks/s]
Processed prompts:  39%|███▉      | 794/2048 [01:04<01:57, 10.71it/s, est. speed input: 12665.59 toks/s, output: 12.37 toks/s]
Processed prompts:  39%|███▉      | 802/2048 [01:04<01:56, 10.71it/s, est. speed input: 12645.98 toks/s, output: 12.35 toks/s]
Processed prompts:  40%|███▉      | 810/2048 [01:05<01:55, 10.70it/s, est. speed input: 12626.81 toks/s, output: 12.33 toks/s]
Processed prompts:  40%|███▉      | 818/2048 [01:06<01:54, 10.71it/s, est. speed input: 12608.19 toks/s, output: 12.31 toks/s]
Processed prompts:  40%|████      | 826/2048 [01:07<01:54, 10.71it/s, est. speed input: 12589.86 toks/s, output: 12.29 toks/s]
Processed prompts:  41%|████      | 834/2048 [01:07<01:53, 10.70it/s, est. speed input: 12571.91 toks/s, output: 12.28 toks/s]
Processed prompts:  41%|████      | 842/2048 [01:08<01:52, 10.70it/s, est. speed input: 12554.30 toks/s, output: 12.26 toks/s]
Processed prompts:  42%|████▏     | 850/2048 [01:09<01:51, 10.70it/s, est. speed input: 12537.16 toks/s, output: 12.24 toks/s]
Processed prompts:  42%|████▏     | 858/2048 [01:10<01:51, 10.70it/s, est. speed input: 12520.33 toks/s, output: 12.23 toks/s]
Processed prompts:  42%|████▏     | 866/2048 [01:10<01:50, 10.70it/s, est. speed input: 12503.82 toks/s, output: 12.21 toks/s]
Processed prompts:  43%|████▎     | 874/2048 [01:11<01:49, 10.70it/s, est. speed input: 12487.72 toks/s, output: 12.20 toks/s]
Processed prompts:  43%|████▎     | 882/2048 [01:12<01:48, 10.70it/s, est. speed input: 12471.89 toks/s, output: 12.18 toks/s]
Processed prompts:  43%|████▎     | 890/2048 [01:13<01:48, 10.70it/s, est. speed input: 12456.54 toks/s, output: 12.16 toks/s]
Processed prompts:  44%|████▍     | 898/2048 [01:13<01:47, 10.70it/s, est. speed input: 12441.26 toks/s, output: 12.15 toks/s]
Processed prompts:  44%|████▍     | 906/2048 [01:14<01:46, 10.70it/s, est. speed input: 12426.43 toks/s, output: 12.14 toks/s]
Processed prompts:  45%|████▍     | 914/2048 [01:15<01:45, 10.70it/s, est. speed input: 12411.86 toks/s, output: 12.12 toks/s]
Processed prompts:  45%|████▌     | 922/2048 [01:16<01:45, 10.70it/s, est. speed input: 12397.46 toks/s, output: 12.11 toks/s]
Processed prompts:  45%|████▌     | 930/2048 [01:16<01:44, 10.70it/s, est. speed input: 12383.53 toks/s, output: 12.09 toks/s]
Processed prompts:  46%|████▌     | 938/2048 [01:17<01:43, 10.70it/s, est. speed input: 12369.74 toks/s, output: 12.08 toks/s]
Processed prompts:  47%|████▋     | 962/2048 [01:18<01:04, 16.78it/s, est. speed input: 12557.18 toks/s, output: 12.26 toks/s]
Processed prompts:  47%|████▋     | 970/2048 [01:19<01:11, 14.98it/s, est. speed input: 12542.09 toks/s, output: 12.25 toks/s]
Processed prompts:  48%|████▊     | 978/2048 [01:19<01:18, 13.71it/s, est. speed input: 12527.32 toks/s, output: 12.23 toks/s]
Processed prompts:  48%|████▊     | 986/2048 [01:20<01:22, 12.82it/s, est. speed input: 12512.87 toks/s, output: 12.22 toks/s]
Processed prompts:  49%|████▊     | 994/2048 [01:21<01:26, 12.19it/s, est. speed input: 12498.64 toks/s, output: 12.21 toks/s]
Processed prompts:  49%|████▉     | 1002/2048 [01:22<01:29, 11.75it/s, est. speed input: 12484.71 toks/s, output: 12.19 toks/s]
Processed prompts:  49%|████▉     | 1010/2048 [01:22<01:30, 11.43it/s, est. speed input: 12470.94 toks/s, output: 12.18 toks/s]
Processed prompts:  50%|████▉     | 1018/2048 [01:23<01:31, 11.21it/s, est. speed input: 12457.45 toks/s, output: 12.17 toks/s]
Processed prompts:  50%|█████     | 1026/2048 [01:24<01:32, 11.06it/s, est. speed input: 12444.20 toks/s, output: 12.15 toks/s]
Processed prompts:  50%|█████     | 1034/2048 [01:25<01:32, 10.95it/s, est. speed input: 12431.13 toks/s, output: 12.14 toks/s]
Processed prompts:  51%|█████     | 1042/2048 [01:25<01:32, 10.87it/s, est. speed input: 12418.17 toks/s, output: 12.13 toks/s]
Processed prompts:  51%|█████▏    | 1050/2048 [01:26<01:32, 10.82it/s, est. speed input: 12405.68 toks/s, output: 12.11 toks/s]
Processed prompts:  52%|█████▏    | 1058/2048 [01:27<01:31, 10.79it/s, est. speed input: 12393.24 toks/s, output: 12.10 toks/s]
Processed prompts:  52%|█████▏    | 1066/2048 [01:28<01:31, 10.76it/s, est. speed input: 12380.98 toks/s, output: 12.09 toks/s]
Processed prompts:  52%|█████▏    | 1074/2048 [01:28<01:30, 10.74it/s, est. speed input: 12368.93 toks/s, output: 12.08 toks/s]
Processed prompts:  53%|█████▎    | 1082/2048 [01:29<01:30, 10.72it/s, est. speed input: 12357.06 toks/s, output: 12.07 toks/s]
Processed prompts:  53%|█████▎    | 1090/2048 [01:30<01:29, 10.72it/s, est. speed input: 12345.45 toks/s, output: 12.06 toks/s]
Processed prompts:  54%|█████▎    | 1098/2048 [01:31<01:28, 10.71it/s, est. speed input: 12334.11 toks/s, output: 12.05 toks/s]
Processed prompts:  54%|█████▍    | 1106/2048 [01:31<01:27, 10.71it/s, est. speed input: 12322.86 toks/s, output: 12.03 toks/s]
Processed prompts:  54%|█████▍    | 1114/2048 [01:32<01:27, 10.70it/s, est. speed input: 12311.77 toks/s, output: 12.02 toks/s]
Processed prompts:  55%|█████▍    | 1122/2048 [01:33<01:26, 10.70it/s, est. speed input: 12300.96 toks/s, output: 12.01 toks/s]
Processed prompts:  55%|█████▌    | 1130/2048 [01:34<01:25, 10.70it/s, est. speed input: 12290.37 toks/s, output: 12.00 toks/s]
Processed prompts:  56%|█████▌    | 1138/2048 [01:34<01:25, 10.70it/s, est. speed input: 12279.82 toks/s, output: 11.99 toks/s]
Processed prompts:  56%|█████▌    | 1146/2048 [01:35<01:24, 10.70it/s, est. speed input: 12269.46 toks/s, output: 11.98 toks/s]
Processed prompts:  56%|█████▋    | 1154/2048 [01:36<01:23, 10.70it/s, est. speed input: 12259.30 toks/s, output: 11.97 toks/s]
Processed prompts:  57%|█████▋    | 1162/2048 [01:37<01:22, 10.70it/s, est. speed input: 12249.36 toks/s, output: 11.96 toks/s]
Processed prompts:  57%|█████▋    | 1170/2048 [01:37<01:22, 10.70it/s, est. speed input: 12239.42 toks/s, output: 11.95 toks/s]
Processed prompts:  58%|█████▊    | 1178/2048 [01:38<01:21, 10.70it/s, est. speed input: 12229.61 toks/s, output: 11.94 toks/s]
Processed prompts:  58%|█████▊    | 1186/2048 [01:39<01:20, 10.69it/s, est. speed input: 12219.94 toks/s, output: 11.93 toks/s]
Processed prompts:  58%|█████▊    | 1194/2048 [01:40<01:19, 10.69it/s, est. speed input: 12210.40 toks/s, output: 11.92 toks/s]
Processed prompts:  59%|█████▊    | 1202/2048 [01:40<01:19, 10.70it/s, est. speed input: 12201.17 toks/s, output: 11.92 toks/s]
Processed prompts:  59%|█████▉    | 1210/2048 [01:41<01:18, 10.70it/s, est. speed input: 12192.01 toks/s, output: 11.91 toks/s]
Processed prompts:  59%|█████▉    | 1218/2048 [01:42<01:17, 10.70it/s, est. speed input: 12182.92 toks/s, output: 11.90 toks/s]
Processed prompts:  60%|█████▉    | 1226/2048 [01:43<01:16, 10.69it/s, est. speed input: 12173.95 toks/s, output: 11.89 toks/s]
Processed prompts:  60%|██████    | 1234/2048 [01:43<01:16, 10.69it/s, est. speed input: 12165.10 toks/s, output: 11.88 toks/s]
Processed prompts:  61%|██████    | 1242/2048 [01:44<01:15, 10.69it/s, est. speed input: 12156.37 toks/s, output: 11.87 toks/s]
Processed prompts:  61%|██████    | 1250/2048 [01:45<01:14, 10.69it/s, est. speed input: 12147.84 toks/s, output: 11.86 toks/s]
Processed prompts:  61%|██████▏   | 1258/2048 [01:46<01:13, 10.69it/s, est. speed input: 12139.34 toks/s, output: 11.85 toks/s]
Processed prompts:  62%|██████▏   | 1266/2048 [01:46<01:13, 10.69it/s, est. speed input: 12131.04 toks/s, output: 11.85 toks/s]
Processed prompts:  62%|██████▏   | 1274/2048 [01:47<01:12, 10.69it/s, est. speed input: 12122.85 toks/s, output: 11.84 toks/s]
Processed prompts:  63%|██████▎   | 1282/2048 [01:48<01:11, 10.70it/s, est. speed input: 12114.80 toks/s, output: 11.83 toks/s]
Processed prompts:  64%|██████▍   | 1306/2048 [01:49<00:44, 16.75it/s, est. speed input: 12250.92 toks/s, output: 11.96 toks/s]
Processed prompts:  64%|██████▍   | 1314/2048 [01:49<00:49, 14.96it/s, est. speed input: 12242.05 toks/s, output: 11.96 toks/s]
Processed prompts:  65%|██████▍   | 1322/2048 [01:50<00:53, 13.69it/s, est. speed input: 12233.36 toks/s, output: 11.95 toks/s]
Processed prompts:  65%|██████▍   | 1330/2048 [01:51<00:56, 12.80it/s, est. speed input: 12224.71 toks/s, output: 11.94 toks/s]
Processed prompts:  65%|██████▌   | 1338/2048 [01:52<00:58, 12.18it/s, est. speed input: 12216.34 toks/s, output: 11.93 toks/s]
Processed prompts:  66%|██████▌   | 1346/2048 [01:52<00:59, 11.73it/s, est. speed input: 12207.92 toks/s, output: 11.92 toks/s]
Processed prompts:  66%|██████▌   | 1354/2048 [01:53<01:00, 11.43it/s, est. speed input: 12199.76 toks/s, output: 11.91 toks/s]
Processed prompts:  67%|██████▋   | 1362/2048 [01:54<01:01, 11.20it/s, est. speed input: 12191.55 toks/s, output: 11.91 toks/s]
Processed prompts:  67%|██████▋   | 1370/2048 [01:55<01:01, 11.05it/s, est. speed input: 12183.51 toks/s, output: 11.90 toks/s]
Processed prompts:  67%|██████▋   | 1378/2048 [01:55<01:01, 10.95it/s, est. speed input: 12175.63 toks/s, output: 11.89 toks/s]
Processed prompts:  68%|██████▊   | 1386/2048 [01:56<01:00, 10.87it/s, est. speed input: 12167.79 toks/s, output: 11.88 toks/s]
Processed prompts:  68%|██████▊   | 1394/2048 [01:57<01:00, 10.82it/s, est. speed input: 12159.99 toks/s, output: 11.87 toks/s]
Processed prompts:  68%|██████▊   | 1402/2048 [01:58<00:59, 10.78it/s, est. speed input: 12152.31 toks/s, output: 11.87 toks/s]
Processed prompts:  69%|██████▉   | 1410/2048 [01:58<00:59, 10.75it/s, est. speed input: 12144.74 toks/s, output: 11.86 toks/s]
Processed prompts:  69%|██████▉   | 1418/2048 [01:59<00:58, 10.74it/s, est. speed input: 12137.30 toks/s, output: 11.85 toks/s]
Processed prompts:  70%|██████▉   | 1426/2048 [02:00<00:58, 10.72it/s, est. speed input: 12129.93 toks/s, output: 11.85 toks/s]
Processed prompts:  70%|███████   | 1434/2048 [02:01<00:57, 10.71it/s, est. speed input: 12122.63 toks/s, output: 11.84 toks/s]
Processed prompts:  70%|███████   | 1442/2048 [02:01<00:56, 10.70it/s, est. speed input: 12115.32 toks/s, output: 11.83 toks/s]
Processed prompts:  71%|███████   | 1450/2048 [02:02<00:55, 10.70it/s, est. speed input: 12108.19 toks/s, output: 11.82 toks/s]
Processed prompts:  71%|███████   | 1458/2048 [02:03<00:55, 10.70it/s, est. speed input: 12101.12 toks/s, output: 11.82 toks/s]
Processed prompts:  72%|███████▏  | 1466/2048 [02:04<00:54, 10.69it/s, est. speed input: 12094.11 toks/s, output: 11.81 toks/s]
Processed prompts:  72%|███████▏  | 1474/2048 [02:04<00:53, 10.69it/s, est. speed input: 12087.26 toks/s, output: 11.80 toks/s]
Processed prompts:  72%|███████▏  | 1482/2048 [02:05<00:52, 10.69it/s, est. speed input: 12080.51 toks/s, output: 11.80 toks/s]
Processed prompts:  73%|███████▎  | 1490/2048 [02:06<00:52, 10.69it/s, est. speed input: 12073.82 toks/s, output: 11.79 toks/s]
Processed prompts:  73%|███████▎  | 1498/2048 [02:07<00:51, 10.69it/s, est. speed input: 12067.15 toks/s, output: 11.78 toks/s]
Processed prompts:  74%|███████▎  | 1506/2048 [02:07<00:50, 10.69it/s, est. speed input: 12060.56 toks/s, output: 11.78 toks/s]
Processed prompts:  74%|███████▍  | 1514/2048 [02:08<00:49, 10.69it/s, est. speed input: 12054.05 toks/s, output: 11.77 toks/s]
Processed prompts:  74%|███████▍  | 1522/2048 [02:09<00:49, 10.69it/s, est. speed input: 12047.61 toks/s, output: 11.77 toks/s]
Processed prompts:  75%|███████▍  | 1530/2048 [02:10<00:48, 10.69it/s, est. speed input: 12041.25 toks/s, output: 11.76 toks/s]
Processed prompts:  75%|███████▌  | 1538/2048 [02:10<00:47, 10.69it/s, est. speed input: 12034.94 toks/s, output: 11.75 toks/s]
Processed prompts:  75%|███████▌  | 1546/2048 [02:11<00:46, 10.69it/s, est. speed input: 12028.79 toks/s, output: 11.75 toks/s]
Processed prompts:  76%|███████▌  | 1554/2048 [02:12<00:46, 10.69it/s, est. speed input: 12022.66 toks/s, output: 11.74 toks/s]
Processed prompts:  76%|███████▋  | 1562/2048 [02:13<00:45, 10.69it/s, est. speed input: 12016.60 toks/s, output: 11.73 toks/s]
Processed prompts:  77%|███████▋  | 1570/2048 [02:13<00:44, 10.69it/s, est. speed input: 12010.60 toks/s, output: 11.73 toks/s]
Processed prompts:  77%|███████▋  | 1578/2048 [02:14<00:43, 10.69it/s, est. speed input: 12004.69 toks/s, output: 11.72 toks/s]
Processed prompts:  77%|███████▋  | 1586/2048 [02:15<00:43, 10.69it/s, est. speed input: 11998.82 toks/s, output: 11.72 toks/s]
Processed prompts:  78%|███████▊  | 1594/2048 [02:16<00:42, 10.69it/s, est. speed input: 11993.06 toks/s, output: 11.71 toks/s]
Processed prompts:  78%|███████▊  | 1602/2048 [02:16<00:41, 10.69it/s, est. speed input: 11987.32 toks/s, output: 11.71 toks/s]
Processed prompts:  79%|███████▊  | 1610/2048 [02:17<00:40, 10.69it/s, est. speed input: 11981.61 toks/s, output: 11.70 toks/s]
Processed prompts:  79%|███████▉  | 1618/2048 [02:18<00:40, 10.69it/s, est. speed input: 11975.99 toks/s, output: 11.70 toks/s]
Processed prompts:  79%|███████▉  | 1626/2048 [02:19<00:39, 10.69it/s, est. speed input: 11970.49 toks/s, output: 11.69 toks/s]
Processed prompts:  80%|███████▉  | 1634/2048 [02:19<00:38, 10.69it/s, est. speed input: 11965.00 toks/s, output: 11.68 toks/s]
Processed prompts:  81%|████████  | 1658/2048 [02:20<00:23, 16.79it/s, est. speed input: 12072.14 toks/s, output: 11.79 toks/s]
Processed prompts:  81%|████████▏ | 1666/2048 [02:21<00:25, 14.99it/s, est. speed input: 12066.28 toks/s, output: 11.78 toks/s]
Processed prompts:  82%|████████▏ | 1674/2048 [02:22<00:27, 13.72it/s, est. speed input: 12060.51 toks/s, output: 11.78 toks/s]
Processed prompts:  82%|████████▏ | 1682/2048 [02:22<00:28, 12.82it/s, est. speed input: 12054.81 toks/s, output: 11.77 toks/s]
Processed prompts:  83%|████████▎ | 1690/2048 [02:23<00:29, 12.19it/s, est. speed input: 12049.12 toks/s, output: 11.77 toks/s]
Processed prompts:  83%|████████▎ | 1698/2048 [02:24<00:29, 11.75it/s, est. speed input: 12043.51 toks/s, output: 11.76 toks/s]
Processed prompts:  83%|████████▎ | 1706/2048 [02:25<00:29, 11.44it/s, est. speed input: 12037.99 toks/s, output: 11.76 toks/s]
Processed prompts:  84%|████████▎ | 1714/2048 [02:25<00:29, 11.22it/s, est. speed input: 12032.47 toks/s, output: 11.75 toks/s]
Processed prompts:  84%|████████▍ | 1722/2048 [02:26<00:29, 11.06it/s, est. speed input: 12027.02 toks/s, output: 11.75 toks/s]
Processed prompts:  84%|████████▍ | 1730/2048 [02:27<00:29, 10.96it/s, est. speed input: 12021.66 toks/s, output: 11.74 toks/s]
Processed prompts:  85%|████████▍ | 1738/2048 [02:28<00:28, 10.88it/s, est. speed input: 12016.35 toks/s, output: 11.73 toks/s]
Processed prompts:  85%|████████▌ | 1746/2048 [02:28<00:27, 10.82it/s, est. speed input: 12010.92 toks/s, output: 11.73 toks/s]
Processed prompts:  86%|████████▌ | 1754/2048 [02:29<00:27, 10.78it/s, est. speed input: 12005.56 toks/s, output: 11.72 toks/s]
Processed prompts:  86%|████████▌ | 1762/2048 [02:30<00:26, 10.76it/s, est. speed input: 12000.34 toks/s, output: 11.72 toks/s]
Processed prompts:  86%|████████▋ | 1770/2048 [02:31<00:25, 10.73it/s, est. speed input: 11995.06 toks/s, output: 11.71 toks/s]
Processed prompts:  87%|████████▋ | 1778/2048 [02:31<00:25, 10.72it/s, est. speed input: 11989.90 toks/s, output: 11.71 toks/s]
Processed prompts:  87%|████████▋ | 1786/2048 [02:32<00:24, 10.71it/s, est. speed input: 11984.74 toks/s, output: 11.70 toks/s]
Processed prompts:  88%|████████▊ | 1794/2048 [02:33<00:23, 10.70it/s, est. speed input: 11979.63 toks/s, output: 11.70 toks/s]
Processed prompts:  88%|████████▊ | 1802/2048 [02:34<00:22, 10.70it/s, est. speed input: 11974.62 toks/s, output: 11.69 toks/s]
Processed prompts:  88%|████████▊ | 1810/2048 [02:34<00:22, 10.69it/s, est. speed input: 11969.61 toks/s, output: 11.69 toks/s]
Processed prompts:  89%|████████▉ | 1818/2048 [02:35<00:21, 10.70it/s, est. speed input: 11964.76 toks/s, output: 11.68 toks/s]
Processed prompts:  89%|████████▉ | 1826/2048 [02:36<00:20, 10.69it/s, est. speed input: 11959.78 toks/s, output: 11.68 toks/s]
Processed prompts:  90%|████████▉ | 1834/2048 [02:37<00:20, 10.69it/s, est. speed input: 11954.93 toks/s, output: 11.67 toks/s]
Processed prompts:  90%|████████▉ | 1842/2048 [02:37<00:19, 10.69it/s, est. speed input: 11950.13 toks/s, output: 11.67 toks/s]
Processed prompts:  90%|█████████ | 1850/2048 [02:38<00:18, 10.68it/s, est. speed input: 11945.31 toks/s, output: 11.67 toks/s]
Processed prompts:  91%|█████████ | 1858/2048 [02:39<00:17, 10.68it/s, est. speed input: 11940.59 toks/s, output: 11.66 toks/s]
Processed prompts:  91%|█████████ | 1866/2048 [02:40<00:17, 10.68it/s, est. speed input: 11935.87 toks/s, output: 11.66 toks/s]
Processed prompts:  92%|█████████▏| 1874/2048 [02:40<00:16, 10.68it/s, est. speed input: 11931.21 toks/s, output: 11.65 toks/s]
Processed prompts:  92%|█████████▏| 1882/2048 [02:41<00:15, 10.68it/s, est. speed input: 11926.61 toks/s, output: 11.65 toks/s]
Processed prompts:  92%|█████████▏| 1890/2048 [02:42<00:14, 10.68it/s, est. speed input: 11921.99 toks/s, output: 11.64 toks/s]
Processed prompts:  93%|█████████▎| 1898/2048 [02:43<00:14, 10.68it/s, est. speed input: 11917.48 toks/s, output: 11.64 toks/s]
Processed prompts:  93%|█████████▎| 1906/2048 [02:43<00:13, 10.68it/s, est. speed input: 11912.99 toks/s, output: 11.63 toks/s]
Processed prompts:  93%|█████████▎| 1914/2048 [02:44<00:12, 10.68it/s, est. speed input: 11908.55 toks/s, output: 11.63 toks/s]
Processed prompts:  94%|█████████▍| 1922/2048 [02:45<00:11, 10.68it/s, est. speed input: 11904.19 toks/s, output: 11.63 toks/s]
Processed prompts:  94%|█████████▍| 1930/2048 [02:46<00:11, 10.68it/s, est. speed input: 11899.86 toks/s, output: 11.62 toks/s]
Processed prompts:  95%|█████████▍| 1938/2048 [02:46<00:10, 10.69it/s, est. speed input: 11895.60 toks/s, output: 11.62 toks/s]
Processed prompts:  95%|█████████▌| 1946/2048 [02:47<00:09, 10.69it/s, est. speed input: 11891.36 toks/s, output: 11.61 toks/s]
Processed prompts:  95%|█████████▌| 1954/2048 [02:48<00:08, 10.69it/s, est. speed input: 11887.14 toks/s, output: 11.61 toks/s]
Processed prompts:  96%|█████████▌| 1962/2048 [02:49<00:08, 10.69it/s, est. speed input: 11883.00 toks/s, output: 11.60 toks/s]
Processed prompts:  96%|█████████▌| 1970/2048 [02:49<00:07, 10.69it/s, est. speed input: 11878.83 toks/s, output: 11.60 toks/s]
Processed prompts:  97%|█████████▋| 1978/2048 [02:50<00:06, 10.69it/s, est. speed input: 11874.73 toks/s, output: 11.60 toks/s]
Processed prompts:  98%|█████████▊| 2002/2048 [02:51<00:02, 16.78it/s, est. speed input: 11963.02 toks/s, output: 11.68 toks/s]
Processed prompts:  98%|█████████▊| 2010/2048 [02:52<00:02, 14.98it/s, est. speed input: 11958.54 toks/s, output: 11.68 toks/s]
Processed prompts:  99%|█████████▊| 2018/2048 [02:52<00:02, 13.73it/s, est. speed input: 11954.49 toks/s, output: 11.67 toks/s]
Processed prompts:  99%|█████████▉| 2026/2048 [02:53<00:01, 12.84it/s, est. speed input: 11950.42 toks/s, output: 11.67 toks/s]
Processed prompts:  99%|█████████▉| 2034/2048 [02:54<00:01, 12.22it/s, est. speed input: 11946.40 toks/s, output: 11.67 toks/s]
Processed prompts: 100%|█████████▉| 2042/2048 [02:55<00:00, 12.19it/s, est. speed input: 11948.17 toks/s, output: 11.67 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:55<00:00, 12.19it/s, est. speed input: 11983.26 toks/s, output: 11.70 toks/s]
Processed prompts: 100%|██████████| 2048/2048 [02:55<00:00, 11.70it/s, est. speed input: 11983.26 toks/s, output: 11.70 toks/s]
[rank0]:[W126 07:53:27.292546357 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=32768 ==========
Time: 2026-01-26 07:53:30
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:54:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:54:08 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=370469) WARNING 01-26 07:54:17 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=370469) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=370469) WARNING 01-26 07:54:38 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=370469) ERROR 01-26 07:55:04 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.

STDERR:
[2026-01-26 07:54:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:54:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:54:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:54:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:54:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:54:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:54:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:54:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:54:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:54:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:54:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:54:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:54:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:54:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:54:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:54:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:54:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:17] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:05,  1.79s/it]
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:03<00:03,  1.79s/it]
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:04<00:01,  1.21s/it]
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.43s/it]
(EngineCore_DP0 pid=370469) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:05<00:00,  1.47s/it]
(EngineCore_DP0 pid=370469) 
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:25] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:25] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=370469) [2026-01-26 07:54:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=370469) [rank0]:W0126 07:54:52.100000 370469 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=370469) [rank0]:W0126 07:54:52.181000 370469 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=370469) [rank0]:W0126 07:54:53.482000 370469 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=370469) [rank0]:W0126 07:54:53.606000 370469 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=370469) Process EngineCore_DP0:
(EngineCore_DP0 pid=370469) Traceback (most recent call last):
(EngineCore_DP0 pid=370469)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=370469)     self.run()
(EngineCore_DP0 pid=370469)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=370469)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=370469)     raise e
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=370469)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=370469)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=370469)     super().__init__(
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=370469)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=370469)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=370469)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=370469)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=370469)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=370469)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=370469)     raise ValueError(
(EngineCore_DP0 pid=370469) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 07:55:05.659475315 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-26 07:55:09
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 07:56:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 07:56:18 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=372495) WARNING 01-26 07:56:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=372495) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=372495) WARNING 01-26 07:56:45 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=372495) ERROR 01-26 07:58:11 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.

STDERR:
[2026-01-26 07:56:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:56:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:56:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:56:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:56:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:56:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:56:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:56:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 07:56:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 07:56:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:56:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 07:56:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 07:56:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 07:56:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 07:56:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 07:56:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 07:56:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:6, expand_ratio=1.500
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:27] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=372495) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=372495) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.85it/s]
(EngineCore_DP0 pid=372495) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.08it/s]
(EngineCore_DP0 pid=372495) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.31it/s]
(EngineCore_DP0 pid=372495) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.47it/s]
(EngineCore_DP0 pid=372495) 
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 6848] -> 1D uint8
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36929536 bytes
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 6848] -> 1D uint8
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26378240 bytes
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 6848] -> 1D uint8
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 142442496 bytes
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 18432] -> 1D uint8
(EngineCore_DP0 pid=372495) [2026-01-26 07:56:31] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70778880 bytes
(EngineCore_DP0 pid=372495) [rank0]:W0126 07:56:59.077000 372495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=372495) [rank0]:W0126 07:56:59.153000 372495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=372495) [rank0]:W0126 07:56:59.519000 372495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=372495) [rank0]:W0126 07:56:59.644000 372495 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=372495) Process EngineCore_DP0:
(EngineCore_DP0 pid=372495) Traceback (most recent call last):
(EngineCore_DP0 pid=372495)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=372495)     self.run()
(EngineCore_DP0 pid=372495)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=372495)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=372495)     raise e
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=372495)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=372495)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=372495)     super().__init__(
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=372495)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=372495)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=372495)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=372495)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=372495)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=372495)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=372495)     raise ValueError(
(EngineCore_DP0 pid=372495) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 07:58:13.983542617 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=32768 ==========
Time: 2026-01-26 21:16:07
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.95 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:16:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:16:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]     self.driver_worker.init_device()
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 247, in init_device
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866] ValueError: Free memory on device (22.39/23.99 GiB) on startup is less than desired GPU memory utilization (0.95, 22.79 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.

STDERR:
[2026-01-26 21:16:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:16:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:16:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:16:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:16:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:16:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:16:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:16:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 21:16:53] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:16:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:16:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:16:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:16:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:16:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:16:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:16:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:16:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1082354) Process EngineCore_DP0:
(EngineCore_DP0 pid=1082354) Traceback (most recent call last):
(EngineCore_DP0 pid=1082354)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1082354)     self.run()
(EngineCore_DP0 pid=1082354)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1082354)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1082354)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1082354)     raise e
(EngineCore_DP0 pid=1082354)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1082354)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1082354)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1082354)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1082354)     super().__init__(
(EngineCore_DP0 pid=1082354)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1082354)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=1082354)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1082354)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=1082354)     self._init_executor()
(EngineCore_DP0 pid=1082354)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
(EngineCore_DP0 pid=1082354)     self.driver_worker.init_device()
(EngineCore_DP0 pid=1082354)   File "/root/vllmbench/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1082354)     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1082354)     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1082354)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 247, in init_device
(EngineCore_DP0 pid=1082354)     raise ValueError(
(EngineCore_DP0 pid=1082354) ValueError: Free memory on device (22.39/23.99 GiB) on startup is less than desired GPU memory utilization (0.95, 22.79 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W126 21:16:56.652771449 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=32768 ==========
Time: 2026-01-26 21:17:19
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=4096, max_num_seqs=32
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 4096 --max-num-seqs 32 --max-model-len 1025 --max-num-batched-tokens 32768 --no-enable-chunked-prefill --gpu-memory-utilization 0.98 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M32768.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:17:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:17:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]     self.driver_worker.init_device()
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 247, in init_device
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866] ValueError: Free memory on device (22.39/23.99 GiB) on startup is less than desired GPU memory utilization (0.98, 23.51 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.

STDERR:
[2026-01-26 21:17:55] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:17:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:17:56] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:17:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:17:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:17:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:17:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:17:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:17:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:17:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:17:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:17:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:17:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:17:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 21:18:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:18:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:18:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:18:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:18:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:18:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:18:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:18:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:18:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:18:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:18:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:18:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:18:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:18:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1083574) Process EngineCore_DP0:
(EngineCore_DP0 pid=1083574) Traceback (most recent call last):
(EngineCore_DP0 pid=1083574)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1083574)     self.run()
(EngineCore_DP0 pid=1083574)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1083574)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1083574)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1083574)     raise e
(EngineCore_DP0 pid=1083574)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1083574)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1083574)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1083574)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1083574)     super().__init__(
(EngineCore_DP0 pid=1083574)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1083574)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=1083574)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1083574)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=1083574)     self._init_executor()
(EngineCore_DP0 pid=1083574)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
(EngineCore_DP0 pid=1083574)     self.driver_worker.init_device()
(EngineCore_DP0 pid=1083574)   File "/root/vllmbench/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1083574)     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1083574)     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1083574)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 247, in init_device
(EngineCore_DP0 pid=1083574)     raise ValueError(
(EngineCore_DP0 pid=1083574) ValueError: Free memory on device (22.39/23.99 GiB) on startup is less than desired GPU memory utilization (0.98, 23.51 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W126 21:18:06.045875897 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=32768

========== M=65536 ==========
Time: 2026-01-26 21:18:31
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.95 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:19:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:19:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]     self.driver_worker.init_device()
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 247, in init_device
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866] ValueError: Free memory on device (22.39/23.99 GiB) on startup is less than desired GPU memory utilization (0.95, 22.79 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.

STDERR:
[2026-01-26 21:19:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:19:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:19:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:19:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:19:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:19:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:19:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:19:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 21:19:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:19:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:19:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:19:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:19:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:19:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:19:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:19:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:19:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1085131) Process EngineCore_DP0:
(EngineCore_DP0 pid=1085131) Traceback (most recent call last):
(EngineCore_DP0 pid=1085131)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1085131)     self.run()
(EngineCore_DP0 pid=1085131)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1085131)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1085131)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1085131)     raise e
(EngineCore_DP0 pid=1085131)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1085131)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1085131)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1085131)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1085131)     super().__init__(
(EngineCore_DP0 pid=1085131)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1085131)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=1085131)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1085131)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=1085131)     self._init_executor()
(EngineCore_DP0 pid=1085131)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
(EngineCore_DP0 pid=1085131)     self.driver_worker.init_device()
(EngineCore_DP0 pid=1085131)   File "/root/vllmbench/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1085131)     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1085131)     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1085131)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 247, in init_device
(EngineCore_DP0 pid=1085131)     raise ValueError(
(EngineCore_DP0 pid=1085131) ValueError: Free memory on device (22.39/23.99 GiB) on startup is less than desired GPU memory utilization (0.95, 22.79 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W126 21:19:47.982418964 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536

========== M=65536 ==========
Time: 2026-01-26 21:20:11
Backend: cuSPARSELt (2:6)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
Params: prompt_len=1024, output_len=1, num_prompts=8192, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6 --dataset-name random --input-len 1024 --output-len 1 --num-prompts 8192 --max-num-seqs 64 --max-model-len 1025 --max-num-batched-tokens 65536 --no-enable-chunked-prefill --gpu-memory-utilization 0.98 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6/json/Qwen2.5-14B-FP8_M65536.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:21:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:21:18 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]     self.driver_worker.init_device()
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 247, in init_device
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866] ValueError: Free memory on device (22.39/23.99 GiB) on startup is less than desired GPU memory utilization (0.98, 23.51 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.

STDERR:
[2026-01-26 21:21:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:21:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:21:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:21:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:21:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:21:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:21:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:21:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 21:21:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:21:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:21:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:21:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:21:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:21:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:21:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:21:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:21:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1086729) Process EngineCore_DP0:
(EngineCore_DP0 pid=1086729) Traceback (most recent call last):
(EngineCore_DP0 pid=1086729)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=1086729)     self.run()
(EngineCore_DP0 pid=1086729)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=1086729)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=1086729)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=1086729)     raise e
(EngineCore_DP0 pid=1086729)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1086729)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1086729)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1086729)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1086729)     super().__init__(
(EngineCore_DP0 pid=1086729)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1086729)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=1086729)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1086729)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=1086729)     self._init_executor()
(EngineCore_DP0 pid=1086729)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 47, in _init_executor
(EngineCore_DP0 pid=1086729)     self.driver_worker.init_device()
(EngineCore_DP0 pid=1086729)   File "/root/vllmbench/vllm/v1/worker/worker_base.py", line 326, in init_device
(EngineCore_DP0 pid=1086729)     self.worker.init_device()  # type: ignore
(EngineCore_DP0 pid=1086729)     ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1086729)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 247, in init_device
(EngineCore_DP0 pid=1086729)     raise ValueError(
(EngineCore_DP0 pid=1086729) ValueError: Free memory on device (22.39/23.99 GiB) on startup is less than desired GPU memory utilization (0.98, 23.51 GiB). Decrease GPU memory utilization or reduce GPU memory used by other processes.
[rank0]:[W126 21:21:28.726338440 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=65536
