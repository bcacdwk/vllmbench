
========== M=16 ==========
Time: 2026-01-25 18:06:14
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=16, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 16 --max-num-seqs 16 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:06:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=269662) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=269662) WARNING 01-25 18:06:25 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.61 requests/s, 4790.39 total tokens/s, 4508.61 output tokens/s
Total num prompt tokens:  256
Total num output tokens:  4096

STDERR:
[2026-01-25 18:06:18] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 18:06:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:06:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:06:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:06:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:06:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:06:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:06:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:06:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:06:22] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 18:06:22] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:06:22] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:06:22] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:22] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:22] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:22] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:22] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:22] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:06:22] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:06:22] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:06:22] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:06:22] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:06:22] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:22] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:22] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:22] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:22] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:22] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=269662) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=269662) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.56it/s]
(EngineCore_DP0 pid=269662) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.55it/s]
(EngineCore_DP0 pid=269662) 
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=269662) [2026-01-25 18:06:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=269662) 2026-01-25 18:06:29,697 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=269662) 2026-01-25 18:06:29,710 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=269662) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00, 24.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 26.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 25.97it/s]
(EngineCore_DP0 pid=269662) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  6.62it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00, 12.73it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 15.67it/s]

Adding requests:   0%|          | 0/16 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 16/16 [00:00<00:00, 1605.13it/s]

Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 1/16 [00:00<00:13,  1.12it/s, est. speed input: 17.92 toks/s, output: 286.74 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:00<00:00,  1.12it/s, est. speed input: 285.59 toks/s, output: 4569.46 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:00<00:00, 17.85it/s, est. speed input: 285.59 toks/s, output: 4569.46 toks/s]
[rank0]:[W125 18:06:32.040264302 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-25 18:06:33
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:06:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=270216) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=270216) WARNING 01-25 18:06:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 77.60 requests/s, 21107.00 total tokens/s, 19865.41 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-25 18:06:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 18:06:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:06:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:06:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:06:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:06:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:06:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:06:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:06:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:06:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 18:06:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:06:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:06:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:06:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:06:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:06:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:06:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:06:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=270216) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=270216) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.52it/s]
(EngineCore_DP0 pid=270216) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.52it/s]
(EngineCore_DP0 pid=270216) 
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=270216) [2026-01-25 18:06:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=270216) 2026-01-25 18:06:47,382 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=270216) 2026-01-25 18:06:47,396 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=270216) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:00<00:00, 32.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:00<00:00, 35.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:00<00:00, 36.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:00<00:00, 36.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:00<00:00, 20.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:01<00:00, 18.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:01<00:00, 21.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:01<00:00, 25.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 28.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 26.19it/s]
(EngineCore_DP0 pid=270216) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  7.06it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:00, 26.03it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:00<00:00, 33.07it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:00<00:00, 36.77it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 33.52it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 4692.19it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<03:19,  1.57s/it, est. speed input: 10.20 toks/s, output: 163.25 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  1.57s/it, est. speed input: 1264.56 toks/s, output: 20232.90 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 79.03it/s, est. speed input: 1264.56 toks/s, output: 20232.90 toks/s]
[rank0]:[W125 18:06:51.725058529 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-25 18:06:53
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 18:06:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=270767) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=270767) WARNING 01-25 18:07:04 [backends.py:609] Failed to read file <frozen os>
Throughput: 82.72 requests/s, 22500.81 total tokens/s, 21177.23 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-25 18:06:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 18:06:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:06:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:06:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:06:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:06:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:06:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:06:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:06:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:06:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 18:07:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 18:07:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 18:07:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 18:07:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:07:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:07:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:07:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:07:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 18:07:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 18:07:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 18:07:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 18:07:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 18:07:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 18:07:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=270767) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=270767) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.48it/s]
(EngineCore_DP0 pid=270767) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.47it/s]
(EngineCore_DP0 pid=270767) 
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=270767) [2026-01-25 18:07:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=270767) 2026-01-25 18:07:07,036 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=270767) 2026-01-25 18:07:07,049 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=270767) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:00, 33.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:00<00:00, 35.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:00<00:00, 36.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:00<00:00, 37.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:00<00:00, 36.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:00<00:00, 37.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:00<00:00, 34.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:00<00:00, 35.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:00<00:00, 36.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:00<00:00, 36.11it/s]
(EngineCore_DP0 pid=270767) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:04,  7.06it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:01, 26.18it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:00<00:00, 33.31it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:00<00:00, 36.84it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:00<00:00, 38.93it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:00<00:00, 39.48it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:00<00:00, 34.44it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:01<00:00, 33.39it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 33.49it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:00<00:34,  7.36it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 1564.49it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:02<11:20,  2.67s/it, est. speed input: 5.99 toks/s, output: 95.89 toks/s]
Processed prompts:  54%|█████▎    | 137/256 [00:02<00:01, 69.33it/s, est. speed input: 790.55 toks/s, output: 12648.78 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:02<00:00, 131.51it/s, est. speed input: 1314.35 toks/s, output: 21029.63 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 131.51it/s, est. speed input: 1397.83 toks/s, output: 22365.28 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 87.36it/s, est. speed input: 1397.83 toks/s, output: 22365.28 toks/s] 
[rank0]:[W125 18:07:13.978258072 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-25 22:26:59
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:27:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=589705) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=589705) WARNING 01-25 22:27:11 [backends.py:609] Failed to read file <frozen os>
Throughput: 54.28 requests/s, 14764.90 total tokens/s, 13896.38 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-25 22:27:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:27:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:27:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:27:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:27:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:27:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:27:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:27:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:27:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:27:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:27:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:27:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:27:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:27:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=589705) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=589705) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.07it/s]
(EngineCore_DP0 pid=589705) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.07it/s]
(EngineCore_DP0 pid=589705) 
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=589705) [2026-01-25 22:27:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=589705) 2026-01-25 22:27:14,806 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=589705) 2026-01-25 22:27:14,821 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=589705) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:01, 15.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:00<00:00, 16.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:00<00:00, 16.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:00<00:00, 17.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:00<00:00, 23.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:00<00:00, 29.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:00<00:00, 23.65it/s]
(EngineCore_DP0 pid=589705) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  6.97it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 22.71it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:00<00:00, 31.24it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 27.86it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 7338.91it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:01<01:12,  1.15s/it, est. speed input: 13.91 toks/s, output: 222.63 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00,  1.15s/it, est. speed input: 875.54 toks/s, output: 14008.40 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00, 54.72it/s, est. speed input: 875.54 toks/s, output: 14008.40 toks/s]
[rank0]:[W125 22:27:18.959157994 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-25 22:27:19
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:27:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=590239) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=590239) WARNING 01-25 22:27:31 [backends.py:609] Failed to read file <frozen os>
Throughput: 78.14 requests/s, 21254.33 total tokens/s, 20004.08 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-25 22:27:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:27:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:27:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:27:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:27:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:27:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:27:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:27:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:27:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:27:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:27:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:27:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:27:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:27:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=590239) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=590239) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.27it/s]
(EngineCore_DP0 pid=590239) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.27it/s]
(EngineCore_DP0 pid=590239) 
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=590239) [2026-01-25 22:27:28] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=590239) 2026-01-25 22:27:33,491 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=590239) 2026-01-25 22:27:33,510 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=590239) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:01, 29.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:00<00:00, 34.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:00<00:00, 35.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:00<00:00, 36.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:00<00:00, 36.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:00<00:00, 36.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:00<00:00, 36.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:00<00:00, 36.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:00<00:00, 35.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:00<00:00, 35.67it/s]
(EngineCore_DP0 pid=590239) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  6.99it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:00, 25.81it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:00<00:00, 32.79it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:00<00:00, 36.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 33.04it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 8359.09it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<03:19,  1.57s/it, est. speed input: 10.19 toks/s, output: 163.05 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  1.57s/it, est. speed input: 1262.92 toks/s, output: 20206.68 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 78.93it/s, est. speed input: 1262.92 toks/s, output: 20206.68 toks/s]
[rank0]:[W125 22:27:37.468170367 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-25 22:27:38
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:27:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=590778) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=590778) WARNING 01-25 22:27:50 [backends.py:609] Failed to read file <frozen os>
Throughput: 85.88 requests/s, 23360.52 total tokens/s, 21986.37 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-25 22:27:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:27:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:42] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:27:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:27:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:27:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:27:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:27:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:27:46] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:27:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:27:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:27:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:27:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:27:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:27:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:27:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:27:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=590778) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=590778) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.22it/s]
(EngineCore_DP0 pid=590778) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.21it/s]
(EngineCore_DP0 pid=590778) 
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=590778) [2026-01-25 22:27:47] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=590778) 2026-01-25 22:27:52,470 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=590778) 2026-01-25 22:27:52,485 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=590778) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:00, 33.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:00<00:00, 31.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:00<00:00, 34.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:00<00:00, 34.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:00<00:00, 35.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:00<00:00, 36.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:00<00:00, 36.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:00<00:00, 37.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:01<00:00, 36.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:01<00:00, 35.74it/s]
(EngineCore_DP0 pid=590778) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:04,  7.06it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:01, 25.45it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:00<00:00, 25.30it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:00<00:00, 25.04it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:00<00:00, 21.50it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:00<00:00, 23.01it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:01<00:00, 28.40it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:01<00:00, 32.30it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 35.27it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 28.28it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 6130.45it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:02<11:22,  2.68s/it, est. speed input: 5.98 toks/s, output: 95.63 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:02<00:01, 68.59it/s, est. speed input: 782.31 toks/s, output: 12517.00 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:02<00:00, 131.23it/s, est. speed input: 1309.97 toks/s, output: 20959.51 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 131.23it/s, est. speed input: 1394.52 toks/s, output: 22312.26 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 87.16it/s, est. speed input: 1394.52 toks/s, output: 22312.26 toks/s] 
[rank0]:[W125 22:27:58.468209483 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-25 22:27:59
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:28:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=591331) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=591331) WARNING 01-25 22:28:11 [backends.py:609] Failed to read file <frozen os>
Throughput: 83.88 requests/s, 22815.01 total tokens/s, 21472.95 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-25 22:28:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:28:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:28:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:28:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:28:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:28:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:28:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:28:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:28:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:28:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:28:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:28:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:28:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:28:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:28:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:28:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 22:28:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 22:28:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:28:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:28:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:28:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:28:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 22:28:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 22:28:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:28:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:28:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:28:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:28:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=591331) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=591331) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.29it/s]
(EngineCore_DP0 pid=591331) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.29it/s]
(EngineCore_DP0 pid=591331) 
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7618560 bytes
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 5079040 bytes
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 40632320 bytes
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=591331) [2026-01-25 22:28:08] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 20185088 bytes
(EngineCore_DP0 pid=591331) 2026-01-25 22:28:15,207 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=591331) 2026-01-25 22:28:15,227 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=591331) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:02, 18.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:01, 25.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:00<00:01, 29.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:00<00:01, 30.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:00<00:01, 32.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:00<00:00, 33.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:00<00:00, 34.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:00<00:00, 35.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:01<00:00, 35.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:01<00:00, 35.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:01<00:00, 35.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:01<00:00, 34.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:01<00:00, 36.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:01<00:00, 33.56it/s]
(EngineCore_DP0 pid=591331) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:07,  7.05it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:00<00:01, 25.96it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:00<00:01, 32.91it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:00<00:00, 36.25it/s]
Capturing CUDA graphs (decode, FULL):  41%|████      | 21/51 [00:00<00:00, 37.90it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:00<00:00, 38.96it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:00<00:00, 36.50it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:00<00:00, 37.87it/s]
Capturing CUDA graphs (decode, FULL):  76%|███████▋  | 39/51 [00:01<00:00, 37.97it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 43/51 [00:01<00:00, 34.65it/s]
Capturing CUDA graphs (decode, FULL):  92%|█████████▏| 47/51 [00:01<00:00, 31.13it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:01<00:00, 29.01it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:01<00:00, 32.66it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 9402.21it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:04<41:41,  4.90s/it, est. speed input: 3.27 toks/s, output: 52.29 toks/s]
Processed prompts:  12%|█▏        | 63/512 [00:05<00:25, 17.75it/s, est. speed input: 201.56 toks/s, output: 3224.97 toks/s]
Processed prompts:  36%|███▌      | 185/512 [00:05<00:05, 64.34it/s, est. speed input: 579.63 toks/s, output: 9274.06 toks/s]
Processed prompts:  66%|██████▌   | 338/512 [00:05<00:01, 140.89it/s, est. speed input: 1037.61 toks/s, output: 16601.72 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:05<00:00, 208.92it/s, est. speed input: 1355.23 toks/s, output: 21683.74 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:06<00:00, 208.92it/s, est. speed input: 1354.53 toks/s, output: 21672.39 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:06<00:00, 84.66it/s, est. speed input: 1354.53 toks/s, output: 21672.39 toks/s] 
[rank0]:[W125 22:28:25.252266717 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-25 22:43:23
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:43:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=614442) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=614442) WARNING 01-25 22:43:37 [backends.py:609] Failed to read file <frozen os>
Throughput: 29.21 requests/s, 7944.10 total tokens/s, 7476.80 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-25 22:43:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:43:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 22:43:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 22:43:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 22:43:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:43:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:43:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:43:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:43:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:43:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:43:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 22:43:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 22:43:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 22:43:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:43:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:43:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:43:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:43:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:32] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:32] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:32] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:32] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:32] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:32] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=614442) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=614442) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.17it/s]
(EngineCore_DP0 pid=614442) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.17it/s]
(EngineCore_DP0 pid=614442) 
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:33] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=614442) [2026-01-25 22:43:33] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=614442) 2026-01-25 22:43:43,116 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=614442) 2026-01-25 22:43:43,131 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=614442) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:02,  6.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:03,  5.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:00<00:01, 12.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:00<00:00, 17.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:00<00:00, 19.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:00<00:00, 22.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:00<00:00, 24.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 18.73it/s]
(EngineCore_DP0 pid=614442) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  7.38it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 21.26it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:00<00:00, 25.89it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 24.40it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2973.53it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:02<02:14,  2.13s/it, est. speed input: 7.52 toks/s, output: 120.28 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:02<00:00,  2.13s/it, est. speed input: 472.31 toks/s, output: 7557.00 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:02<00:00, 29.52it/s, est. speed input: 472.31 toks/s, output: 7557.00 toks/s]
[rank0]:[W125 22:43:47.711390959 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-25 22:43:49
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:43:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=615080) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=615080) WARNING 01-25 22:44:02 [backends.py:609] Failed to read file <frozen os>
Throughput: 43.80 requests/s, 11913.20 total tokens/s, 11212.43 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-25 22:43:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:43:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 22:43:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 22:43:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 22:43:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:43:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:43:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:43:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:43:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:43:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:43:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 22:43:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 22:43:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:43:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 22:43:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:43:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:43:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:43:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:43:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:57] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:57] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:57] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:57] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:57] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:57] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=615080) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=615080) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.05it/s]
(EngineCore_DP0 pid=615080) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.05it/s]
(EngineCore_DP0 pid=615080) 
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:58] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=615080) [2026-01-25 22:43:58] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=615080) 2026-01-25 22:44:06,256 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=615080) 2026-01-25 22:44:06,270 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=615080) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:04,  7.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:04,  7.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:00<00:01, 15.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:00<00:01, 21.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:00<00:00, 24.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:00<00:00, 25.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:00<00:00, 26.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:00<00:00, 26.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:01<00:00, 27.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:01<00:00, 28.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:01<00:00, 27.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 27.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 24.64it/s]
(EngineCore_DP0 pid=615080) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  7.44it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:00<00:00, 21.64it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:00<00:00, 26.71it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:00<00:00, 29.16it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:00<00:00, 30.59it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 27.93it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 8437.12it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:02<05:56,  2.81s/it, est. speed input: 5.70 toks/s, output: 91.26 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:02<00:00, 61.36it/s, est. speed input: 699.11 toks/s, output: 11185.72 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00, 61.36it/s, est. speed input: 704.60 toks/s, output: 11273.52 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00, 44.04it/s, est. speed input: 704.60 toks/s, output: 11273.52 toks/s]
[rank0]:[W125 22:44:12.121533586 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-25 22:44:13
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:44:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=615708) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=615708) WARNING 01-25 22:44:26 [backends.py:609] Failed to read file <frozen os>
Throughput: 47.13 requests/s, 12818.42 total tokens/s, 12064.39 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-25 22:44:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:44:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 22:44:17] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 22:44:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 22:44:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:44:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:44:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:44:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:44:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:44:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:44:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 22:44:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 22:44:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 22:44:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:44:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:44:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:44:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:44:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=615708) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=615708) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.04it/s]
(EngineCore_DP0 pid=615708) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.04it/s]
(EngineCore_DP0 pid=615708) 
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=615708) [2026-01-25 22:44:22] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=615708) 2026-01-25 22:44:30,674 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=615708) 2026-01-25 22:44:30,688 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=615708) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:01, 28.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:00<00:01, 27.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:00<00:00, 29.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:00<00:00, 29.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:00<00:00, 29.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:00<00:00, 27.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:00<00:00, 28.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:00<00:00, 28.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:01<00:00, 28.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:01<00:00, 29.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:01<00:00, 28.70it/s]
(EngineCore_DP0 pid=615708) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:04,  7.48it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:00<00:01, 21.79it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:00<00:00, 26.62it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:00<00:00, 27.37it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:00<00:00, 28.93it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:00<00:00, 30.10it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:00<00:00, 30.44it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:01<00:00, 27.40it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:01<00:00, 26.11it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 24.70it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 26.06it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 6165.76it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:04<19:45,  4.65s/it, est. speed input: 3.44 toks/s, output: 55.04 toks/s]
Processed prompts:  29%|██▉       | 75/256 [00:04<00:08, 22.16it/s, est. speed input: 251.80 toks/s, output: 4028.81 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:04<00:01, 52.37it/s, est. speed input: 498.83 toks/s, output: 7981.27 toks/s]
Processed prompts:  82%|████████▏ | 210/256 [00:04<00:00, 80.61it/s, est. speed input: 673.45 toks/s, output: 10775.13 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:05<00:00, 80.61it/s, est. speed input: 760.12 toks/s, output: 12161.94 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:05<00:00, 47.51it/s, est. speed input: 760.12 toks/s, output: 12161.94 toks/s]
[rank0]:[W125 22:44:39.550481040 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-25 22:44:40
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 22:44:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=616352) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=616352) WARNING 01-25 22:44:54 [backends.py:609] Failed to read file <frozen os>
Throughput: 40.90 requests/s, 11126.01 total tokens/s, 10471.54 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-25 22:44:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:44:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 22:44:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 22:44:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 22:44:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:44:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:44:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:44:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:44:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 22:44:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 22:44:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-25 22:44:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-25 22:44:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-25 22:44:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-25 22:44:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 22:44:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 22:44:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 22:44:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 22:44:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:49] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:49] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:49] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:49] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:49] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=616352) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=616352) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.00it/s]
(EngineCore_DP0 pid=616352) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.00it/s]
(EngineCore_DP0 pid=616352) 
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19005440 bytes
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11403264 bytes
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 60817408 bytes
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=616352) [2026-01-25 22:44:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 30277632 bytes
(EngineCore_DP0 pid=616352) 2026-01-25 22:44:59,621 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=616352) 2026-01-25 22:44:59,635 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=616352) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:01, 27.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:02, 19.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:00<00:02, 14.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:00<00:02, 14.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:00<00:02, 16.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:00<00:01, 19.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:01<00:01, 21.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:01<00:01, 23.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:01<00:00, 25.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:01<00:00, 26.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:01<00:00, 27.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:01<00:00, 27.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:01<00:00, 28.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:01<00:00, 27.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:02<00:00, 27.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:02<00:00, 27.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:02<00:00, 23.76it/s]
(EngineCore_DP0 pid=616352) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:06,  7.28it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:02, 18.13it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:00<00:01, 22.75it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:00<00:01, 26.44it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:00<00:01, 28.80it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:00<00:01, 29.66it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:00<00:01, 28.17it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:00<00:00, 29.43it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:01<00:00, 27.56it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:01<00:00, 24.83it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:01<00:00, 22.54it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:01<00:00, 22.99it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:01<00:00, 25.70it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:01<00:00, 27.69it/s]
Capturing CUDA graphs (decode, FULL):  96%|█████████▌| 49/51 [00:01<00:00, 27.95it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:01<00:00, 26.20it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 7462.09it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:06<57:28,  6.75s/it, est. speed input: 2.37 toks/s, output: 37.94 toks/s]
Processed prompts:  18%|█▊        | 91/512 [00:06<00:22, 18.71it/s, est. speed input: 211.89 toks/s, output: 3390.26 toks/s]
Processed prompts:  40%|████      | 205/512 [00:07<00:06, 49.56it/s, est. speed input: 464.62 toks/s, output: 7433.95 toks/s]
Processed prompts:  50%|█████     | 256/512 [00:08<00:06, 42.35it/s, est. speed input: 471.31 toks/s, output: 7540.92 toks/s]
Processed prompts:  56%|█████▋    | 289/512 [00:09<00:05, 39.48it/s, est. speed input: 474.86 toks/s, output: 7597.75 toks/s]
Processed prompts:  61%|██████    | 311/512 [00:10<00:04, 40.94it/s, est. speed input: 488.99 toks/s, output: 7823.83 toks/s]
Processed prompts:  64%|██████▍   | 327/512 [00:10<00:04, 42.40it/s, est. speed input: 499.41 toks/s, output: 7990.60 toks/s]
Processed prompts:  66%|██████▋   | 340/512 [00:10<00:03, 44.71it/s, est. speed input: 509.59 toks/s, output: 8153.49 toks/s]
Processed prompts:  69%|██████▊   | 351/512 [00:10<00:03, 47.56it/s, est. speed input: 518.86 toks/s, output: 8301.70 toks/s]
Processed prompts:  71%|███████   | 361/512 [00:10<00:03, 49.00it/s, est. speed input: 525.27 toks/s, output: 8404.31 toks/s]
Processed prompts:  72%|███████▏  | 370/512 [00:11<00:02, 52.52it/s, est. speed input: 532.89 toks/s, output: 8526.28 toks/s]
Processed prompts:  74%|███████▍  | 380/512 [00:11<00:02, 57.82it/s, est. speed input: 541.94 toks/s, output: 8670.96 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:11<00:01, 69.45it/s, est. speed input: 556.55 toks/s, output: 8904.82 toks/s]
Processed prompts:  79%|███████▉  | 404/512 [00:11<00:01, 73.71it/s, est. speed input: 565.25 toks/s, output: 9044.03 toks/s]
Processed prompts:  81%|████████▏ | 416/512 [00:11<00:01, 82.20it/s, est. speed input: 576.78 toks/s, output: 9228.47 toks/s]
Processed prompts:  84%|████████▍ | 431/512 [00:11<00:00, 95.22it/s, est. speed input: 591.99 toks/s, output: 9471.78 toks/s]
Processed prompts:  87%|████████▋ | 446/512 [00:11<00:00, 105.69it/s, est. speed input: 606.87 toks/s, output: 9709.94 toks/s]
Processed prompts:  90%|█████████ | 461/512 [00:11<00:00, 113.96it/s, est. speed input: 621.49 toks/s, output: 9943.86 toks/s]
Processed prompts:  93%|█████████▎| 474/512 [00:11<00:00, 117.33it/s, est. speed input: 633.55 toks/s, output: 10136.74 toks/s]
Processed prompts:  95%|█████████▌| 487/512 [00:12<00:00, 119.75it/s, est. speed input: 645.37 toks/s, output: 10325.90 toks/s]
Processed prompts:  98%|█████████▊| 500/512 [00:12<00:00, 70.79it/s, est. speed input: 643.08 toks/s, output: 10289.30 toks/s] 
Processed prompts: 100%|██████████| 512/512 [00:12<00:00, 70.79it/s, est. speed input: 658.18 toks/s, output: 10530.87 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:12<00:00, 41.14it/s, est. speed input: 658.18 toks/s, output: 10530.87 toks/s]
[rank0]:[W125 22:45:17.181718279 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-25 23:03:29
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:03:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=642417) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=642417) WARNING 01-25 23:03:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.97 requests/s, 4887.25 total tokens/s, 4599.76 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-25 23:03:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:03:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:03:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:03:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:03:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:03:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:03:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:03:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:03:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:03:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:03:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:03:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:03:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:03:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:03:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:03:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:03:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:38] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:38] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:38] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:38] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:38] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:38] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=642417) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=642417) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.76s/it]
(EngineCore_DP0 pid=642417) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:03<00:00,  1.83s/it]
(EngineCore_DP0 pid=642417) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:03<00:00,  1.82s/it]
(EngineCore_DP0 pid=642417) 
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:42] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=642417) [2026-01-25 23:03:42] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=642417) 2026-01-25 23:03:52,200 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=642417) 2026-01-25 23:03:52,220 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=642417) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:00, 24.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:00<00:00, 27.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:00<00:00, 26.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:00<00:00, 27.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:00<00:00, 28.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:00<00:00, 28.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:00<00:00, 27.72it/s]
(EngineCore_DP0 pid=642417) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  7.14it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 20.76it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:00<00:00, 26.26it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 24.58it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 4488.59it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:03<03:39,  3.48s/it, est. speed input: 4.59 toks/s, output: 73.48 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:03<00:00,  3.48s/it, est. speed input: 288.74 toks/s, output: 4619.76 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:03<00:00, 18.05it/s, est. speed input: 288.74 toks/s, output: 4619.76 toks/s]
[rank0]:[W125 23:03:58.854928194 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-25 23:03:59
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:04:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=643108) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=643108) WARNING 01-25 23:04:13 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4302, in _dummy_sampler_run
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     sampler_output = self.sampler(
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]                      ^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 96, in forward
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     sampled, processed_logprobs = self.sample(logits, sampling_metadata)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 187, in sample
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     random_sampled, processed_logprobs = self.topk_topp_sampler(
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]                                          ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 104, in forward_native
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     logits = self.apply_top_k_top_p(logits, k, p)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 258, in apply_top_k_top_p
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 56.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 12.16 GiB is allocated by PyTorch, with 68.00 MiB allocated in private pools (e.g., CUDA Graphs), and 2.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866] 
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866] The above exception was the direct cause of the following exception:
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866] 
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 538, in compile_or_warm_up_model
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     self.model_runner._dummy_sampler_run(hidden_states=last_hidden_states)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4307, in _dummy_sampler_run
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866]     raise RuntimeError(
(EngineCore_DP0 pid=643108) ERROR 01-25 23:04:20 [core.py:866] RuntimeError: CUDA out of memory occurred when warming up sampler with 128 dummy requests. Please try lowering `max_num_seqs` or `gpu_memory_utilization` when initializing the engine.

STDERR:
[2026-01-25 23:04:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:04:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:04:03] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:04:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:04:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:04:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:04:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:04:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:04:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:04:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:04:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:04:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:04:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:04:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:04:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:04:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:07] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:07] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:07] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:07] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:07] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=643108) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=643108) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.14it/s]
(EngineCore_DP0 pid=643108) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.58it/s]
(EngineCore_DP0 pid=643108) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.64it/s]
(EngineCore_DP0 pid=643108) 
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=643108) [2026-01-25 23:04:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=643108) 2026-01-25 23:04:17,593 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=643108) 2026-01-25 23:04:17,607 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=643108) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:01, 24.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:00<00:01, 25.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:00<00:01, 16.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:00<00:01, 14.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:00<00:01, 18.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:00<00:00, 20.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:00<00:00, 22.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:01<00:00, 24.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:01<00:00, 26.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:01<00:00, 27.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 27.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 23.34it/s]
(EngineCore_DP0 pid=643108) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  7.08it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:00<00:00, 21.15it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:00<00:00, 26.12it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:00<00:00, 28.81it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:00<00:00, 30.32it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 27.50it/s]
(EngineCore_DP0 pid=643108) Process EngineCore_DP0:
(EngineCore_DP0 pid=643108) Traceback (most recent call last):
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4302, in _dummy_sampler_run
(EngineCore_DP0 pid=643108)     sampler_output = self.sampler(
(EngineCore_DP0 pid=643108)                      ^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=643108)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=643108)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=643108)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=643108)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 96, in forward
(EngineCore_DP0 pid=643108)     sampled, processed_logprobs = self.sample(logits, sampling_metadata)
(EngineCore_DP0 pid=643108)                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 187, in sample
(EngineCore_DP0 pid=643108)     random_sampled, processed_logprobs = self.topk_topp_sampler(
(EngineCore_DP0 pid=643108)                                          ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=643108)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=643108)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=643108)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=643108)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 104, in forward_native
(EngineCore_DP0 pid=643108)     logits = self.apply_top_k_top_p(logits, k, p)
(EngineCore_DP0 pid=643108)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 258, in apply_top_k_top_p
(EngineCore_DP0 pid=643108)     logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
(EngineCore_DP0 pid=643108)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 224.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 56.94 MiB is free. Including non-PyTorch memory, this process has 15.19 GiB memory in use. Of the allocated memory 12.16 GiB is allocated by PyTorch, with 68.00 MiB allocated in private pools (e.g., CUDA Graphs), and 2.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
(EngineCore_DP0 pid=643108) 
(EngineCore_DP0 pid=643108) The above exception was the direct cause of the following exception:
(EngineCore_DP0 pid=643108) 
(EngineCore_DP0 pid=643108) Traceback (most recent call last):
(EngineCore_DP0 pid=643108)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=643108)     self.run()
(EngineCore_DP0 pid=643108)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=643108)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=643108)     raise e
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=643108)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=643108)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=643108)     super().__init__(
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=643108)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=643108)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=643108)     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=643108)     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=643108)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=643108)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=643108)     return func(*args, **kwargs)
(EngineCore_DP0 pid=643108)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 538, in compile_or_warm_up_model
(EngineCore_DP0 pid=643108)     self.model_runner._dummy_sampler_run(hidden_states=last_hidden_states)
(EngineCore_DP0 pid=643108)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=643108)     return func(*args, **kwargs)
(EngineCore_DP0 pid=643108)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=643108)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4307, in _dummy_sampler_run
(EngineCore_DP0 pid=643108)     raise RuntimeError(
(EngineCore_DP0 pid=643108) RuntimeError: CUDA out of memory occurred when warming up sampler with 128 dummy requests. Please try lowering `max_num_seqs` or `gpu_memory_utilization` when initializing the engine.
[rank0]:[W125 23:04:20.472786998 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=128

========== M=256 ==========
Time: 2026-01-25 23:04:22
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:04:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=643676) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=643676) WARNING 01-25 23:04:37 [backends.py:609] Failed to read file <frozen os>
Throughput: 23.13 requests/s, 6291.55 total tokens/s, 5921.46 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-25 23:04:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:04:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:04:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:04:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:04:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:04:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:04:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:04:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:04:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:04:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:04:30] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:04:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:04:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:04:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:04:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:04:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:04:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:31] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:31] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:31] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:31] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:31] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:31] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=643676) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=643676) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.12it/s]
(EngineCore_DP0 pid=643676) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.57it/s]
(EngineCore_DP0 pid=643676) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.63it/s]
(EngineCore_DP0 pid=643676) 
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:32] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=643676) [2026-01-25 23:04:32] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=643676) 2026-01-25 23:04:41,309 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=643676) 2026-01-25 23:04:41,323 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=643676) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:01, 26.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:00<00:01, 26.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:00<00:00, 27.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:00<00:00, 27.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:00<00:00, 21.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:00<00:01, 14.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:01<00:00, 16.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:01<00:00, 19.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:01<00:00, 22.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:01<00:00, 24.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:01<00:00, 25.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:01<00:00, 22.31it/s]
(EngineCore_DP0 pid=643676) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:04,  7.31it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:00<00:01, 20.58it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:00<00:01, 25.10it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:00<00:00, 27.52it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:00<00:00, 29.08it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:00<00:00, 30.08it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:00<00:00, 30.80it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:01<00:00, 30.47it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:01<00:00, 30.52it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 28.53it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 7932.43it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:05<22:56,  5.40s/it, est. speed input: 2.96 toks/s, output: 47.42 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:05<00:07, 22.28it/s, est. speed input: 252.59 toks/s, output: 4041.45 toks/s]
Processed prompts:  52%|█████▏    | 133/256 [00:07<00:05, 22.10it/s, est. speed input: 279.46 toks/s, output: 4471.39 toks/s]
Processed prompts:  62%|██████▏   | 159/256 [00:08<00:04, 22.17it/s, est. speed input: 289.89 toks/s, output: 4638.18 toks/s]
Processed prompts:  69%|██████▉   | 176/256 [00:09<00:03, 23.80it/s, est. speed input: 303.66 toks/s, output: 4858.60 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:09<00:02, 25.37it/s, est. speed input: 313.77 toks/s, output: 5020.25 toks/s]
Processed prompts:  77%|███████▋  | 198/256 [00:09<00:02, 26.83it/s, est. speed input: 321.63 toks/s, output: 5146.11 toks/s]
Processed prompts:  80%|████████  | 206/256 [00:10<00:01, 28.43it/s, est. speed input: 328.25 toks/s, output: 5252.05 toks/s]
Processed prompts:  83%|████████▎ | 213/256 [00:10<00:01, 30.36it/s, est. speed input: 334.38 toks/s, output: 5350.02 toks/s]
Processed prompts:  86%|████████▌ | 219/256 [00:10<00:01, 32.41it/s, est. speed input: 339.70 toks/s, output: 5435.20 toks/s]
Processed prompts:  88%|████████▊ | 225/256 [00:10<00:00, 33.80it/s, est. speed input: 344.14 toks/s, output: 5506.29 toks/s]
Processed prompts:  90%|█████████ | 231/256 [00:10<00:00, 36.36it/s, est. speed input: 349.33 toks/s, output: 5589.25 toks/s]
Processed prompts:  93%|█████████▎| 237/256 [00:10<00:00, 39.64it/s, est. speed input: 354.81 toks/s, output: 5676.90 toks/s]
Processed prompts:  95%|█████████▍| 243/256 [00:10<00:00, 43.06it/s, est. speed input: 360.29 toks/s, output: 5764.68 toks/s]
Processed prompts:  97%|█████████▋| 249/256 [00:10<00:00, 45.44it/s, est. speed input: 365.41 toks/s, output: 5846.48 toks/s]
Processed prompts: 100%|█████████▉| 255/256 [00:11<00:00, 46.57it/s, est. speed input: 370.12 toks/s, output: 5921.96 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 46.57it/s, est. speed input: 371.21 toks/s, output: 5939.28 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:11<00:00, 23.20it/s, est. speed input: 371.21 toks/s, output: 5939.28 toks/s]
[rank0]:[W125 23:04:56.097582121 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-25 23:04:57
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:05:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=644435) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=644435) WARNING 01-25 23:05:11 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4302, in _dummy_sampler_run
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     sampler_output = self.sampler(
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]                      ^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 96, in forward
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     sampled, processed_logprobs = self.sample(logits, sampling_metadata)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 187, in sample
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     random_sampled, processed_logprobs = self.topk_topp_sampler(
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]                                          ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 104, in forward_native
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     logits = self.apply_top_k_top_p(logits, k, p)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 258, in apply_top_k_top_p
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 892.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 814.94 MiB is free. Including non-PyTorch memory, this process has 14.45 GiB memory in use. Of the allocated memory 11.33 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866] 
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866] The above exception was the direct cause of the following exception:
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866] 
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4481, in profile_run
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     output = self._dummy_sampler_run(last_hidden_states)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4307, in _dummy_sampler_run
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866]     raise RuntimeError(
(EngineCore_DP0 pid=644435) ERROR 01-25 23:05:17 [core.py:866] RuntimeError: CUDA out of memory occurred when warming up sampler with 512 dummy requests. Please try lowering `max_num_seqs` or `gpu_memory_utilization` when initializing the engine.

STDERR:
[2026-01-25 23:05:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:05:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:05:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:05:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:05:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:05:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:05:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:05:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:05:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:05:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:05:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-25 23:05:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-25 23:05:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:05:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:05:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:05:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:05:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=644435) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=644435) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  2.10it/s]
(EngineCore_DP0 pid=644435) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.56it/s]
(EngineCore_DP0 pid=644435) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.62it/s]
(EngineCore_DP0 pid=644435) 
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:07] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=644435) [2026-01-25 23:05:07] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=644435) Process EngineCore_DP0:
(EngineCore_DP0 pid=644435) Traceback (most recent call last):
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4302, in _dummy_sampler_run
(EngineCore_DP0 pid=644435)     sampler_output = self.sampler(
(EngineCore_DP0 pid=644435)                      ^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=644435)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=644435)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=644435)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=644435)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 96, in forward
(EngineCore_DP0 pid=644435)     sampled, processed_logprobs = self.sample(logits, sampling_metadata)
(EngineCore_DP0 pid=644435)                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 187, in sample
(EngineCore_DP0 pid=644435)     random_sampled, processed_logprobs = self.topk_topp_sampler(
(EngineCore_DP0 pid=644435)                                          ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=644435)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=644435)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=644435)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=644435)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 104, in forward_native
(EngineCore_DP0 pid=644435)     logits = self.apply_top_k_top_p(logits, k, p)
(EngineCore_DP0 pid=644435)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 258, in apply_top_k_top_p
(EngineCore_DP0 pid=644435)     logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
(EngineCore_DP0 pid=644435)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 892.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 814.94 MiB is free. Including non-PyTorch memory, this process has 14.45 GiB memory in use. Of the allocated memory 11.33 GiB is allocated by PyTorch, and 2.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
(EngineCore_DP0 pid=644435) 
(EngineCore_DP0 pid=644435) The above exception was the direct cause of the following exception:
(EngineCore_DP0 pid=644435) 
(EngineCore_DP0 pid=644435) Traceback (most recent call last):
(EngineCore_DP0 pid=644435)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=644435)     self.run()
(EngineCore_DP0 pid=644435)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=644435)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=644435)     raise e
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=644435)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=644435)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=644435)     super().__init__(
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=644435)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=644435)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=644435)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=644435)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=644435)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=644435)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=644435)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=644435)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=644435)     return func(*args, **kwargs)
(EngineCore_DP0 pid=644435)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=644435)     return func(*args, **kwargs)
(EngineCore_DP0 pid=644435)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=644435)     self.model_runner.profile_run()
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4481, in profile_run
(EngineCore_DP0 pid=644435)     output = self._dummy_sampler_run(last_hidden_states)
(EngineCore_DP0 pid=644435)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=644435)     return func(*args, **kwargs)
(EngineCore_DP0 pid=644435)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=644435)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4307, in _dummy_sampler_run
(EngineCore_DP0 pid=644435)     raise RuntimeError(
(EngineCore_DP0 pid=644435) RuntimeError: CUDA out of memory occurred when warming up sampler with 512 dummy requests. Please try lowering `max_num_seqs` or `gpu_memory_utilization` when initializing the engine.
[rank0]:[W125 23:05:17.558032947 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=64 ==========
Time: 2026-01-25 23:19:26
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:19:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 70.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     raise e
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 655, in create_weights
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py", line 67, in create_weights
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) ERROR 01-25 23:19:34 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 70.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

STDERR:
[2026-01-25 23:19:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:19:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:19:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:19:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:19:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:19:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:19:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:19:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:19:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:19:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:19:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:19:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=666185) [2026-01-25 23:19:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=666185) [2026-01-25 23:19:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=666185) [2026-01-25 23:19:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=666185) [2026-01-25 23:19:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=666185) [2026-01-25 23:19:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=666185) [2026-01-25 23:19:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=666185) Process EngineCore_DP0:
(EngineCore_DP0 pid=666185) Traceback (most recent call last):
(EngineCore_DP0 pid=666185)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=666185)     self.run()
(EngineCore_DP0 pid=666185)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=666185)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=666185)     raise e
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=666185)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=666185)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=666185)     super().__init__(
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=666185)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=666185)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=666185)     self._init_executor()
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=666185)     self.driver_worker.load_model()
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=666185)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=666185)     raise e
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=666185)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=666185)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=666185)     model = initialize_model(
(EngineCore_DP0 pid=666185)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=666185)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=666185)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=666185)     self.model = Qwen2Model(
(EngineCore_DP0 pid=666185)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=666185)     old_init(self, **kwargs)
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=666185)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=666185)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=666185)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=666185)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=666185)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=666185)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=666185)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=666185)                ^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=666185)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=666185)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=666185)     super().__init__(
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=666185)     self.quant_method.create_weights(
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=666185)     layer.scheme.create_weights(
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 655, in create_weights
(EngineCore_DP0 pid=666185)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=666185)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py", line 67, in create_weights
(EngineCore_DP0 pid=666185)     data=torch.empty(
(EngineCore_DP0 pid=666185)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=666185)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=666185)     return func(*args, **kwargs)
(EngineCore_DP0 pid=666185)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666185) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 70.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 23:19:35.862931358 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=64

========== M=128 ==========
Time: 2026-01-25 23:19:36
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:19:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 70.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     raise e
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 655, in create_weights
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py", line 67, in create_weights
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) ERROR 01-25 23:19:45 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 70.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

STDERR:
[2026-01-25 23:19:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:19:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:19:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:19:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:19:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:19:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:19:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:19:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:19:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:19:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:19:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:19:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=666575) [2026-01-25 23:19:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=666575) [2026-01-25 23:19:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=666575) [2026-01-25 23:19:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=666575) [2026-01-25 23:19:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=666575) [2026-01-25 23:19:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=666575) [2026-01-25 23:19:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=666575) Process EngineCore_DP0:
(EngineCore_DP0 pid=666575) Traceback (most recent call last):
(EngineCore_DP0 pid=666575)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=666575)     self.run()
(EngineCore_DP0 pid=666575)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=666575)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=666575)     raise e
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=666575)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=666575)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=666575)     super().__init__(
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=666575)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=666575)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=666575)     self._init_executor()
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=666575)     self.driver_worker.load_model()
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=666575)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=666575)     raise e
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=666575)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=666575)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=666575)     model = initialize_model(
(EngineCore_DP0 pid=666575)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=666575)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=666575)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=666575)     self.model = Qwen2Model(
(EngineCore_DP0 pid=666575)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=666575)     old_init(self, **kwargs)
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=666575)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=666575)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=666575)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=666575)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=666575)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=666575)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=666575)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=666575)                ^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=666575)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=666575)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=666575)     super().__init__(
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=666575)     self.quant_method.create_weights(
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=666575)     layer.scheme.create_weights(
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 655, in create_weights
(EngineCore_DP0 pid=666575)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=666575)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py", line 67, in create_weights
(EngineCore_DP0 pid=666575)     data=torch.empty(
(EngineCore_DP0 pid=666575)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=666575)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=666575)     return func(*args, **kwargs)
(EngineCore_DP0 pid=666575)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666575) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 70.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 23:19:45.411506014 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=128

========== M=256 ==========
Time: 2026-01-25 23:19:47
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:19:50 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 70.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     raise e
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 655, in create_weights
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py", line 67, in create_weights
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) ERROR 01-25 23:19:55 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 70.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

STDERR:
[2026-01-25 23:19:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:19:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:19:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:19:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:19:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:19:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:19:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:19:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:19:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:19:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:19:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:19:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:19:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:19:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=666967) [2026-01-25 23:19:55] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=666967) [2026-01-25 23:19:55] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=666967) [2026-01-25 23:19:55] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=666967) [2026-01-25 23:19:55] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=666967) [2026-01-25 23:19:55] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=666967) [2026-01-25 23:19:55] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=666967) Process EngineCore_DP0:
(EngineCore_DP0 pid=666967) Traceback (most recent call last):
(EngineCore_DP0 pid=666967)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=666967)     self.run()
(EngineCore_DP0 pid=666967)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=666967)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=666967)     raise e
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=666967)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=666967)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=666967)     super().__init__(
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=666967)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=666967)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=666967)     self._init_executor()
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=666967)     self.driver_worker.load_model()
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=666967)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=666967)     raise e
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=666967)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=666967)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=666967)     model = initialize_model(
(EngineCore_DP0 pid=666967)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=666967)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=666967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=666967)     self.model = Qwen2Model(
(EngineCore_DP0 pid=666967)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=666967)     old_init(self, **kwargs)
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=666967)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=666967)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=666967)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=666967)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=666967)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=666967)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=666967)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=666967)                ^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=666967)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=666967)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=666967)     super().__init__(
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=666967)     self.quant_method.create_weights(
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=666967)     layer.scheme.create_weights(
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 655, in create_weights
(EngineCore_DP0 pid=666967)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=666967)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py", line 67, in create_weights
(EngineCore_DP0 pid=666967)     data=torch.empty(
(EngineCore_DP0 pid=666967)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=666967)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=666967)     return func(*args, **kwargs)
(EngineCore_DP0 pid=666967)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=666967) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 70.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 23:19:56.899542979 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=256

========== M=512 ==========
Time: 2026-01-25 23:19:57
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 23:20:01 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [gpu_model_runner.py:3657] Failed to load model - not enough GPU memory. Try lowering --gpu-memory-utilization to free memory for weights, increasing --tensor-parallel-size, or using --quantization. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more tips. (original error: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 68.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables))
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     self._init_executor()
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     self.driver_worker.load_model()
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     raise e
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     self.model = model_loader.load_model(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     model = initialize_model(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     self.model = Qwen2Model(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]                  ^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     old_init(self, **kwargs)
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]                ^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     self.quant_method.create_weights(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     layer.scheme.create_weights(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 655, in create_weights
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py", line 67, in create_weights
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     data=torch.empty(
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]          ^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) ERROR 01-25 23:20:06 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 68.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

STDERR:
[2026-01-25 23:20:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:20:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:20:01] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:20:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:20:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:20:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:20:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:20:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 23:20:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 23:20:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:20:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-25 23:20:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-25 23:20:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 23:20:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 23:20:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 23:20:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 23:20:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=667351) [2026-01-25 23:20:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=667351) [2026-01-25 23:20:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=667351) [2026-01-25 23:20:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=667351) [2026-01-25 23:20:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=667351) [2026-01-25 23:20:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=667351) [2026-01-25 23:20:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=667351) Process EngineCore_DP0:
(EngineCore_DP0 pid=667351) Traceback (most recent call last):
(EngineCore_DP0 pid=667351)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=667351)     self.run()
(EngineCore_DP0 pid=667351)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=667351)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=667351)     raise e
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=667351)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=667351)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=667351)     super().__init__(
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=667351)     self.model_executor = executor_class(vllm_config)
(EngineCore_DP0 pid=667351)                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 101, in __init__
(EngineCore_DP0 pid=667351)     self._init_executor()
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
(EngineCore_DP0 pid=667351)     self.driver_worker.load_model()
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 289, in load_model
(EngineCore_DP0 pid=667351)     self.model_runner.load_model(eep_scale_up=eep_scale_up)
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3658, in load_model
(EngineCore_DP0 pid=667351)     raise e
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 3581, in load_model
(EngineCore_DP0 pid=667351)     self.model = model_loader.load_model(
(EngineCore_DP0 pid=667351)                  ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
(EngineCore_DP0 pid=667351)     model = initialize_model(
(EngineCore_DP0 pid=667351)             ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/model_loader/utils.py", line 48, in initialize_model
(EngineCore_DP0 pid=667351)     return model_class(vllm_config=vllm_config, prefix=prefix)
(EngineCore_DP0 pid=667351)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 543, in __init__
(EngineCore_DP0 pid=667351)     self.model = Qwen2Model(
(EngineCore_DP0 pid=667351)                  ^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/compilation/decorators.py", line 291, in __init__
(EngineCore_DP0 pid=667351)     old_init(self, **kwargs)
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 394, in __init__
(EngineCore_DP0 pid=667351)     self.start_layer, self.end_layer, self.layers = make_layers(
(EngineCore_DP0 pid=667351)                                                     ^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/models/utils.py", line 606, in make_layers
(EngineCore_DP0 pid=667351)     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
(EngineCore_DP0 pid=667351)                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 396, in <lambda>
(EngineCore_DP0 pid=667351)     lambda prefix: decoder_layer_type(
(EngineCore_DP0 pid=667351)                    ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 272, in __init__
(EngineCore_DP0 pid=667351)     self.mlp = Qwen2MLP(
(EngineCore_DP0 pid=667351)                ^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 85, in __init__
(EngineCore_DP0 pid=667351)     self.gate_up_proj = MergedColumnParallelLinear(
(EngineCore_DP0 pid=667351)                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 631, in __init__
(EngineCore_DP0 pid=667351)     super().__init__(
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/layers/linear.py", line 484, in __init__
(EngineCore_DP0 pid=667351)     self.quant_method.create_weights(
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py", line 932, in create_weights
(EngineCore_DP0 pid=667351)     layer.scheme.create_weights(
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/slidesparse/core/SlideSparseLinearMethod_INT8.py", line 655, in create_weights
(EngineCore_DP0 pid=667351)     return self.original_scheme.create_weights(
(EngineCore_DP0 pid=667351)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/root/vllmbench/vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py", line 67, in create_weights
(EngineCore_DP0 pid=667351)     data=torch.empty(
(EngineCore_DP0 pid=667351)          ^^^^^^^^^^^^
(EngineCore_DP0 pid=667351)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_device.py", line 103, in __torch_function__
(EngineCore_DP0 pid=667351)     return func(*args, **kwargs)
(EngineCore_DP0 pid=667351)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=667351) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 216.00 MiB. GPU 0 has a total capacity of 15.46 GiB of which 120.94 MiB is free. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 68.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W125 23:20:06.640774178 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=128 ==========
Time: 2026-01-26 03:22:40
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.85 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:22:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=914794) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=914794) WARNING 01-26 03:22:56 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 459, in compile_or_warm_up_model
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     cuda_graph_memory_bytes = self.model_runner.capture_model()
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4540, in capture_model
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     self._capture_cudagraphs(
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4641, in _capture_cudagraphs
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     self._dummy_run(
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     hidden_states = self.model(
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]                     ^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     def forward(
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return fn(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     raise e
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "<eval_with_key>.58", line 346, in forward
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     submod_8 = self.submod_8(getitem_18, s72, l_self_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_post_attention_layernorm_parameters_weight_, getitem_19, l_self_modules_layers_modules_3_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_3_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_3_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_4_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_18 = l_self_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_post_attention_layernorm_parameters_weight_ = getitem_19 = l_self_modules_layers_modules_3_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_3_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_3_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_4_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return range_entry.runnable(*args)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/vllm/compilation/compiler_interface.py", line 268, in compiled_graph_wrapper
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     graph_output = inductor_compiled_graph(*args)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return self._compiled_fn(*args)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 184, in <lambda>
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return CompiledArtifact(lambda *args: compiled_fn(list(args)), None)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]                                           ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]                             ^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return self.current_callable(inputs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     out = model(new_inputs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/tmp/torchinductor_root/gf/cgfdacf5mdofsioguze4gd3476smitxucnxsvsy4pxfxg3ysc4fg.py", line 950, in call
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     buf12 = torch.ops.slidesparse.cusparselt_int8_mm.default(arg6_1, buf10, 37888, 5760, 'bf16')
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/gemm_wrapper.py", line 1120, in _cusparselt_int8_mm_impl
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     return ext.cusparselt_int8_mm(weight_compressed, qinput, N, K_slide, inner_dtype,
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]   File "/root/vllmbench/slidesparse/core/gemm_wrapper.py", line 800, in cusparselt_int8_mm
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]     output = torch.empty((M_pad, N), dtype=out_dtype, device=qinput.device)
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) ERROR 01-26 03:23:01 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.47 GiB of which 18.94 MiB is free. Including non-PyTorch memory, this process has 15.43 GiB memory in use. Of the allocated memory 12.46 GiB is allocated by PyTorch, with 68.00 MiB allocated in private pools (e.g., CUDA Graphs), and 2.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

STDERR:
[2026-01-26 03:22:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:22:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:22:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:22:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:22:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:22:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:22:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:22:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:22:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:22:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:22:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:22:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:22:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:22:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:22:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:22:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:22:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:49] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:49] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:49] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:49] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:49] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=914794) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=914794) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.16it/s]
(EngineCore_DP0 pid=914794) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.26s/it]
(EngineCore_DP0 pid=914794) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.20s/it]
(EngineCore_DP0 pid=914794) 
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=914794) [2026-01-26 03:22:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=914794) 2026-01-26 03:22:59,489 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=914794) 2026-01-26 03:22:59,503 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=914794) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:01, 23.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:00<00:01, 26.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:00<00:00, 26.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:00<00:01, 17.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:00<00:01, 17.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:00<00:00, 19.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:01<00:00, 21.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:01<00:00, 23.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:01<00:00, 22.05it/s]
(EngineCore_DP0 pid=914794) Process EngineCore_DP0:
(EngineCore_DP0 pid=914794) Traceback (most recent call last):
(EngineCore_DP0 pid=914794)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=914794)     self.run()
(EngineCore_DP0 pid=914794)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=914794)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=914794)     raise e
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=914794)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=914794)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=914794)     super().__init__(
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=914794)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=914794)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=914794)     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=914794)     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=914794)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=914794)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=914794)     return func(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 459, in compile_or_warm_up_model
(EngineCore_DP0 pid=914794)     cuda_graph_memory_bytes = self.model_runner.capture_model()
(EngineCore_DP0 pid=914794)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4540, in capture_model
(EngineCore_DP0 pid=914794)     self._capture_cudagraphs(
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4641, in _capture_cudagraphs
(EngineCore_DP0 pid=914794)     self._dummy_run(
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=914794)     return func(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=914794)     outputs = self.model(
(EngineCore_DP0 pid=914794)               ^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=914794)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=914794)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=914794)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
(EngineCore_DP0 pid=914794)     hidden_states = self.model(
(EngineCore_DP0 pid=914794)                     ^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/compilation/decorators.py", line 439, in __call__
(EngineCore_DP0 pid=914794)     return TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 223, in __call__
(EngineCore_DP0 pid=914794)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=914794)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
(EngineCore_DP0 pid=914794)     def forward(
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
(EngineCore_DP0 pid=914794)     return fn(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
(EngineCore_DP0 pid=914794)     return self.optimized_call(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
(EngineCore_DP0 pid=914794)     return self._wrapped_call(self, *args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
(EngineCore_DP0 pid=914794)     raise e
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
(EngineCore_DP0 pid=914794)     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=914794)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=914794)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "<eval_with_key>.58", line 346, in forward
(EngineCore_DP0 pid=914794)     submod_8 = self.submod_8(getitem_18, s72, l_self_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_post_attention_layernorm_parameters_weight_, getitem_19, l_self_modules_layers_modules_3_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_3_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_3_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_3_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_4_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_18 = l_self_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_3_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_post_attention_layernorm_parameters_weight_ = getitem_19 = l_self_modules_layers_modules_3_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_3_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_3_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_3_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_4_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_4_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
(EngineCore_DP0 pid=914794)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=914794)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
(EngineCore_DP0 pid=914794)     return range_entry.runnable(*args)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/vllm/compilation/compiler_interface.py", line 268, in compiled_graph_wrapper
(EngineCore_DP0 pid=914794)     graph_output = inductor_compiled_graph(*args)
(EngineCore_DP0 pid=914794)                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
(EngineCore_DP0 pid=914794)     return self._compiled_fn(*args)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 184, in <lambda>
(EngineCore_DP0 pid=914794)     return CompiledArtifact(lambda *args: compiled_fn(list(args)), None)
(EngineCore_DP0 pid=914794)                                           ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
(EngineCore_DP0 pid=914794)     all_outs = call_func_at_runtime_with_args(
(EngineCore_DP0 pid=914794)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
(EngineCore_DP0 pid=914794)     out = normalize_as_list(f(args))
(EngineCore_DP0 pid=914794)                             ^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
(EngineCore_DP0 pid=914794)     return compiled_fn(runtime_args)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
(EngineCore_DP0 pid=914794)     return self.current_callable(inputs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
(EngineCore_DP0 pid=914794)     out = model(new_inputs)
(EngineCore_DP0 pid=914794)           ^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/tmp/torchinductor_root/gf/cgfdacf5mdofsioguze4gd3476smitxucnxsvsy4pxfxg3ysc4fg.py", line 950, in call
(EngineCore_DP0 pid=914794)     buf12 = torch.ops.slidesparse.cusparselt_int8_mm.default(arg6_1, buf10, 37888, 5760, 'bf16')
(EngineCore_DP0 pid=914794)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
(EngineCore_DP0 pid=914794)     return self._op(*args, **kwargs)
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/slidesparse/core/gemm_wrapper.py", line 1120, in _cusparselt_int8_mm_impl
(EngineCore_DP0 pid=914794)     return ext.cusparselt_int8_mm(weight_compressed, qinput, N, K_slide, inner_dtype,
(EngineCore_DP0 pid=914794)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794)   File "/root/vllmbench/slidesparse/core/gemm_wrapper.py", line 800, in cusparselt_int8_mm
(EngineCore_DP0 pid=914794)     output = torch.empty((M_pad, N), dtype=out_dtype, device=qinput.device)
(EngineCore_DP0 pid=914794)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=914794) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.47 GiB of which 18.94 MiB is free. Including non-PyTorch memory, this process has 15.43 GiB memory in use. Of the allocated memory 12.46 GiB is allocated by PyTorch, with 68.00 MiB allocated in private pools (e.g., CUDA Graphs), and 2.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W126 03:23:01.375505093 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=128

========== M=128 ==========
Time: 2026-01-26 03:23:12
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.7999999999999999 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:23:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=915638) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=915638) WARNING 01-26 03:23:28 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.25 requests/s, 8226.64 total tokens/s, 7742.72 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 03:23:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:23:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:23:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:23:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:23:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:23:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:23:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:23:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:23:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:23:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:23:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:23:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:23:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:23:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:23:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:23:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:21] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:21] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:21] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:21] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:21] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=915638) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=915638) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.29it/s]
(EngineCore_DP0 pid=915638) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.00it/s]
(EngineCore_DP0 pid=915638) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=915638) 
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:23] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=915638) [2026-01-26 03:23:23] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=915638) 2026-01-26 03:23:31,885 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=915638) 2026-01-26 03:23:31,899 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=915638) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:01, 25.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:00<00:01, 26.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:00<00:01, 25.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:00<00:00, 26.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:00<00:00, 27.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:00<00:00, 27.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:00<00:00, 27.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:00<00:00, 27.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:01<00:00, 23.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:01<00:00, 21.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:01<00:00, 22.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 24.54it/s]
(EngineCore_DP0 pid=915638) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  7.58it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:00<00:00, 21.61it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:00<00:00, 26.25it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:00<00:00, 28.62it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:00<00:00, 30.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 27.53it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 4174.48it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:04<08:34,  4.05s/it, est. speed input: 3.95 toks/s, output: 63.24 toks/s]
Processed prompts:  68%|██████▊   | 87/128 [00:04<00:01, 29.52it/s, est. speed input: 335.30 toks/s, output: 5364.76 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 29.52it/s, est. speed input: 487.75 toks/s, output: 7803.96 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 30.48it/s, est. speed input: 487.75 toks/s, output: 7803.96 toks/s]
[rank0]:[W126 03:23:39.081488101 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 03:23:54
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:23:58 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=916656) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=916656) WARNING 01-26 03:24:10 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4302, in _dummy_sampler_run
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     sampler_output = self.sampler(
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]                      ^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 96, in forward
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     sampled, processed_logprobs = self.sample(logits, sampling_metadata)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 187, in sample
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     random_sampled, processed_logprobs = self.topk_topp_sampler(
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]                                          ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 104, in forward_native
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     logits = self.apply_top_k_top_p(logits, k, p)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 258, in apply_top_k_top_p
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 892.00 MiB. GPU 0 has a total capacity of 15.47 GiB of which 790.94 MiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 11.57 GiB is allocated by PyTorch, with 142.00 MiB allocated in private pools (e.g., CUDA Graphs), and 2.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866] 
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866] The above exception was the direct cause of the following exception:
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866] 
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 538, in compile_or_warm_up_model
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     self.model_runner._dummy_sampler_run(hidden_states=last_hidden_states)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4307, in _dummy_sampler_run
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866]     raise RuntimeError(
(EngineCore_DP0 pid=916656) ERROR 01-26 03:24:17 [core.py:866] RuntimeError: CUDA out of memory occurred when warming up sampler with 512 dummy requests. Please try lowering `max_num_seqs` or `gpu_memory_utilization` when initializing the engine.

STDERR:
[2026-01-26 03:23:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:23:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:23:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:23:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:23:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:23:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:23:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:23:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:23:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:24:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:24:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:24:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:24:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:24:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:24:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:24:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:24:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:03] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:03] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:03] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:03] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:03] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:03] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=916656) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=916656) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.29it/s]
(EngineCore_DP0 pid=916656) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.00it/s]
(EngineCore_DP0 pid=916656) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=916656) 
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:05] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=916656) [2026-01-26 03:24:05] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=916656) 2026-01-26 03:24:13,486 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=916656) 2026-01-26 03:24:13,500 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=916656) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:02, 20.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:02, 20.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:00<00:01, 21.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:00<00:01, 21.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:00<00:01, 22.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:00<00:01, 23.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:00<00:01, 24.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:01<00:01, 25.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:01<00:00, 26.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:01<00:00, 26.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:01<00:00, 26.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:01<00:00, 18.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:01<00:00, 18.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:01<00:00, 21.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:01<00:00, 22.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:02<00:00, 25.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:02<00:00, 23.30it/s]
(EngineCore_DP0 pid=916656) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:07,  6.84it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:02, 15.76it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:00<00:02, 19.08it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:00<00:01, 20.86it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:00<00:01, 22.99it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:00<00:01, 24.58it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:00<00:01, 26.58it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:01<00:00, 27.97it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:01<00:00, 29.10it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:01<00:00, 29.86it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:01<00:00, 30.78it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:01<00:00, 31.55it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:01<00:00, 30.59it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:01<00:00, 31.22it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:01<00:00, 27.46it/s]
(EngineCore_DP0 pid=916656) Process EngineCore_DP0:
(EngineCore_DP0 pid=916656) Traceback (most recent call last):
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4302, in _dummy_sampler_run
(EngineCore_DP0 pid=916656)     sampler_output = self.sampler(
(EngineCore_DP0 pid=916656)                      ^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=916656)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=916656)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=916656)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=916656)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 96, in forward
(EngineCore_DP0 pid=916656)     sampled, processed_logprobs = self.sample(logits, sampling_metadata)
(EngineCore_DP0 pid=916656)                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 187, in sample
(EngineCore_DP0 pid=916656)     random_sampled, processed_logprobs = self.topk_topp_sampler(
(EngineCore_DP0 pid=916656)                                          ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=916656)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=916656)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=916656)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=916656)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 104, in forward_native
(EngineCore_DP0 pid=916656)     logits = self.apply_top_k_top_p(logits, k, p)
(EngineCore_DP0 pid=916656)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 258, in apply_top_k_top_p
(EngineCore_DP0 pid=916656)     logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
(EngineCore_DP0 pid=916656)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 892.00 MiB. GPU 0 has a total capacity of 15.47 GiB of which 790.94 MiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 11.57 GiB is allocated by PyTorch, with 142.00 MiB allocated in private pools (e.g., CUDA Graphs), and 2.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
(EngineCore_DP0 pid=916656) 
(EngineCore_DP0 pid=916656) The above exception was the direct cause of the following exception:
(EngineCore_DP0 pid=916656) 
(EngineCore_DP0 pid=916656) Traceback (most recent call last):
(EngineCore_DP0 pid=916656)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=916656)     self.run()
(EngineCore_DP0 pid=916656)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=916656)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=916656)     raise e
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=916656)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=916656)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=916656)     super().__init__(
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=916656)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=916656)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=916656)     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=916656)     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=916656)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=916656)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=916656)     return func(*args, **kwargs)
(EngineCore_DP0 pid=916656)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 538, in compile_or_warm_up_model
(EngineCore_DP0 pid=916656)     self.model_runner._dummy_sampler_run(hidden_states=last_hidden_states)
(EngineCore_DP0 pid=916656)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=916656)     return func(*args, **kwargs)
(EngineCore_DP0 pid=916656)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=916656)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4307, in _dummy_sampler_run
(EngineCore_DP0 pid=916656)     raise RuntimeError(
(EngineCore_DP0 pid=916656) RuntimeError: CUDA out of memory occurred when warming up sampler with 512 dummy requests. Please try lowering `max_num_seqs` or `gpu_memory_utilization` when initializing the engine.
[rank0]:[W126 03:24:18.188071163 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=512 ==========
Time: 2026-01-26 03:24:29
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.75 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 03:24:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=917550) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=917550) WARNING 01-26 03:24:44 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=917550) ERROR 01-26 03:24:47 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.

STDERR:
[2026-01-26 03:24:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:24:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:24:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:24:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:24:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:24:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:24:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:24:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 03:24:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 03:24:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:24:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 03:24:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 03:24:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 03:24:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 03:24:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 03:24:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 03:24:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=917550) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=917550) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.30it/s]
(EngineCore_DP0 pid=917550) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.00it/s]
(EngineCore_DP0 pid=917550) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=917550) 
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:40] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=917550) [2026-01-26 03:24:40] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=917550) Process EngineCore_DP0:
(EngineCore_DP0 pid=917550) Traceback (most recent call last):
(EngineCore_DP0 pid=917550)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=917550)     self.run()
(EngineCore_DP0 pid=917550)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=917550)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=917550)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=917550)     raise e
(EngineCore_DP0 pid=917550)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=917550)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=917550)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=917550)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=917550)     super().__init__(
(EngineCore_DP0 pid=917550)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=917550)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=917550)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=917550)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=917550)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=917550)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=917550)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=917550)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=917550)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=917550)     raise ValueError(
(EngineCore_DP0 pid=917550) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 03:24:48.934048668 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=512 ==========
Time: 2026-01-26 04:18:40
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:18:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=962651) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=962651) WARNING 01-26 04:18:55 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4302, in _dummy_sampler_run
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     sampler_output = self.sampler(
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]                      ^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 96, in forward
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     sampled, processed_logprobs = self.sample(logits, sampling_metadata)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 187, in sample
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     random_sampled, processed_logprobs = self.topk_topp_sampler(
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]                                          ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 104, in forward_native
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     logits = self.apply_top_k_top_p(logits, k, p)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 258, in apply_top_k_top_p
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 892.00 MiB. GPU 0 has a total capacity of 15.47 GiB of which 790.94 MiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 11.57 GiB is allocated by PyTorch, with 142.00 MiB allocated in private pools (e.g., CUDA Graphs), and 2.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866] 
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866] The above exception was the direct cause of the following exception:
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866] 
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 538, in compile_or_warm_up_model
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     self.model_runner._dummy_sampler_run(hidden_states=last_hidden_states)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4307, in _dummy_sampler_run
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866]     raise RuntimeError(
(EngineCore_DP0 pid=962651) ERROR 01-26 04:19:03 [core.py:866] RuntimeError: CUDA out of memory occurred when warming up sampler with 512 dummy requests. Please try lowering `max_num_seqs` or `gpu_memory_utilization` when initializing the engine.

STDERR:
[2026-01-26 04:18:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:18:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:18:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:18:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:18:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:18:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:18:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:18:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:18:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:18:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:18:48] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:18:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:18:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:18:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:18:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:18:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:18:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:49] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:49] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:49] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:49] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:49] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=962651) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=962651) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.30it/s]
(EngineCore_DP0 pid=962651) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.01it/s]
(EngineCore_DP0 pid=962651) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=962651) 
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:51] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=962651) [2026-01-26 04:18:51] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=962651) 2026-01-26 04:18:58,952 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=962651) 2026-01-26 04:18:58,966 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=962651) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:02, 20.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:02, 20.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:00<00:01, 21.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:00<00:01, 22.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:00<00:01, 22.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:00<00:01, 23.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:00<00:01, 21.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:01<00:01, 19.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:01<00:01, 19.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:01<00:00, 21.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:01<00:00, 23.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:01<00:00, 24.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:01<00:00, 25.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:01<00:00, 26.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:02<00:00, 27.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:02<00:00, 27.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:02<00:00, 23.78it/s]
(EngineCore_DP0 pid=962651) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:07,  6.72it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:03, 15.62it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:00<00:02, 18.96it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:00<00:01, 20.91it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:00<00:01, 23.03it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:00<00:01, 24.70it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:00<00:01, 26.67it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:01<00:00, 27.90it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:01<00:00, 28.97it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:01<00:00, 29.70it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:01<00:00, 30.46it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:01<00:00, 30.84it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:01<00:00, 30.79it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:01<00:00, 28.66it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:01<00:00, 25.93it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:01<00:00, 26.02it/s]
(EngineCore_DP0 pid=962651) Process EngineCore_DP0:
(EngineCore_DP0 pid=962651) Traceback (most recent call last):
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4302, in _dummy_sampler_run
(EngineCore_DP0 pid=962651)     sampler_output = self.sampler(
(EngineCore_DP0 pid=962651)                      ^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=962651)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=962651)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=962651)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=962651)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 96, in forward
(EngineCore_DP0 pid=962651)     sampled, processed_logprobs = self.sample(logits, sampling_metadata)
(EngineCore_DP0 pid=962651)                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/sample/sampler.py", line 187, in sample
(EngineCore_DP0 pid=962651)     random_sampled, processed_logprobs = self.topk_topp_sampler(
(EngineCore_DP0 pid=962651)                                          ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=962651)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=962651)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=962651)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=962651)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 104, in forward_native
(EngineCore_DP0 pid=962651)     logits = self.apply_top_k_top_p(logits, k, p)
(EngineCore_DP0 pid=962651)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/sample/ops/topk_topp_sampler.py", line 258, in apply_top_k_top_p
(EngineCore_DP0 pid=962651)     logits_sort, logits_idx = logits.sort(dim=-1, descending=False)
(EngineCore_DP0 pid=962651)                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651) torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 892.00 MiB. GPU 0 has a total capacity of 15.47 GiB of which 790.94 MiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 11.57 GiB is allocated by PyTorch, with 142.00 MiB allocated in private pools (e.g., CUDA Graphs), and 2.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
(EngineCore_DP0 pid=962651) 
(EngineCore_DP0 pid=962651) The above exception was the direct cause of the following exception:
(EngineCore_DP0 pid=962651) 
(EngineCore_DP0 pid=962651) Traceback (most recent call last):
(EngineCore_DP0 pid=962651)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=962651)     self.run()
(EngineCore_DP0 pid=962651)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=962651)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=962651)     raise e
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=962651)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=962651)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=962651)     super().__init__(
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=962651)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=962651)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/engine/core.py", line 256, in _initialize_kv_caches
(EngineCore_DP0 pid=962651)     self.model_executor.initialize_from_config(kv_cache_configs)
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 116, in initialize_from_config
(EngineCore_DP0 pid=962651)     self.collective_rpc("compile_or_warm_up_model")
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=962651)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=962651)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=962651)     return func(*args, **kwargs)
(EngineCore_DP0 pid=962651)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 538, in compile_or_warm_up_model
(EngineCore_DP0 pid=962651)     self.model_runner._dummy_sampler_run(hidden_states=last_hidden_states)
(EngineCore_DP0 pid=962651)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=962651)     return func(*args, **kwargs)
(EngineCore_DP0 pid=962651)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=962651)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4307, in _dummy_sampler_run
(EngineCore_DP0 pid=962651)     raise RuntimeError(
(EngineCore_DP0 pid=962651) RuntimeError: CUDA out of memory occurred when warming up sampler with 512 dummy requests. Please try lowering `max_num_seqs` or `gpu_memory_utilization` when initializing the engine.
[rank0]:[W126 04:19:03.728935890 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=512 ==========
Time: 2026-01-26 04:20:01
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.7 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:20:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=964180) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=964180) WARNING 01-26 04:20:16 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=964180) ERROR 01-26 04:20:19 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.

STDERR:
[2026-01-26 04:20:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:20:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:20:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:20:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:20:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:20:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:20:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:20:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:20:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:20:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:20:09] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:20:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:20:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:20:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:20:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:20:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:20:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:09] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:09] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:09] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:09] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:09] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=964180) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=964180) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.29it/s]
(EngineCore_DP0 pid=964180) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.01it/s]
(EngineCore_DP0 pid=964180) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=964180) 
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:12] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=964180) [2026-01-26 04:20:12] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=964180) Process EngineCore_DP0:
(EngineCore_DP0 pid=964180) Traceback (most recent call last):
(EngineCore_DP0 pid=964180)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=964180)     self.run()
(EngineCore_DP0 pid=964180)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=964180)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=964180)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=964180)     raise e
(EngineCore_DP0 pid=964180)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=964180)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=964180)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=964180)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=964180)     super().__init__(
(EngineCore_DP0 pid=964180)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=964180)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=964180)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=964180)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=964180)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=964180)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=964180)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=964180)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=964180)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=964180)     raise ValueError(
(EngineCore_DP0 pid=964180) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 04:20:20.054148615 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=512 ==========
Time: 2026-01-26 04:26:08
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.6 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:26:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=969710) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=969710) WARNING 01-26 04:26:23 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=969710) ERROR 01-26 04:26:26 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.

STDERR:
[2026-01-26 04:26:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:26:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:26:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:26:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:26:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:26:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:26:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:26:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:26:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:26:16] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:26:16] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:16] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:16] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:16] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:16] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:16] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:26:16] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:26:16] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:26:16] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:26:16] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:26:16] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:26:16] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:17] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:17] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:17] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:17] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:17] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:17] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=969710) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=969710) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.29it/s]
(EngineCore_DP0 pid=969710) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.00it/s]
(EngineCore_DP0 pid=969710) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=969710) 
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:19] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=969710) [2026-01-26 04:26:19] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=969710) Process EngineCore_DP0:
(EngineCore_DP0 pid=969710) Traceback (most recent call last):
(EngineCore_DP0 pid=969710)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=969710)     self.run()
(EngineCore_DP0 pid=969710)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=969710)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=969710)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=969710)     raise e
(EngineCore_DP0 pid=969710)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=969710)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=969710)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=969710)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=969710)     super().__init__(
(EngineCore_DP0 pid=969710)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=969710)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=969710)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=969710)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=969710)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=969710)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=969710)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=969710)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=969710)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=969710)     raise ValueError(
(EngineCore_DP0 pid=969710) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 04:26:27.071879127 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=512 ==========
Time: 2026-01-26 04:30:30
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.55 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:30:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=973709) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=973709) WARNING 01-26 04:30:45 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=973709) ERROR 01-26 04:30:49 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.

STDERR:
[2026-01-26 04:30:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:30:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:30:34] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:34] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:34] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:30:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:30:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:30:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:30:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:30:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:30:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:30:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:30:38] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:30:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:30:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:30:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:30:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:30:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:30:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:39] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=973709) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=973709) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.29it/s]
(EngineCore_DP0 pid=973709) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.01it/s]
(EngineCore_DP0 pid=973709) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=973709) 
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=973709) [2026-01-26 04:30:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=973709) Process EngineCore_DP0:
(EngineCore_DP0 pid=973709) Traceback (most recent call last):
(EngineCore_DP0 pid=973709)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=973709)     self.run()
(EngineCore_DP0 pid=973709)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=973709)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=973709)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=973709)     raise e
(EngineCore_DP0 pid=973709)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=973709)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=973709)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=973709)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=973709)     super().__init__(
(EngineCore_DP0 pid=973709)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=973709)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=973709)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=973709)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=973709)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=973709)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=973709)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=973709)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=973709)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=973709)     raise ValueError(
(EngineCore_DP0 pid=973709) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 04:30:49.331524830 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=512 ==========
Time: 2026-01-26 04:34:58
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.7 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:35:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:35:02 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=977926) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=977926) ERROR 01-26 04:35:11 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.

STDERR:
[2026-01-26 04:35:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:35:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:35:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:35:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:35:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:35:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:35:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:35:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:35:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:35:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:35:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:35:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:35:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:35:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:35:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:35:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:35:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:07] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:07] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:07] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:07] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:07] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=977926) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=977926) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.29it/s]
(EngineCore_DP0 pid=977926) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.00it/s]
(EngineCore_DP0 pid=977926) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=977926) 
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=977926) [2026-01-26 04:35:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=977926) Process EngineCore_DP0:
(EngineCore_DP0 pid=977926) Traceback (most recent call last):
(EngineCore_DP0 pid=977926)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=977926)     self.run()
(EngineCore_DP0 pid=977926)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=977926)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=977926)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=977926)     raise e
(EngineCore_DP0 pid=977926)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=977926)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=977926)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=977926)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=977926)     super().__init__(
(EngineCore_DP0 pid=977926)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=977926)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=977926)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=977926)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=977926)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=977926)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=977926)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=977926)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=977926)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=977926)     raise ValueError(
(EngineCore_DP0 pid=977926) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 04:35:11.365612174 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=512 ==========
Time: 2026-01-26 04:41:12
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.5 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json --enforce-eager


========== M=512 ==========
Time: 2026-01-26 04:41:28
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.5 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:41:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:41:32 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=984173) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=984173) ERROR 01-26 04:41:41 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.

STDERR:
[2026-01-26 04:41:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:41:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:41:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:41:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:41:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:41:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:41:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:41:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:41:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:41:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:41:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:41:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:41:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:41:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:41:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:41:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=984173) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=984173) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.29it/s]
(EngineCore_DP0 pid=984173) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.01it/s]
(EngineCore_DP0 pid=984173) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=984173) 
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=984173) [2026-01-26 04:41:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=984173) Process EngineCore_DP0:
(EngineCore_DP0 pid=984173) Traceback (most recent call last):
(EngineCore_DP0 pid=984173)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=984173)     self.run()
(EngineCore_DP0 pid=984173)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=984173)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=984173)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=984173)     raise e
(EngineCore_DP0 pid=984173)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=984173)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=984173)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984173)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=984173)     super().__init__(
(EngineCore_DP0 pid=984173)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=984173)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=984173)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984173)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=984173)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=984173)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984173)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=984173)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=984173)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=984173)     raise ValueError(
(EngineCore_DP0 pid=984173) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 04:41:41.320744664 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=512 ==========
Time: 2026-01-26 04:41:50
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.5 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-INT8_M512.json --enforce-eager

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:41:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 04:41:54 [vllm.py:622] Enforce eager set, overriding optimization level to -O0
(EngineCore_DP0 pid=984841) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866]     raise ValueError(
(EngineCore_DP0 pid=984841) ERROR 01-26 04:42:03 [core.py:866] ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.

STDERR:
[2026-01-26 04:41:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:41:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:41:54] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:41:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:41:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:41:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:41:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:41:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:41:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:41:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:41:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 04:41:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 04:41:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 04:41:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:41:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:41:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:41:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=984841) [2026-01-26 04:41:59] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=984841) [2026-01-26 04:41:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=984841) [2026-01-26 04:41:59] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=984841) [2026-01-26 04:41:59] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=984841) [2026-01-26 04:41:59] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=984841) [2026-01-26 04:41:59] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=984841) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=984841) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.29it/s]
(EngineCore_DP0 pid=984841) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.00it/s]
(EngineCore_DP0 pid=984841) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.04it/s]
(EngineCore_DP0 pid=984841) 
(EngineCore_DP0 pid=984841) [2026-01-26 04:42:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=984841) [2026-01-26 04:42:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19906560 bytes
(EngineCore_DP0 pid=984841) [2026-01-26 04:42:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=984841) [2026-01-26 04:42:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 15482880 bytes
(EngineCore_DP0 pid=984841) [2026-01-26 04:42:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=984841) [2026-01-26 04:42:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 163676160 bytes
(EngineCore_DP0 pid=984841) [2026-01-26 04:42:01] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=984841) [2026-01-26 04:42:01] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 81543168 bytes
(EngineCore_DP0 pid=984841) Process EngineCore_DP0:
(EngineCore_DP0 pid=984841) Traceback (most recent call last):
(EngineCore_DP0 pid=984841)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=984841)     self.run()
(EngineCore_DP0 pid=984841)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=984841)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=984841)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=984841)     raise e
(EngineCore_DP0 pid=984841)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=984841)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=984841)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984841)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=984841)     super().__init__(
(EngineCore_DP0 pid=984841)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=984841)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=984841)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984841)   File "/root/vllmbench/vllm/v1/engine/core.py", line 248, in _initialize_kv_caches
(EngineCore_DP0 pid=984841)     kv_cache_configs = get_kv_cache_configs(
(EngineCore_DP0 pid=984841)                        ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=984841)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 1340, in get_kv_cache_configs
(EngineCore_DP0 pid=984841)     check_enough_kv_cache_memory(
(EngineCore_DP0 pid=984841)   File "/root/vllmbench/vllm/v1/core/kv_cache_utils.py", line 687, in check_enough_kv_cache_memory
(EngineCore_DP0 pid=984841)     raise ValueError(
(EngineCore_DP0 pid=984841) ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine. See https://docs.vllm.ai/en/latest/configuration/conserving_memory/ for more details.
[rank0]:[W126 04:42:03.376991876 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=64 ==========
Time: 2026-01-28 01:17:36
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 01:17:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3540150) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3540150) WARNING 01-28 01:17:49 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.48 requests/s, 8563.76 total tokens/s, 8060.01 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-28 01:17:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 01:17:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 01:17:40] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 01:17:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:17:40] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:17:40] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:17:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:17:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:17:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 01:17:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 01:17:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 01:17:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 01:17:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 01:17:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 01:17:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 01:17:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 01:17:44] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 01:17:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:17:44] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:17:44] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:17:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:17:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:17:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 01:17:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 01:17:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 01:17:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 01:17:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 01:17:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:44] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:44] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:44] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:44] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:44] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:44] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3540150) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3540150) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.47it/s]
(EngineCore_DP0 pid=3540150) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.47it/s]
(EngineCore_DP0 pid=3540150) 
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11796480 bytes
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42467328 bytes
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:45] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3540150) [2026-01-28 01:17:45] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21299200 bytes
(EngineCore_DP0 pid=3540150) 2026-01-28 01:17:55,669 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3540150) 2026-01-28 01:17:55,684 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3540150) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:04,  3.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:04,  4.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:00<00:01, 10.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:00<00:00, 14.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:00<00:00, 17.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:00<00:00, 20.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:01<00:00, 21.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 15.78it/s]
(EngineCore_DP0 pid=3540150) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  6.58it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:00, 11.15it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 13.87it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 19.27it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 18.39it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2562.68it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:01<02:04,  1.97s/it, est. speed input: 8.11 toks/s, output: 129.74 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:02<00:00,  1.97s/it, est. speed input: 510.52 toks/s, output: 8168.28 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:02<00:00, 31.91it/s, est. speed input: 510.52 toks/s, output: 8168.28 toks/s]
[rank0]:[W128 01:18:00.421515407 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-28 01:18:01
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 01:18:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3540816) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3540816) WARNING 01-28 01:18:14 [backends.py:609] Failed to read file <frozen os>
Throughput: 51.02 requests/s, 13877.27 total tokens/s, 13060.96 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-28 01:18:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 01:18:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 01:18:05] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 01:18:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:05] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:05] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 01:18:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 01:18:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 01:18:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 01:18:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 01:18:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 01:18:09] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 01:18:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 01:18:09] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 01:18:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:09] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:09] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 01:18:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 01:18:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 01:18:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 01:18:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 01:18:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3540816) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3540816) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=3540816) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.56it/s]
(EngineCore_DP0 pid=3540816) 
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11796480 bytes
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42467328 bytes
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3540816) [2026-01-28 01:18:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21299200 bytes
(EngineCore_DP0 pid=3540816) 2026-01-28 01:18:19,184 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3540816) 2026-01-28 01:18:19,201 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3540816) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:04,  6.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:06,  5.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:00<00:02, 11.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:00<00:01, 16.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:00<00:01, 19.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:00<00:00, 21.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:00<00:00, 22.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:01<00:00, 23.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:01<00:00, 24.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:01<00:00, 24.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:01<00:00, 23.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:01<00:00, 24.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 22.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 20.45it/s]
(EngineCore_DP0 pid=3540816) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:03,  5.93it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:01, 10.40it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:00<00:01, 13.36it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:00<00:00, 18.68it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:00<00:00, 21.99it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:00<00:00, 23.60it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:00<00:00, 25.48it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 20.98it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 3861.30it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:02<05:03,  2.39s/it, est. speed input: 6.70 toks/s, output: 107.16 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00,  2.39s/it, est. speed input: 827.86 toks/s, output: 13245.81 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00, 51.74it/s, est. speed input: 827.86 toks/s, output: 13245.81 toks/s]
[rank0]:[W128 01:18:25.152191407 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-28 01:18:26
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 01:18:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3541451) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3541451) WARNING 01-28 01:18:39 [backends.py:609] Failed to read file <frozen os>
Throughput: 60.08 requests/s, 16342.35 total tokens/s, 15381.04 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-28 01:18:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 01:18:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 01:18:30] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 01:18:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:30] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:30] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 01:18:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 01:18:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 01:18:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 01:18:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 01:18:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 01:18:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 01:18:34] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 01:18:34] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 01:18:34] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:34] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:34] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:34] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:34] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:34] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 01:18:34] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 01:18:34] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 01:18:34] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 01:18:34] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 01:18:34] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3541451) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3541451) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.54it/s]
(EngineCore_DP0 pid=3541451) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.53it/s]
(EngineCore_DP0 pid=3541451) 
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11796480 bytes
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42467328 bytes
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:35] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3541451) [2026-01-28 01:18:35] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21299200 bytes
(EngineCore_DP0 pid=3541451) 2026-01-28 01:18:43,845 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3541451) 2026-01-28 01:18:43,861 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3541451) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:01, 25.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:00<00:01, 25.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:00<00:01, 26.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:00<00:00, 26.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:00<00:00, 24.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:00<00:00, 24.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:00<00:00, 24.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:00<00:00, 25.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:01<00:00, 20.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:01<00:00, 16.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:01<00:00, 18.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:01<00:00, 19.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:01<00:00, 21.63it/s]
(EngineCore_DP0 pid=3541451) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:04,  7.23it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:01, 18.50it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:00<00:01, 23.21it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:00<00:00, 25.45it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:00<00:00, 26.73it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:00<00:00, 27.54it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:00<00:00, 27.90it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:00<00:00, 28.25it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:00<00:00, 28.44it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:01<00:00, 27.54it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:01<00:00, 27.95it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 28.66it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 26.57it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 9143.21it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:03<16:11,  3.81s/it, est. speed input: 4.20 toks/s, output: 67.22 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:03<00:05, 31.30it/s, est. speed input: 355.76 toks/s, output: 5692.15 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:04<00:01, 71.33it/s, est. speed input: 685.26 toks/s, output: 10964.14 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:04<00:00, 106.91it/s, est. speed input: 912.33 toks/s, output: 14597.27 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:04<00:00, 106.91it/s, est. speed input: 967.88 toks/s, output: 15486.10 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:04<00:00, 60.49it/s, est. speed input: 967.88 toks/s, output: 15486.10 toks/s] 
[rank0]:[W128 01:18:52.967094984 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-28 01:18:53
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-INT8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_INT8_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 01:18:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3542082) [INFO] Loading compress extension: cusparselt_compress_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3542082) WARNING 01-28 01:19:06 [backends.py:609] Failed to read file <frozen os>
Throughput: 53.15 requests/s, 14456.45 total tokens/s, 13606.07 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-28 01:18:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 01:18:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 01:18:57] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 01:18:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:57] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:57] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:18:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 01:18:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 01:18:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 01:18:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 01:18:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 01:18:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 01:19:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 01:19:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-INT8'
[2026-01-28 01:19:01] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-INT8
[2026-01-28 01:19:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:19:01] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:19:01] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:19:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:19:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-INT8
[2026-01-28 01:19:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-INT8'
[2026-01-28 01:19:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 01:19:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 01:19:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 01:19:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 01:19:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:01] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:01] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX5080_cc120_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:01] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:01] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:01] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: BitNet-2B-INT8
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:01] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=3542082) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3542082) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.35it/s]
(EngineCore_DP0 pid=3542082) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.35it/s]
(EngineCore_DP0 pid=3542082) 
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11796480 bytes
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7864320 bytes
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 42467328 bytes
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:02] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3542082) [2026-01-28 01:19:02] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 21299200 bytes
(EngineCore_DP0 pid=3542082) 2026-01-28 01:19:12,550 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3542082) 2026-01-28 01:19:12,566 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3542082) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:02, 19.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:00<00:02, 22.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:00<00:01, 24.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:00<00:01, 24.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:00<00:01, 24.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:00<00:01, 25.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:00<00:01, 25.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:00<00:01, 25.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:01<00:00, 26.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:01<00:00, 25.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:01<00:00, 25.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:01<00:00, 25.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:01<00:00, 25.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:01<00:00, 25.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:01<00:00, 25.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:01<00:00, 26.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:01<00:00, 26.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:02<00:00, 25.40it/s]
(EngineCore_DP0 pid=3542082) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:08,  6.19it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:03, 14.69it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:00<00:02, 16.51it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:00<00:02, 16.44it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:00<00:02, 18.88it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:00<00:01, 21.54it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:00<00:01, 23.73it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:01<00:01, 25.44it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▉     | 25/51 [00:01<00:00, 26.58it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:01<00:00, 26.03it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:01<00:00, 26.96it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:01<00:00, 27.58it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 37/51 [00:01<00:00, 28.13it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:01<00:00, 28.49it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 43/51 [00:01<00:00, 28.83it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:01<00:00, 29.02it/s]
Capturing CUDA graphs (decode, FULL):  96%|█████████▌| 49/51 [00:02<00:00, 29.17it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:02<00:00, 24.58it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 9408.97it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:06<56:34,  6.64s/it, est. speed input: 2.41 toks/s, output: 38.54 toks/s]
Processed prompts:  23%|██▎       | 117/512 [00:06<00:16, 24.45it/s, est. speed input: 276.72 toks/s, output: 4427.56 toks/s]
Processed prompts:  40%|████      | 205/512 [00:06<00:06, 49.02it/s, est. speed input: 476.31 toks/s, output: 7620.97 toks/s]
Processed prompts:  56%|█████▋    | 288/512 [00:06<00:02, 79.95it/s, est. speed input: 659.52 toks/s, output: 10552.32 toks/s]
Processed prompts:  70%|███████   | 359/512 [00:07<00:01, 110.69it/s, est. speed input: 804.75 toks/s, output: 12876.00 toks/s]
Processed prompts:  82%|████████▏ | 422/512 [00:08<00:01, 86.94it/s, est. speed input: 820.53 toks/s, output: 13128.46 toks/s] 
Processed prompts:  91%|█████████ | 466/512 [00:08<00:00, 92.31it/s, est. speed input: 866.32 toks/s, output: 13861.13 toks/s]
Processed prompts:  97%|█████████▋| 499/512 [00:09<00:00, 68.98it/s, est. speed input: 833.61 toks/s, output: 13337.76 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:09<00:00, 68.98it/s, est. speed input: 855.30 toks/s, output: 13684.79 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:09<00:00, 53.46it/s, est. speed input: 855.30 toks/s, output: 13684.79 toks/s]
[rank0]:[W128 01:19:27.322303989 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

