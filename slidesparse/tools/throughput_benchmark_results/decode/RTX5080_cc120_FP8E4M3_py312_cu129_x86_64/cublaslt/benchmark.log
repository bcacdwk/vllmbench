
========== M=16 ==========
Time: 2026-01-21 23:41:55
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8
Params: prompt_len=16, output_len=512, num_prompts=16, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8 --dataset-name random --input-len 16 --output-len 512 --num-prompts 16 --max-num-seqs 16 --max-model-len 656 --max-num-batched-tokens 10496 --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Qwen2.5-0.5B-FP8_M16.json


========== M=128 ==========
Time: 2026-01-21 23:41:55
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8
Params: prompt_len=16, output_len=512, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8 --dataset-name random --input-len 16 --output-len 512 --num-prompts 128 --max-num-seqs 128 --max-model-len 656 --max-num-batched-tokens 83968 --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Qwen2.5-0.5B-FP8_M128.json


========== M=512 ==========
Time: 2026-01-21 23:41:55
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8
Params: prompt_len=16, output_len=512, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8 --dataset-name random --input-len 16 --output-len 512 --num-prompts 512 --max-num-seqs 512 --max-model-len 656 --max-num-batched-tokens 335872 --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Qwen2.5-0.5B-FP8_M512.json


========== M=16 ==========
Time: 2026-01-21 23:41:55
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Llama3.2-1B-FP8
Params: prompt_len=16, output_len=512, num_prompts=16, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Llama3.2-1B-FP8 --dataset-name random --input-len 16 --output-len 512 --num-prompts 16 --max-num-seqs 16 --max-model-len 656 --max-num-batched-tokens 10496 --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Llama3.2-1B-FP8_M16.json


========== M=128 ==========
Time: 2026-01-21 23:41:55
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Llama3.2-1B-FP8
Params: prompt_len=16, output_len=512, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Llama3.2-1B-FP8 --dataset-name random --input-len 16 --output-len 512 --num-prompts 128 --max-num-seqs 128 --max-model-len 656 --max-num-batched-tokens 83968 --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Llama3.2-1B-FP8_M128.json


========== M=16 ==========
Time: 2026-01-21 23:46:51
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8
Params: prompt_len=16, output_len=256, num_prompts=16, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 16 --max-num-seqs 16 --max-model-len 400 --max-num-batched-tokens 6400 --gpu-memory-utilization 0.9 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Qwen2.5-0.5B-FP8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
Throughput: 15.81 requests/s, 4300.43 total tokens/s, 4047.46 output tokens/s
Total num prompt tokens:  256
Total num output tokens:  4096

STDERR:
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
(EngineCore_DP0 pid=3236279) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3236279) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 14.10it/s]
(EngineCore_DP0 pid=3236279) 
(EngineCore_DP0 pid=3236279) 2026-01-21 23:47:09,205 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3236279) 2026-01-21 23:47:09,239 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3236279) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  8.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 36.33it/s]
(EngineCore_DP0 pid=3236279) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  7.97it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 31.09it/s]

Adding requests:   0%|          | 0/16 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 16/16 [00:00<00:00, 1411.72it/s]

Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 1/16 [00:00<00:14,  1.01it/s, est. speed input: 16.09 toks/s, output: 257.39 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:00<00:00,  1.01it/s, est. speed input: 256.36 toks/s, output: 4101.72 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:00<00:00, 16.02it/s, est. speed input: 256.36 toks/s, output: 4101.72 toks/s]
[rank0]:[W121 23:47:11.533942321 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-21 23:47:12
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 400 --max-num-batched-tokens 51200 --gpu-memory-utilization 0.9 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Qwen2.5-0.5B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
Throughput: 83.72 requests/s, 22771.05 total tokens/s, 21431.58 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
(EngineCore_DP0 pid=3236771) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3236771) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 13.95it/s]
(EngineCore_DP0 pid=3236771) 
(EngineCore_DP0 pid=3236771) 2026-01-21 23:47:33,109 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3236771) 2026-01-21 23:47:33,114 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3236771) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:01, 21.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:00<00:01, 20.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:00<00:00, 42.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:00<00:00, 58.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:00<00:00, 68.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:00<00:00, 55.07it/s]
(EngineCore_DP0 pid=3236771) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  7.83it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:00<00:00, 64.33it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 65.76it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 4218.43it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<03:09,  1.49s/it, est. speed input: 10.74 toks/s, output: 171.89 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  1.49s/it, est. speed input: 1368.22 toks/s, output: 21891.42 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 85.51it/s, est. speed input: 1368.22 toks/s, output: 21891.42 toks/s]
[rank0]:[W121 23:47:36.501442860 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-21 23:47:37
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Qwen2.5-0.5B-FP8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 400 --max-num-batched-tokens 204800 --gpu-memory-utilization 0.9 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Qwen2.5-0.5B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
Throughput: 135.18 requests/s, 36768.41 total tokens/s, 34605.56 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
(EngineCore_DP0 pid=3237270) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3237270) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 14.32it/s]
(EngineCore_DP0 pid=3237270) 
(EngineCore_DP0 pid=3237270) [rank0]:W0121 23:47:53.151000 3237270 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3237270) [rank0]:W0121 23:47:55.147000 3237270 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3237270) 2026-01-21 23:48:01,127 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3237270) 2026-01-21 23:48:01,132 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3237270) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:35,  1.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:00<00:02, 16.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:00<00:01, 29.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:01<00:00, 41.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:01<00:00, 52.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:01<00:00, 61.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:01<00:00, 38.87it/s]
(EngineCore_DP0 pid=3237270) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:06,  7.53it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:00<00:00, 50.13it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:00<00:00, 70.32it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:00<00:00, 60.30it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:00<00:00, 49.24it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 41/51 [00:00<00:00, 40.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:01<00:00, 50.80it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 7207.24it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:03<31:26,  3.69s/it, est. speed input: 4.33 toks/s, output: 69.34 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00,  3.69s/it, est. speed input: 2205.30 toks/s, output: 35284.70 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 137.83it/s, est. speed input: 2205.30 toks/s, output: 35284.70 toks/s]
[rank0]:[W121 23:48:08.183545554 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=16 ==========
Time: 2026-01-21 23:52:06
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Llama3.2-1B-FP8
Params: prompt_len=16, output_len=256, num_prompts=16, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Llama3.2-1B-FP8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 16 --max-num-seqs 16 --max-model-len 400 --max-num-batched-tokens 6400 --gpu-memory-utilization 0.9 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Llama3.2-1B-FP8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
Throughput: 12.56 requests/s, 3415.60 total tokens/s, 3214.68 output tokens/s
Total num prompt tokens:  256
Total num output tokens:  4096

STDERR:
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
(EngineCore_DP0 pid=3243483) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3243483) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.34it/s]
(EngineCore_DP0 pid=3243483) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.33it/s]
(EngineCore_DP0 pid=3243483) 
(EngineCore_DP0 pid=3243483) 2026-01-21 23:52:24,319 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3243483) 2026-01-21 23:52:24,336 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3243483) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 70.13it/s]
(EngineCore_DP0 pid=3243483) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  8.18it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 33.00it/s]

Adding requests:   0%|          | 0/16 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 16/16 [00:00<00:00, 1079.04it/s]

Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 1/16 [00:01<00:18,  1.25s/it, est. speed input: 12.79 toks/s, output: 204.62 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:01<00:00,  1.25s/it, est. speed input: 203.78 toks/s, output: 3260.41 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:01<00:00, 12.73it/s, est. speed input: 203.78 toks/s, output: 3260.41 toks/s]
[rank0]:[W121 23:52:26.774350755 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-21 23:52:28
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Llama3.2-1B-FP8
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Llama3.2-1B-FP8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 400 --max-num-batched-tokens 51200 --gpu-memory-utilization 0.9 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Llama3.2-1B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
Throughput: 67.57 requests/s, 18380.22 total tokens/s, 17299.03 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
(EngineCore_DP0 pid=3244020) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3244020) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.69it/s]
(EngineCore_DP0 pid=3244020) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.68it/s]
(EngineCore_DP0 pid=3244020) 
(EngineCore_DP0 pid=3244020) [rank0]:W0121 23:52:42.028000 3244020 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3244020) [rank0]:W0121 23:52:42.722000 3244020 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3244020) [rank0]:W0121 23:52:44.023000 3244020 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3244020) [rank0]:W0121 23:52:44.106000 3244020 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 1 large pointwise nodes are separated
(EngineCore_DP0 pid=3244020) 2026-01-21 23:52:48,219 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3244020) 2026-01-21 23:52:48,279 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3244020) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:10,  3.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:00<00:00, 38.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:00<00:00, 63.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:00<00:00, 58.60it/s]
(EngineCore_DP0 pid=3244020) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  8.07it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:00<00:00, 71.52it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 71.55it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 7223.48it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<03:57,  1.87s/it, est. speed input: 8.57 toks/s, output: 137.17 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  1.87s/it, est. speed input: 1091.82 toks/s, output: 17469.16 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 68.24it/s, est. speed input: 1091.82 toks/s, output: 17469.16 toks/s]
[rank0]:[W121 23:52:52.958431556 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-21 23:52:53
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Llama3.2-1B-FP8
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Llama3.2-1B-FP8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 400 --max-num-batched-tokens 204800 --gpu-memory-utilization 0.9 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Llama3.2-1B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return self._compile_to_module()
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     return self._generate(is_inference)
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866]     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=3244675) ERROR 01-21 23:53:09 [core.py:866] torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 15.46 GiB of which 2.49 GiB is free. Including non-PyTorch memory, this process has 12.73 GiB memory in use. Of the allocated memory 11.57 GiB is allocated by PyTorch, and 813.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

STDERR:
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
(EngineCore_DP0 pid=3244675) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3244675) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.17it/s]
(EngineCore_DP0 pid=3244675) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.17it/s]
(EngineCore_DP0 pid=3244675) 
(EngineCore_DP0 pid=3244675) [rank0]:W0121 23:53:07.569000 3244675 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=3244675) [rank0]:W0121 23:53:07.909000 3244675 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=3244675) [rank0]:W0121 23:53:08.923000 3244675 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=3244675) [rank0]:W0121 23:53:08.991000 3244675 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=3244675) Process EngineCore_DP0:
(EngineCore_DP0 pid=3244675) Traceback (most recent call last):
(EngineCore_DP0 pid=3244675)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=3244675)     self.run()
(EngineCore_DP0 pid=3244675)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=3244675)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=3244675)     raise e
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=3244675)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=3244675)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=3244675)     super().__init__(
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=3244675)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=3244675)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=3244675)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=3244675)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=3244675)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=3244675)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=3244675)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=3244675)     return func(*args, **kwargs)
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=3244675)     return func(*args, **kwargs)
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=3244675)     self.model_runner.profile_run()
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=3244675)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=3244675)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=3244675)     return func(*args, **kwargs)
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=3244675)     outputs = self.model(
(EngineCore_DP0 pid=3244675)               ^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=3244675)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=3244675)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=3244675)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=3244675)     model_output = self.model(
(EngineCore_DP0 pid=3244675)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=3244675)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=3244675)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=3244675)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=3244675)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=3244675)     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=3244675)     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=3244675)     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=3244675)     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=3244675)                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=3244675)     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=3244675)     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=3244675)                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=3244675)     return self._compile_to_module()
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=3244675)     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=3244675)                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=3244675)     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=3244675)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=3244675)     return self._generate(is_inference)
(EngineCore_DP0 pid=3244675)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=3244675)     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=3244675)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=3244675)     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=3244675) torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 15.46 GiB of which 2.49 GiB is free. Including non-PyTorch memory, this process has 12.73 GiB memory in use. Of the allocated memory 11.57 GiB is allocated by PyTorch, and 813.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W121 23:53:10.850384046 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512

========== M=512 ==========
Time: 2026-01-22 00:13:14
Backend: cuBLASLt
Checkpoint: /root/vllmbench/checkpoints/Llama3.2-1B-FP8
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints/Llama3.2-1B-FP8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 400 --max-num-batched-tokens 204800 --gpu-memory-utilization 0.9 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX5080_cc120_FP8E4M3_py312_cu129_x86_64/cublaslt/json/Llama3.2-1B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
INFO 01-22 00:13:18 [datasets.py:612] Sampling input_len from [15, 15] and output_len from [256, 256]
INFO 01-22 00:13:18 [utils.py:253] non-default args: {'tokenizer': '/root/vllmbench/checkpoints/Llama3.2-1B-FP8', 'max_model_len': 400, 'max_num_batched_tokens': 204800, 'max_num_seqs': 512, 'disable_log_stats': True, 'enable_lora': None, 'reasoning_parser_plugin': '', 'model': '/root/vllmbench/checkpoints/Llama3.2-1B-FP8'}
INFO 01-22 00:13:18 [model.py:514] Resolved architecture: LlamaForCausalLM
INFO 01-22 00:13:18 [model.py:1661] Using max model len 400
INFO 01-22 00:13:18 [scheduler.py:230] Chunked prefill is enabled with max_num_batched_tokens=204800.
(EngineCore_DP0 pid=3254977) INFO 01-22 00:13:22 [core.py:93] Initializing a V1 LLM engine (v0.13.1.dev7+gd5e6597bf) with config: model='/root/vllmbench/checkpoints/Llama3.2-1B-FP8', speculative_config=None, tokenizer='/root/vllmbench/checkpoints/Llama3.2-1B-FP8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=400, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, kv_cache_metrics=False, kv_cache_metrics_sample=0.01, cudagraph_metrics=False, enable_layerwise_nvtx_tracing=False), seed=0, served_model_name=/root/vllmbench/checkpoints/Llama3.2-1B-FP8, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'compile_sizes': [], 'compile_ranges_split_points': [204800], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {'fuse_norm_quant': False, 'fuse_act_quant': False, 'fuse_attn_quant': False, 'eliminate_noops': True, 'enable_sp': False, 'fuse_gemm_comms': False, 'fuse_allreduce_rms': False}, 'max_cudagraph_capture_size': 512, 'dynamic_shapes_config': {'type': <DynamicShapesType.BACKED: 'backed'>, 'evaluate_guards': False}, 'local_cache_dir': None}
(EngineCore_DP0 pid=3254977) INFO 01-22 00:13:22 [parallel_state.py:1203] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.172.141.44:41857 backend=nccl
(EngineCore_DP0 pid=3254977) INFO 01-22 00:13:22 [parallel_state.py:1411] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, PCP rank 0, TP rank 0, EP rank 0
(EngineCore_DP0 pid=3254977) INFO 01-22 00:13:23 [gpu_model_runner.py:3562] Starting to load model /root/vllmbench/checkpoints/Llama3.2-1B-FP8...
(EngineCore_DP0 pid=3254977) INFO 01-22 00:13:23 [cuda.py:351] Using FLASH_ATTN attention backend out of potential backends: ('FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION')
(EngineCore_DP0 pid=3254977) INFO 01-22 00:13:23 [default_loader.py:308] Loading weights took 0.15 seconds
(EngineCore_DP0 pid=3254977) INFO 01-22 00:13:23 [gpu_model_runner.py:3659] Model loading took 1.4145 GiB memory and 0.337086 seconds
(EngineCore_DP0 pid=3254977) INFO 01-22 00:13:26 [backends.py:643] Using cache directory: /root/.cache/vllm/torch_compile_cache/2a1cea4ebe/rank_0_0/backbone for vLLM's torch.compile
(EngineCore_DP0 pid=3254977) INFO 01-22 00:13:26 [backends.py:703] Dynamo bytecode transform time: 2.60 s
(EngineCore_DP0 pid=3254977) INFO 01-22 00:13:27 [backends.py:261] Cache the graph of compile range (1, 204800) for later use
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     self.model_runner.profile_run()
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return func(*args, **kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     outputs = self.model(
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]               ^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     model_output = self.model(
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]                    ^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return self._compile_to_module()
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     return self._generate(is_inference)
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866]     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=3254977) ERROR 01-22 00:13:28 [core.py:866] torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 15.46 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.34 GiB memory in use. Of the allocated memory 11.57 GiB is allocated by PyTorch, and 413.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

STDERR:
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:81: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
(EngineCore_DP0 pid=3254977) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3254977) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.14it/s]
(EngineCore_DP0 pid=3254977) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.13it/s]
(EngineCore_DP0 pid=3254977) 
(EngineCore_DP0 pid=3254977) [rank0]:W0122 00:13:28.672000 3254977 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=3254977) [rank0]:W0122 00:13:28.752000 3254977 torch/_inductor/codegen/triton_combo_kernel.py:110] ComboKernels: 2 large pointwise nodes are separated
(EngineCore_DP0 pid=3254977) Process EngineCore_DP0:
(EngineCore_DP0 pid=3254977) Traceback (most recent call last):
(EngineCore_DP0 pid=3254977)   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
(EngineCore_DP0 pid=3254977)     self.run()
(EngineCore_DP0 pid=3254977)   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
(EngineCore_DP0 pid=3254977)     self._target(*self._args, **self._kwargs)
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
(EngineCore_DP0 pid=3254977)     raise e
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=3254977)     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=3254977)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=3254977)     super().__init__(
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
(EngineCore_DP0 pid=3254977)     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
(EngineCore_DP0 pid=3254977)                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
(EngineCore_DP0 pid=3254977)     available_gpu_memory = self.model_executor.determine_available_memory()
(EngineCore_DP0 pid=3254977)                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
(EngineCore_DP0 pid=3254977)     return self.collective_rpc("determine_available_memory")
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
(EngineCore_DP0 pid=3254977)     result = run_method(self.driver_worker, method, args, kwargs)
(EngineCore_DP0 pid=3254977)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
(EngineCore_DP0 pid=3254977)     return func(*args, **kwargs)
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=3254977)     return func(*args, **kwargs)
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
(EngineCore_DP0 pid=3254977)     self.model_runner.profile_run()
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
(EngineCore_DP0 pid=3254977)     hidden_states, last_hidden_states = self._dummy_run(
(EngineCore_DP0 pid=3254977)                                         ^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
(EngineCore_DP0 pid=3254977)     return func(*args, **kwargs)
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
(EngineCore_DP0 pid=3254977)     outputs = self.model(
(EngineCore_DP0 pid=3254977)               ^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
(EngineCore_DP0 pid=3254977)     return self.runnable(*args, **kwargs)
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
(EngineCore_DP0 pid=3254977)     return self._call_impl(*args, **kwargs)
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
(EngineCore_DP0 pid=3254977)     return forward_call(*args, **kwargs)
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/model_executor/models/llama.py", line 623, in forward
(EngineCore_DP0 pid=3254977)     model_output = self.model(
(EngineCore_DP0 pid=3254977)                    ^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
(EngineCore_DP0 pid=3254977)     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
(EngineCore_DP0 pid=3254977)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
(EngineCore_DP0 pid=3254977)     return self._call_with_optional_nvtx_range(
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
(EngineCore_DP0 pid=3254977)     return callable_fn(*args, **kwargs)
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 845, in compile_wrapper
(EngineCore_DP0 pid=3254977)     raise e.remove_dynamo_frames() from None  # see TORCHDYNAMO_VERBOSE=1
(EngineCore_DP0 pid=3254977)     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 990, in _compile_fx_inner
(EngineCore_DP0 pid=3254977)     raise InductorError(e, currentframe()).with_traceback(
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 974, in _compile_fx_inner
(EngineCore_DP0 pid=3254977)     mb_compiled_graph = fx_codegen_and_compile(
(EngineCore_DP0 pid=3254977)                         ^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1695, in fx_codegen_and_compile
(EngineCore_DP0 pid=3254977)     return scheme.codegen_and_compile(gm, example_inputs, inputs_to_check, graph_kwargs)
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/compile_fx.py", line 1505, in codegen_and_compile
(EngineCore_DP0 pid=3254977)     compiled_module = graph.compile_to_module()
(EngineCore_DP0 pid=3254977)                       ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2319, in compile_to_module
(EngineCore_DP0 pid=3254977)     return self._compile_to_module()
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2325, in _compile_to_module
(EngineCore_DP0 pid=3254977)     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()
(EngineCore_DP0 pid=3254977)                                                              ^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/graph.py", line 2271, in codegen
(EngineCore_DP0 pid=3254977)     result = self.wrapper_code.generate(self.is_inference)
(EngineCore_DP0 pid=3254977)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1552, in generate
(EngineCore_DP0 pid=3254977)     return self._generate(is_inference)
(EngineCore_DP0 pid=3254977)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1615, in _generate
(EngineCore_DP0 pid=3254977)     self.generate_and_run_autotune_block()
(EngineCore_DP0 pid=3254977)   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/codegen/wrapper.py", line 1695, in generate_and_run_autotune_block
(EngineCore_DP0 pid=3254977)     raise RuntimeError(f"Failed to run autotuning code block: {e}") from e
(EngineCore_DP0 pid=3254977) torch._inductor.exc.InductorError: RuntimeError: Failed to run autotuning code block: CUDA out of memory. Tried to allocate 3.12 GiB. GPU 0 has a total capacity of 15.46 GiB of which 2.88 GiB is free. Including non-PyTorch memory, this process has 12.34 GiB memory in use. Of the allocated memory 11.57 GiB is allocated by PyTorch, and 413.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W122 00:13:29.061799523 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

ERROR: Test failed for M=512
