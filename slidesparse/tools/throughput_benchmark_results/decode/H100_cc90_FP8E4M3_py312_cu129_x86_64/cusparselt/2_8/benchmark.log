
========== M=64 ==========
Time: 2026-01-26 16:20:11
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Llama3.2-1B-FP8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:20:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1601475) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1601475) WARNING 01-26 16:20:32 [backends.py:609] Failed to read file <frozen os>
Throughput: 46.00 requests/s, 12512.21 total tokens/s, 11776.20 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 16:20:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:20:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 16:20:18] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 16:20:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:18] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:18] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 16:20:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:20:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:20:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:20:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:20:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:20:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:20:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 16:20:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 16:20:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 16:20:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:20:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:20:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:20:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:20:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:27] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:27] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:27] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:27] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:27] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:27] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1601475) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1601475) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.33it/s]
(EngineCore_DP0 pid=1601475) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.32it/s]
(EngineCore_DP0 pid=1601475) 
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:28] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1601475) [2026-01-26 16:20:28] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1601475) 2026-01-26 16:20:39,380 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1601475) 2026-01-26 16:20:39,411 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1601475) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:03,  5.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:02,  7.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:01<00:03,  4.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:01<00:02,  4.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:01<00:02,  5.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:01<00:01,  7.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:01<00:00, 10.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:01<00:00, 12.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:01<00:00, 14.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:01<00:00, 16.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:02<00:00,  9.40it/s]
(EngineCore_DP0 pid=1601475) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:01,  6.05it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:02,  3.54it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00,  6.36it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:01<00:00, 10.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00, 11.19it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  8.74it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 3985.21it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:01<01:25,  1.36s/it, est. speed input: 11.81 toks/s, output: 188.92 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00,  1.36s/it, est. speed input: 745.47 toks/s, output: 11927.39 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00, 46.58it/s, est. speed input: 745.47 toks/s, output: 11927.39 toks/s]
[rank0]:[W126 16:20:45.887551151 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 16:20:47
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Llama3.2-1B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:20:54 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1602488) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1602488) WARNING 01-26 16:21:07 [backends.py:609] Failed to read file <frozen os>
Throughput: 73.99 requests/s, 20125.23 total tokens/s, 18941.39 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 16:20:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:20:54] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 16:20:54] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 16:20:54] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:54] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:54] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:54] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:54] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:20:54] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 16:20:54] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:20:54] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:20:54] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:20:54] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:20:54] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:21:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:21:01] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 16:21:01] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 16:21:01] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:01] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:01] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:01] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:01] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:01] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 16:21:01] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:21:01] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:21:01] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:21:01] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:21:01] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:02] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:02] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:02] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:02] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:02] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:02] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1602488) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1602488) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.64it/s]
(EngineCore_DP0 pid=1602488) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.63it/s]
(EngineCore_DP0 pid=1602488) 
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:03] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1602488) [2026-01-26 16:21:03] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1602488) 2026-01-26 16:21:12,451 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1602488) 2026-01-26 16:21:12,482 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1602488) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:11,  2.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:16,  2.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:01<00:10,  3.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:01<00:05,  5.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:01<00:03,  8.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:01<00:02, 11.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:01<00:02, 10.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:01<00:02,  8.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:02<00:02,  9.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:02<00:03,  5.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:02<00:02,  7.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:03<00:01,  7.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:03<00:01,  8.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:03<00:00, 10.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:03<00:00, 10.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:03<00:00, 11.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:04<00:00,  6.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:04<00:00,  7.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:04<00:00,  7.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:04<00:00,  7.49it/s]
(EngineCore_DP0 pid=1602488) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:00, 19.18it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:00<00:00, 19.92it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:00<00:00, 19.66it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:00<00:00, 19.78it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:00<00:00, 15.22it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:01<00:00, 10.22it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:01<00:00,  7.08it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:01<00:00,  9.54it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:01<00:00, 11.31it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2912.14it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<03:27,  1.64s/it, est. speed input: 9.77 toks/s, output: 156.31 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  1.64s/it, est. speed input: 1216.03 toks/s, output: 19456.36 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 75.99it/s, est. speed input: 1216.03 toks/s, output: 19456.36 toks/s]
[rank0]:[W126 16:21:22.275695722 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 16:21:24
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Llama3.2-1B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:21:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1603503) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1603503) WARNING 01-26 16:21:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 110.31 requests/s, 30004.36 total tokens/s, 28239.40 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 16:21:30] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:21:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 16:21:31] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 16:21:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 16:21:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:21:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:21:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:21:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:21:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:21:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:21:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 16:21:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 16:21:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:21:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 16:21:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:21:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:21:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:21:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:21:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:39] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:39] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:39] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:39] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:39] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1603503) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1603503) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.57it/s]
(EngineCore_DP0 pid=1603503) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.57it/s]
(EngineCore_DP0 pid=1603503) 
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1603503) [2026-01-26 16:21:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1603503) 2026-01-26 16:21:49,588 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1603503) 2026-01-26 16:21:49,637 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1603503) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:09,  3.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:03,  8.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:00<00:02, 11.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:00<00:02, 13.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:00<00:02, 11.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███       | 11/36 [00:01<00:02,  9.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:01<00:02,  9.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:01<00:03,  5.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:02<00:02,  7.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:02<00:02,  6.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:02<00:01,  8.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:02<00:01, 10.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▉   | 25/36 [00:02<00:01, 10.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:03<00:00,  9.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:03<00:01,  5.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:03<00:01,  5.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:03<00:00,  7.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:04<00:00,  9.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:04<00:00, 11.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:04<00:00,  8.57it/s]
(EngineCore_DP0 pid=1603503) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:01, 18.99it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:01, 19.42it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:01, 19.50it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:00<00:02, 11.17it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:01<00:03,  6.74it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:01<00:03,  7.36it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:01<00:02,  9.17it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:01<00:02,  9.17it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:01<00:01, 11.81it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:01<00:01, 13.31it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:02<00:00, 14.68it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:02<00:00, 15.89it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:02<00:00, 16.90it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:02<00:00,  9.43it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:03<00:00,  6.42it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:03<00:00,  8.74it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:03<00:00, 10.33it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 4142.95it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:02<08:36,  2.02s/it, est. speed input: 7.91 toks/s, output: 126.49 toks/s]
Processed prompts:  62%|██████▏   | 159/256 [00:02<00:00, 104.54it/s, est. speed input: 1197.07 toks/s, output: 19152.85 toks/s]
Processed prompts:  98%|█████████▊| 251/256 [00:02<00:00, 172.07it/s, est. speed input: 1790.57 toks/s, output: 28648.81 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 172.07it/s, est. speed input: 1814.49 toks/s, output: 29031.63 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 113.40it/s, est. speed input: 1814.49 toks/s, output: 29031.63 toks/s]
[rank0]:[W126 16:22:01.334257718 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 16:22:03
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Llama3.2-1B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:22:10 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1604528) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1604528) WARNING 01-26 16:22:24 [backends.py:609] Failed to read file <frozen os>
Throughput: 115.17 requests/s, 31327.25 total tokens/s, 29484.47 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 16:22:09] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:22:10] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 16:22:10] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 16:22:10] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:22:10] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:22:10] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:22:10] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:22:10] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:22:10] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 16:22:10] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:22:10] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:22:10] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:22:10] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:22:10] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:22:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:22:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 16:22:17] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 16:22:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:22:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:22:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:22:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:22:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 16:22:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 16:22:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:22:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:22:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:22:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:22:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:19] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:19] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:19] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:19] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:19] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:19] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1604528) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1604528) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.56it/s]
(EngineCore_DP0 pid=1604528) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  4.56it/s]
(EngineCore_DP0 pid=1604528) 
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 5898240 bytes
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3072] -> 1D uint8
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 3932160 bytes
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 31457280 bytes
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:20] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 12288] -> 1D uint8
(EngineCore_DP0 pid=1604528) [2026-01-26 16:22:20] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15728640 bytes
(EngineCore_DP0 pid=1604528) 2026-01-26 16:22:31,988 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1604528) 2026-01-26 16:22:32,020 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1604528) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:08,  5.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:05,  8.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:05,  8.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:00<00:10,  4.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:01<00:08,  5.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:01<00:08,  5.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:01<00:05,  8.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:01<00:03, 10.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:01<00:02, 12.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:01<00:02, 14.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:01<00:02, 14.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:02<00:02, 12.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:02<00:05,  5.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:02<00:04,  6.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:03<00:03,  8.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:03<00:02, 10.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:03<00:02, 10.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:03<00:01, 12.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:03<00:01, 13.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:03<00:01, 14.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:04<00:01, 10.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:04<00:01,  6.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:04<00:01,  7.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:04<00:00,  9.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:05<00:00, 11.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:05<00:00, 13.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:05<00:00,  9.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:05<00:00,  9.19it/s]
(EngineCore_DP0 pid=1604528) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:02, 19.11it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:08,  5.31it/s]
Capturing CUDA graphs (decode, FULL):  10%|▉         | 5/51 [00:00<00:08,  5.39it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:00<00:05,  7.99it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:01<00:05,  7.53it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:01<00:03, 10.63it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:01<00:02, 13.15it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:01<00:02, 15.14it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:02<00:04,  6.53it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:02<00:03,  7.31it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:02<00:03,  7.81it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:02<00:02,  9.42it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:03<00:01, 11.79it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:03<00:01, 13.22it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:03<00:01, 15.21it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:03<00:01, 13.05it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:04<00:02,  6.33it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:04<00:01,  7.58it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:04<00:00,  9.20it/s]
Capturing CUDA graphs (decode, FULL):  88%|████████▊ | 45/51 [00:04<00:00, 11.59it/s]
Capturing CUDA graphs (decode, FULL):  92%|█████████▏| 47/51 [00:04<00:00, 10.67it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:05<00:00, 12.95it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:05<00:00,  9.88it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  58%|█████▊    | 298/512 [00:00<00:00, 2977.49it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 3469.94it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:03<28:09,  3.31s/it, est. speed input: 4.84 toks/s, output: 77.43 toks/s]
Processed prompts:  36%|███▌      | 183/512 [00:03<00:04, 75.59it/s, est. speed input: 858.97 toks/s, output: 13743.44 toks/s]
Processed prompts:  72%|███████▏  | 367/512 [00:03<00:00, 173.83it/s, est. speed input: 1672.42 toks/s, output: 26758.47 toks/s]
Processed prompts:  99%|█████████▉| 506/512 [00:04<00:00, 175.47it/s, est. speed input: 1886.49 toks/s, output: 30183.79 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:04<00:00, 175.47it/s, est. speed input: 1906.96 toks/s, output: 30511.30 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:04<00:00, 119.18it/s, est. speed input: 1906.96 toks/s, output: 30511.30 toks/s]
[rank0]:[W126 16:22:49.027916023 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 16:51:10
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Llama3.2-3B-FP8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:51:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1647226) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1647226) WARNING 01-26 16:51:33 [backends.py:609] Failed to read file <frozen os>
Throughput: 29.55 requests/s, 8038.29 total tokens/s, 7565.45 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 16:51:16] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:51:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 16:51:17] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 16:51:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 16:51:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:51:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:51:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:51:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:51:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:51:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:51:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 16:51:24] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 16:51:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 16:51:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:51:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:51:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:51:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:51:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:26] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:26] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:26] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:26] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:26] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:26] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1647226) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1647226) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.92it/s]
(EngineCore_DP0 pid=1647226) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.92it/s]
(EngineCore_DP0 pid=1647226) 
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:27] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1647226) [2026-01-26 16:51:27] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1647226) 2026-01-26 16:51:43,374 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1647226) 2026-01-26 16:51:43,414 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1647226) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:03,  5.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:02,  6.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:00<00:01, 10.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:01<00:02,  4.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:01<00:01,  6.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:01<00:01,  5.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:01<00:01,  6.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:01<00:00,  8.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:01<00:00, 10.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:02<00:00, 12.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:02<00:00, 11.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:02<00:00,  8.30it/s]
(EngineCore_DP0 pid=1647226) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:03,  2.87it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:02,  3.99it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00,  6.82it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:01<00:00, 10.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00, 13.45it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  9.00it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2813.73it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:02<02:12,  2.11s/it, est. speed input: 7.59 toks/s, output: 121.49 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:02<00:00,  2.11s/it, est. speed input: 478.29 toks/s, output: 7652.52 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:02<00:00, 29.89it/s, est. speed input: 478.29 toks/s, output: 7652.52 toks/s]
[rank0]:[W126 16:51:51.027426992 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 16:51:53
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Llama3.2-3B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:52:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1648315) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1648315) WARNING 01-26 16:52:16 [backends.py:609] Failed to read file <frozen os>
Throughput: 49.20 requests/s, 13382.60 total tokens/s, 12595.39 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 16:51:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:51:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 16:51:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 16:51:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:51:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 16:52:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:52:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:52:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:52:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:52:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:52:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:52:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 16:52:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 16:52:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 16:52:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:52:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:52:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:52:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:52:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1648315) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1648315) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.92it/s]
(EngineCore_DP0 pid=1648315) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.92it/s]
(EngineCore_DP0 pid=1648315) 
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:10] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1648315) [2026-01-26 16:52:10] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1648315) 2026-01-26 16:52:23,284 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1648315) 2026-01-26 16:52:23,307 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1648315) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:15,  2.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:01<00:18,  1.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:01<00:07,  3.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:01<00:04,  6.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:01<00:03,  7.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:01<00:02,  9.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:01<00:02, 11.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:01<00:01, 12.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:01<00:01, 14.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:02<00:03,  5.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:03<00:02,  6.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:03<00:01,  8.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:03<00:01,  9.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:03<00:00,  9.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:03<00:00, 11.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:03<00:00, 10.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:04<00:00,  9.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:04<00:00,  6.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:04<00:00,  6.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:04<00:00,  7.46it/s]
(EngineCore_DP0 pid=1648315) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:00, 18.63it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:01, 12.95it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:01, 12.07it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:00<00:00, 14.15it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:00<00:00, 12.68it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:00<00:00, 14.48it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:01<00:00, 11.57it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:01<00:00,  5.71it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:01<00:00,  7.09it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:02<00:00,  9.40it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2764.85it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:02<05:13,  2.47s/it, est. speed input: 6.48 toks/s, output: 103.64 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00,  2.47s/it, est. speed input: 802.09 toks/s, output: 12833.37 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00, 50.13it/s, est. speed input: 802.09 toks/s, output: 12833.37 toks/s]
[rank0]:[W126 16:52:34.384941886 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 16:52:36
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Llama3.2-3B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:52:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1649423) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1649423) WARNING 01-26 16:52:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 66.80 requests/s, 18169.21 total tokens/s, 17100.43 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 16:52:43] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:52:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 16:52:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 16:52:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 16:52:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:52:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:52:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:52:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:52:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:52:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:52:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 16:52:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 16:52:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:52:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 16:52:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:52:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:52:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:52:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:52:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:52] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:52] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:52] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:52] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:52] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1649423) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1649423) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.92it/s]
(EngineCore_DP0 pid=1649423) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.92it/s]
(EngineCore_DP0 pid=1649423) 
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:53] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1649423) [2026-01-26 16:52:53] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1649423) 2026-01-26 16:53:08,123 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1649423) 2026-01-26 16:53:08,334 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1649423) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:04,  7.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:02, 12.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:00<00:02, 14.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:00<00:01, 16.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:00<00:01, 17.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███       | 11/36 [00:00<00:02,  9.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:01<00:04,  5.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:01<00:02,  7.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:01<00:02,  9.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:01<00:01, 10.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:02<00:01,  8.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:02<00:01,  8.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▉   | 25/36 [00:03<00:02,  5.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:03<00:01,  5.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:03<00:01,  6.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:03<00:01,  6.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 31/36 [00:03<00:00,  8.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:03<00:00, 10.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:03<00:00, 12.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:04<00:00,  8.76it/s]
(EngineCore_DP0 pid=1649423) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:01, 18.67it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:03,  9.95it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:05,  5.39it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:01<00:05,  5.43it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:01<00:03,  7.71it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:01<00:02,  9.97it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:01<00:01, 12.90it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:01<00:01, 14.30it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:01<00:00, 16.24it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:02<00:01, 12.04it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:02<00:02,  5.95it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:02<00:01,  7.43it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:03<00:00,  8.47it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:03<00:00,  9.36it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:03<00:00, 11.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:03<00:00, 13.92it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:03<00:00, 10.01it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  98%|█████████▊| 250/256 [00:00<00:00, 2492.42it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2478.86it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:03<14:03,  3.31s/it, est. speed input: 4.84 toks/s, output: 77.43 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:03<00:03, 40.38it/s, est. speed input: 459.62 toks/s, output: 7353.85 toks/s]
Processed prompts:  71%|███████▏  | 183/256 [00:03<00:00, 85.38it/s, est. speed input: 833.17 toks/s, output: 13330.66 toks/s]
Processed prompts:  98%|█████████▊| 251/256 [00:03<00:00, 121.61it/s, est. speed input: 1085.78 toks/s, output: 17372.28 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 121.61it/s, est. speed input: 1099.01 toks/s, output: 17584.09 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 68.68it/s, est. speed input: 1099.01 toks/s, output: 17584.09 toks/s] 
[rank0]:[W126 16:53:21.533578921 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 16:53:23
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Llama3.2-3B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 16:53:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1650585) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1650585) WARNING 01-26 16:53:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 70.68 requests/s, 19225.49 total tokens/s, 18094.58 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 16:53:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:53:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 16:53:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 16:53:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:53:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:53:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:53:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:53:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:53:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 16:53:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:53:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:53:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:53:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:53:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 16:53:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 16:53:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 16:53:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 16:53:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:53:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:53:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:53:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:53:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 16:53:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 16:53:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 16:53:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 16:53:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 16:53:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 16:53:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:39] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:39] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:39] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:39] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:39] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:39] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1650585) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1650585) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.93it/s]
(EngineCore_DP0 pid=1650585) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.93it/s]
(EngineCore_DP0 pid=1650585) 
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4608] -> 1D uint8
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 14745600 bytes
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4608] -> 1D uint8
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 8847360 bytes
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4608] -> 1D uint8
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 47185920 bytes
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:40] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 12288] -> 1D uint8
(EngineCore_DP0 pid=1650585) [2026-01-26 16:53:40] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 23592960 bytes
(EngineCore_DP0 pid=1650585) 2026-01-26 16:53:57,307 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1650585) 2026-01-26 16:53:57,360 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1650585) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:07,  6.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:07,  6.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:07,  6.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:00<00:05,  7.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:01<00:11,  3.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:01<00:07,  5.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:01<00:07,  5.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:01<00:06,  6.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:01<00:04,  8.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:01<00:03, 10.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:02<00:03, 10.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:02<00:02, 11.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:03<00:05,  5.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:03<00:05,  5.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:03<00:03,  7.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:03<00:02,  9.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:03<00:02, 10.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:03<00:01, 12.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:03<00:01, 13.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:04<00:01, 14.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:04<00:01,  8.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:05<00:02,  6.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:05<00:01,  7.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:05<00:01,  7.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:05<00:00,  9.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:05<00:00, 11.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:05<00:00, 10.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:05<00:00, 12.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:06<00:00,  8.37it/s]
(EngineCore_DP0 pid=1650585) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:27,  1.80it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 3/51 [00:00<00:09,  5.08it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:08,  5.55it/s]
Capturing CUDA graphs (decode, FULL):  10%|▉         | 5/51 [00:00<00:07,  6.49it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:01<00:04,  9.28it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:01<00:04,  9.35it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:01<00:03, 11.55it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:01<00:02, 14.40it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:01<00:02, 12.37it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:02<00:05,  6.16it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:02<00:04,  7.45it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 23/51 [00:02<00:02,  9.93it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:02<00:02, 12.15it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:03<00:01, 14.02it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:03<00:01, 12.45it/s]
Capturing CUDA graphs (decode, FULL):  65%|██████▍   | 33/51 [00:03<00:01, 11.47it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:04<00:02,  6.04it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 37/51 [00:04<00:01,  7.15it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:04<00:01,  9.42it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:04<00:00, 10.90it/s]
Capturing CUDA graphs (decode, FULL):  88%|████████▊ | 45/51 [00:04<00:00, 13.12it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:04<00:00, 14.95it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:05<00:00, 16.30it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:05<00:00, 10.09it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  59%|█████▉    | 302/512 [00:00<00:00, 3016.04it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 3501.52it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:05<44:57,  5.28s/it, est. speed input: 3.03 toks/s, output: 48.50 toks/s]
Processed prompts:  23%|██▎       | 117/512 [00:05<00:12, 30.64it/s, est. speed input: 347.14 toks/s, output: 5554.26 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:05<00:03, 74.52it/s, est. speed input: 704.04 toks/s, output: 11264.56 toks/s]
Processed prompts:  68%|██████▊   | 348/512 [00:05<00:01, 122.69it/s, est. speed input: 994.04 toks/s, output: 15904.52 toks/s]
Processed prompts:  86%|████████▌ | 441/512 [00:05<00:00, 173.37it/s, est. speed input: 1233.62 toks/s, output: 19737.89 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:07<00:00, 173.37it/s, est. speed input: 1154.54 toks/s, output: 18472.55 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:07<00:00, 72.16it/s, est. speed input: 1154.54 toks/s, output: 18472.55 toks/s] 
[rank0]:[W126 16:54:17.754406177 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 17:23:38
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 17:23:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1694087) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1694087) WARNING 01-26 17:24:01 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.20 requests/s, 6582.31 total tokens/s, 6195.11 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 17:23:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 17:23:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:23:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:23:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:23:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:23:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:23:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:23:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 17:23:51] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 17:23:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:23:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:23:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:23:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:23:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:23:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:23:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:23:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1694087) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1694087) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.95it/s]
(EngineCore_DP0 pid=1694087) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=1694087) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.46it/s]
(EngineCore_DP0 pid=1694087) 
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:55] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1694087) [2026-01-26 17:23:55] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1694087) 2026-01-26 17:24:12,267 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1694087) 2026-01-26 17:24:12,297 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1694087) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:07,  2.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:05,  3.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:03,  4.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:00<00:01,  7.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:00<00:01, 10.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:01<00:00, 12.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:01<00:00, 14.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:01<00:01,  5.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:02<00:00,  6.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:02<00:00,  8.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:02<00:00,  7.49it/s]
(EngineCore_DP0 pid=1694087) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00, 18.78it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00, 20.26it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 20.60it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 13.18it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 14.93it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2228.90it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:02<02:41,  2.57s/it, est. speed input: 6.22 toks/s, output: 99.56 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:02<00:00,  2.57s/it, est. speed input: 391.75 toks/s, output: 6267.90 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:02<00:00, 24.48it/s, est. speed input: 391.75 toks/s, output: 6267.90 toks/s]
[rank0]:[W126 17:24:20.400823357 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 17:24:22
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 17:24:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1695192) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1695192) WARNING 01-26 17:24:46 [backends.py:609] Failed to read file <frozen os>
Throughput: 41.34 requests/s, 11245.77 total tokens/s, 10584.26 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 17:24:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 17:24:29] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:24:29] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:29] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:29] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:29] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:29] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:29] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:29] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:24:29] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:24:29] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:24:29] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:24:29] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:24:29] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 17:24:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 17:24:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:24:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:24:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:24:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:24:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:24:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:24:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:24:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:37] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:37] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:37] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:37] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:37] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1695192) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1695192) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.92it/s]
(EngineCore_DP0 pid=1695192) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=1695192) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.46it/s]
(EngineCore_DP0 pid=1695192) 
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:39] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1695192) [2026-01-26 17:24:39] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1695192) 2026-01-26 17:24:54,861 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1695192) 2026-01-26 17:24:54,910 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1695192) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:03,  9.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:05,  6.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:00<00:02, 11.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:00<00:02, 13.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:00<00:02,  9.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:01<00:05,  4.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:01<00:03,  6.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:01<00:02,  8.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:01<00:01, 10.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:02<00:01,  9.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:02<00:01, 11.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:02<00:00, 13.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:02<00:00, 14.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:02<00:00, 10.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:03<00:01,  5.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:03<00:00,  7.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:03<00:00,  8.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:03<00:00, 11.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:03<00:00,  9.10it/s]
(EngineCore_DP0 pid=1695192) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:02,  7.02it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:02,  7.62it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:00<00:01, 10.94it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:00<00:01,  9.58it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:01<00:01,  5.53it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:01<00:01,  6.24it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:01<00:01,  6.72it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:01<00:00,  9.82it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:01<00:00, 12.49it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:02<00:00,  9.28it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2507.81it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:02<06:13,  2.94s/it, est. speed input: 5.44 toks/s, output: 87.09 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:03<00:00, 58.63it/s, est. speed input: 667.81 toks/s, output: 10684.86 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 58.63it/s, est. speed input: 673.02 toks/s, output: 10768.23 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 42.06it/s, est. speed input: 673.02 toks/s, output: 10768.23 toks/s]
[rank0]:[W126 17:25:05.578859926 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 17:25:07
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 17:25:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1696317) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1696317) WARNING 01-26 17:25:30 [backends.py:609] Failed to read file <frozen os>
Throughput: 55.05 requests/s, 14973.12 total tokens/s, 14092.35 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 17:25:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 17:25:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:25:14] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:14] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:14] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:25:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:25:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:25:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:25:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:25:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 17:25:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 17:25:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:25:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:25:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:25:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:25:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:25:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:25:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:25:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1696317) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1696317) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.96it/s]
(EngineCore_DP0 pid=1696317) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=1696317) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.46it/s]
(EngineCore_DP0 pid=1696317) 
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:24] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1696317) [2026-01-26 17:25:24] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1696317) 2026-01-26 17:25:38,636 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1696317) 2026-01-26 17:25:38,687 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1696317) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:02, 12.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:02, 15.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:00<00:01, 17.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:00<00:01, 18.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:00<00:01, 13.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:01<00:04,  5.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:01<00:03,  6.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:01<00:02,  8.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:01<00:01, 10.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:02<00:01,  9.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:02<00:01, 11.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:02<00:00, 12.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:02<00:00, 13.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:02<00:00, 10.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:03<00:01,  5.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:03<00:00,  7.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:03<00:00,  9.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:03<00:00,  9.64it/s]
(EngineCore_DP0 pid=1696317) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:01, 19.14it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:03,  9.27it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:02, 10.49it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:00<00:02, 10.62it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:01<00:03,  6.22it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:01<00:02,  7.46it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:01<00:02,  7.65it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:01<00:01, 10.32it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:02<00:01, 12.68it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:02<00:00, 11.13it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:03<00:01,  6.90it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:03<00:00,  7.78it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:03<00:00,  8.41it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:03<00:00,  9.82it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:03<00:00, 12.18it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:03<00:00,  9.46it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2856.79it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:04<17:10,  4.04s/it, est. speed input: 3.96 toks/s, output: 63.36 toks/s]
Processed prompts:  34%|███▍      | 87/256 [00:04<00:05, 29.53it/s, est. speed input: 335.59 toks/s, output: 5369.32 toks/s]
Processed prompts:  65%|██████▍   | 166/256 [00:04<00:01, 64.51it/s, est. speed input: 623.74 toks/s, output: 9979.71 toks/s]
Processed prompts:  88%|████████▊ | 225/256 [00:04<00:00, 95.30it/s, est. speed input: 820.49 toks/s, output: 13127.78 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:04<00:00, 95.30it/s, est. speed input: 898.47 toks/s, output: 14375.48 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:04<00:00, 56.15it/s, est. speed input: 898.47 toks/s, output: 14375.48 toks/s]
[rank0]:[W126 17:25:52.496654749 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 17:25:54
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Qwen2.5-7B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 17:26:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1697466) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1697466) WARNING 01-26 17:26:18 [backends.py:609] Failed to read file <frozen os>
Throughput: 57.10 requests/s, 15531.58 total tokens/s, 14617.96 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 17:26:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 17:26:02] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:26:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:02] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:26:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:26:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:26:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:26:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:26:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 17:26:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 17:26:08] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:26:08] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:08] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:08] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:08] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:08] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:08] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 17:26:08] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 17:26:08] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 17:26:08] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 17:26:08] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 17:26:08] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 17:26:08] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:10] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:10] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:10] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:10] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:10] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:10] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1697466) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1697466) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.95it/s]
(EngineCore_DP0 pid=1697466) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.40it/s]
(EngineCore_DP0 pid=1697466) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.46it/s]
(EngineCore_DP0 pid=1697466) 
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5376] -> 1D uint8
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15482880 bytes
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5376] -> 1D uint8
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12042240 bytes
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5376] -> 1D uint8
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 127303680 bytes
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 28416] -> 1D uint8
(EngineCore_DP0 pid=1697466) [2026-01-26 17:26:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 63651840 bytes
(EngineCore_DP0 pid=1697466) 2026-01-26 17:26:29,729 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1697466) 2026-01-26 17:26:29,779 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1697466) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:02, 19.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:03, 12.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:02, 15.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:01<00:07,  5.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:01<00:06,  6.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:01<00:05,  7.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:01<00:04,  9.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:01<00:03, 10.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:01<00:02, 11.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:02<00:02, 13.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:02<00:03,  8.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:03<00:04,  5.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:03<00:03,  7.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:03<00:02,  8.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:03<00:02,  9.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:03<00:01, 10.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:03<00:01, 11.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:03<00:01, 13.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:04<00:01, 10.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:04<00:02,  5.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:05<00:01,  6.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:05<00:00,  8.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:05<00:00, 10.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:05<00:00, 11.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:05<00:00,  8.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:05<00:00,  8.83it/s]
(EngineCore_DP0 pid=1697466) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:06,  7.90it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 3/51 [00:00<00:13,  3.48it/s]
Capturing CUDA graphs (decode, FULL):  10%|▉         | 5/51 [00:00<00:07,  5.84it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:01<00:07,  6.17it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:01<00:06,  6.73it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:01<00:04,  9.34it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:01<00:03, 12.79it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:01<00:02, 15.21it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 17/51 [00:01<00:03, 11.12it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:02<00:04,  6.58it/s]
Capturing CUDA graphs (decode, FULL):  41%|████      | 21/51 [00:02<00:03,  7.52it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:02<00:02,  9.95it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:03<00:02,  9.71it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:03<00:01, 12.06it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:03<00:01, 13.41it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:03<00:01, 15.21it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:03<00:01, 10.93it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:04<00:02,  6.44it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:04<00:01,  7.90it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 43/51 [00:04<00:00, 10.27it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:04<00:00, 12.42it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:05<00:00, 11.43it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:05<00:00, 13.51it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:05<00:00,  9.87it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  55%|█████▌    | 284/512 [00:00<00:00, 2838.41it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 3446.66it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:06<55:32,  6.52s/it, est. speed input: 2.45 toks/s, output: 39.26 toks/s]
Processed prompts:  18%|█▊        | 91/512 [00:06<00:21, 19.40it/s, est. speed input: 219.55 toks/s, output: 3512.74 toks/s]
Processed prompts:  40%|████      | 205/512 [00:06<00:05, 52.41it/s, est. speed input: 486.23 toks/s, output: 7779.71 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:06<00:02, 89.44it/s, est. speed input: 705.54 toks/s, output: 11288.58 toks/s]
Processed prompts:  75%|███████▌  | 384/512 [00:06<00:00, 128.55it/s, est. speed input: 882.80 toks/s, output: 14124.78 toks/s]
Processed prompts:  90%|█████████ | 463/512 [00:07<00:00, 169.03it/s, est. speed input: 1040.71 toks/s, output: 16651.36 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:08<00:00, 169.03it/s, est. speed input: 929.22 toks/s, output: 14867.49 toks/s] 
Processed prompts: 100%|██████████| 512/512 [00:08<00:00, 58.07it/s, est. speed input: 929.22 toks/s, output: 14867.49 toks/s] 
[rank0]:[W126 17:26:51.494146443 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 18:04:57
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:05:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1747609) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1747609) WARNING 01-26 18:05:25 [backends.py:609] Failed to read file <frozen os>
Throughput: 15.42 requests/s, 4192.93 total tokens/s, 3946.29 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 18:05:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 18:05:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:05:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:05:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:05:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:05:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:05:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:05:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:05:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 18:05:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:05:11] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:05:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:05:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:05:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:05:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:05:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:12] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:12] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:12] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:12] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:12] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1747609) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1747609) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.30it/s]
(EngineCore_DP0 pid=1747609) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.19it/s]
(EngineCore_DP0 pid=1747609) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.63it/s]
(EngineCore_DP0 pid=1747609) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.45it/s]
(EngineCore_DP0 pid=1747609) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.43it/s]
(EngineCore_DP0 pid=1747609) 
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=1747609) [2026-01-26 18:05:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=1747609) 2026-01-26 18:05:39,256 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1747609) 2026-01-26 18:05:39,298 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1747609) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:02,  8.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:01, 10.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:00<00:01, 11.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:01<00:02,  4.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:01<00:02,  4.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:01<00:01,  5.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:01<00:01,  6.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:02<00:01,  6.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:02<00:01,  5.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:02<00:00,  5.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:03<00:00,  3.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:03<00:00,  4.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  5.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  5.30it/s]
(EngineCore_DP0 pid=1747609) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00, 11.67it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:00,  9.38it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00,  8.74it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:00<00:00,  8.77it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:01<00:00,  4.99it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  4.64it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:01<00:00,  5.29it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.55it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2391.30it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:04<04:15,  4.05s/it, est. speed input: 3.95 toks/s, output: 63.22 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:04<00:00,  4.05s/it, est. speed input: 248.36 toks/s, output: 3973.82 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:04<00:00, 15.52it/s, est. speed input: 248.36 toks/s, output: 3973.82 toks/s]
[rank0]:[W126 18:05:50.661537287 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 18:05:52
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:05:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1748851) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1748851) WARNING 01-26 18:06:21 [backends.py:609] Failed to read file <frozen os>
Throughput: 24.32 requests/s, 6615.79 total tokens/s, 6226.63 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 18:05:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 18:05:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:05:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:05:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:05:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:05:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:05:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:05:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:05:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:06:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 18:06:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:06:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:06:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:06:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:06:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:06:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:06:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:09] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:09] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:09] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:09] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:09] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:09] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1748851) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1748851) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.31it/s]
(EngineCore_DP0 pid=1748851) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.20it/s]
(EngineCore_DP0 pid=1748851) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.64it/s]
(EngineCore_DP0 pid=1748851) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.46it/s]
(EngineCore_DP0 pid=1748851) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.43it/s]
(EngineCore_DP0 pid=1748851) 
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=1748851) [2026-01-26 18:06:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=1748851) 2026-01-26 18:06:34,154 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1748851) 2026-01-26 18:06:34,224 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1748851) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:08,  4.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:05,  6.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:01<00:10,  3.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:01<00:09,  3.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:01<00:05,  5.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:01<00:03,  6.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:01<00:03,  6.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:02<00:03,  6.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:02<00:03,  6.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:02<00:04,  5.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:02<00:05,  3.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:03<00:04,  4.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:03<00:03,  4.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:03<00:02,  6.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:03<00:01,  7.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:04<00:01,  6.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:04<00:03,  3.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:04<00:02,  4.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:04<00:02,  4.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:05<00:01,  5.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:05<00:01,  6.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:05<00:00,  7.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:05<00:00,  7.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:06<00:00,  6.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:06<00:00,  3.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:06<00:00,  4.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:06<00:00,  5.17it/s]
(EngineCore_DP0 pid=1748851) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:01, 11.42it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:01, 12.04it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:01,  7.62it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:00<00:01,  7.43it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:01<00:01,  6.63it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:01<00:02,  4.43it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:01<00:01,  4.64it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:01<00:01,  5.21it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:02<00:00,  6.93it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:02<00:00,  8.36it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:02<00:00,  9.46it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:02<00:00,  7.05it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2510.80it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:05<10:38,  5.03s/it, est. speed input: 3.18 toks/s, output: 50.94 toks/s]
Processed prompts:  59%|█████▊    | 75/128 [00:05<00:02, 20.57it/s, est. speed input: 233.52 toks/s, output: 3736.28 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 20.57it/s, est. speed input: 393.11 toks/s, output: 6289.79 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:05<00:00, 24.57it/s, est. speed input: 393.11 toks/s, output: 6289.79 toks/s]
[rank0]:[W126 18:06:50.939537982 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 18:06:52
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:06:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1750161) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1750161) WARNING 01-26 18:07:21 [backends.py:609] Failed to read file <frozen os>
Throughput: 31.41 requests/s, 8544.62 total tokens/s, 8041.99 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 18:06:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 18:06:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:06:59] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:06:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:06:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:06:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:06:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:06:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:06:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:07:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 18:07:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:07:07] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 18:07:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:07:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:07:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:07:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:07:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:07:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:07:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:07:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:07:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:07:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:07:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:08] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:08] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:08] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:08] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:08] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1750161) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1750161) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.30it/s]
(EngineCore_DP0 pid=1750161) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.20it/s]
(EngineCore_DP0 pid=1750161) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.64it/s]
(EngineCore_DP0 pid=1750161) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.46it/s]
(EngineCore_DP0 pid=1750161) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.43it/s]
(EngineCore_DP0 pid=1750161) 
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:12] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=1750161) [2026-01-26 18:07:12] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=1750161) 2026-01-26 18:07:33,683 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1750161) 2026-01-26 18:07:33,748 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1750161) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:07,  4.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:07,  4.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:01<00:12,  2.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:01<00:10,  2.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:01<00:06,  4.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:01<00:04,  6.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:01<00:03,  7.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:01<00:02,  8.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:02<00:05,  4.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:03<00:04,  4.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:03<00:03,  5.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:03<00:03,  5.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:03<00:02,  6.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:03<00:02,  6.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:04<00:02,  6.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:04<00:02,  4.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:05<00:02,  4.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:05<00:01,  4.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:05<00:01,  5.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:05<00:00,  6.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 31/36 [00:05<00:00,  5.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:06<00:01,  3.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:06<00:00,  4.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:06<00:00,  5.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:06<00:00,  6.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:06<00:00,  5.22it/s]
(EngineCore_DP0 pid=1750161) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:02, 11.66it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:03,  9.22it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:00<00:04,  7.18it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:01<00:07,  4.06it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:01<00:05,  4.92it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:01<00:04,  6.03it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:01<00:03,  7.38it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:01<00:02,  8.63it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:01<00:02,  9.62it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:02<00:02,  8.93it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:02<00:02,  6.82it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:03<00:03,  4.43it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:03<00:02,  5.07it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:03<00:01,  6.63it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:03<00:01,  6.55it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:03<00:01,  7.95it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:03<00:00,  9.11it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:03<00:00,  9.99it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:04<00:00,  7.04it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:04<00:00,  4.59it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:05<00:00,  5.88it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:05<00:00,  6.71it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 3014.83it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:07<30:16,  7.12s/it, est. speed input: 2.25 toks/s, output: 35.93 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:07<00:22,  9.34it/s, est. speed input: 106.04 toks/s, output: 1696.59 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:07<00:06, 22.60it/s, est. speed input: 213.09 toks/s, output: 3409.35 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:07<00:03, 35.84it/s, est. speed input: 291.51 toks/s, output: 4664.15 toks/s]
Processed prompts:  70%|██████▉   | 178/256 [00:07<00:01, 54.79it/s, est. speed input: 375.72 toks/s, output: 6011.51 toks/s]
Processed prompts:  83%|████████▎ | 213/256 [00:07<00:00, 72.95it/s, est. speed input: 441.92 toks/s, output: 7070.72 toks/s]
Processed prompts:  96%|█████████▌| 245/256 [00:07<00:00, 86.05it/s, est. speed input: 494.91 toks/s, output: 7918.57 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:08<00:00, 86.05it/s, est. speed input: 508.04 toks/s, output: 8128.66 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:08<00:00, 31.75it/s, est. speed input: 508.04 toks/s, output: 8128.66 toks/s]
[rank0]:[W126 18:07:55.843362933 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 18:07:57
Backend: cuSPARSELt (2:8)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8/json/Qwen2.5-14B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 18:08:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1751534) [INFO] Loading compress extension: cusparselt_compress_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1751534) WARNING 01-26 18:08:25 [backends.py:609] Failed to read file <frozen os>
Throughput: 32.36 requests/s, 8801.14 total tokens/s, 8283.43 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 18:08:04] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 18:08:04] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:08:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:04] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:08:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:08:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:08:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:08:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:08:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 18:08:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 18:08:12] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:08:12] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:12] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:12] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:12] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:12] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:12] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 18:08:12] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 18:08:12] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 18:08:12] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 18:08:12] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 18:08:12] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 18:08:12] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:13] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:13] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:13] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:13] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:8, expand_ratio=1.333
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:13] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:13] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1751534) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1751534) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.30it/s]
(EngineCore_DP0 pid=1751534) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.19it/s]
(EngineCore_DP0 pid=1751534) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.63it/s]
(EngineCore_DP0 pid=1751534) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.45it/s]
(EngineCore_DP0 pid=1751534) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.42it/s]
(EngineCore_DP0 pid=1751534) 
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 7680] -> 1D uint8
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 34406400 bytes
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 7680] -> 1D uint8
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 24576000 bytes
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 7680] -> 1D uint8
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 132710400 bytes
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 20736] -> 1D uint8
(EngineCore_DP0 pid=1751534) [2026-01-26 18:08:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 66355200 bytes
(EngineCore_DP0 pid=1751534) 2026-01-26 18:08:39,617 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1751534) 2026-01-26 18:08:39,656 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1751534) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:22,  2.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:14,  3.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:10,  4.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:00<00:06,  6.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:01<00:06,  7.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:01<00:05,  7.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:01<00:09,  4.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:02<00:11,  3.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:02<00:09,  4.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:02<00:06,  5.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:02<00:05,  6.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:02<00:04,  7.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:02<00:04,  7.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:03<00:04,  7.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:03<00:06,  5.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:03<00:08,  3.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:04<00:06,  4.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:04<00:05,  5.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:04<00:03,  6.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:04<00:03,  6.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:04<00:03,  6.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:05<00:03,  6.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:05<00:05,  4.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:06<00:04,  4.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:06<00:03,  4.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:06<00:02,  5.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:06<00:01,  7.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:07<00:02,  4.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:07<00:03,  3.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:07<00:02,  4.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:07<00:02,  4.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:08<00:01,  6.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:08<00:00,  6.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:08<00:00,  6.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:09<00:00,  5.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:09<00:00,  4.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:09<00:00,  4.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:09<00:00,  5.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:09<00:00,  5.28it/s]
(EngineCore_DP0 pid=1751534) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:04, 11.17it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:04, 11.70it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:00<00:03, 11.92it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 8/51 [00:01<00:06,  6.40it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:01<00:09,  4.32it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:01<00:08,  4.68it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:01<00:07,  5.26it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:01<00:05,  6.92it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:02<00:04,  7.21it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 17/51 [00:02<00:04,  8.05it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:02<00:04,  6.61it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:03<00:07,  4.44it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:03<00:06,  4.99it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:03<00:05,  4.95it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 23/51 [00:03<00:05,  5.31it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▉     | 25/51 [00:04<00:03,  6.83it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 27/51 [00:04<00:02,  8.03it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:04<00:03,  7.48it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:04<00:05,  4.34it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:05<00:04,  4.42it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:05<00:03,  5.16it/s]
Capturing CUDA graphs (decode, FULL):  65%|██████▍   | 33/51 [00:05<00:02,  6.85it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:05<00:01,  8.18it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:05<00:02,  7.44it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:05<00:01,  8.72it/s]
Capturing CUDA graphs (decode, FULL):  76%|███████▋  | 39/51 [00:06<00:01,  8.12it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:06<00:02,  4.74it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 41/51 [00:06<00:02,  4.10it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 43/51 [00:07<00:01,  5.66it/s]
Capturing CUDA graphs (decode, FULL):  88%|████████▊ | 45/51 [00:07<00:00,  7.08it/s]
Capturing CUDA graphs (decode, FULL):  92%|█████████▏| 47/51 [00:07<00:00,  8.30it/s]
Capturing CUDA graphs (decode, FULL):  96%|█████████▌| 49/51 [00:07<00:00,  9.34it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:08<00:00,  6.84it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:08<00:00,  6.37it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  63%|██████▎   | 325/512 [00:00<00:00, 3243.60it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 3711.54it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:11<1:39:18, 11.66s/it, est. speed input: 1.37 toks/s, output: 21.95 toks/s]
Processed prompts:   6%|▋         | 33/512 [00:11<02:01,  3.95it/s, est. speed input: 44.87 toks/s, output: 717.85 toks/s]
Processed prompts:  18%|█▊        | 91/512 [00:11<00:30, 13.73it/s, est. speed input: 122.66 toks/s, output: 1962.53 toks/s]
Processed prompts:  32%|███▏      | 164/512 [00:12<00:11, 30.46it/s, est. speed input: 218.63 toks/s, output: 3498.05 toks/s]
Processed prompts:  44%|████▍     | 224/512 [00:12<00:05, 48.71it/s, est. speed input: 295.76 toks/s, output: 4732.16 toks/s]
Processed prompts:  56%|█████▋    | 288/512 [00:12<00:03, 74.03it/s, est. speed input: 376.43 toks/s, output: 6022.79 toks/s]
Processed prompts:  66%|██████▋   | 340/512 [00:12<00:01, 99.42it/s, est. speed input: 440.30 toks/s, output: 7044.83 toks/s]
Processed prompts:  76%|███████▌  | 390/512 [00:12<00:00, 126.33it/s, est. speed input: 499.40 toks/s, output: 7990.42 toks/s]
Processed prompts:  85%|████████▍ | 435/512 [00:12<00:00, 150.03it/s, est. speed input: 550.34 toks/s, output: 8805.51 toks/s]
Processed prompts:  93%|█████████▎| 476/512 [00:12<00:00, 158.14it/s, est. speed input: 591.92 toks/s, output: 9470.63 toks/s]
Processed prompts: 100%|█████████▉| 510/512 [00:15<00:00, 40.91it/s, est. speed input: 520.71 toks/s, output: 8331.42 toks/s] 
Processed prompts: 100%|██████████| 512/512 [00:15<00:00, 40.91it/s, est. speed input: 522.33 toks/s, output: 8357.26 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:15<00:00, 32.65it/s, est. speed input: 522.33 toks/s, output: 8357.26 toks/s]
[rank0]:[W126 18:09:15.147716231 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

