
========== M=16 ==========
Time: 2026-01-25 17:04:55
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=16, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 16 --max-num-seqs 16 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 17:05:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 17:05:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=163800) WARNING 01-25 17:05:12 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=163800) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=163800) WARNING 01-25 17:05:19 [backends.py:609] Failed to read file <frozen os>
Throughput: 12.85 requests/s, 3495.30 total tokens/s, 3289.69 output tokens/s
Total num prompt tokens:  256
Total num output tokens:  4096

STDERR:
[2026-01-25 17:05:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:05:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 17:05:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 17:05:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 17:05:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:05:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:05:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:05:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:05:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 17:05:11] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:05:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 17:05:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 17:05:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 17:05:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:05:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:05:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:05:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:05:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:12] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:12] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:12] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:12] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:12] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:12] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=163800) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=163800) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.81it/s]
(EngineCore_DP0 pid=163800) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.81it/s]
(EngineCore_DP0 pid=163800) 
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3145728 bytes
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25165824 bytes
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:13] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=163800) [2026-01-25 17:05:13] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12582912 bytes
(EngineCore_DP0 pid=163800) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:00,  7.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00,  7.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 3/7 [00:00<00:00,  8.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 4/7 [00:00<00:00,  6.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00,  7.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 6/7 [00:00<00:00,  7.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  6.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:01<00:00,  6.74it/s]
(EngineCore_DP0 pid=163800) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 1/5 [00:00<00:00,  8.10it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 2/5 [00:00<00:00,  8.96it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00,  9.24it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 4/5 [00:00<00:00,  9.49it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00,  9.45it/s]

Adding requests:   0%|          | 0/16 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 16/16 [00:00<00:00, 2280.91it/s]

Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 1/16 [00:01<00:18,  1.23s/it, est. speed input: 12.99 toks/s, output: 207.77 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:01<00:00,  1.23s/it, est. speed input: 207.02 toks/s, output: 3312.35 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:01<00:00, 12.94it/s, est. speed input: 207.02 toks/s, output: 3312.35 toks/s]
[rank0]:[W125 17:05:33.106190605 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-25 17:05:36
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 17:05:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 17:05:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=164614) WARNING 01-25 17:05:53 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=164614) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=164614) WARNING 01-25 17:06:00 [backends.py:609] Failed to read file <frozen os>
Throughput: 53.28 requests/s, 14491.88 total tokens/s, 13639.41 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-25 17:05:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:05:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 17:05:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 17:05:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 17:05:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:05:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:05:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:05:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:05:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 17:05:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:05:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 17:05:52] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 17:05:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:05:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 17:05:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:05:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:05:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:05:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:05:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:53] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:53] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:53] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:53] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:53] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=164614) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=164614) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.82it/s]
(EngineCore_DP0 pid=164614) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.82it/s]
(EngineCore_DP0 pid=164614) 
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3145728 bytes
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25165824 bytes
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:54] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=164614) [2026-01-25 17:05:54] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12582912 bytes
(EngineCore_DP0 pid=164614) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:03,  8.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:03,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:03,  8.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:00<00:03,  9.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:00<00:03,  9.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:00<00:03,  9.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:00<00:02,  9.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:00<00:02,  9.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:00<00:02,  9.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:01<00:02,  9.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:01<00:02,  9.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:01<00:02,  9.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:01<00:02,  9.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:01<00:02,  8.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:01<00:02,  6.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:02<00:03,  5.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:02<00:04,  4.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:02<00:03,  5.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:02<00:02,  6.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:02<00:01,  7.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:03<00:01,  8.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:03<00:00,  8.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:03<00:00,  9.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:03<00:00,  9.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 18.41it/s]
(EngineCore_DP0 pid=164614) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  8.61it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:01,  9.75it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:00<00:01,  9.84it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:01,  8.93it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:00<00:01,  8.83it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:00<00:01,  7.57it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:01<00:01,  7.72it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:01<00:00,  8.90it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:01<00:00,  9.50it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:01<00:00,  9.94it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:01<00:00, 10.26it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:01<00:00, 10.55it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:01<00:00,  9.55it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2927.53it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:02<04:51,  2.29s/it, est. speed input: 6.97 toks/s, output: 111.55 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00,  2.29s/it, est. speed input: 868.83 toks/s, output: 13901.17 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00, 54.30it/s, est. speed input: 868.83 toks/s, output: 13901.17 toks/s]
[rank0]:[W125 17:06:16.407173874 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-25 17:06:19
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-25 17:06:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-25 17:06:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=165446) WARNING 01-25 17:06:36 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=165446) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=165446) WARNING 01-25 17:06:42 [backends.py:609] Failed to read file <frozen os>
Throughput: 81.99 requests/s, 22302.51 total tokens/s, 20990.60 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-25 17:06:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:06:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 17:06:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 17:06:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:06:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:06:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:06:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:06:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:06:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 17:06:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:06:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:06:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:06:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:06:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-25 17:06:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-25 17:06:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-25 17:06:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-25 17:06:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:06:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:06:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:06:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:06:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-25 17:06:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-25 17:06:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-25 17:06:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-25 17:06:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-25 17:06:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-25 17:06:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=165446) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=165446) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.15it/s]
(EngineCore_DP0 pid=165446) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.15it/s]
(EngineCore_DP0 pid=165446) 
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3145728 bytes
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25165824 bytes
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:37] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=165446) [2026-01-25 17:06:37] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12582912 bytes
(EngineCore_DP0 pid=165446) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:05,  6.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:06,  4.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:06,  5.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:05,  5.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:00<00:04,  6.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:00<00:03,  7.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:01<00:03,  8.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:01<00:03,  8.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:01<00:03,  8.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:01<00:02,  9.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:01<00:02,  9.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:01<00:02,  9.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:01<00:02,  9.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:02<00:01,  9.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:02<00:01,  9.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:02<00:01,  9.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:02<00:01,  9.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:02<00:01, 10.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:02<00:00, 10.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:03<00:00,  9.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:03<00:00,  8.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:03<00:00,  8.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 31/36 [00:03<00:00,  7.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:03<00:00,  8.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:03<00:00,  9.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:04<00:00,  9.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:04<00:00,  8.74it/s]
(EngineCore_DP0 pid=165446) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:04,  7.56it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:03,  8.73it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:00<00:03,  9.19it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:03,  9.38it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:00<00:03,  9.30it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:03,  9.45it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:00<00:02,  9.57it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:00<00:02,  9.51it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:00<00:02,  9.43it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:01<00:02,  9.49it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:01<00:02,  9.42it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:01<00:02,  9.46it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:01<00:02,  9.36it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:01<00:02,  9.31it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:01<00:02,  9.34it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:01<00:02,  9.38it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:01<00:01,  9.42it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:01<00:01,  9.43it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:02<00:01,  9.44it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:02<00:01,  9.40it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:02<00:01,  9.06it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:02<00:01,  8.07it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:02<00:01,  8.26it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:02<00:01,  6.92it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:02<00:01,  7.10it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:02<00:01,  7.66it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:03<00:00,  8.16it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:03<00:00,  8.36it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:03<00:00,  8.79it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:03<00:00,  9.11it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:03<00:00,  9.23it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:03<00:00,  9.32it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:03<00:00,  9.45it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:03<00:00,  9.47it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:03<00:00,  8.96it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2934.59it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:02<11:34,  2.73s/it, est. speed input: 5.87 toks/s, output: 93.93 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:02<00:02, 58.59it/s, est. speed input: 667.99 toks/s, output: 10687.84 toks/s]
Processed prompts:  84%|████████▍ | 216/256 [00:02<00:00, 119.58it/s, est. speed input: 1180.04 toks/s, output: 18880.50 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 119.58it/s, est. speed input: 1350.39 toks/s, output: 21606.18 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 84.39it/s, est. speed input: 1350.39 toks/s, output: 21606.18 toks/s] 
[rank0]:[W125 17:07:03.744946030 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 08:48:51
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:48:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:49:00 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=421169) WARNING 01-26 08:49:08 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=421169) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=421169) WARNING 01-26 08:49:15 [backends.py:609] Failed to read file <frozen os>
Throughput: 39.75 requests/s, 10813.09 total tokens/s, 10177.02 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 08:48:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:48:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:48:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:48:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:48:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:48:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:48:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:48:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:48:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:48:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:48:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:48:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:48:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:48:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:49:07] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:49:07] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:49:07] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:49:07] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:07] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:07] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:07] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:07] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:07] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:49:07] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:49:07] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:49:07] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:49:07] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:49:07] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=421169) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=421169) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.25s/it]
(EngineCore_DP0 pid=421169) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.25s/it]
(EngineCore_DP0 pid=421169) 
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3145728 bytes
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25165824 bytes
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:10] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=421169) [2026-01-26 08:49:10] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12582912 bytes
(EngineCore_DP0 pid=421169) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:10,  1.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:01<00:09,  1.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:01<00:06,  2.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:01<00:04,  3.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:01<00:02,  5.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:01<00:01,  6.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:01<00:01,  7.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:02<00:01,  7.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:02<00:01,  7.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:02<00:00,  8.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:02<00:00,  9.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:02<00:00,  9.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:02<00:00,  9.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:02<00:00,  6.42it/s]
(EngineCore_DP0 pid=421169) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  6.87it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:01,  6.61it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:01,  4.13it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:01,  5.32it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:01,  5.55it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:01<00:01,  4.84it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:01<00:00,  5.67it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  7.23it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  8.35it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.56it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2759.67it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:01<01:38,  1.56s/it, est. speed input: 10.25 toks/s, output: 163.93 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00,  1.56s/it, est. speed input: 646.01 toks/s, output: 10336.17 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00, 40.37it/s, est. speed input: 646.01 toks/s, output: 10336.17 toks/s]
[rank0]:[W126 08:49:31.866076310 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 08:49:34
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:49:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:49:44 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=421955) WARNING 01-26 08:49:50 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=421955) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=421955) WARNING 01-26 08:49:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 52.80 requests/s, 14361.30 total tokens/s, 13516.51 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 08:49:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:49:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:49:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:49:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:49:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:49:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:49:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:49:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:49:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:49:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:49:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:49:49] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:49:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:49:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:49:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:49:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:49:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:49:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:49:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:51] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:51] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:51] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:51] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:51] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=421955) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=421955) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.06it/s]
(EngineCore_DP0 pid=421955) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.06it/s]
(EngineCore_DP0 pid=421955) 
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3145728 bytes
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25165824 bytes
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:52] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=421955) [2026-01-26 08:49:52] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12582912 bytes
(EngineCore_DP0 pid=421955) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:04,  7.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:04,  8.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:04,  7.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:00<00:04,  6.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:00<00:06,  4.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:01<00:06,  4.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:01<00:05,  5.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:01<00:07,  3.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:01<00:05,  4.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:01<00:04,  5.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:02<00:03,  6.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:02<00:03,  6.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:02<00:02,  7.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:02<00:02,  8.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:02<00:02,  8.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:02<00:02,  8.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:02<00:02,  8.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:02<00:01,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:02<00:01,  9.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:02<00:01,  9.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:03<00:01,  9.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:03<00:01,  9.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:03<00:01,  9.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:03<00:01,  9.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:03<00:01,  9.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:03<00:01,  7.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:04<00:01,  4.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:04<00:01,  5.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:04<00:01,  5.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:04<00:01,  4.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:04<00:00,  4.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:05<00:00,  5.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:05<00:00,  6.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:05<00:00,  7.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:05<00:00,  7.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:05<00:00,  6.50it/s]
(EngineCore_DP0 pid=421955) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  7.56it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:01,  9.27it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:01,  9.43it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:00<00:01,  9.61it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:00<00:01,  9.80it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:00<00:01,  9.86it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:01<00:00,  9.78it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:01<00:00,  9.83it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:01<00:00,  9.86it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:01<00:00,  9.04it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:01<00:00,  6.75it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:01<00:00,  6.47it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:02<00:00,  7.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:02<00:00,  4.96it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:02<00:00,  7.36it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2819.76it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:02<04:54,  2.32s/it, est. speed input: 6.90 toks/s, output: 110.46 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00,  2.32s/it, est. speed input: 861.49 toks/s, output: 13783.79 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00, 53.84it/s, est. speed input: 861.49 toks/s, output: 13783.79 toks/s]
[rank0]:[W126 08:50:17.437286751 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 08:50:19
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:50:27 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:50:28 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=422809) WARNING 01-26 08:50:36 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=422809) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=422809) WARNING 01-26 08:50:44 [backends.py:609] Failed to read file <frozen os>
Throughput: 80.07 requests/s, 21779.65 total tokens/s, 20498.49 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 08:50:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:50:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:50:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:50:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:50:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:50:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:50:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:50:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:50:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:50:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:50:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:50:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:50:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:50:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:50:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:50:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:50:35] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:50:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:50:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:50:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:50:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:50:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:50:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:50:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:50:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:50:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:50:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:50:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:37] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:37] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:37] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:37] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:37] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:37] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=422809) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=422809) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.16it/s]
(EngineCore_DP0 pid=422809) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.16it/s]
(EngineCore_DP0 pid=422809) 
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3145728 bytes
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25165824 bytes
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:38] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=422809) [2026-01-26 08:50:38] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12582912 bytes
(EngineCore_DP0 pid=422809) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:16,  2.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:13,  2.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:01<00:12,  2.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:01<00:09,  3.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:01<00:06,  4.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:01<00:05,  5.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:01<00:04,  6.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:01<00:03,  7.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:01<00:03,  7.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:01<00:03,  8.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███       | 11/36 [00:02<00:02,  8.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:02<00:02,  9.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:02<00:02,  9.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:02<00:02,  9.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:02<00:02,  9.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:02<00:02,  9.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:02<00:02,  9.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:02<00:01,  9.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:02<00:02,  8.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:03<00:02,  7.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:03<00:03,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:03<00:03,  4.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:04<00:03,  3.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:04<00:03,  3.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▉   | 25/36 [00:04<00:02,  4.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:04<00:01,  5.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:04<00:01,  6.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:04<00:01,  6.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:04<00:00,  7.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:05<00:00,  7.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 31/36 [00:05<00:00,  7.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:05<00:00,  8.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:05<00:00,  8.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:05<00:00,  8.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:05<00:00,  8.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:05<00:00,  7.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:05<00:00,  6.24it/s]
(EngineCore_DP0 pid=422809) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:04,  7.53it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:03,  8.57it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:00<00:04,  7.60it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:08,  3.58it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:01<00:06,  4.53it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:01<00:06,  4.77it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:01<00:06,  4.05it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:01<00:06,  4.45it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:01<00:04,  5.36it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:01<00:04,  6.24it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:02<00:03,  6.98it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:02<00:03,  7.59it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:02<00:02,  8.15it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:02<00:02,  8.62it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:02<00:02,  8.95it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:02<00:02,  9.20it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:02<00:01,  9.41it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:02<00:01,  9.71it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:02<00:01,  9.77it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:03<00:01,  9.44it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:03<00:01,  9.54it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:03<00:01,  9.56it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:03<00:01,  9.60it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:03<00:01,  8.91it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:03<00:01,  5.65it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:04<00:01,  5.56it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:04<00:01,  5.95it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:04<00:01,  4.81it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:04<00:00,  5.51it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:04<00:00,  6.33it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:04<00:00,  7.06it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:05<00:00,  8.18it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:05<00:00,  6.89it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2907.50it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:02<11:55,  2.81s/it, est. speed input: 5.70 toks/s, output: 91.23 toks/s]
Processed prompts:  46%|████▌     | 118/256 [00:02<00:02, 56.98it/s, est. speed input: 649.37 toks/s, output: 10389.92 toks/s]
Processed prompts:  86%|████████▌ | 219/256 [00:03<00:00, 118.31it/s, est. speed input: 1163.51 toks/s, output: 18616.01 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 118.31it/s, est. speed input: 1318.16 toks/s, output: 21090.45 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 82.38it/s, est. speed input: 1318.16 toks/s, output: 21090.45 toks/s] 
[rank0]:[W126 08:51:06.851841335 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 08:51:09
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-1B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 08:51:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 08:51:17 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=423671) WARNING 01-26 08:51:25 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=423671) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=423671) WARNING 01-26 08:51:32 [backends.py:609] Failed to read file <frozen os>
Throughput: 79.32 requests/s, 21575.27 total tokens/s, 20306.13 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 08:51:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:51:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:51:17] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:51:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:51:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:51:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:51:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:51:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:51:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:51:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:51:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:51:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:51:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:51:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 08:51:23] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 08:51:23] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 08:51:23] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 08:51:23] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:51:23] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:51:23] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:51:23] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:51:23] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 08:51:23] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 08:51:23] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 08:51:23] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 08:51:23] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 08:51:23] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 08:51:23] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:25] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:25] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:25] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:25] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:25] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=423671) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=423671) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.04it/s]
(EngineCore_DP0 pid=423671) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.04it/s]
(EngineCore_DP0 pid=423671) 
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 2048] -> 1D uint8
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 4718592 bytes
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 2048] -> 1D uint8
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 3145728 bytes
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 2048] -> 1D uint8
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 25165824 bytes
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:26] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [2048, 8192] -> 1D uint8
(EngineCore_DP0 pid=423671) [2026-01-26 08:51:26] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12582912 bytes
(EngineCore_DP0 pid=423671) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:05,  9.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:05,  9.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:04,  9.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:04,  9.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:00<00:04,  9.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:04,  9.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:00<00:04,  9.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:00<00:04,  9.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:01<00:04,  9.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:01<00:04,  9.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:01<00:04,  9.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:01<00:05,  6.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:01<00:07,  4.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:01<00:06,  5.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:02<00:05,  6.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:02<00:09,  3.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:02<00:07,  4.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:02<00:06,  5.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:02<00:05,  6.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:03<00:04,  6.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:03<00:03,  7.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:03<00:03,  8.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:03<00:03,  8.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:03<00:02,  8.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:03<00:02,  9.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:03<00:02,  9.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:03<00:02,  9.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:03<00:02,  9.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:04<00:02,  9.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:04<00:02,  9.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:04<00:02,  8.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:04<00:02,  6.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:04<00:03,  5.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:05<00:03,  4.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:05<00:03,  4.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:05<00:03,  3.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:05<00:02,  4.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:05<00:02,  5.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:06<00:01,  6.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:06<00:01,  6.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:06<00:01,  7.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:06<00:00,  7.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:06<00:00,  8.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:06<00:00,  8.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:06<00:00,  8.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:06<00:00,  8.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:06<00:00,  8.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:07<00:00,  9.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:07<00:00,  8.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:07<00:00,  7.06it/s]
(EngineCore_DP0 pid=423671) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:08,  5.78it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:07,  6.52it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 3/51 [00:00<00:08,  5.62it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:00<00:01, 20.52it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:00<00:02, 16.47it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:01<00:02, 14.11it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 17/51 [00:01<00:02, 12.70it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:01<00:02, 11.81it/s]
Capturing CUDA graphs (decode, FULL):  41%|████      | 21/51 [00:01<00:02, 11.22it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 23/51 [00:01<00:02, 10.29it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▉     | 25/51 [00:02<00:04,  6.33it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:02<00:03,  6.73it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 27/51 [00:02<00:03,  6.86it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:03<00:04,  5.55it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:03<00:04,  5.09it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:03<00:03,  5.78it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:03<00:03,  6.48it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:03<00:02,  7.13it/s]
Capturing CUDA graphs (decode, FULL):  65%|██████▍   | 33/51 [00:03<00:02,  7.75it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:03<00:01,  8.59it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:04<00:01,  8.89it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:04<00:01,  9.32it/s]
Capturing CUDA graphs (decode, FULL):  76%|███████▋  | 39/51 [00:04<00:01,  9.46it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 41/51 [00:04<00:01,  9.70it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 43/51 [00:04<00:00,  9.89it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:04<00:00,  9.86it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:05<00:00,  9.56it/s]
Capturing CUDA graphs (decode, FULL):  92%|█████████▏| 47/51 [00:05<00:00,  8.88it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:05<00:00,  8.79it/s]
Capturing CUDA graphs (decode, FULL):  96%|█████████▌| 49/51 [00:05<00:00,  5.73it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:05<00:00,  6.93it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:05<00:00,  8.63it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  56%|█████▌    | 286/512 [00:00<00:00, 2851.70it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 2935.53it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:04<42:18,  4.97s/it, est. speed input: 3.22 toks/s, output: 51.54 toks/s]
Processed prompts:  12%|█▏        | 63/512 [00:05<00:25, 17.51it/s, est. speed input: 198.76 toks/s, output: 3180.20 toks/s]
Processed prompts:  36%|███▌      | 185/512 [00:05<00:05, 63.50it/s, est. speed input: 571.79 toks/s, output: 9148.55 toks/s]
Processed prompts:  64%|██████▍   | 327/512 [00:05<00:01, 133.58it/s, est. speed input: 990.83 toks/s, output: 15853.27 toks/s]
Processed prompts:  85%|████████▍ | 433/512 [00:05<00:00, 197.28it/s, est. speed input: 1287.50 toks/s, output: 20599.94 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:06<00:00, 197.28it/s, est. speed input: 1304.79 toks/s, output: 20876.65 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:06<00:00, 81.55it/s, est. speed input: 1304.79 toks/s, output: 20876.65 toks/s] 
[rank0]:[W126 08:52:06.455085391 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 09:23:53
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:24:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 09:24:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=458976) WARNING 01-26 09:24:10 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=458976) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=458976) WARNING 01-26 09:24:24 [backends.py:609] Failed to read file <frozen os>
Throughput: 20.43 requests/s, 5558.07 total tokens/s, 5231.12 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 09:24:00] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:24:00] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:24:00] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:24:00] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:00] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:00] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:00] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:00] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:00] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:24:00] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:24:00] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:24:00] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:24:00] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:24:00] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:24:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:24:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:24:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:24:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:24:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:24:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:24:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:24:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:24:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:11] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:11] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:11] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:11] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:11] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:11] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=458976) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=458976) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:02<00:00,  2.96s/it]
(EngineCore_DP0 pid=458976) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:02<00:00,  2.96s/it]
(EngineCore_DP0 pid=458976) 
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11796480 bytes
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:14] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=458976) [2026-01-26 09:24:14] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=458976) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:02,  7.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:02,  7.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:02,  7.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:00<00:01,  7.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:00<00:01,  8.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:00<00:01,  8.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:00<00:01,  7.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:01<00:01,  6.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:01<00:02,  3.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:01<00:02,  3.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:02<00:02,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:02<00:01,  3.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:02<00:01,  4.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:02<00:00,  5.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:02<00:00,  6.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:02<00:00,  6.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:02<00:00,  7.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:03<00:00,  7.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  7.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  5.88it/s]
(EngineCore_DP0 pid=458976) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  7.48it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:01,  8.31it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:00,  8.60it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:00,  8.73it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:00<00:00,  8.85it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00,  8.84it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:00<00:00,  8.96it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00,  7.76it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  4.20it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:01<00:00,  4.47it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  5.18it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00,  6.25it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2671.19it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:03<03:13,  3.07s/it, est. speed input: 5.22 toks/s, output: 83.45 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:03<00:00,  3.07s/it, est. speed input: 329.64 toks/s, output: 5274.22 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:03<00:00, 20.60it/s, est. speed input: 329.64 toks/s, output: 5274.22 toks/s]
[rank0]:[W126 09:24:47.773856627 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 09:24:51
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:24:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 09:24:58 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=460000) WARNING 01-26 09:25:07 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=460000) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=460000) WARNING 01-26 09:25:19 [backends.py:609] Failed to read file <frozen os>
Throughput: 36.22 requests/s, 9850.95 total tokens/s, 9271.49 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 09:24:59] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:24:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:24:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:24:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:24:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:24:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:24:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:24:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:24:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:24:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:25:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:25:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:25:05] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:25:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:25:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:25:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:25:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:25:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:25:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:08] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:08] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:08] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:08] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:08] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:08] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=460000) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=460000) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.33it/s]
(EngineCore_DP0 pid=460000) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.33it/s]
(EngineCore_DP0 pid=460000) 
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11796480 bytes
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:09] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=460000) [2026-01-26 09:25:09] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=460000) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:22,  1.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:01<00:22,  1.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:01<00:13,  2.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:01<00:09,  3.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:01<00:07,  4.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:01<00:05,  5.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:01<00:04,  5.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:02<00:04,  6.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:02<00:03,  6.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:02<00:03,  7.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:02<00:03,  7.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:02<00:03,  7.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:02<00:02,  7.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:02<00:02,  7.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:02<00:02,  8.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:03<00:02,  7.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:03<00:02,  6.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:03<00:04,  4.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:04<00:03,  4.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:04<00:04,  3.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:04<00:03,  3.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:04<00:03,  4.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:04<00:02,  4.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:05<00:01,  5.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:05<00:01,  5.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:05<00:01,  6.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:05<00:01,  6.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:05<00:01,  6.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:05<00:00,  6.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:05<00:00,  7.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:06<00:00,  7.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:06<00:00,  7.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:06<00:00,  6.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:06<00:00,  3.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:07<00:00,  4.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:07<00:00,  4.95it/s]
(EngineCore_DP0 pid=460000) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:06,  2.74it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:05,  3.01it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:04,  3.97it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:03,  4.68it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:01<00:02,  5.22it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:01<00:02,  5.70it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:01<00:01,  6.10it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:01<00:01,  6.46it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:01<00:01,  7.05it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:01<00:01,  7.56it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:01<00:00,  8.00it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:02<00:00,  8.25it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:02<00:00,  8.49it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:02<00:00,  8.61it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:02<00:00,  7.28it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:02<00:00,  7.50it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:02<00:00,  5.42it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:02<00:00,  5.74it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:03<00:00,  5.99it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:03<00:00,  6.05it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2810.49it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:03<07:09,  3.38s/it, est. speed input: 4.73 toks/s, output: 75.70 toks/s]
Processed prompts:  99%|█████████▉| 127/128 [00:03<00:00, 51.24it/s, est. speed input: 582.74 toks/s, output: 9323.85 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 51.24it/s, est. speed input: 587.30 toks/s, output: 9396.81 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.70it/s, est. speed input: 587.30 toks/s, output: 9396.81 toks/s]
[rank0]:[W126 09:25:45.791105232 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 09:25:48
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:25:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 09:25:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=461030) WARNING 01-26 09:26:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=461030) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=461030) WARNING 01-26 09:26:16 [backends.py:609] Failed to read file <frozen os>
Throughput: 49.34 requests/s, 13420.40 total tokens/s, 12630.96 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 09:25:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:25:56] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:25:56] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:25:56] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:56] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:56] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:56] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:56] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:25:56] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:25:56] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:25:56] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:25:56] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:25:56] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:25:56] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:26:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:26:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:26:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:26:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:26:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:26:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:26:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:26:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:26:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=461030) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=461030) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.33it/s]
(EngineCore_DP0 pid=461030) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.33it/s]
(EngineCore_DP0 pid=461030) 
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11796480 bytes
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=461030) [2026-01-26 09:26:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=461030) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:13,  2.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:09,  3.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:01<00:11,  2.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:01<00:08,  3.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:01<00:06,  4.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:01<00:05,  5.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:01<00:04,  6.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:01<00:04,  6.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:01<00:03,  7.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:01<00:03,  7.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███       | 11/36 [00:01<00:03,  7.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:02<00:02,  8.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:02<00:02,  8.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:02<00:02,  8.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:02<00:02,  8.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:02<00:02,  8.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:02<00:02,  8.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:02<00:03,  5.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:03<00:04,  3.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:03<00:04,  3.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:04<00:04,  3.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:04<00:03,  3.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:04<00:02,  4.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:04<00:00, 20.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:04<00:00,  7.78it/s]
(EngineCore_DP0 pid=461030) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:14,  2.33it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:09,  3.39it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:01<00:13,  2.42it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:01<00:09,  3.13it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:01<00:08,  3.74it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:01<00:06,  4.34it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:01<00:05,  4.87it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:01<00:04,  5.53it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:02<00:04,  6.28it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:02<00:03,  6.47it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:02<00:03,  6.63it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:02<00:03,  7.15it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:02<00:02,  7.57it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:02<00:02,  7.82it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:02<00:02,  8.08it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:02<00:02,  8.27it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:03<00:02,  8.10it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:03<00:03,  4.51it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:03<00:03,  4.95it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:03<00:02,  5.17it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:04<00:02,  4.86it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:04<00:02,  4.46it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:04<00:02,  5.28it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:04<00:01,  6.04it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:04<00:01,  6.43it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:04<00:01,  6.69it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:04<00:01,  7.22it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:05<00:00,  7.59it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:05<00:00,  7.96it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:05<00:00,  8.23it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:05<00:00,  8.49it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:05<00:00,  8.76it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:05<00:00,  8.93it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:05<00:00,  9.06it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:05<00:00,  9.14it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:05<00:00,  6.00it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2886.97it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:04<19:24,  4.57s/it, est. speed input: 3.50 toks/s, output: 56.07 toks/s]
Processed prompts:  24%|██▍       | 62/256 [00:04<00:10, 18.71it/s, est. speed input: 212.57 toks/s, output: 3401.10 toks/s]
Processed prompts:  53%|█████▎    | 136/256 [00:04<00:02, 48.50it/s, est. speed input: 455.71 toks/s, output: 7291.27 toks/s]
Processed prompts:  75%|███████▌  | 193/256 [00:04<00:00, 77.59it/s, est. speed input: 633.37 toks/s, output: 10133.83 toks/s]
Processed prompts:  96%|█████████▋| 247/256 [00:05<00:00, 106.43it/s, est. speed input: 783.64 toks/s, output: 12538.27 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:05<00:00, 106.43it/s, est. speed input: 803.43 toks/s, output: 12854.79 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:05<00:00, 50.21it/s, est. speed input: 803.43 toks/s, output: 12854.79 toks/s] 
[rank0]:[W126 09:26:45.432870546 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 09:26:48
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Llama3.2-3B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 09:26:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 09:26:58 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=462099) WARNING 01-26 09:27:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=462099) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=462099) WARNING 01-26 09:27:16 [backends.py:609] Failed to read file <frozen os>
Throughput: 50.08 requests/s, 13621.98 total tokens/s, 12820.69 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 09:26:57] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:26:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:26:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:26:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:26:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:26:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:26:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:26:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:26:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:26:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 09:27:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 09:27:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-INT8'
[2026-01-26 09:27:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-INT8
[2026-01-26 09:27:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-INT8
[2026-01-26 09:27:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-INT8'
[2026-01-26 09:27:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 09:27:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 09:27:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 09:27:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 09:27:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:05] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:05] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:05] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:05] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:05] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-3B-INT8
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:05] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=462099) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=462099) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.32it/s]
(EngineCore_DP0 pid=462099) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.32it/s]
(EngineCore_DP0 pid=462099) 
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 3072] -> 1D uint8
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 11796480 bytes
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 3072] -> 1D uint8
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 7077888 bytes
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [16384, 3072] -> 1D uint8
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 37748736 bytes
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:06] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3072, 8192] -> 1D uint8
(EngineCore_DP0 pid=462099) [2026-01-26 09:27:06] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 18874368 bytes
(EngineCore_DP0 pid=462099) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:06,  8.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:05,  8.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:05,  8.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:05,  8.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:00<00:05,  8.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:05,  7.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:01<00:07,  5.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:01<00:11,  3.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:01<00:02, 15.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:01<00:02, 12.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:02<00:02, 11.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:02<00:02, 10.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:03<00:03,  6.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:03<00:04,  4.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:04<00:04,  4.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:04<00:04,  5.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:04<00:03,  5.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:04<00:03,  5.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:04<00:02,  6.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:04<00:02,  6.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:04<00:02,  6.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:05<00:02,  6.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:05<00:02,  6.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:05<00:01,  6.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:05<00:01,  6.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:05<00:01,  6.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:05<00:01,  5.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:06<00:02,  3.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:06<00:02,  3.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:06<00:02,  3.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:07<00:01,  3.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:07<00:01,  4.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:07<00:00,  4.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:07<00:00,  5.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:07<00:00,  5.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:07<00:00,  5.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:08<00:00,  5.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:08<00:00,  6.27it/s]
(EngineCore_DP0 pid=462099) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:11,  4.43it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:08,  6.01it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 3/51 [00:00<00:07,  6.81it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:06,  6.96it/s]
Capturing CUDA graphs (decode, FULL):  10%|▉         | 5/51 [00:00<00:07,  6.34it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:01<00:11,  3.77it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:01<00:09,  4.54it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 8/51 [00:01<00:09,  4.59it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:01<00:10,  3.82it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:02<00:09,  4.16it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:02<00:08,  4.93it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:02<00:06,  5.62it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:02<00:06,  6.30it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:02<00:05,  6.92it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:02<00:04,  7.41it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:02<00:04,  7.76it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 17/51 [00:02<00:04,  8.05it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:03<00:03,  8.25it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:03<00:03,  8.42it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:03<00:03,  8.48it/s]
Capturing CUDA graphs (decode, FULL):  41%|████      | 21/51 [00:03<00:03,  8.23it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:03<00:03,  7.63it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 23/51 [00:03<00:03,  7.85it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:03<00:04,  6.32it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▉     | 25/51 [00:04<00:06,  4.00it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:04<00:05,  4.75it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 27/51 [00:04<00:05,  4.70it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:04<00:05,  4.52it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:05<00:05,  4.04it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:05<00:04,  4.77it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:05<00:03,  5.48it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:05<00:03,  6.07it/s]
Capturing CUDA graphs (decode, FULL):  65%|██████▍   | 33/51 [00:05<00:02,  6.62it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:05<00:02,  7.11it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:06<00:02,  7.49it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:06<00:01,  7.70it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 37/51 [00:06<00:01,  7.89it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:06<00:01,  8.06it/s]
Capturing CUDA graphs (decode, FULL):  76%|███████▋  | 39/51 [00:06<00:01,  8.23it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:06<00:01,  8.26it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 41/51 [00:06<00:01,  8.38it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:06<00:01,  7.42it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 43/51 [00:07<00:01,  6.67it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:07<00:01,  4.05it/s]
Capturing CUDA graphs (decode, FULL):  88%|████████▊ | 45/51 [00:07<00:01,  4.21it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:08<00:01,  3.64it/s]
Capturing CUDA graphs (decode, FULL):  92%|█████████▏| 47/51 [00:08<00:01,  3.95it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:08<00:00,  4.58it/s]
Capturing CUDA graphs (decode, FULL):  96%|█████████▌| 49/51 [00:08<00:00,  5.21it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:08<00:00,  5.76it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:08<00:00,  6.23it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:08<00:00,  5.76it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  59%|█████▉    | 301/512 [00:00<00:00, 3003.68it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 3034.39it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:07<1:06:40,  7.83s/it, est. speed input: 2.04 toks/s, output: 32.70 toks/s]
Processed prompts:   6%|▋         | 33/512 [00:07<01:22,  5.84it/s, est. speed input: 66.41 toks/s, output: 1062.54 toks/s]
Processed prompts:  18%|█▊        | 91/512 [00:08<00:20, 20.09it/s, est. speed input: 180.74 toks/s, output: 2891.83 toks/s]
Processed prompts:  32%|███▏      | 164/512 [00:08<00:07, 44.36it/s, est. speed input: 321.59 toks/s, output: 5145.39 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:08<00:03, 78.64it/s, est. speed input: 468.78 toks/s, output: 7500.44 toks/s]
Processed prompts:  64%|██████▍   | 327/512 [00:08<00:01, 125.80it/s, est. speed input: 624.92 toks/s, output: 9998.69 toks/s]
Processed prompts:  78%|███████▊  | 399/512 [00:08<00:00, 172.41it/s, est. speed input: 752.44 toks/s, output: 12039.04 toks/s]
Processed prompts:  91%|█████████ | 464/512 [00:08<00:00, 213.55it/s, est. speed input: 861.13 toks/s, output: 13778.06 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:10<00:00, 213.55it/s, est. speed input: 814.89 toks/s, output: 13038.20 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:10<00:00, 50.93it/s, est. speed input: 814.89 toks/s, output: 13038.20 toks/s] 
[rank0]:[W126 09:28:02.655262550 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 10:07:23
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:07:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:07:32 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=503800) WARNING 01-26 10:07:41 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=503800) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=503800) WARNING 01-26 10:07:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 17.95 requests/s, 4881.80 total tokens/s, 4594.63 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 10:07:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:07:31] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:07:31] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:31] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:31] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:31] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:31] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:31] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:31] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:07:31] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:07:31] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:07:31] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:07:31] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:07:31] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:07:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:07:40] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:07:40] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:40] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:40] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:40] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:40] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:40] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:07:40] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:07:40] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:07:40] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:07:40] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:07:40] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:07:40] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:41] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:41] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:41] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:41] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:41] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:41] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=503800) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=503800) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:02<00:02,  2.97s/it]
(EngineCore_DP0 pid=503800) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.54s/it]
(EngineCore_DP0 pid=503800) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.46s/it]
(EngineCore_DP0 pid=503800) 
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=503800) [2026-01-26 10:07:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=503800) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:05,  3.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:05,  3.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:03,  4.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:01<00:05,  2.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:01<00:04,  3.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:01<00:03,  3.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:02<00:04,  2.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:02<00:03,  3.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:02<00:02,  4.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:02<00:01,  5.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:02<00:01,  5.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:02<00:01,  6.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:02<00:00,  6.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:03<00:00,  7.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:03<00:00,  7.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:03<00:00,  7.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:03<00:00,  8.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:03<00:00,  8.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  7.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:03<00:00,  5.12it/s]
(EngineCore_DP0 pid=503800) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:01,  7.11it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:01,  6.12it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:02,  3.60it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:01,  3.96it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:01<00:01,  4.61it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:01<00:01,  3.83it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:01<00:01,  3.89it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:01<00:00,  4.72it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:01<00:00,  5.55it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:02<00:00,  6.23it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:02<00:00,  6.87it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:02<00:00,  5.11it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2434.02it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:03<03:39,  3.48s/it, est. speed input: 4.59 toks/s, output: 73.48 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:03<00:00,  3.48s/it, est. speed input: 289.44 toks/s, output: 4631.04 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:03<00:00, 18.09it/s, est. speed input: 289.44 toks/s, output: 4631.04 toks/s]
[rank0]:[W126 10:08:25.271482857 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 10:08:27
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:08:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:08:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=504914) WARNING 01-26 10:08:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=504914) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=504914) WARNING 01-26 10:08:58 [backends.py:609] Failed to read file <frozen os>
Throughput: 30.75 requests/s, 8364.38 total tokens/s, 7872.36 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 10:08:35] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:08:36] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:08:36] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:36] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:36] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:36] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:36] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:36] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:36] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:08:36] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:08:36] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:08:36] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:08:36] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:08:36] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:08:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:08:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:08:44] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:08:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:08:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:08:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:08:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:08:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:08:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:46] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:46] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:46] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:46] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:46] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=504914) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=504914) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.21s/it]
(EngineCore_DP0 pid=504914) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.17s/it]
(EngineCore_DP0 pid=504914) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.18s/it]
(EngineCore_DP0 pid=504914) 
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:49] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:49] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=504914) [2026-01-26 10:08:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=504914) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:17,  1.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:15,  2.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:01<00:09,  3.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:01<00:07,  4.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:01<00:05,  5.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:01<00:04,  5.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:01<00:04,  6.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:01<00:03,  6.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:01<00:03,  6.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:02<00:04,  5.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:02<00:06,  3.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:02<00:06,  3.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:03<00:07,  2.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:03<00:06,  3.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:03<00:04,  4.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:03<00:03,  4.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:03<00:03,  5.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:04<00:02,  6.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:04<00:02,  6.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:04<00:02,  7.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:04<00:01,  7.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:04<00:01,  7.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:04<00:01,  7.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:04<00:01,  8.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:04<00:01,  8.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:05<00:01,  7.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:05<00:01,  6.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:05<00:01,  3.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:06<00:01,  3.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:06<00:01,  3.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:06<00:01,  3.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:06<00:00,  4.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:06<00:00,  5.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:07<00:00,  5.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:07<00:00,  5.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:07<00:00,  4.88it/s]
(EngineCore_DP0 pid=504914) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:03,  5.67it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:02,  6.33it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:02,  6.56it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:02,  6.68it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:00<00:02,  6.72it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:02,  6.33it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:01<00:02,  5.93it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:01<00:03,  3.62it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:01<00:02,  4.11it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:02<00:02,  3.23it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:02<00:02,  3.22it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:02<00:01,  3.73it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:02<00:01,  4.21it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:03<00:01,  4.94it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:03<00:00,  5.65it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:03<00:00,  6.32it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▉ | 17/19 [00:03<00:00,  6.93it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:03<00:00,  7.41it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:03<00:00,  7.72it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:03<00:00,  5.27it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2578.32it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:03<08:25,  3.98s/it, est. speed input: 4.02 toks/s, output: 64.27 toks/s]
Processed prompts:  84%|████████▍ | 108/128 [00:04<00:00, 37.18it/s, est. speed input: 422.31 toks/s, output: 6756.87 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 37.18it/s, est. speed input: 498.17 toks/s, output: 7970.67 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:04<00:00, 31.13it/s, est. speed input: 498.17 toks/s, output: 7970.67 toks/s]
[rank0]:[W126 10:09:27.436022059 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 10:09:28
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:09:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:09:38 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=505980) WARNING 01-26 10:09:47 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=505980) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=505980) WARNING 01-26 10:09:59 [backends.py:609] Failed to read file <frozen os>
Throughput: 39.44 requests/s, 10727.81 total tokens/s, 10096.76 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 10:09:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:09:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:09:37] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:09:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:09:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:09:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:09:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:09:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:09:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:09:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:09:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:09:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:09:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:09:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:09:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:09:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:09:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:47] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:47] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:47] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:47] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:47] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:47] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=505980) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=505980) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.30it/s]
(EngineCore_DP0 pid=505980) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.09it/s]
(EngineCore_DP0 pid=505980) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.12it/s]
(EngineCore_DP0 pid=505980) 
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:50] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=505980) [2026-01-26 10:09:50] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=505980) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:04,  8.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:04,  8.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:04,  8.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:03,  8.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:00<00:03,  8.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:00<00:03,  8.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:00<00:03,  8.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:00<00:03,  8.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:01<00:03,  8.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:01<00:03,  8.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███       | 11/36 [00:01<00:07,  3.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:02<00:07,  3.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:02<00:08,  2.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:02<00:06,  3.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:02<00:05,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:03<00:04,  4.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:03<00:03,  5.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:03<00:02,  6.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:03<00:02,  6.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:03<00:02,  7.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:03<00:02,  7.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:03<00:01,  7.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:03<00:01,  7.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:04<00:01,  8.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▉   | 25/36 [00:04<00:01,  8.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:04<00:01,  7.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:04<00:01,  7.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:05<00:02,  3.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:05<00:01,  3.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:05<00:01,  3.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 31/36 [00:05<00:01,  3.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:06<00:00,  4.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:06<00:00,  4.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:06<00:00,  5.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:06<00:00,  5.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:06<00:00,  5.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:06<00:00,  5.38it/s]
(EngineCore_DP0 pid=505980) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:06,  5.03it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:05,  5.62it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:00<00:05,  5.89it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:05,  6.00it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:00<00:05,  5.16it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:01<00:08,  3.30it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:01<00:07,  3.71it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:01<00:07,  3.62it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:02<00:07,  3.34it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:02<00:06,  4.12it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:02<00:04,  4.92it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:02<00:04,  5.65it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:02<00:03,  6.32it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:02<00:03,  6.92it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:02<00:02,  7.34it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:03<00:02,  7.75it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:03<00:02,  8.06it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:03<00:02,  8.34it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:03<00:01,  8.54it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:03<00:01,  8.65it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:03<00:01,  8.62it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:03<00:01,  8.64it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:03<00:01,  8.64it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:04<00:01,  7.33it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:04<00:02,  4.64it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:04<00:01,  4.64it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:04<00:01,  4.76it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:05<00:01,  4.18it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:05<00:01,  3.96it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:05<00:01,  4.71it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:05<00:00,  5.52it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:05<00:00,  6.24it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:05<00:00,  6.82it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:06<00:00,  7.32it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:06<00:00,  7.69it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:06<00:00,  5.69it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2565.29it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:05<24:23,  5.74s/it, est. speed input: 2.79 toks/s, output: 44.59 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:04<00:00,  5.74s/it, est. speed input: 828.23 toks/s, output: 13251.67 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:04<00:00, 51.76it/s, est. speed input: 828.23 toks/s, output: 13251.67 toks/s]
[rank0]:[W126 10:10:30.112526694 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 10:10:33
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-7B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:10:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:10:43 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=507100) WARNING 01-26 10:10:51 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=507100) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=507100) WARNING 01-26 10:11:03 [backends.py:609] Failed to read file <frozen os>
Throughput: 40.39 requests/s, 10987.29 total tokens/s, 10340.98 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 10:10:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:10:42] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:10:42] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:42] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:42] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:42] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:42] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:42] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:42] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:10:42] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:10:42] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:10:42] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:10:42] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:10:42] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:10:50] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:10:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:10:50] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 10:10:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 10:10:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:10:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:10:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:10:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:10:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:52] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:52] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:52] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:52] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:52] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:52] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=507100) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=507100) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.42it/s]
(EngineCore_DP0 pid=507100) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.11it/s]
(EngineCore_DP0 pid=507100) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.15it/s]
(EngineCore_DP0 pid=507100) 
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [4608, 3584] -> 1D uint8
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 12386304 bytes
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 3584] -> 1D uint8
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 9633792 bytes
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [37888, 3584] -> 1D uint8
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 101842944 bytes
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:55] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [3584, 18944] -> 1D uint8
(EngineCore_DP0 pid=507100) [2026-01-26 10:10:55] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 50921472 bytes
(EngineCore_DP0 pid=507100) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:06,  7.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:06,  8.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:05,  8.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:05,  8.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:00<00:05,  8.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:05,  8.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:00<00:05,  8.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:00<00:05,  7.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:01<00:07,  5.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:01<00:11,  3.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:02<00:11,  3.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:02<00:13,  2.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:02<00:10,  3.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:02<00:08,  4.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:02<00:07,  5.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:03<00:06,  5.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:03<00:05,  6.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:03<00:04,  6.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:03<00:04,  7.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:03<00:04,  7.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:03<00:03,  7.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:03<00:03,  7.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:03<00:03,  8.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:03<00:03,  8.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:04<00:03,  7.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:04<00:04,  5.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:04<00:06,  3.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:05<00:06,  3.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:05<00:07,  2.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:05<00:05,  3.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:05<00:04,  4.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:06<00:03,  5.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:06<00:03,  5.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:06<00:02,  6.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:06<00:02,  6.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:06<00:02,  7.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:06<00:01,  7.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:06<00:01,  7.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:06<00:01,  7.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:07<00:01,  8.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:07<00:01,  8.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:07<00:01,  7.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:07<00:01,  5.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:07<00:01,  3.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:08<00:01,  3.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:08<00:01,  3.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:08<00:01,  3.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:09<00:00,  4.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:09<00:00,  4.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:09<00:00,  5.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:09<00:00,  5.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:09<00:00,  5.36it/s]
(EngineCore_DP0 pid=507100) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   2%|▏         | 1/51 [00:00<00:12,  3.85it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:11,  4.31it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 3/51 [00:00<00:08,  5.60it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:07,  6.54it/s]
Capturing CUDA graphs (decode, FULL):  10%|▉         | 5/51 [00:00<00:06,  7.23it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:00<00:05,  7.72it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:01<00:06,  6.94it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 8/51 [00:01<00:11,  3.84it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:01<00:09,  4.32it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:02<00:13,  2.96it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:02<00:11,  3.53it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:02<00:09,  4.33it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:02<00:07,  5.15it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:02<00:06,  5.93it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:02<00:05,  6.52it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:03<00:04,  7.11it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 17/51 [00:03<00:04,  7.52it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:03<00:04,  7.84it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:03<00:03,  8.12it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:03<00:03,  8.22it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:03<00:00, 27.34it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:04<00:01, 10.88it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:04<00:01, 10.38it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:04<00:01,  9.95it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:05<00:01,  9.62it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:05<00:01,  9.47it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:05<00:00,  9.36it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:05<00:00,  9.16it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:06<00:00,  5.69it/s]
Capturing CUDA graphs (decode, FULL):  92%|█████████▏| 47/51 [00:06<00:00,  6.05it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:06<00:00,  5.84it/s]
Capturing CUDA graphs (decode, FULL):  96%|█████████▌| 49/51 [00:07<00:00,  4.35it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:07<00:00,  4.73it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:07<00:00,  5.39it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:07<00:00,  6.86it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  55%|█████▍    | 281/512 [00:00<00:00, 2805.61it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 2853.00it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:09<1:20:40,  9.47s/it, est. speed input: 1.69 toks/s, output: 27.02 toks/s]
Processed prompts:   6%|▋         | 33/512 [00:09<01:39,  4.83it/s, est. speed input: 54.89 toks/s, output: 878.29 toks/s]
Processed prompts:  18%|█▊        | 91/512 [00:09<00:25, 16.59it/s, est. speed input: 149.34 toks/s, output: 2389.40 toks/s]
Processed prompts:  32%|███▏      | 164/512 [00:09<00:09, 36.70it/s, est. speed input: 265.88 toks/s, output: 4254.15 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:09<00:04, 65.31it/s, est. speed input: 387.96 toks/s, output: 6207.30 toks/s]
Processed prompts:  62%|██████▏   | 315/512 [00:10<00:01, 99.77it/s, est. speed input: 499.63 toks/s, output: 7994.07 toks/s]
Processed prompts:  73%|███████▎  | 376/512 [00:10<00:01, 134.98it/s, est. speed input: 590.41 toks/s, output: 9446.48 toks/s]
Processed prompts:  85%|████████▍ | 434/512 [00:10<00:00, 171.83it/s, est. speed input: 673.48 toks/s, output: 10775.71 toks/s]
Processed prompts:  96%|█████████▌| 489/512 [00:10<00:00, 182.29it/s, est. speed input: 740.43 toks/s, output: 11846.84 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:12<00:00, 182.29it/s, est. speed input: 655.69 toks/s, output: 10491.04 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:12<00:00, 40.98it/s, est. speed input: 655.69 toks/s, output: 10491.04 toks/s] 
[rank0]:[W126 10:11:51.281716686 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 10:58:50
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 10:58:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 10:58:58 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=555560) WARNING 01-26 10:59:06 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=555560) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=555560) WARNING 01-26 10:59:35 [backends.py:609] Failed to read file <frozen os>
Throughput: 10.89 requests/s, 2962.78 total tokens/s, 2788.50 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 10:58:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:58:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 10:58:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 10:58:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 10:58:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 10:58:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 10:58:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 10:58:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 10:58:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 10:58:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:58:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:58:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:58:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:58:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 10:59:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 10:59:05] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 10:59:05] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 10:59:05] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 10:59:05] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 10:59:05] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 10:59:05] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 10:59:05] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 10:59:05] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 10:59:05] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 10:59:05] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 10:59:05] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 10:59:05] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 10:59:05] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:07] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:07] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:07] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:07] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:07] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:07] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=555560) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=555560) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:03<00:11,  3.98s/it]
(EngineCore_DP0 pid=555560) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:07<00:07,  3.91s/it]
(EngineCore_DP0 pid=555560) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:09<00:02,  2.68s/it]
(EngineCore_DP0 pid=555560) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:12<00:00,  3.05s/it]
(EngineCore_DP0 pid=555560) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:12<00:00,  3.17s/it]
(EngineCore_DP0 pid=555560) 
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 27525120 bytes
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19660800 bytes
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 106168320 bytes
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:21] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=555560) [2026-01-26 10:59:21] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 53084160 bytes
(EngineCore_DP0 pid=555560) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:09,  1.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:01<00:13,  1.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:02<00:11,  1.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:02<00:08,  1.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:02<00:06,  2.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:02<00:04,  2.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:03<00:03,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:03<00:03,  3.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:03<00:02,  3.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:03<00:02,  4.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:04<00:02,  3.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:04<00:02,  2.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:05<00:02,  2.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:05<00:02,  2.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:05<00:01,  2.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:06<00:00,  3.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:06<00:00,  3.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:06<00:00,  4.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:06<00:00,  4.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:06<00:00,  2.85it/s]
(EngineCore_DP0 pid=555560) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▉         | 1/11 [00:00<00:02,  3.97it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:02,  4.04it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:02,  2.74it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:01<00:02,  2.84it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 5/11 [00:01<00:02,  2.50it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:02<00:01,  2.77it/s]
Capturing CUDA graphs (decode, FULL):  64%|██████▎   | 7/11 [00:02<00:01,  3.27it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:02<00:00,  3.69it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:02<00:00,  4.03it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:02<00:00,  4.32it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:03<00:00,  4.57it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:03<00:00,  3.58it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 2473.47it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:05<06:02,  5.75s/it, est. speed input: 2.78 toks/s, output: 44.49 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:05<00:00,  5.75s/it, est. speed input: 175.10 toks/s, output: 2801.66 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:05<00:00, 10.94it/s, est. speed input: 175.10 toks/s, output: 2801.66 toks/s]
[rank0]:[W126 11:00:14.573336143 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 11:00:17
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:00:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:00:25 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=557017) WARNING 01-26 11:00:34 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=557017) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=557017) WARNING 01-26 11:00:54 [backends.py:609] Failed to read file <frozen os>
Throughput: 15.30 requests/s, 4162.32 total tokens/s, 3917.47 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 11:00:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:00:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:00:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:00:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:00:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:00:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:00:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:00:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:00:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:00:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:00:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:00:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:00:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:00:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:00:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:00:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:00:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:34] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:34] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:34] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:34] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:34] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=557017) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=557017) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.03it/s]
(EngineCore_DP0 pid=557017) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.14s/it]
(EngineCore_DP0 pid=557017) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.12it/s]
(EngineCore_DP0 pid=557017) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.05it/s]
(EngineCore_DP0 pid=557017) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.03it/s]
(EngineCore_DP0 pid=557017) 
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 27525120 bytes
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19660800 bytes
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 106168320 bytes
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:39] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=557017) [2026-01-26 11:00:39] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 53084160 bytes
(EngineCore_DP0 pid=557017) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:26,  1.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:01<00:26,  1.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:01<00:16,  1.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:01<00:12,  2.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:02<00:09,  3.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:02<00:08,  3.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:02<00:07,  3.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:02<00:06,  4.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:03<00:06,  3.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:03<00:09,  2.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:04<00:11,  2.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:04<00:09,  2.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:04<00:07,  2.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:05<00:06,  3.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:05<00:05,  3.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:05<00:04,  3.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:05<00:04,  4.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:06<00:03,  4.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:06<00:04,  3.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:06<00:05,  2.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:07<00:06,  2.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:07<00:05,  2.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:08<00:04,  2.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:08<00:03,  3.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:08<00:02,  3.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:08<00:02,  3.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:08<00:01,  4.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:09<00:01,  4.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:09<00:02,  2.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:10<00:02,  1.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:11<00:01,  2.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:11<00:01,  2.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:11<00:00,  3.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:11<00:00,  3.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:11<00:00,  3.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:11<00:00,  2.96it/s]
(EngineCore_DP0 pid=557017) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:04,  4.12it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:03,  4.78it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:03,  4.58it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:03,  4.77it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:01<00:04,  3.35it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:01<00:03,  3.27it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 7/19 [00:02<00:04,  2.64it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:02<00:03,  3.00it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:02<00:02,  3.48it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:02<00:02,  3.90it/s]
Capturing CUDA graphs (decode, FULL):  58%|█████▊    | 11/19 [00:02<00:01,  4.25it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:03<00:01,  4.56it/s]
Capturing CUDA graphs (decode, FULL):  68%|██████▊   | 13/19 [00:03<00:01,  4.76it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:03<00:00, 10.68it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:03<00:00,  5.25it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2613.45it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:07<16:05,  7.60s/it, est. speed input: 2.10 toks/s, output: 33.66 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:07<00:15,  5.96it/s, est. speed input: 67.98 toks/s, output: 1087.72 toks/s]
Processed prompts:  77%|███████▋  | 98/128 [00:07<00:01, 22.27it/s, est. speed input: 199.17 toks/s, output: 3186.63 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 22.27it/s, est. speed input: 246.33 toks/s, output: 3941.33 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:08<00:00, 15.40it/s, est. speed input: 246.33 toks/s, output: 3941.33 toks/s]
[rank0]:[W126 11:01:38.134101046 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 11:01:41
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:01:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:01:50 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=558451) WARNING 01-26 11:01:58 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=558451) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=558451) WARNING 01-26 11:02:19 [backends.py:609] Failed to read file <frozen os>
Throughput: 14.92 requests/s, 4057.63 total tokens/s, 3818.94 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 11:01:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:01:49] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:01:49] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:49] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:49] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:49] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:49] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:49] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:49] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:01:49] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:01:49] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:01:49] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:01:49] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:01:49] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:01:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:01:58] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:01:58] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:58] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:58] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:58] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:58] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:58] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:01:58] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:01:58] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:01:58] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:01:58] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:01:58] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:01:58] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=558451) [2026-01-26 11:01:59] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=558451) [2026-01-26 11:01:59] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=558451) [2026-01-26 11:01:59] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=558451) [2026-01-26 11:01:59] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=558451) [2026-01-26 11:01:59] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=558451) [2026-01-26 11:01:59] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=558451) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=558451) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.00s/it]
(EngineCore_DP0 pid=558451) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.03s/it]
(EngineCore_DP0 pid=558451) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.35it/s]
(EngineCore_DP0 pid=558451) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.20it/s]
(EngineCore_DP0 pid=558451) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.17it/s]
(EngineCore_DP0 pid=558451) 
(EngineCore_DP0 pid=558451) [2026-01-26 11:02:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=558451) [2026-01-26 11:02:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 27525120 bytes
(EngineCore_DP0 pid=558451) [2026-01-26 11:02:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=558451) [2026-01-26 11:02:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19660800 bytes
(EngineCore_DP0 pid=558451) [2026-01-26 11:02:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=558451) [2026-01-26 11:02:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 106168320 bytes
(EngineCore_DP0 pid=558451) [2026-01-26 11:02:04] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=558451) [2026-01-26 11:02:04] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 53084160 bytes
(EngineCore_DP0 pid=558451) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:15,  2.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:10,  3.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 3/36 [00:00<00:08,  3.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:01<00:07,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/36 [00:01<00:07,  4.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:01<00:06,  4.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:01<00:06,  4.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:02<00:11,  2.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:02<00:10,  2.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:03<00:11,  2.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███       | 11/36 [00:03<00:09,  2.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:03<00:07,  3.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:04<00:06,  3.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:04<00:05,  3.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:04<00:05,  4.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:04<00:04,  4.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 17/36 [00:04<00:04,  4.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:05<00:07,  2.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:06<00:08,  2.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:06<00:06,  2.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:06<00:05,  2.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:07<00:04,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 23/36 [00:07<00:03,  3.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:07<00:03,  3.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▉   | 25/36 [00:07<00:02,  4.11it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:07<00:02,  4.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:08<00:02,  3.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:08<00:03,  2.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:09<00:03,  2.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:09<00:02,  2.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 31/36 [00:10<00:01,  2.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:10<00:01,  3.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:10<00:00,  3.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:10<00:00,  4.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:10<00:00,  4.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:11<00:00,  4.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:11<00:00,  3.26it/s]
(EngineCore_DP0 pid=558451) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   3%|▎         | 1/35 [00:00<00:12,  2.70it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:15,  2.20it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:01<00:12,  2.64it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:01<00:14,  2.19it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▍        | 5/35 [00:02<00:12,  2.50it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:02<00:09,  3.02it/s]
Capturing CUDA graphs (decode, FULL):  20%|██        | 7/35 [00:02<00:08,  3.49it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:02<00:06,  3.90it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:02<00:06,  4.23it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:03<00:05,  4.48it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 11/35 [00:03<00:05,  4.67it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:03<00:05,  4.33it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 13/35 [00:04<00:07,  2.98it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:04<00:06,  3.16it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:04<00:07,  2.54it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:05<00:06,  2.87it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▊     | 17/35 [00:05<00:05,  3.30it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:05<00:04,  3.70it/s]
Capturing CUDA graphs (decode, FULL):  54%|█████▍    | 19/35 [00:05<00:03,  4.05it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:05<00:03,  4.32it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:06<00:03,  4.57it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:06<00:02,  4.69it/s]
Capturing CUDA graphs (decode, FULL):  66%|██████▌   | 23/35 [00:06<00:02,  4.48it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:07<00:03,  2.95it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████▏  | 25/35 [00:07<00:03,  2.94it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:08<00:03,  2.59it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:08<00:02,  2.80it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:08<00:02,  3.22it/s]
Capturing CUDA graphs (decode, FULL):  83%|████████▎ | 29/35 [00:08<00:01,  3.63it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:08<00:01,  3.98it/s]
Capturing CUDA graphs (decode, FULL):  89%|████████▊ | 31/35 [00:09<00:00,  4.29it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:09<00:00,  4.54it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:09<00:00,  4.73it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:09<00:00,  4.34it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:10<00:00,  3.03it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:10<00:00,  3.40it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2608.90it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:08<37:17,  8.77s/it, est. speed input: 1.82 toks/s, output: 29.17 toks/s]
Processed prompts:  19%|█▉        | 48/256 [00:08<00:27,  7.62it/s, est. speed input: 86.35 toks/s, output: 1381.56 toks/s]
Processed prompts:  42%|████▏     | 108/256 [00:09<00:07, 20.76it/s, est. speed input: 191.81 toks/s, output: 3069.02 toks/s]
Processed prompts:  57%|█████▋    | 145/256 [00:12<00:06, 16.40it/s, est. speed input: 191.69 toks/s, output: 3067.11 toks/s]
Processed prompts:  66%|██████▌   | 168/256 [00:13<00:05, 15.67it/s, est. speed input: 195.18 toks/s, output: 3122.84 toks/s]
Processed prompts:  71%|███████▏  | 183/256 [00:14<00:04, 16.46it/s, est. speed input: 202.18 toks/s, output: 3234.95 toks/s]
Processed prompts:  76%|███████▌  | 194/256 [00:14<00:03, 17.42it/s, est. speed input: 208.01 toks/s, output: 3328.18 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:15<00:02, 18.10it/s, est. speed input: 211.76 toks/s, output: 3388.13 toks/s]
Processed prompts:  82%|████████▏ | 209/256 [00:15<00:02, 19.40it/s, est. speed input: 216.04 toks/s, output: 3456.60 toks/s]
Processed prompts:  84%|████████▍ | 215/256 [00:15<00:01, 20.64it/s, est. speed input: 219.52 toks/s, output: 3512.38 toks/s]
Processed prompts:  86%|████████▌ | 220/256 [00:15<00:01, 20.90it/s, est. speed input: 221.48 toks/s, output: 3543.67 toks/s]
Processed prompts:  88%|████████▊ | 224/256 [00:16<00:01, 21.68it/s, est. speed input: 223.44 toks/s, output: 3575.09 toks/s]
Processed prompts:  89%|████████▉ | 228/256 [00:16<00:01, 22.57it/s, est. speed input: 225.41 toks/s, output: 3606.61 toks/s]
Processed prompts:  91%|█████████ | 232/256 [00:16<00:01, 23.50it/s, est. speed input: 227.36 toks/s, output: 3637.80 toks/s]
Processed prompts:  92%|█████████▏| 236/256 [00:16<00:00, 25.03it/s, est. speed input: 229.54 toks/s, output: 3672.62 toks/s]
Processed prompts:  94%|█████████▍| 240/256 [00:16<00:00, 26.56it/s, est. speed input: 231.71 toks/s, output: 3707.33 toks/s]
Processed prompts:  95%|█████████▌| 244/256 [00:16<00:00, 28.13it/s, est. speed input: 233.90 toks/s, output: 3742.45 toks/s]
Processed prompts:  97%|█████████▋| 248/256 [00:16<00:00, 29.61it/s, est. speed input: 236.10 toks/s, output: 3777.62 toks/s]
Processed prompts:  98%|█████████▊| 252/256 [00:16<00:00, 29.07it/s, est. speed input: 237.87 toks/s, output: 3805.89 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:17<00:00, 30.81it/s, est. speed input: 240.08 toks/s, output: 3841.33 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:17<00:00, 30.81it/s, est. speed input: 240.08 toks/s, output: 3841.33 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:17<00:00, 15.00it/s, est. speed input: 240.08 toks/s, output: 3841.33 toks/s]
[rank0]:[W126 11:03:16.909191722 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 11:03:19
Backend: cuSPARSELt (2:4)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4/json/Qwen2.5-14B-INT8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 11:03:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 11:03:29 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=560018) WARNING 01-26 11:03:35 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=560018) [INFO] Loading compress extension: cusparselt_compress_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=560018) WARNING 01-26 11:03:56 [backends.py:609] Failed to read file <frozen os>
Throughput: 15.27 requests/s, 4153.91 total tokens/s, 3909.56 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 11:03:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:03:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:03:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:03:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:03:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:03:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:03:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:03:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 11:03:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 11:03:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:03:35] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:35] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:35] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-INT8
[2026-01-26 11:03:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-INT8'
[2026-01-26 11:03:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 11:03:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 11:03:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 11:03:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 11:03:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:36] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:36] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_RTX4090_cc89_py312_cu129_x86_64.so
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:36] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:36] INFO SlideSparseLinearMethod_INT8.py:604: SlideSparseInt8LinearMethod: cuSPARSELt sparsity=2:4, expand_ratio=2.000
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:36] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-14B-INT8
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:36] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuSPARSELt, symmetric=True
(EngineCore_DP0 pid=560018) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=560018) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.04it/s]
(EngineCore_DP0 pid=560018) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.01s/it]
(EngineCore_DP0 pid=560018) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.38it/s]
(EngineCore_DP0 pid=560018) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.22it/s]
(EngineCore_DP0 pid=560018) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.19it/s]
(EngineCore_DP0 pid=560018) 
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [7168, 5120] -> 1D uint8
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 27525120 bytes
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 5120] -> 1D uint8
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 19660800 bytes
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [27648, 5120] -> 1D uint8
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 106168320 bytes
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:41] INFO SlideSparseLinearMethod_INT8.py:719: cuSPARSELt INT8 compression: [5120, 13824] -> 1D uint8
(EngineCore_DP0 pid=560018) [2026-01-26 11:03:41] INFO SlideSparseLinearMethod_INT8.py:729: cuSPARSELt INT8 compression done: 53084160 bytes
(EngineCore_DP0 pid=560018) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:10,  4.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:10,  4.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:09,  4.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:10,  4.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:01<00:11,  3.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:02<00:20,  2.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:02<00:22,  1.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:02<00:17,  2.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:03<00:14,  2.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:03<00:12,  3.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:03<00:10,  3.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:03<00:09,  3.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:03<00:09,  4.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:04<00:09,  3.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:04<00:14,  2.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:05<00:16,  2.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:05<00:14,  2.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:06<00:11,  2.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:06<00:10,  3.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:06<00:08,  3.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:06<00:07,  3.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:06<00:06,  4.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:07<00:06,  4.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:07<00:10,  2.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:08<00:13,  1.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:08<00:11,  2.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:09<00:08,  2.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:09<00:07,  3.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:09<00:06,  3.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:09<00:05,  3.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:09<00:04,  4.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:10<00:04,  4.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:10<00:05,  3.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:11<00:06,  2.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:11<00:07,  2.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:12<00:05,  2.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:12<00:04,  2.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:12<00:03,  3.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:12<00:03,  3.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:12<00:02,  3.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:13<00:02,  4.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:13<00:02,  4.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:13<00:02,  3.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:14<00:02,  2.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:15<00:03,  1.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:15<00:02,  2.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:15<00:01,  2.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:15<00:00,  3.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:15<00:00,  3.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:16<00:00,  3.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:16<00:00,  3.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:16<00:00,  3.11it/s]
(EngineCore_DP0 pid=560018) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:02, 15.71it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:00<00:05,  7.89it/s]
Capturing CUDA graphs (decode, FULL):  14%|█▎        | 7/51 [00:00<00:06,  7.04it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 8/51 [00:01<00:06,  6.48it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:01<00:06,  6.07it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:01<00:06,  5.86it/s]
Capturing CUDA graphs (decode, FULL):  22%|██▏       | 11/51 [00:01<00:07,  5.61it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:01<00:07,  5.06it/s]
Capturing CUDA graphs (decode, FULL):  25%|██▌       | 13/51 [00:02<00:12,  3.03it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:02<00:11,  3.16it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:03<00:13,  2.63it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:03<00:12,  2.87it/s]
Capturing CUDA graphs (decode, FULL):  33%|███▎      | 17/51 [00:03<00:10,  3.29it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:04<00:08,  3.73it/s]
Capturing CUDA graphs (decode, FULL):  37%|███▋      | 19/51 [00:04<00:07,  4.09it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:04<00:07,  4.39it/s]
Capturing CUDA graphs (decode, FULL):  41%|████      | 21/51 [00:04<00:06,  4.60it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:04<00:06,  4.74it/s]
Capturing CUDA graphs (decode, FULL):  45%|████▌     | 23/51 [00:04<00:05,  4.85it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:05<00:05,  4.54it/s]
Capturing CUDA graphs (decode, FULL):  49%|████▉     | 25/51 [00:05<00:07,  3.39it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:05<00:07,  3.43it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 27/51 [00:06<00:08,  2.73it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:06<00:07,  3.07it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 29/51 [00:06<00:06,  3.51it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:07<00:05,  3.92it/s]
Capturing CUDA graphs (decode, FULL):  61%|██████    | 31/51 [00:07<00:04,  4.25it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:07<00:04,  4.51it/s]
Capturing CUDA graphs (decode, FULL):  65%|██████▍   | 33/51 [00:07<00:03,  4.74it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:07<00:03,  4.89it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 35/51 [00:08<00:03,  4.88it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:08<00:03,  4.25it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 37/51 [00:08<00:04,  3.27it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:09<00:03,  3.40it/s]
Capturing CUDA graphs (decode, FULL):  76%|███████▋  | 39/51 [00:09<00:04,  2.69it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:09<00:03,  2.86it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 41/51 [00:10<00:03,  3.31it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:10<00:02,  3.70it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 43/51 [00:10<00:01,  4.05it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:10<00:01,  4.31it/s]
Capturing CUDA graphs (decode, FULL):  88%|████████▊ | 45/51 [00:10<00:01,  4.53it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:11<00:01,  4.72it/s]
Capturing CUDA graphs (decode, FULL):  92%|█████████▏| 47/51 [00:11<00:00,  4.16it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:11<00:00,  3.28it/s]
Capturing CUDA graphs (decode, FULL):  96%|█████████▌| 49/51 [00:12<00:00,  3.68it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:12<00:00,  3.79it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:12<00:00,  3.47it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:12<00:00,  4.02it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  54%|█████▍    | 279/512 [00:00<00:00, 2785.57it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 2819.60it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:08<1:13:09,  8.59s/it, est. speed input: 1.86 toks/s, output: 29.80 toks/s]
Processed prompts:  12%|█▏        | 63/512 [00:08<00:43, 10.24it/s, est. speed input: 115.85 toks/s, output: 1853.54 toks/s]
Processed prompts:  19%|█▉        | 96/512 [00:10<00:34, 12.10it/s, est. speed input: 142.62 toks/s, output: 2281.96 toks/s]
Processed prompts:  22%|██▏       | 115/512 [00:12<00:32, 12.38it/s, est. speed input: 150.75 toks/s, output: 2412.06 toks/s]
Processed prompts:  25%|██▍       | 127/512 [00:13<00:30, 12.76it/s, est. speed input: 156.07 toks/s, output: 2497.13 toks/s]
Processed prompts:  27%|██▋       | 136/512 [00:13<00:28, 13.07it/s, est. speed input: 159.69 toks/s, output: 2555.00 toks/s]
Processed prompts:  28%|██▊       | 142/512 [00:13<00:26, 13.91it/s, est. speed input: 163.61 toks/s, output: 2617.71 toks/s]
Processed prompts:  29%|██▊       | 147/512 [00:14<00:26, 13.60it/s, est. speed input: 164.44 toks/s, output: 2631.01 toks/s]
Processed prompts:  29%|██▉       | 151/512 [00:14<00:24, 14.62it/s, est. speed input: 167.18 toks/s, output: 2674.85 toks/s]
Processed prompts:  30%|███       | 155/512 [00:14<00:22, 15.89it/s, est. speed input: 169.94 toks/s, output: 2719.00 toks/s]
Processed prompts:  31%|███       | 159/512 [00:14<00:24, 14.56it/s, est. speed input: 170.00 toks/s, output: 2719.98 toks/s]
Processed prompts:  32%|███▏      | 163/512 [00:15<00:21, 16.26it/s, est. speed input: 172.64 toks/s, output: 2762.26 toks/s]
Processed prompts:  32%|███▏      | 166/512 [00:15<00:19, 17.41it/s, est. speed input: 174.44 toks/s, output: 2791.03 toks/s]
Processed prompts:  33%|███▎      | 171/512 [00:15<00:16, 20.46it/s, est. speed input: 177.96 toks/s, output: 2847.34 toks/s]
Processed prompts:  34%|███▍      | 175/512 [00:15<00:15, 22.06it/s, est. speed input: 180.47 toks/s, output: 2887.48 toks/s]
Processed prompts:  41%|████      | 210/512 [00:15<00:04, 74.22it/s, est. speed input: 214.77 toks/s, output: 3436.31 toks/s]
Processed prompts:  43%|████▎     | 221/512 [00:15<00:04, 65.54it/s, est. speed input: 222.82 toks/s, output: 3565.05 toks/s]
Processed prompts:  45%|████▍     | 230/512 [00:16<00:08, 33.68it/s, est. speed input: 222.07 toks/s, output: 3553.10 toks/s]
Processed prompts:  46%|████▋     | 237/512 [00:17<00:16, 16.83it/s, est. speed input: 213.02 toks/s, output: 3408.27 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:18<00:21, 12.44it/s, est. speed input: 206.98 toks/s, output: 3311.64 toks/s]
Processed prompts:  48%|████▊     | 246/512 [00:19<00:21, 12.44it/s, est. speed input: 206.83 toks/s, output: 3309.31 toks/s]
Processed prompts:  49%|████▊     | 249/512 [00:19<00:20, 13.03it/s, est. speed input: 207.53 toks/s, output: 3320.44 toks/s]
Processed prompts:  49%|████▉     | 252/512 [00:19<00:19, 13.39it/s, est. speed input: 207.92 toks/s, output: 3326.68 toks/s]
Processed prompts:  50%|████▉     | 255/512 [00:19<00:18, 13.72it/s, est. speed input: 208.28 toks/s, output: 3332.40 toks/s]
Processed prompts:  50%|█████     | 257/512 [00:19<00:18, 14.15it/s, est. speed input: 208.65 toks/s, output: 3338.34 toks/s]
Processed prompts:  51%|█████     | 259/512 [00:19<00:17, 14.76it/s, est. speed input: 209.10 toks/s, output: 3345.66 toks/s]
Processed prompts:  51%|█████     | 262/512 [00:19<00:14, 16.85it/s, est. speed input: 210.30 toks/s, output: 3364.85 toks/s]
Processed prompts:  53%|█████▎    | 269/512 [00:20<00:09, 24.56it/s, est. speed input: 214.33 toks/s, output: 3429.26 toks/s]
Processed prompts:  53%|█████▎    | 273/512 [00:20<00:09, 24.18it/s, est. speed input: 215.67 toks/s, output: 3450.73 toks/s]
Processed prompts:  54%|█████▍    | 276/512 [00:20<00:10, 21.91it/s, est. speed input: 216.13 toks/s, output: 3458.07 toks/s]
Processed prompts:  54%|█████▍    | 279/512 [00:20<00:11, 21.07it/s, est. speed input: 216.79 toks/s, output: 3468.71 toks/s]
Processed prompts:  55%|█████▌    | 282/512 [00:20<00:11, 20.85it/s, est. speed input: 217.56 toks/s, output: 3480.96 toks/s]
Processed prompts:  56%|█████▌    | 285/512 [00:20<00:13, 17.41it/s, est. speed input: 217.28 toks/s, output: 3476.47 toks/s]
Processed prompts:  56%|█████▋    | 288/512 [00:21<00:12, 18.17it/s, est. speed input: 218.04 toks/s, output: 3488.69 toks/s]
Processed prompts:  57%|█████▋    | 292/512 [00:21<00:09, 22.40it/s, est. speed input: 220.02 toks/s, output: 3520.34 toks/s]
Processed prompts:  58%|█████▊    | 297/512 [00:21<00:07, 28.20it/s, est. speed input: 222.70 toks/s, output: 3563.23 toks/s]
Processed prompts:  59%|█████▉    | 302/512 [00:21<00:06, 32.81it/s, est. speed input: 225.32 toks/s, output: 3605.16 toks/s]
Processed prompts:  60%|█████▉    | 306/512 [00:21<00:07, 28.38it/s, est. speed input: 226.32 toks/s, output: 3621.17 toks/s]
Processed prompts:  61%|██████    | 310/512 [00:21<00:07, 25.43it/s, est. speed input: 227.21 toks/s, output: 3635.40 toks/s]
Processed prompts:  61%|██████    | 313/512 [00:22<00:08, 22.39it/s, est. speed input: 227.48 toks/s, output: 3639.67 toks/s]
Processed prompts:  62%|██████▏   | 316/512 [00:22<00:08, 22.48it/s, est. speed input: 228.29 toks/s, output: 3652.70 toks/s]
Processed prompts:  62%|██████▏   | 319/512 [00:22<00:08, 22.13it/s, est. speed input: 229.00 toks/s, output: 3663.96 toks/s]
Processed prompts:  63%|██████▎   | 322/512 [00:22<00:08, 22.09it/s, est. speed input: 229.74 toks/s, output: 3675.91 toks/s]
Processed prompts:  64%|██████▍   | 327/512 [00:22<00:06, 27.55it/s, est. speed input: 232.14 toks/s, output: 3714.26 toks/s]
Processed prompts:  65%|██████▌   | 335/512 [00:22<00:04, 38.21it/s, est. speed input: 236.56 toks/s, output: 3785.00 toks/s]
Processed prompts:  68%|██████▊   | 348/512 [00:22<00:02, 55.14it/s, est. speed input: 244.22 toks/s, output: 3907.55 toks/s]
Processed prompts:  69%|██████▉   | 354/512 [00:23<00:08, 18.14it/s, est. speed input: 238.27 toks/s, output: 3812.26 toks/s]
Processed prompts:  70%|███████   | 359/512 [00:24<00:12, 12.67it/s, est. speed input: 233.92 toks/s, output: 3742.71 toks/s]
Processed prompts:  71%|███████   | 363/512 [00:24<00:11, 13.08it/s, est. speed input: 233.97 toks/s, output: 3743.45 toks/s]
Processed prompts:  71%|███████▏  | 366/512 [00:25<00:11, 12.91it/s, est. speed input: 233.58 toks/s, output: 3737.35 toks/s]
Processed prompts:  72%|███████▏  | 369/512 [00:25<00:12, 11.85it/s, est. speed input: 232.42 toks/s, output: 3718.72 toks/s]
Processed prompts:  72%|███████▏  | 371/512 [00:25<00:12, 11.75it/s, est. speed input: 232.06 toks/s, output: 3712.94 toks/s]
Processed prompts:  73%|███████▎  | 373/512 [00:25<00:11, 12.06it/s, est. speed input: 231.97 toks/s, output: 3711.57 toks/s]
Processed prompts:  73%|███████▎  | 375/512 [00:25<00:10, 12.80it/s, est. speed input: 232.12 toks/s, output: 3713.96 toks/s]
Processed prompts:  74%|███████▎  | 377/512 [00:25<00:10, 13.16it/s, est. speed input: 232.12 toks/s, output: 3713.95 toks/s]
Processed prompts:  74%|███████▍  | 379/512 [00:26<00:10, 12.31it/s, est. speed input: 231.63 toks/s, output: 3706.02 toks/s]
Processed prompts:  74%|███████▍  | 381/512 [00:26<00:11, 11.73it/s, est. speed input: 231.15 toks/s, output: 3698.36 toks/s]
Processed prompts:  75%|███████▍  | 383/512 [00:26<00:12, 10.55it/s, est. speed input: 230.26 toks/s, output: 3684.23 toks/s]
Processed prompts:  75%|███████▌  | 385/512 [00:26<00:11, 11.32it/s, est. speed input: 230.22 toks/s, output: 3683.55 toks/s]
Processed prompts:  76%|███████▌  | 387/512 [00:26<00:09, 12.50it/s, est. speed input: 230.40 toks/s, output: 3686.39 toks/s]
Processed prompts:  76%|███████▌  | 389/512 [00:27<00:10, 11.84it/s, est. speed input: 229.96 toks/s, output: 3679.32 toks/s]
Processed prompts:  77%|███████▋  | 392/512 [00:27<00:08, 14.31it/s, est. speed input: 230.54 toks/s, output: 3688.71 toks/s]
Processed prompts:  77%|███████▋  | 394/512 [00:27<00:08, 14.59it/s, est. speed input: 230.62 toks/s, output: 3689.94 toks/s]
Processed prompts:  77%|███████▋  | 396/512 [00:27<00:09, 12.70it/s, est. speed input: 230.02 toks/s, output: 3680.26 toks/s]
Processed prompts:  78%|███████▊  | 398/512 [00:27<00:09, 12.53it/s, est. speed input: 229.80 toks/s, output: 3676.81 toks/s]
Processed prompts:  78%|███████▊  | 400/512 [00:27<00:08, 12.48it/s, est. speed input: 229.61 toks/s, output: 3673.81 toks/s]
Processed prompts:  79%|███████▊  | 403/512 [00:28<00:07, 14.78it/s, est. speed input: 230.16 toks/s, output: 3682.59 toks/s]
Processed prompts:  79%|███████▉  | 406/512 [00:28<00:06, 16.53it/s, est. speed input: 230.70 toks/s, output: 3691.28 toks/s]
Processed prompts:  80%|███████▉  | 409/512 [00:28<00:05, 18.58it/s, est. speed input: 231.41 toks/s, output: 3702.54 toks/s]
Processed prompts:  80%|████████  | 412/512 [00:28<00:05, 19.48it/s, est. speed input: 231.97 toks/s, output: 3711.53 toks/s]
Processed prompts:  81%|████████▏ | 417/512 [00:28<00:03, 25.90it/s, est. speed input: 233.88 toks/s, output: 3742.03 toks/s]
Processed prompts:  83%|████████▎ | 423/512 [00:28<00:02, 32.90it/s, est. speed input: 236.28 toks/s, output: 3780.46 toks/s]
Processed prompts:  84%|████████▍ | 430/512 [00:28<00:02, 40.79it/s, est. speed input: 239.24 toks/s, output: 3827.80 toks/s]
Processed prompts:  86%|████████▌ | 438/512 [00:28<00:01, 49.22it/s, est. speed input: 242.73 toks/s, output: 3883.75 toks/s]
Processed prompts:  87%|████████▋ | 444/512 [00:28<00:01, 50.59it/s, est. speed input: 245.12 toks/s, output: 3921.87 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:29<00:01, 52.33it/s, est. speed input: 247.53 toks/s, output: 3960.45 toks/s]
Processed prompts:  89%|████████▉ | 456/512 [00:29<00:01, 51.42it/s, est. speed input: 249.79 toks/s, output: 3996.58 toks/s]
Processed prompts:  94%|█████████▍| 481/512 [00:29<00:00, 100.18it/s, est. speed input: 262.42 toks/s, output: 4198.79 toks/s]
Processed prompts:  96%|█████████▌| 492/512 [00:29<00:00, 66.05it/s, est. speed input: 265.64 toks/s, output: 4250.30 toks/s] 
Processed prompts:  98%|█████████▊| 501/512 [00:31<00:00, 17.49it/s, est. speed input: 256.31 toks/s, output: 4100.97 toks/s]
Processed prompts:  99%|█████████▉| 507/512 [00:31<00:00, 17.21it/s, est. speed input: 256.34 toks/s, output: 4101.37 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:31<00:00, 18.26it/s, est. speed input: 257.23 toks/s, output: 4115.60 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:31<00:00, 18.26it/s, est. speed input: 257.23 toks/s, output: 4115.60 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:31<00:00, 16.08it/s, est. speed input: 257.23 toks/s, output: 4115.60 toks/s]
[rank0]:[W126 11:05:20.302487617 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

