
========== M=16 ==========
Time: 2026-01-26 13:24:30
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=16, max_num_seqs=16
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 16 --max-num-seqs 16 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M16.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:24:37 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=488721) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=488721) WARNING 01-26 13:24:50 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=488721) WARNING 01-26 13:24:57 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 23.89 requests/s, 6497.73 total tokens/s, 6115.51 output tokens/s
Total num prompt tokens:  256
Total num output tokens:  4096

STDERR:
[2026-01-26 13:24:37] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:24:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 13:24:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 13:24:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:24:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:24:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:24:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:24:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:24:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 13:24:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:24:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:24:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:24:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:24:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:24:44] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:24:44] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 13:24:44] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 13:24:44] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:24:44] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:24:44] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:24:44] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:24:44] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:24:44] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 13:24:44] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:24:44] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:24:44] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:24:44] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:24:44] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:45] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:45] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:45] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:45] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:45] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:45] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=488721) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=488721) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=488721) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.59it/s]
(EngineCore_DP0 pid=488721) 
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:46] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=488721) [2026-01-26 13:24:46] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=488721) 2026-01-26 13:24:57,272 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=488721) 2026-01-26 13:24:57,293 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=488721) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 2/7 [00:00<00:00, 19.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 5/7 [00:00<00:00, 22.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 21.03it/s]
(EngineCore_DP0 pid=488721) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 3/5 [00:00<00:00, 16.22it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 17.79it/s]

Adding requests:   0%|          | 0/16 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 16/16 [00:00<00:00, 3783.34it/s]

Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 1/16 [00:00<00:09,  1.51it/s, est. speed input: 24.19 toks/s, output: 387.00 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:00<00:00,  1.51it/s, est. speed input: 385.28 toks/s, output: 6164.40 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:00<00:00, 24.08it/s, est. speed input: 385.28 toks/s, output: 6164.40 toks/s]
[rank0]:[W126 13:25:00.611467222 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 13:25:02
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:25:09 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=489727) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=489727) WARNING 01-26 13:25:21 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=489727) WARNING 01-26 13:25:26 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 102.89 requests/s, 27985.84 total tokens/s, 26339.61 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 13:25:08] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:25:09] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 13:25:09] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 13:25:09] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:09] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:09] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:09] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:09] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:09] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 13:25:09] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:25:09] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:25:09] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:25:09] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:25:09] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:25:15] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:25:15] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 13:25:15] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 13:25:15] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:15] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:15] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:15] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:15] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:15] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 13:25:15] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:25:15] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:25:15] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:25:15] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:25:15] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:16] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:16] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:16] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:16] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:16] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:16] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=489727) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=489727) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.38it/s]
(EngineCore_DP0 pid=489727) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.38it/s]
(EngineCore_DP0 pid=489727) 
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:17] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=489727) [2026-01-26 13:25:17] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=489727) 2026-01-26 13:25:26,285 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=489727) 2026-01-26 13:25:26,307 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=489727) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:01, 18.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:00<00:02, 13.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:00<00:02, 11.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:00<00:01, 14.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:00<00:01, 17.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:00<00:01, 18.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:01<00:01, 15.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:01<00:00, 16.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:01<00:00, 18.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:01<00:00, 17.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:01<00:00, 17.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:01<00:00, 18.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:01<00:00, 20.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:02<00:00, 17.42it/s]
(EngineCore_DP0 pid=489727) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:00, 22.37it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:00, 22.82it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:00<00:00, 22.95it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:00<00:00, 23.06it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:00<00:00, 23.13it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:00<00:00, 22.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 22.14it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 4773.50it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<02:29,  1.18s/it, est. speed input: 13.57 toks/s, output: 217.16 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  1.18s/it, est. speed input: 1684.04 toks/s, output: 26944.59 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 105.24it/s, est. speed input: 1684.04 toks/s, output: 26944.59 toks/s]
[rank0]:[W126 13:25:32.481372731 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 13:25:34
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 13:25:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=490728) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=490728) WARNING 01-26 13:25:53 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=490728) WARNING 01-26 13:25:58 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 160.18 requests/s, 43568.52 total tokens/s, 41005.66 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 13:25:40] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:25:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 13:25:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 13:25:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 13:25:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:25:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:25:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:25:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:25:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 13:25:47] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 13:25:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 13:25:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 13:25:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 13:25:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 13:25:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 13:25:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 13:25:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 13:25:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 13:25:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:48] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:48] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:48] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:48] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:48] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:48] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=490728) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=490728) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.67it/s]
(EngineCore_DP0 pid=490728) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.67it/s]
(EngineCore_DP0 pid=490728) 
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:49] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=490728) [2026-01-26 13:25:49] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=490728) 2026-01-26 13:25:58,220 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=490728) 2026-01-26 13:25:58,242 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=490728) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:01, 19.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:01, 19.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:00<00:01, 17.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 9/36 [00:00<00:01, 16.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:00<00:01, 18.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 15/36 [00:00<00:01, 19.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:00<00:00, 19.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 21/36 [00:01<00:00, 20.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:01<00:00, 20.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:01<00:00, 20.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:01<00:00, 20.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:01<00:00, 19.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 35/36 [00:01<00:00, 19.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:01<00:00, 19.17it/s]
(EngineCore_DP0 pid=490728) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:00<00:01, 22.15it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:01, 22.40it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:00<00:01, 22.50it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:00<00:01, 22.67it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:00<00:00, 22.75it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:00<00:00, 22.71it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:00<00:00, 20.62it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:01<00:00, 19.47it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:01<00:00, 20.45it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:01<00:00, 21.16it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:01<00:00, 21.70it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 21.62it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 5009.43it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:01<05:48,  1.37s/it, est. speed input: 11.71 toks/s, output: 187.32 toks/s]
Processed prompts:  79%|███████▉  | 202/256 [00:01<00:00, 190.77it/s, est. speed input: 2202.71 toks/s, output: 35243.15 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:01<00:00, 190.77it/s, est. speed input: 2649.41 toks/s, output: 42390.50 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:01<00:00, 165.58it/s, est. speed input: 2649.41 toks/s, output: 42390.50 toks/s]
[rank0]:[W126 13:26:05.568859542 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 19:59:06
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:59:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1037419) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1037419) WARNING 01-26 19:59:25 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1037419) WARNING 01-26 19:59:30 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 72.76 requests/s, 19791.34 total tokens/s, 18627.14 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 19:59:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 19:59:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 19:59:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 19:59:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 19:59:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:59:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:59:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:59:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:59:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:59:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 19:59:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 19:59:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 19:59:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 19:59:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:59:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:59:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:59:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:59:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:20] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:20] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:20] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:20] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:20] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:20] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1037419) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1037419) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.39it/s]
(EngineCore_DP0 pid=1037419) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.39it/s]
(EngineCore_DP0 pid=1037419) 
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:21] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1037419) [2026-01-26 19:59:21] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1037419) 2026-01-26 19:59:30,541 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1037419) 2026-01-26 19:59:30,564 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1037419) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:00, 19.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:00<00:00, 20.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:00<00:00, 21.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:00<00:00, 20.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:00<00:00, 19.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:00<00:00, 20.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:00<00:00, 19.95it/s]
(EngineCore_DP0 pid=1037419) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 3/11 [00:00<00:00, 22.08it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00, 22.49it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 9/11 [00:00<00:00, 22.64it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 22.64it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 3880.47it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:00<00:53,  1.18it/s, est. speed input: 18.90 toks/s, output: 302.37 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:00<00:00,  1.18it/s, est. speed input: 1188.01 toks/s, output: 19007.99 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:00<00:00, 74.24it/s, est. speed input: 1188.01 toks/s, output: 19007.99 toks/s]
[rank0]:[W126 19:59:34.846756360 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 19:59:36
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 19:59:43 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1038423) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1038423) WARNING 01-26 19:59:55 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1038423) WARNING 01-26 19:59:59 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 104.11 requests/s, 28317.26 total tokens/s, 26651.54 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 19:59:42] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 19:59:43] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 19:59:43] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 19:59:43] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:43] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:43] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:43] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:43] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:43] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 19:59:43] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:59:43] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:59:43] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:59:43] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:59:43] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 19:59:49] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 19:59:50] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 19:59:50] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 19:59:50] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:50] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:50] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:50] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:50] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 19:59:50] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 19:59:50] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 19:59:50] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 19:59:50] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 19:59:50] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 19:59:50] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:50] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1038423) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1038423) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.36it/s]
(EngineCore_DP0 pid=1038423) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.36it/s]
(EngineCore_DP0 pid=1038423) 
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1038423) [2026-01-26 19:59:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1038423) 2026-01-26 19:59:59,540 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1038423) 2026-01-26 19:59:59,564 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1038423) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:02, 12.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:00<00:01, 16.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:00<00:01, 19.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:00<00:01, 20.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:00<00:00, 21.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:00<00:00, 21.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:00<00:00, 21.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:01<00:00, 20.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:01<00:00, 18.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:01<00:00, 19.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:01<00:00, 20.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 20.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 20.01it/s]
(EngineCore_DP0 pid=1038423) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 3/19 [00:00<00:00, 22.84it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:00, 23.28it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:00<00:00, 23.38it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:00<00:00, 23.50it/s]
Capturing CUDA graphs (decode, FULL):  79%|███████▉  | 15/19 [00:00<00:00, 21.52it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:00<00:00, 20.87it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 21.91it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 4848.91it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<02:27,  1.16s/it, est. speed input: 13.74 toks/s, output: 219.81 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  1.16s/it, est. speed input: 1703.80 toks/s, output: 27260.67 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 106.48it/s, est. speed input: 1703.80 toks/s, output: 27260.67 toks/s]
[rank0]:[W126 20:00:05.361683134 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 20:00:06
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:00:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1039448) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1039448) WARNING 01-26 20:00:26 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1039448) WARNING 01-26 20:00:30 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 137.61 requests/s, 37429.56 total tokens/s, 35227.82 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 20:00:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:00:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 20:00:13] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 20:00:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 20:00:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:00:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:00:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:00:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:00:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:00:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:00:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 20:00:20] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 20:00:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 20:00:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:00:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:00:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:00:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:00:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:21] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:21] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:21] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:21] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:21] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:21] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1039448) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1039448) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.72it/s]
(EngineCore_DP0 pid=1039448) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.71it/s]
(EngineCore_DP0 pid=1039448) 
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:22] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1039448) [2026-01-26 20:00:22] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1039448) 2026-01-26 20:00:30,081 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1039448) 2026-01-26 20:00:30,108 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1039448) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:02, 12.95it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:02, 14.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:00<00:01, 17.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:00<00:01, 18.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 13/36 [00:00<00:01, 19.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:00<00:01, 19.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 19/36 [00:01<00:00, 20.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:01<00:00, 20.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▉   | 25/36 [00:01<00:00, 18.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▌  | 27/36 [00:01<00:00, 18.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:01<00:00, 18.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 33/36 [00:01<00:00, 20.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:01<00:00, 19.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:01<00:00, 19.05it/s]
(EngineCore_DP0 pid=1039448) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   9%|▊         | 3/35 [00:00<00:01, 21.92it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:01, 22.11it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:00<00:01, 22.08it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:00<00:01, 20.09it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 15/35 [00:00<00:01, 18.70it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:00<00:00, 19.76it/s]
Capturing CUDA graphs (decode, FULL):  60%|██████    | 21/35 [00:01<00:00, 20.60it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:01<00:00, 21.12it/s]
Capturing CUDA graphs (decode, FULL):  77%|███████▋  | 27/35 [00:01<00:00, 21.55it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:01<00:00, 21.79it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 33/35 [00:01<00:00, 22.02it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 21.24it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:00<01:01,  4.12it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 877.72it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:01<05:49,  1.37s/it, est. speed input: 11.68 toks/s, output: 186.94 toks/s]
Processed prompts:  73%|███████▎  | 188/256 [00:01<00:00, 176.87it/s, est. speed input: 2043.45 toks/s, output: 32695.00 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:01<00:00, 176.87it/s, est. speed input: 2613.06 toks/s, output: 41808.86 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:01<00:00, 163.31it/s, est. speed input: 2613.06 toks/s, output: 41808.86 toks/s]
[rank0]:[W126 20:00:37.544189611 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 20:00:39
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-1B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-1B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:00:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1040492) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1040492) WARNING 01-26 20:00:58 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1040492) WARNING 01-26 20:01:05 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 173.66 requests/s, 47236.46 total tokens/s, 44457.84 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 20:00:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:00:46] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 20:00:46] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 20:00:46] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:46] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:46] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:46] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:46] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:46] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 20:00:46] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:00:46] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:00:46] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:00:46] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:00:46] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:00:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:00:53] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-FP8'
[2026-01-26 20:00:53] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-FP8
[2026-01-26 20:00:53] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:53] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:53] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:53] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:53] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-FP8
[2026-01-26 20:00:53] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-FP8'
[2026-01-26 20:00:53] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:00:53] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:00:53] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:00:53] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:00:53] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-1B-FP8
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1040492) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1040492) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.00it/s]
(EngineCore_DP0 pid=1040492) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  3.00it/s]
(EngineCore_DP0 pid=1040492) 
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 3296] -> 1D uint8
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6340608 bytes
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 3296] -> 1D uint8
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 4227072 bytes
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 3296] -> 1D uint8
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 33816576 bytes
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2048, 13120] -> 1D uint8
(EngineCore_DP0 pid=1040492) [2026-01-26 20:00:54] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16809984 bytes
(EngineCore_DP0 pid=1040492) 2026-01-26 20:01:05,653 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1040492) 2026-01-26 20:01:05,676 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1040492) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:03, 15.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:02, 17.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:00<00:02, 18.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 9/51 [00:00<00:02, 18.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:00<00:02, 18.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:00<00:02, 17.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:00<00:01, 18.63it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:00<00:01, 18.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:01<00:01, 18.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:01<00:01, 17.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:01<00:01, 17.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:01<00:01, 18.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:01<00:01, 18.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:01<00:00, 19.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:01<00:00, 19.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:02<00:00, 20.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:02<00:00, 20.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:02<00:00, 19.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:02<00:00, 19.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|█████████▌| 49/51 [00:02<00:00, 20.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:02<00:00, 19.14it/s]
(EngineCore_DP0 pid=1040492) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 3/51 [00:00<00:02, 22.95it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:00<00:01, 23.22it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 9/51 [00:00<00:01, 23.45it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:00<00:01, 23.20it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▉       | 15/51 [00:00<00:01, 23.29it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:00<00:01, 23.27it/s]
Capturing CUDA graphs (decode, FULL):  41%|████      | 21/51 [00:00<00:01, 20.23it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:01<00:01, 20.09it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 27/51 [00:01<00:01, 20.95it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:01<00:00, 21.41it/s]
Capturing CUDA graphs (decode, FULL):  65%|██████▍   | 33/51 [00:01<00:00, 21.95it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:01<00:00, 22.21it/s]
Capturing CUDA graphs (decode, FULL):  76%|███████▋  | 39/51 [00:01<00:00, 22.57it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:01<00:00, 22.85it/s]
Capturing CUDA graphs (decode, FULL):  88%|████████▊ | 45/51 [00:02<00:00, 22.98it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:02<00:00, 20.68it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:02<00:00, 20.04it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:02<00:00, 21.61it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 5397.25it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:02<17:45,  2.08s/it, est. speed input: 7.68 toks/s, output: 122.81 toks/s]
Processed prompts:  53%|█████▎    | 273/512 [00:02<00:01, 174.42it/s, est. speed input: 1995.59 toks/s, output: 31929.27 toks/s]
Processed prompts:  88%|████████▊ | 450/512 [00:02<00:00, 307.75it/s, est. speed input: 3144.35 toks/s, output: 50309.44 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:02<00:00, 307.75it/s, est. speed input: 2872.13 toks/s, output: 45954.00 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:02<00:00, 179.50it/s, est. speed input: 2872.13 toks/s, output: 45954.00 toks/s]
[rank0]:[W126 20:01:15.034888800 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 20:25:34
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:25:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1083308) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1083308) WARNING 01-26 20:25:57 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1083308) WARNING 01-26 20:26:07 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 45.46 requests/s, 12365.57 total tokens/s, 11638.19 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 20:25:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:25:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 20:25:41] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 20:25:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:25:41] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:25:41] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:25:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:25:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:25:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 20:25:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:25:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:25:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:25:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:25:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:25:48] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:25:48] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 20:25:48] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 20:25:48] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:25:48] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:25:48] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:25:48] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:25:48] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:25:48] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 20:25:48] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:25:48] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:25:48] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:25:48] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:25:48] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:49] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:49] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:49] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:49] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:49] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:49] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1083308) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1083308) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.00it/s]
(EngineCore_DP0 pid=1083308) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.00it/s]
(EngineCore_DP0 pid=1083308) 
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:51] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1083308) [2026-01-26 20:25:51] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1083308) 2026-01-26 20:26:07,122 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1083308) 2026-01-26 20:26:07,145 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1083308) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:01, 14.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:00<00:00, 15.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:00<00:00, 15.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:00<00:00, 14.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:00<00:00, 14.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:00<00:00, 15.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:00<00:00, 16.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:01<00:00, 15.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:01<00:00, 15.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 14.90it/s]
(EngineCore_DP0 pid=1083308) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00, 13.78it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:00, 16.20it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00, 17.15it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 17.66it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:00<00:00, 18.00it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 17.36it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 4810.67it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:01<01:26,  1.37s/it, est. speed input: 11.67 toks/s, output: 186.78 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00,  1.37s/it, est. speed input: 734.88 toks/s, output: 11758.00 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00, 45.93it/s, est. speed input: 734.88 toks/s, output: 11758.00 toks/s]
[rank0]:[W126 20:26:12.403312248 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 20:26:14
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:26:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1084458) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1084458) WARNING 01-26 20:26:37 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1084458) WARNING 01-26 20:26:43 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 74.61 requests/s, 20292.84 total tokens/s, 19099.15 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 20:26:20] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:26:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 20:26:21] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 20:26:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 20:26:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:26:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:26:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:26:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:26:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:26:27] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:26:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 20:26:27] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 20:26:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 20:26:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:26:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:26:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:26:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:26:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:29] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:29] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:29] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:29] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:29] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:29] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1084458) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1084458) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.03s/it]
(EngineCore_DP0 pid=1084458) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.03s/it]
(EngineCore_DP0 pid=1084458) 
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1084458) [2026-01-26 20:26:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1084458) 2026-01-26 20:26:43,633 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1084458) 2026-01-26 20:26:43,656 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1084458) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:06,  4.99it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:06,  5.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█▏        | 4/35 [00:00<00:03,  9.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:00<00:02, 11.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  23%|██▎       | 8/35 [00:00<00:02, 13.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:00<00:01, 14.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:00<00:01, 15.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 14/35 [00:01<00:01, 13.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▌     | 16/35 [00:01<00:01, 13.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:01<00:01, 14.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:01<00:00, 15.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:01<00:00, 15.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 24/35 [00:01<00:00, 15.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:01<00:00, 16.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 28/35 [00:02<00:00, 16.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▌ | 30/35 [00:02<00:00, 16.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:02<00:00, 16.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:02<00:00, 16.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:02<00:00, 14.20it/s]
(EngineCore_DP0 pid=1084458) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:00, 17.64it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:00, 18.08it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:00, 18.15it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:00<00:00, 18.21it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:00<00:00, 18.25it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:00<00:00, 18.37it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:00<00:00, 18.42it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:00<00:00, 18.44it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:00<00:00, 17.80it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:01<00:00, 18.07it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 4787.34it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<03:27,  1.63s/it, est. speed input: 9.80 toks/s, output: 156.82 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  1.63s/it, est. speed input: 1213.41 toks/s, output: 19414.43 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 75.83it/s, est. speed input: 1213.41 toks/s, output: 19414.43 toks/s]
[rank0]:[W126 20:26:50.800353423 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 20:26:52
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:26:59 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1085591) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1085591) WARNING 01-26 20:27:15 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1085591) WARNING 01-26 20:27:21 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 114.65 requests/s, 31186.01 total tokens/s, 29351.54 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 20:26:58] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:26:59] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 20:26:59] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 20:26:59] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:59] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:59] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:59] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:59] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:26:59] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 20:26:59] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:26:59] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:26:59] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:26:59] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:26:59] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:27:05] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:27:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 20:27:06] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 20:27:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 20:27:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:27:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:27:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:27:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:27:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:06] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:06] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:06] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:06] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:06] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:06] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1085591) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1085591) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.04it/s]
(EngineCore_DP0 pid=1085591) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.04it/s]
(EngineCore_DP0 pid=1085591) 
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:08] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1085591) [2026-01-26 20:27:08] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1085591) 2026-01-26 20:27:21,647 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1085591) 2026-01-26 20:27:21,670 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1085591) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:02, 14.74it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:02, 15.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:00<00:01, 15.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:00<00:01, 16.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:00<00:01, 16.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:00<00:01, 16.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:00<00:01, 16.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:01<00:01, 15.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:01<00:01, 14.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:01<00:01, 14.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:01<00:00, 15.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:01<00:00, 15.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:01<00:00, 15.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:01<00:00, 16.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:01<00:00, 16.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:02<00:00, 16.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:02<00:00, 17.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:02<00:00, 16.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:02<00:00, 15.88it/s]
(EngineCore_DP0 pid=1085591) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:02, 15.74it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:01, 16.98it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:01, 17.53it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:00<00:01, 17.84it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:00<00:01, 17.99it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:00<00:01, 18.09it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:00<00:01, 18.05it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:00<00:01, 18.08it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:01<00:00, 18.20it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:01<00:00, 18.21it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:01<00:00, 16.82it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:01<00:00, 16.45it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:01<00:00, 16.97it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:01<00:00, 17.37it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:01<00:00, 17.69it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:01<00:00, 17.95it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:01<00:00, 18.13it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 17.69it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 5296.00it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:01<08:09,  1.92s/it, est. speed input: 8.34 toks/s, output: 133.42 toks/s]
Processed prompts:  62%|██████▏   | 159/256 [00:02<00:00, 109.71it/s, est. speed input: 1258.09 toks/s, output: 20129.45 toks/s]
Processed prompts:  97%|█████████▋| 249/256 [00:02<00:00, 175.37it/s, est. speed input: 1847.69 toks/s, output: 29562.93 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 175.37it/s, est. speed input: 1875.97 toks/s, output: 30015.48 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 117.24it/s, est. speed input: 1875.97 toks/s, output: 30015.48 toks/s]
[rank0]:[W126 20:27:30.227916816 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 20:27:31
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Llama3.2-3B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Llama3.2-3B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:27:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1086718) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1086718) WARNING 01-26 20:27:54 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1086718) WARNING 01-26 20:28:03 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 124.40 requests/s, 33837.19 total tokens/s, 31846.77 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 20:27:38] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:27:38] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 20:27:38] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 20:27:38] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:38] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:38] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:38] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:38] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:38] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 20:27:38] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:27:38] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:27:38] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:27:38] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:27:38] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:27:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:27:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-3B-FP8'
[2026-01-26 20:27:45] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B-FP8
[2026-01-26 20:27:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B-FP8
[2026-01-26 20:27:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-3B-FP8'
[2026-01-26 20:27:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:27:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:27:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:27:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:27:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:46] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:46] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:46] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:46] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:46] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Llama3.2-3B-FP8
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:46] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1086718) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1086718) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.12it/s]
(EngineCore_DP0 pid=1086718) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.12it/s]
(EngineCore_DP0 pid=1086718) 
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 4928] -> 1D uint8
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 15810560 bytes
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 4928] -> 1D uint8
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9486336 bytes
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [16384, 4928] -> 1D uint8
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 50593792 bytes
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:47] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3072, 13120] -> 1D uint8
(EngineCore_DP0 pid=1086718) [2026-01-26 20:27:47] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 25214976 bytes
(EngineCore_DP0 pid=1086718) 2026-01-26 20:28:03,584 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1086718) 2026-01-26 20:28:03,608 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1086718) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:03, 15.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:03, 15.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:02, 15.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:00<00:02, 14.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:00<00:03, 13.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:00<00:03, 12.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:01<00:02, 12.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:01<00:02, 13.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:01<00:02, 13.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:01<00:02, 14.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:01<00:01, 14.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:01<00:01, 15.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:01<00:01, 13.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:02<00:01, 13.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:02<00:01, 14.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:02<00:01, 15.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:02<00:01, 14.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:02<00:00, 15.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:02<00:00, 15.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:02<00:00, 15.79it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:02<00:00, 15.20it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:03<00:00, 12.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:03<00:00, 12.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:03<00:00, 13.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:03<00:00, 14.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:03<00:00, 14.20it/s]
(EngineCore_DP0 pid=1086718) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:02, 17.55it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:02, 16.93it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:00<00:02, 16.20it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 8/51 [00:00<00:02, 16.82it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:00<00:02, 16.13it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:00<00:02, 15.04it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:00<00:02, 15.26it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:00<00:02, 16.05it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:01<00:01, 16.59it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:01<00:01, 16.94it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:01<00:01, 17.26it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:01<00:01, 16.86it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:01<00:01, 17.18it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:01<00:01, 17.35it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:01<00:01, 16.91it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:01<00:01, 15.52it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:02<00:01, 15.64it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:02<00:00, 16.28it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:02<00:00, 16.66it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:02<00:00, 17.00it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:02<00:00, 17.19it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:02<00:00, 17.39it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:02<00:00, 17.55it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:02<00:00, 17.70it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:02<00:00, 17.90it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:03<00:00, 16.71it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  98%|█████████▊| 500/512 [00:00<00:00, 4992.57it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 4992.07it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:02<24:28,  2.87s/it, est. speed input: 5.57 toks/s, output: 89.11 toks/s]
Processed prompts:  40%|████      | 205/512 [00:02<00:03, 96.71it/s, est. speed input: 1101.21 toks/s, output: 17619.27 toks/s]
Processed prompts:  75%|███████▌  | 384/512 [00:03<00:00, 203.17it/s, est. speed input: 1992.76 toks/s, output: 31884.05 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:04<00:00, 203.17it/s, est. speed input: 2041.92 toks/s, output: 32670.74 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:04<00:00, 127.62it/s, est. speed input: 2041.92 toks/s, output: 32670.74 toks/s]
[rank0]:[W126 20:28:16.518428499 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 20:53:20
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:53:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1131015) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1131015) WARNING 01-26 20:53:43 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1131015) WARNING 01-26 20:53:52 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 43.23 requests/s, 11759.25 total tokens/s, 11067.53 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 20:53:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:53:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:53:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:53:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:53:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:53:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:53:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:53:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:53:33] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:53:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:53:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:53:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:53:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:53:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:53:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:53:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:53:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:34] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:34] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:34] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:34] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:34] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1131015) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1131015) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.06it/s]
(EngineCore_DP0 pid=1131015) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.08s/it]
(EngineCore_DP0 pid=1131015) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.06s/it]
(EngineCore_DP0 pid=1131015) 
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1131015) [2026-01-26 20:53:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1131015) 2026-01-26 20:53:52,701 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1131015) 2026-01-26 20:53:52,723 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1131015) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:03,  5.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:04,  3.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:00<00:02,  6.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:00<00:01,  9.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:00<00:00, 11.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:01<00:00, 12.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:01<00:00, 14.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:01<00:00, 14.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:01<00:00, 15.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:01<00:00, 16.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 12.26it/s]
(EngineCore_DP0 pid=1131015) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00, 13.62it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:00, 15.02it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00, 16.38it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 17.19it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:00<00:00, 17.74it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 16.97it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 3977.35it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:01<01:30,  1.44s/it, est. speed input: 11.13 toks/s, output: 178.08 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00,  1.44s/it, est. speed input: 699.81 toks/s, output: 11196.85 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00, 43.73it/s, est. speed input: 699.81 toks/s, output: 11196.85 toks/s]
[rank0]:[W126 20:53:57.103686738 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 20:53:59
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:54:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1132171) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1132171) WARNING 01-26 20:54:23 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1132171) WARNING 01-26 20:54:30 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 61.30 requests/s, 16674.43 total tokens/s, 15693.58 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 20:54:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:54:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:54:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:54:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:54:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:54:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:54:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:54:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:54:12] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:54:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:54:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:54:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:54:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:54:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:54:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:54:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:14] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:14] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:14] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:14] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:14] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:14] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1132171) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1132171) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.23it/s]
(EngineCore_DP0 pid=1132171) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.19s/it]
(EngineCore_DP0 pid=1132171) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.14s/it]
(EngineCore_DP0 pid=1132171) 
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:16] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1132171) [2026-01-26 20:54:16] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1132171) 2026-01-26 20:54:30,152 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1132171) 2026-01-26 20:54:30,175 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1132171) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:03,  9.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:02, 13.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:00<00:01, 15.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:00<00:01, 15.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:00<00:01, 16.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:00<00:01, 16.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:00<00:01, 16.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:00<00:01, 16.67it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:01<00:01, 16.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:01<00:01, 14.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:01<00:01, 12.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:01<00:00, 12.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:01<00:00, 13.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:01<00:00, 14.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:01<00:00, 15.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:02<00:00, 15.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:02<00:00, 16.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:02<00:00, 15.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:02<00:00, 15.08it/s]
(EngineCore_DP0 pid=1132171) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:01, 13.14it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:01, 13.90it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:00, 15.57it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:00<00:00, 16.57it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:00<00:00, 17.20it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:00<00:00, 17.60it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:00<00:00, 17.93it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:00<00:00, 18.08it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:01<00:00, 18.34it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:01<00:00, 17.25it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:   5%|▌         | 7/128 [00:00<00:03, 30.67it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 503.60it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<03:06,  1.47s/it, est. speed input: 10.88 toks/s, output: 174.05 toks/s]
Processed prompts:   5%|▌         | 7/128 [00:01<00:24,  5.01it/s, est. speed input: 63.02 toks/s, output: 1008.25 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  5.01it/s, est. speed input: 1117.46 toks/s, output: 17879.39 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 69.84it/s, est. speed input: 1117.46 toks/s, output: 17879.39 toks/s]
[rank0]:[W126 20:54:37.422035411 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 20:54:39
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:54:45 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1133296) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1133296) WARNING 01-26 20:55:02 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1133296) WARNING 01-26 20:55:09 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 94.58 requests/s, 25725.50 total tokens/s, 24212.24 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 20:54:45] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:54:45] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:54:45] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:45] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:45] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:45] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:45] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:45] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:45] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:54:45] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:54:45] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:54:45] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:54:45] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:54:45] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:54:52] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:54:52] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:54:52] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:52] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:52] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:52] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:52] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:52] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:54:52] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:54:52] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:54:52] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:54:52] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:54:52] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:54:52] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:53] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:53] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:53] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:53] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:53] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:53] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1133296) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1133296) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.02s/it]
(EngineCore_DP0 pid=1133296) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.20s/it]
(EngineCore_DP0 pid=1133296) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.17s/it]
(EngineCore_DP0 pid=1133296) 
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:56] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1133296) [2026-01-26 20:54:56] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1133296) 2026-01-26 20:55:09,229 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1133296) 2026-01-26 20:55:09,252 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1133296) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:02, 15.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:02, 13.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:00<00:02, 13.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:00<00:01, 14.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:00<00:01, 13.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:00<00:01, 13.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:00<00:01, 14.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:01<00:01, 15.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:01<00:01, 15.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:01<00:01, 15.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:01<00:00, 15.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:01<00:00, 16.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:01<00:00, 16.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:01<00:00, 15.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:02<00:00, 14.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:02<00:00, 15.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:02<00:00, 16.31it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:02<00:00, 15.59it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:02<00:00, 15.11it/s]
(EngineCore_DP0 pid=1133296) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:01, 17.90it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:01, 15.91it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:01, 16.73it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:00<00:01, 17.37it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:00<00:01, 17.67it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:00<00:01, 16.44it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:00<00:01, 16.04it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:00<00:01, 16.62it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:01<00:00, 17.05it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:01<00:00, 17.31it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:01<00:00, 17.55it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:01<00:00, 17.69it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:01<00:00, 17.89it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:01<00:00, 18.02it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:01<00:00, 18.11it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:01<00:00, 17.62it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:01<00:00, 16.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:02<00:00, 17.15it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:00<01:02,  4.10it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 859.67it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:02<08:57,  2.11s/it, est. speed input: 7.59 toks/s, output: 121.46 toks/s]
Processed prompts:  56%|█████▋    | 144/256 [00:02<00:01, 91.16it/s, est. speed input: 1043.17 toks/s, output: 16690.70 toks/s]
Processed prompts:  90%|████████▉ | 230/256 [00:02<00:00, 154.52it/s, est. speed input: 1591.18 toks/s, output: 25458.88 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 154.52it/s, est. speed input: 1701.18 toks/s, output: 27218.83 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 106.32it/s, est. speed input: 1701.18 toks/s, output: 27218.83 toks/s]
[rank0]:[W126 20:55:17.095851960 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 20:55:19
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-7B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:55:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1134443) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1134443) WARNING 01-26 20:55:43 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1134443) WARNING 01-26 20:55:52 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 109.44 requests/s, 29768.62 total tokens/s, 28017.53 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 20:55:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:55:26] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:55:26] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:26] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:26] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:26] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:26] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:26] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:26] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:55:26] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:55:26] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:55:26] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:55:26] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:55:26] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 20:55:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 20:55:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:55:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-FP8
[2026-01-26 20:55:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-FP8'
[2026-01-26 20:55:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 20:55:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 20:55:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 20:55:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 20:55:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:34] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:34] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:34] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:34] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:34] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-7B-FP8
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:34] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1134443) 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1134443) 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.06it/s]
(EngineCore_DP0 pid=1134443) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.09s/it]
(EngineCore_DP0 pid=1134443) 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.07s/it]
(EngineCore_DP0 pid=1134443) 
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [4608, 5760] -> 1D uint8
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 16588800 bytes
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 5760] -> 1D uint8
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 12902400 bytes
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [37888, 5760] -> 1D uint8
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 136396800 bytes
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:36] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3584, 30336] -> 1D uint8
(EngineCore_DP0 pid=1134443) [2026-01-26 20:55:36] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 67952640 bytes
(EngineCore_DP0 pid=1134443) 2026-01-26 20:55:52,786 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1134443) 2026-01-26 20:55:52,809 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1134443) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:03, 15.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:02, 15.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:02, 15.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:00<00:02, 15.83it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:00<00:02, 15.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:00<00:02, 15.86it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:00<00:02, 15.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:01<00:02, 14.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:01<00:02, 13.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:01<00:02, 14.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:01<00:01, 15.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:01<00:01, 15.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:01<00:01, 16.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:01<00:01, 16.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:01<00:01, 16.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:02<00:01, 16.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:02<00:01, 16.14it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:02<00:00, 15.02it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:02<00:00, 14.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:02<00:00, 13.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:02<00:00, 13.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:02<00:00, 14.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:03<00:00, 14.71it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:03<00:00, 15.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:03<00:00, 16.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:03<00:00, 15.21it/s]
(EngineCore_DP0 pid=1134443) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:03, 13.31it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:03, 14.51it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:00<00:02, 15.99it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 8/51 [00:00<00:02, 16.91it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:00<00:02, 17.52it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:00<00:02, 17.86it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:00<00:02, 18.16it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:00<00:01, 18.29it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:01<00:01, 18.40it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:01<00:01, 18.43it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:01<00:01, 18.48it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:01<00:01, 17.29it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:01<00:01, 15.23it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:01<00:01, 13.50it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:01<00:01, 14.71it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:01<00:01, 15.65it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:02<00:01, 16.34it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:02<00:00, 16.79it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:02<00:00, 17.18it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:02<00:00, 17.47it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:02<00:00, 16.46it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:02<00:00, 15.94it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:02<00:00, 15.90it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:02<00:00, 16.47it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:03<00:00, 16.91it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:03<00:00, 16.60it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  96%|█████████▋| 493/512 [00:00<00:00, 4920.96it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 4919.85it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:03<27:14,  3.20s/it, est. speed input: 5.00 toks/s, output: 80.05 toks/s]
Processed prompts:  36%|███▌      | 185/512 [00:03<00:04, 78.84it/s, est. speed input: 896.35 toks/s, output: 14341.59 toks/s]
Processed prompts:  70%|██████▉   | 358/512 [00:03<00:00, 173.31it/s, est. speed input: 1681.48 toks/s, output: 26903.61 toks/s]
Processed prompts:  96%|█████████▌| 491/512 [00:03<00:00, 241.50it/s, est. speed input: 2174.69 toks/s, output: 34795.05 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:04<00:00, 241.50it/s, est. speed input: 1791.39 toks/s, output: 28662.23 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:04<00:00, 111.96it/s, est. speed input: 1791.39 toks/s, output: 28662.23 toks/s]
[rank0]:[W126 20:56:05.864543308 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-26 21:30:26
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:30:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1185714) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1185714) WARNING 01-26 21:30:55 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1185714) WARNING 01-26 21:31:09 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 27.70 requests/s, 7533.42 total tokens/s, 7090.28 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-26 21:30:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:30:33] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:30:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:33] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:30:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:30:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:30:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:30:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:30:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 21:30:39] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:30:39] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:30:39] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:39] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:39] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:39] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:39] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:39] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:30:39] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:30:39] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:30:39] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:30:39] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:30:39] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:30:39] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:40] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:40] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:40] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:40] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:40] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:40] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1185714) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1185714) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.50s/it]
(EngineCore_DP0 pid=1185714) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.15it/s]
(EngineCore_DP0 pid=1185714) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.11s/it]
(EngineCore_DP0 pid=1185714) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.24s/it]
(EngineCore_DP0 pid=1185714) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
(EngineCore_DP0 pid=1185714) 
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:45] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1185714) [2026-01-26 21:30:45] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1185714) 2026-01-26 21:31:09,821 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1185714) 2026-01-26 21:31:09,859 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1185714) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:02,  8.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 3/19 [00:00<00:01,  9.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▋       | 5/19 [00:00<00:01, 10.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 7/19 [00:00<00:01, 10.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 9/19 [00:00<00:00, 10.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 11/19 [00:01<00:00,  9.69it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  68%|██████▊   | 13/19 [00:01<00:00,  9.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 15/19 [00:01<00:00, 10.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 17/19 [00:01<00:00, 10.45it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 10.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 10.03it/s]
(EngineCore_DP0 pid=1185714) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00,  9.54it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:00, 10.25it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00, 10.73it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 10.99it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:00<00:00, 11.18it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:01<00:00, 10.91it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 4356.87it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:02<02:21,  2.25s/it, est. speed input: 7.10 toks/s, output: 113.60 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:02<00:00,  2.25s/it, est. speed input: 446.18 toks/s, output: 7138.79 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:02<00:00, 27.88it/s, est. speed input: 446.18 toks/s, output: 7138.79 toks/s]
[rank0]:[W126 21:31:16.097675913 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-26 21:31:18
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:31:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1187031) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1187031) WARNING 01-26 21:31:48 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1187031) WARNING 01-26 21:32:00 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 44.02 requests/s, 11973.70 total tokens/s, 11269.37 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-26 21:31:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:31:25] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:31:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:25] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:31:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:31:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:31:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:31:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:31:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 21:31:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:31:32] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:31:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:31:32] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:31:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:31:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:31:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:31:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:31:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:33] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:33] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:33] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:33] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:33] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:33] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1187031) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1187031) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.49s/it]
(EngineCore_DP0 pid=1187031) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.15it/s]
(EngineCore_DP0 pid=1187031) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.11s/it]
(EngineCore_DP0 pid=1187031) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.17s/it]
(EngineCore_DP0 pid=1187031) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
(EngineCore_DP0 pid=1187031) 
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:38] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1187031) [2026-01-26 21:31:38] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1187031) 2026-01-26 21:32:00,685 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1187031) 2026-01-26 21:32:00,723 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1187031) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:08,  4.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/35 [00:00<00:07,  4.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:05,  5.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:00<00:03,  7.70it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:00<00:03,  8.65it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:01<00:02,  8.90it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▊       | 10/35 [00:01<00:02,  8.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:01<00:03,  7.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:01<00:02,  8.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:01<00:02,  9.00it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:02<00:01,  9.33it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:02<00:01,  9.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 20/35 [00:02<00:01,  9.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:02<00:02,  6.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:02<00:01,  7.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:02<00:01,  7.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:03<00:01,  8.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:03<00:00,  9.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:03<00:00,  9.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:03<00:00,  9.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████▏| 32/35 [00:03<00:00,  9.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:03<00:00,  9.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:04<00:00,  9.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:04<00:00,  9.24it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:04<00:00,  8.48it/s]
(EngineCore_DP0 pid=1187031) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:01, 11.08it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:01, 11.29it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:01, 11.30it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:00<00:00, 11.31it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:00<00:00, 10.98it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:01<00:00, 11.00it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:01<00:00, 11.08it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:01<00:00, 11.19it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:01<00:00, 10.61it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:01<00:00, 10.97it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 4415.09it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:02<05:53,  2.78s/it, est. speed input: 5.76 toks/s, output: 92.09 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00,  2.78s/it, est. speed input: 711.69 toks/s, output: 11387.03 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:02<00:00, 44.48it/s, est. speed input: 711.69 toks/s, output: 11387.03 toks/s]
[rank0]:[W126 21:32:11.504606915 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-26 21:32:13
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:32:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1188391) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1188391) WARNING 01-26 21:32:43 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1188391) WARNING 01-26 21:32:55 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 62.93 requests/s, 17115.89 total tokens/s, 16109.07 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-26 21:32:19] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:32:20] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:32:20] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:20] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:20] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:20] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:20] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:20] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:20] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:32:20] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:32:20] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:32:20] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:32:20] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:32:20] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 21:32:26] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:32:27] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:32:27] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:27] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:27] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:27] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:27] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:27] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:32:27] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:32:27] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:32:27] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:32:27] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:32:27] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:32:27] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:28] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:28] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:28] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:28] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:28] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:28] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1188391) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1188391) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.50s/it]
(EngineCore_DP0 pid=1188391) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.15it/s]
(EngineCore_DP0 pid=1188391) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.14s/it]
(EngineCore_DP0 pid=1188391) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.19s/it]
(EngineCore_DP0 pid=1188391) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.16s/it]
(EngineCore_DP0 pid=1188391) 
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:33] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1188391) [2026-01-26 21:32:33] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1188391) 2026-01-26 21:32:55,572 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1188391) 2026-01-26 21:32:55,610 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1188391) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:03,  9.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:03,  9.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:00<00:03,  9.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 7/36 [00:00<00:03,  9.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:00<00:02,  9.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:01<00:02,  9.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:01<00:02, 10.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:01<00:02, 10.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:01<00:01, 10.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:01<00:01, 10.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:02<00:01,  8.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:02<00:01,  8.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:02<00:01,  9.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:02<00:01,  9.47it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:02<00:00,  9.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|████████  | 29/36 [00:03<00:00,  9.34it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:03<00:00,  9.32it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:03<00:00,  9.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:03<00:00, 10.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:03<00:00,  9.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:03<00:00,  9.60it/s]
(EngineCore_DP0 pid=1188391) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:02, 11.04it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:03, 10.23it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:02, 10.23it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:00<00:02, 10.64it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:00<00:02, 10.84it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:01<00:02, 10.95it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:01<00:01, 11.08it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:01<00:01, 11.02it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:01<00:01, 10.69it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:01<00:01, 10.64it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:02<00:01, 10.04it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:02<00:01, 10.34it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:02<00:00, 10.60it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:02<00:00, 10.79it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:02<00:00, 10.55it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:03<00:00, 10.39it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:03<00:00, 10.66it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:03<00:00, 10.64it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:  38%|███▊      | 98/256 [00:00<00:00, 311.10it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 727.87it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:02<12:30,  2.94s/it, est. speed input: 5.43 toks/s, output: 86.94 toks/s]
Processed prompts:  38%|███▊      | 98/256 [00:03<00:03, 39.95it/s, est. speed input: 470.99 toks/s, output: 7535.84 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:03<00:01, 78.58it/s, est. speed input: 802.51 toks/s, output: 12840.08 toks/s]
Processed prompts:  86%|████████▌ | 219/256 [00:03<00:00, 107.10it/s, est. speed input: 992.57 toks/s, output: 15881.04 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 107.10it/s, est. speed input: 1102.45 toks/s, output: 17639.21 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:03<00:00, 68.90it/s, est. speed input: 1102.45 toks/s, output: 17639.21 toks/s] 
[rank0]:[W126 21:33:08.895463679 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-26 21:33:10
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/Qwen2.5-14B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:33:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=1189761) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1189761) WARNING 01-26 21:33:40 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=1189761) WARNING 01-26 21:33:55 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 71.40 requests/s, 19421.37 total tokens/s, 18278.94 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-26 21:33:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:33:17] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:33:17] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:17] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:17] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:17] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:17] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:17] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:17] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:33:17] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:33:17] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:33:17] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:33:17] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:33:17] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 21:33:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 21:33:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:33:24] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:24] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:24] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B-FP8
[2026-01-26 21:33:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-14B-FP8'
[2026-01-26 21:33:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 21:33:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 21:33:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 21:33:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 21:33:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: Qwen2.5-14B-FP8
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=1189761) 
Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
(EngineCore_DP0 pid=1189761) 
Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:04,  1.51s/it]
(EngineCore_DP0 pid=1189761) 
Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.14it/s]
(EngineCore_DP0 pid=1189761) 
Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.12s/it]
(EngineCore_DP0 pid=1189761) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.18s/it]
(EngineCore_DP0 pid=1189761) 
Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.15s/it]
(EngineCore_DP0 pid=1189761) 
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [7168, 8192] -> 1D uint8
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 36700160 bytes
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 8192] -> 1D uint8
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 26214400 bytes
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [27648, 8192] -> 1D uint8
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 141557760 bytes
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:30] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [5120, 22144] -> 1D uint8
(EngineCore_DP0 pid=1189761) [2026-01-26 21:33:30] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 70860800 bytes
(EngineCore_DP0 pid=1189761) 2026-01-26 21:33:55,430 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=1189761) 2026-01-26 21:33:55,473 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=1189761) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   2%|▏         | 1/51 [00:00<00:06,  7.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:05,  8.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 3/51 [00:00<00:05,  8.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:05,  9.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|▉         | 5/51 [00:00<00:04,  9.42it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:04,  9.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▎        | 7/51 [00:00<00:04,  9.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:00<00:04,  9.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:01<00:04,  8.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 11/51 [00:01<00:04,  8.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:01<00:04,  8.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 13/51 [00:01<00:04,  8.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:01<00:04,  9.05it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  29%|██▉       | 15/51 [00:01<00:03,  9.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:01<00:03,  9.37it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 17/51 [00:01<00:03,  9.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 19/51 [00:02<00:03,  8.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  41%|████      | 21/51 [00:02<00:03,  8.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:02<00:03,  8.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▌     | 23/51 [00:02<00:03,  8.39it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:02<00:03,  8.75it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 25/51 [00:02<00:02,  8.93it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 27/51 [00:03<00:02,  9.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 29/51 [00:03<00:02,  9.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 31/51 [00:03<00:02,  9.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:03<00:01,  9.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  65%|██████▍   | 33/51 [00:03<00:02,  8.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:03<00:01,  8.87it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|██████▊   | 35/51 [00:03<00:01,  9.01it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 37/51 [00:04<00:01,  9.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▋  | 39/51 [00:04<00:01,  9.58it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  80%|████████  | 41/51 [00:04<00:01,  9.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 43/51 [00:04<00:00,  9.73it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:04<00:00,  9.35it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 45/51 [00:04<00:00,  9.08it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  92%|█████████▏| 47/51 [00:05<00:00,  9.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:05<00:00,  9.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:05<00:00,  9.91it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:05<00:00,  9.36it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:05<00:00,  9.12it/s]
(EngineCore_DP0 pid=1189761) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:04, 10.90it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:04, 11.06it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:00<00:04, 10.48it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 8/51 [00:00<00:04, 10.55it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:00<00:03, 10.78it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:01<00:03, 11.00it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:01<00:03, 11.12it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:01<00:03, 11.22it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:01<00:03, 10.83it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:01<00:02, 10.62it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:02<00:02, 10.80it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:02<00:02, 10.10it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:02<00:02, 10.33it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:02<00:02, 10.62it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:02<00:01, 10.82it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:03<00:01, 10.26it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:03<00:01, 10.08it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:03<00:01, 10.40it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:03<00:01, 10.60it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:03<00:01, 10.81it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:03<00:00, 10.90it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:04<00:00, 10.35it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:04<00:00, 10.51it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:04<00:00, 10.64it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:04<00:00, 10.83it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:04<00:00, 10.67it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests:  96%|█████████▋| 493/512 [00:00<00:00, 4920.29it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 4919.62it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:04<41:52,  4.92s/it, est. speed input: 3.25 toks/s, output: 52.07 toks/s]
Processed prompts:  23%|██▎       | 117/512 [00:05<00:12, 32.87it/s, est. speed input: 372.50 toks/s, output: 5960.05 toks/s]
Processed prompts:  47%|████▋     | 242/512 [00:05<00:03, 79.70it/s, est. speed input: 754.25 toks/s, output: 12068.02 toks/s]
Processed prompts:  68%|██████▊   | 348/512 [00:05<00:01, 130.21it/s, est. speed input: 1061.92 toks/s, output: 16990.62 toks/s]
Processed prompts:  86%|████████▌ | 439/512 [00:05<00:00, 179.15it/s, est. speed input: 1304.81 toks/s, output: 20876.99 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:07<00:00, 179.15it/s, est. speed input: 1159.45 toks/s, output: 18551.14 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:07<00:00, 72.46it/s, est. speed input: 1159.45 toks/s, output: 18551.14 toks/s] 
[rank0]:[W126 21:34:15.544444132 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=64 ==========
Time: 2026-01-28 14:39:11
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=64, max_num_seqs=64
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 64 --max-num-seqs 64 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M64.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 14:39:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3334266) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3334266) WARNING 01-28 14:39:33 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=3334266) WARNING 01-28 14:39:43 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 41.33 requests/s, 11242.68 total tokens/s, 10581.35 output tokens/s
Total num prompt tokens:  1024
Total num output tokens:  16384

STDERR:
[2026-01-28 14:39:17] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 14:39:18] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 14:39:18] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 14:39:18] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:18] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:18] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:18] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:18] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:18] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 14:39:18] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 14:39:18] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 14:39:18] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 14:39:18] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 14:39:18] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 14:39:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 14:39:24] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 14:39:24] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 14:39:24] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:24] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:24] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:24] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:24] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:24] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 14:39:24] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 14:39:24] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 14:39:24] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 14:39:24] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 14:39:24] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:25] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:25] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:25] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:25] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:25] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:25] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3334266) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3334266) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.45it/s]
(EngineCore_DP0 pid=3334266) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.45it/s]
(EngineCore_DP0 pid=3334266) 
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:26] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3334266) [2026-01-28 14:39:26] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17735680 bytes
(EngineCore_DP0 pid=3334266) 2026-01-28 14:39:43,335 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3334266) 2026-01-28 14:39:43,361 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3334266) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   5%|▌         | 1/19 [00:00<00:03,  5.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 2/19 [00:00<00:03,  5.41it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 4/19 [00:00<00:01,  8.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  32%|███▏      | 6/19 [00:00<00:01, 10.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 8/19 [00:00<00:00, 11.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  53%|█████▎    | 10/19 [00:00<00:00, 12.53it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 12/19 [00:01<00:00, 12.23it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▎  | 14/19 [00:01<00:00, 11.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|████████▍ | 16/19 [00:01<00:00, 12.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  95%|█████████▍| 18/19 [00:01<00:00, 13.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 19/19 [00:01<00:00, 11.34it/s]
(EngineCore_DP0 pid=3334266) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/11 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  18%|█▊        | 2/11 [00:00<00:00, 15.56it/s]
Capturing CUDA graphs (decode, FULL):  36%|███▋      | 4/11 [00:00<00:00, 15.99it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 6/11 [00:00<00:00, 16.07it/s]
Capturing CUDA graphs (decode, FULL):  73%|███████▎  | 8/11 [00:00<00:00, 16.15it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████ | 10/11 [00:00<00:00, 16.21it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 11/11 [00:00<00:00, 16.12it/s]

Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 64/64 [00:00<00:00, 5000.19it/s]

Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   2%|▏         | 1/64 [00:01<01:35,  1.51s/it, est. speed input: 10.59 toks/s, output: 169.51 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00,  1.51s/it, est. speed input: 667.27 toks/s, output: 10676.32 toks/s]
Processed prompts: 100%|██████████| 64/64 [00:01<00:00, 41.70it/s, est. speed input: 667.27 toks/s, output: 10676.32 toks/s]
[rank0]:[W128 14:39:48.119013260 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=128 ==========
Time: 2026-01-28 14:39:50
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=128, max_num_seqs=128
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 128 --max-num-seqs 128 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M128.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 14:39:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3335379) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3335379) WARNING 01-28 14:40:12 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=3335379) WARNING 01-28 14:40:19 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 73.25 requests/s, 19923.94 total tokens/s, 18751.95 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768

STDERR:
[2026-01-28 14:39:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 14:39:57] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 14:39:57] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 14:39:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:57] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:57] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:39:57] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 14:39:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 14:39:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 14:39:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 14:39:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 14:39:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 14:40:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 14:40:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 14:40:03] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 14:40:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:03] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:03] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 14:40:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 14:40:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 14:40:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 14:40:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 14:40:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:04] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:04] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:04] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:04] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:04] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:04] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3335379) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3335379) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.49it/s]
(EngineCore_DP0 pid=3335379) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.49it/s]
(EngineCore_DP0 pid=3335379) 
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:05] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3335379) [2026-01-28 14:40:05] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17735680 bytes
(EngineCore_DP0 pid=3335379) 2026-01-28 14:40:19,555 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3335379) 2026-01-28 14:40:19,581 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3335379) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/35 [00:00<00:03,  9.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:03, 10.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:00<00:02, 12.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|██        | 7/35 [00:00<00:02, 13.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  26%|██▌       | 9/35 [00:00<00:01, 13.60it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:00<00:01, 13.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 13/35 [00:00<00:01, 14.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:01<00:01, 14.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▊     | 17/35 [00:01<00:01, 14.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:01<00:01, 13.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|██████    | 21/35 [00:01<00:01, 12.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|██████▌   | 23/35 [00:01<00:00, 13.18it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████▏  | 25/35 [00:01<00:00, 13.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:02<00:00, 13.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:02<00:00, 13.96it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▊ | 31/35 [00:02<00:00, 14.48it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 33/35 [00:02<00:00, 14.76it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:02<00:00, 13.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:02<00:00, 13.50it/s]
(EngineCore_DP0 pid=3335379) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  11%|█         | 2/19 [00:00<00:01, 13.47it/s]
Capturing CUDA graphs (decode, FULL):  21%|██        | 4/19 [00:00<00:01, 12.51it/s]
Capturing CUDA graphs (decode, FULL):  32%|███▏      | 6/19 [00:00<00:01, 12.88it/s]
Capturing CUDA graphs (decode, FULL):  42%|████▏     | 8/19 [00:00<00:00, 13.93it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:00<00:00, 14.59it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 12/19 [00:00<00:00, 15.06it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▎  | 14/19 [00:00<00:00, 15.34it/s]
Capturing CUDA graphs (decode, FULL):  84%|████████▍ | 16/19 [00:01<00:00, 15.61it/s]
Capturing CUDA graphs (decode, FULL):  95%|█████████▍| 18/19 [00:01<00:00, 15.10it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:01<00:00, 14.60it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 4961.24it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<03:31,  1.66s/it, est. speed input: 9.62 toks/s, output: 153.95 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  1.66s/it, est. speed input: 1190.26 toks/s, output: 19044.04 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 74.39it/s, est. speed input: 1190.26 toks/s, output: 19044.04 toks/s]
[rank0]:[W128 14:40:26.936848395 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=256 ==========
Time: 2026-01-28 14:40:28
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=256, max_num_seqs=256
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 256 --max-num-seqs 256 --max-model-len 272 --max-num-batched-tokens 272 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M256.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 14:40:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3336453) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3336453) WARNING 01-28 14:40:50 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=3336453) WARNING 01-28 14:40:57 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 106.69 requests/s, 29020.94 total tokens/s, 27313.83 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536

STDERR:
[2026-01-28 14:40:34] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 14:40:35] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 14:40:35] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 14:40:35] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:35] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:35] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:35] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:35] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:35] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 14:40:35] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 14:40:35] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 14:40:35] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 14:40:35] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 14:40:35] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 14:40:41] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 14:40:41] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 14:40:41] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 14:40:41] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:41] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:41] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:41] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:41] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:40:41] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 14:40:41] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 14:40:41] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 14:40:41] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 14:40:41] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 14:40:41] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:42] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:42] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:42] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:42] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:42] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:42] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3336453) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3336453) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.50it/s]
(EngineCore_DP0 pid=3336453) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.50it/s]
(EngineCore_DP0 pid=3336453) 
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:43] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3336453) [2026-01-28 14:40:43] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17735680 bytes
(EngineCore_DP0 pid=3336453) 2026-01-28 14:40:57,400 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3336453) 2026-01-28 14:40:57,427 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3336453) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 2/36 [00:00<00:03, 11.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  11%|█         | 4/36 [00:00<00:03,  8.81it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/36 [00:00<00:02, 10.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:00<00:02, 12.15it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 10/36 [00:00<00:02, 12.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 12/36 [00:00<00:01, 13.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 14/36 [00:01<00:01, 13.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  44%|████▍     | 16/36 [00:01<00:01, 12.72it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:01<00:01, 12.88it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  56%|█████▌    | 20/36 [00:01<00:01, 13.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|██████    | 22/36 [00:01<00:01, 13.62it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 24/36 [00:01<00:00, 13.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|███████▏  | 26/36 [00:02<00:00, 14.12it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:02<00:00, 14.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 30/36 [00:02<00:00, 14.30it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  89%|████████▉ | 32/36 [00:02<00:00, 14.07it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 34/36 [00:02<00:00, 13.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:02<00:00, 13.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:02<00:00, 13.16it/s]
(EngineCore_DP0 pid=3336453) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   6%|▌         | 2/35 [00:00<00:02, 15.39it/s]
Capturing CUDA graphs (decode, FULL):  11%|█▏        | 4/35 [00:00<00:01, 15.82it/s]
Capturing CUDA graphs (decode, FULL):  17%|█▋        | 6/35 [00:00<00:01, 15.98it/s]
Capturing CUDA graphs (decode, FULL):  23%|██▎       | 8/35 [00:00<00:01, 15.92it/s]
Capturing CUDA graphs (decode, FULL):  29%|██▊       | 10/35 [00:00<00:01, 15.79it/s]
Capturing CUDA graphs (decode, FULL):  34%|███▍      | 12/35 [00:00<00:01, 15.85it/s]
Capturing CUDA graphs (decode, FULL):  40%|████      | 14/35 [00:00<00:01, 14.01it/s]
Capturing CUDA graphs (decode, FULL):  46%|████▌     | 16/35 [00:01<00:01, 13.47it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:01<00:01, 14.10it/s]
Capturing CUDA graphs (decode, FULL):  57%|█████▋    | 20/35 [00:01<00:01, 14.63it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 22/35 [00:01<00:00, 14.94it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:01<00:00, 15.26it/s]
Capturing CUDA graphs (decode, FULL):  74%|███████▍  | 26/35 [00:01<00:00, 15.44it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:01<00:00, 15.67it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▌ | 30/35 [00:01<00:00, 15.71it/s]
Capturing CUDA graphs (decode, FULL):  91%|█████████▏| 32/35 [00:02<00:00, 15.90it/s]
Capturing CUDA graphs (decode, FULL):  97%|█████████▋| 34/35 [00:02<00:00, 15.37it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:02<00:00, 15.22it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests:   0%|          | 1/256 [00:00<00:50,  5.07it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 1052.09it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:01<07:58,  1.88s/it, est. speed input: 8.52 toks/s, output: 136.33 toks/s]
Processed prompts:  59%|█████▉    | 152/256 [00:01<00:00, 106.88it/s, est. speed input: 1226.58 toks/s, output: 19625.24 toks/s]
Processed prompts:  93%|█████████▎| 237/256 [00:02<00:00, 174.32it/s, est. speed input: 1817.90 toks/s, output: 29086.29 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 174.32it/s, est. speed input: 1900.71 toks/s, output: 30411.22 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 118.79it/s, est. speed input: 1900.71 toks/s, output: 30411.22 toks/s]
[rank0]:[W128 14:41:06.695950096 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())


========== M=512 ==========
Time: 2026-01-28 14:41:08
Backend: cuSPARSELt (2:10)
Checkpoint: /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10
Params: prompt_len=16, output_len=256, num_prompts=512, max_num_seqs=512
Command: vllm bench throughput --model /root/vllmbench/checkpoints_slidesparse/BitNet-2B-FP8-SlideSparse-2_10 --dataset-name random --input-len 16 --output-len 256 --num-prompts 512 --max-num-seqs 512 --max-model-len 272 --max-num-batched-tokens 512 --no-enable-chunked-prefill --gpu-memory-utilization 0.8 --disable-log-stats --output-json /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/B200_cc100_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10/json/BitNet-2B-FP8_M512.json

STDOUT:
When dataset path is not set, it will default to random dataset
WARNING 01-28 14:41:14 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=3337552) [INFO] Loading compress extension: cusparselt_compress_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3337552) WARNING 01-28 14:41:30 [backends.py:609] Failed to read file <frozen os>
(EngineCore_DP0 pid=3337552) WARNING 01-28 14:41:40 [flashinfer.py:363] Using TRTLLM prefill attention (auto-detected).
Throughput: 127.62 requests/s, 34711.67 total tokens/s, 32669.81 output tokens/s
Total num prompt tokens:  8192
Total num output tokens:  131072

STDERR:
[2026-01-28 14:41:14] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 14:41:14] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 14:41:14] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 14:41:14] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:41:14] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:41:14] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:41:14] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:41:14] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:41:14] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 14:41:14] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 14:41:14] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 14:41:14] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 14:41:14] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 14:41:14] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-28 14:41:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-28 14:41:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'BitNet-2B-FP8'
[2026-01-28 14:41:21] INFO kernels.py:109: Loaded tuned kernel for model: BitNet-2B-FP8
[2026-01-28 14:41:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:41:21] INFO kernels.py:224: FP8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:41:21] INFO kernels.py:348: INT8 quant kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:41:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:41:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: BitNet-2B-FP8
[2026-01-28 14:41:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'BitNet-2B-FP8'
[2026-01-28 14:41:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-28 14:41:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-28 14:41:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-28 14:41:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-28 14:41:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:22] INFO SlideSparseLinearMethod_FP8.py:734: Wrapping CompressedTensorsW8A8Fp8 with SlideSparse (cuSPARSELt)
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:22] INFO gemm_wrapper.py:870: cusparselt GEMM extension loaded: cusparselt_gemm_B200_cc100_py312_cu129_x86_64.so
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:22] INFO SlideSparseLinearMethod_FP8.py:392: SlideSparseFp8LinearOp initialized (kernel=cuSPARSELt)
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:22] INFO SlideSparseLinearMethod_FP8.py:539: SlideSparseFp8LinearMethod: cuSPARSELt sparsity=2:10, expand_ratio=1.250
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:22] INFO SlideSparseLinearMethod_FP8.py:556: Preloaded FP8 Triton kernels for model: BitNet-2B-FP8
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:22] INFO SlideSparseLinearMethod_FP8.py:560: SlideSparseFp8LinearMethod initialized, kernel=cuSPARSELt
(EngineCore_DP0 pid=3337552) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=3337552) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.51it/s]
(EngineCore_DP0 pid=3337552) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.51it/s]
(EngineCore_DP0 pid=3337552) 
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [3840, 4096] -> 1D uint8
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 9830400 bytes
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 4096] -> 1D uint8
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 6553600 bytes
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [13824, 4096] -> 1D uint8
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 35389440 bytes
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:23] INFO SlideSparseLinearMethod_FP8.py:660: cuSPARSELt compression: [2560, 11072] -> 1D uint8
(EngineCore_DP0 pid=3337552) [2026-01-28 14:41:23] INFO SlideSparseLinearMethod_FP8.py:670: cuSPARSELt compression done: 17735680 bytes
(EngineCore_DP0 pid=3337552) 2026-01-28 14:41:39,980 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=3337552) 2026-01-28 14:41:40,006 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=3337552) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 2/51 [00:00<00:03, 14.19it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   8%|▊         | 4/51 [00:00<00:04, 10.80it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 6/51 [00:00<00:03, 11.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▌        | 8/51 [00:00<00:03, 12.44it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  20%|█▉        | 10/51 [00:00<00:03, 12.57it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▎       | 12/51 [00:00<00:02, 13.09it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 14/51 [00:01<00:02, 13.04it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 16/51 [00:01<00:02, 13.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  35%|███▌      | 18/51 [00:01<00:02, 12.28it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 20/51 [00:01<00:02, 12.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 22/51 [00:01<00:02, 13.03it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  47%|████▋     | 24/51 [00:01<00:01, 13.56it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 26/51 [00:02<00:01, 13.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▍    | 28/51 [00:02<00:01, 14.10it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  59%|█████▉    | 30/51 [00:02<00:01, 14.27it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 32/51 [00:02<00:01, 13.38it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 34/51 [00:02<00:01, 12.52it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  71%|███████   | 36/51 [00:02<00:01, 11.43it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|███████▍  | 38/51 [00:02<00:01, 12.21it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 40/51 [00:03<00:00, 12.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 42/51 [00:03<00:00, 13.29it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  86%|████████▋ | 44/51 [00:03<00:00, 13.68it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|█████████ | 46/51 [00:03<00:00, 13.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 48/51 [00:03<00:00, 14.40it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  98%|█████████▊| 50/51 [00:03<00:00, 14.78it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:03<00:00, 13.07it/s]
(EngineCore_DP0 pid=3337552) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/51 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   4%|▍         | 2/51 [00:00<00:03, 12.81it/s]
Capturing CUDA graphs (decode, FULL):   8%|▊         | 4/51 [00:00<00:03, 14.12it/s]
Capturing CUDA graphs (decode, FULL):  12%|█▏        | 6/51 [00:00<00:02, 15.06it/s]
Capturing CUDA graphs (decode, FULL):  16%|█▌        | 8/51 [00:00<00:02, 15.54it/s]
Capturing CUDA graphs (decode, FULL):  20%|█▉        | 10/51 [00:00<00:02, 15.85it/s]
Capturing CUDA graphs (decode, FULL):  24%|██▎       | 12/51 [00:00<00:02, 16.00it/s]
Capturing CUDA graphs (decode, FULL):  27%|██▋       | 14/51 [00:00<00:02, 15.23it/s]
Capturing CUDA graphs (decode, FULL):  31%|███▏      | 16/51 [00:01<00:02, 15.46it/s]
Capturing CUDA graphs (decode, FULL):  35%|███▌      | 18/51 [00:01<00:02, 14.91it/s]
Capturing CUDA graphs (decode, FULL):  39%|███▉      | 20/51 [00:01<00:02, 14.44it/s]
Capturing CUDA graphs (decode, FULL):  43%|████▎     | 22/51 [00:01<00:01, 14.91it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 24/51 [00:01<00:01, 15.27it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████     | 26/51 [00:01<00:01, 15.35it/s]
Capturing CUDA graphs (decode, FULL):  55%|█████▍    | 28/51 [00:01<00:01, 15.54it/s]
Capturing CUDA graphs (decode, FULL):  59%|█████▉    | 30/51 [00:01<00:01, 15.65it/s]
Capturing CUDA graphs (decode, FULL):  63%|██████▎   | 32/51 [00:02<00:01, 15.78it/s]
Capturing CUDA graphs (decode, FULL):  67%|██████▋   | 34/51 [00:02<00:01, 15.82it/s]
Capturing CUDA graphs (decode, FULL):  71%|███████   | 36/51 [00:02<00:00, 15.89it/s]
Capturing CUDA graphs (decode, FULL):  75%|███████▍  | 38/51 [00:02<00:00, 14.89it/s]
Capturing CUDA graphs (decode, FULL):  78%|███████▊  | 40/51 [00:02<00:00, 14.68it/s]
Capturing CUDA graphs (decode, FULL):  82%|████████▏ | 42/51 [00:02<00:00, 15.09it/s]
Capturing CUDA graphs (decode, FULL):  86%|████████▋ | 44/51 [00:02<00:00, 15.42it/s]
Capturing CUDA graphs (decode, FULL):  90%|█████████ | 46/51 [00:03<00:00, 15.62it/s]
Capturing CUDA graphs (decode, FULL):  94%|█████████▍| 48/51 [00:03<00:00, 15.83it/s]
Capturing CUDA graphs (decode, FULL):  98%|█████████▊| 50/51 [00:03<00:00, 15.96it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 51/51 [00:03<00:00, 15.39it/s]

Adding requests:   0%|          | 0/512 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 512/512 [00:00<00:00, 5438.22it/s]

Processed prompts:   0%|          | 0/512 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/512 [00:02<23:30,  2.76s/it, est. speed input: 5.80 toks/s, output: 92.75 toks/s]
Processed prompts:  40%|████      | 205/512 [00:02<00:03, 100.70it/s, est. speed input: 1146.52 toks/s, output: 18344.34 toks/s]
Processed prompts:  75%|███████▌  | 384/512 [00:02<00:00, 211.11it/s, est. speed input: 2072.50 toks/s, output: 33159.95 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 211.11it/s, est. speed input: 2091.54 toks/s, output: 33464.56 toks/s]
Processed prompts: 100%|██████████| 512/512 [00:03<00:00, 130.72it/s, est. speed input: 2091.54 toks/s, output: 33464.56 toks/s]
[rank0]:[W128 14:41:53.271613074 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

