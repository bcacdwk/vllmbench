A100 SlideSparse Benchmark é‡è¯•æ—¥å¿—
å¼€å§‹æ—¶é—´: 2026-01-26 01:47:16
æ€»æµ‹è¯•æ•°: 5
æœ€å¤§é‡è¯•: 3
GPU ID: 0

======================================================================

======================================================================
Test: qwen2.5-7b-int8 | cublaslt | prefill | M=[65536]
Attempt: 1
Time: 2026-01-26 01:47:16
Duration: 93.5s
Exit Code: 1
Command: python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-7b-int8 --stage prefill --backend cublaslt --M 65536 --gpu-mem 0.8 --gpu-id 0

STDOUT:

[0;36m============================================================[0m
[0;36m  SlideSparse vLLM Throughput Benchmark[0m
[0;36m============================================================[0m


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Hardware Information                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GPU:              NVIDIA A100 80GB PCIe                     â”‚â”‚
â”‚ GPU (short):      A100                                      â”‚
â”‚ Memory:           79.3 GB                                    â”‚
â”‚ CC:               cc80 (Ampere)                              â”‚â”‚
â”‚ SM Code:          sm_80                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CUDA Runtime:     12.9                                      â”‚
â”‚ CUDA Driver:      13.0                                      â”‚
â”‚ Driver:           580.95.05                                 â”‚
â”‚ PyTorch:          2.9.0+cu129                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Triton:           âœ“ supported                               â”‚â”‚
â”‚ FP8 Support:      âœ—                                         â”‚
â”‚ INT8 Support:     âœ“                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æµ‹è¯•é…ç½®:
  æ¨¡å‹:             ['qwen2.5-7b-int8']
  Backends:         ['cublaslt']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU å†…å­˜åˆ©ç”¨ç‡:   0.8

è¾“å‡ºç›®å½•ç»“æ„:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[0;34m[INFO][0m æ—¥å¿—æ–‡ä»¶: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_014721.log


[0;36m============================================================[0m
[0;36m  Qwen2.5-7B-INT8 | cuBLASLt | prefill[0m
[0;36m============================================================[0m

[0;34m[INFO][0m Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-7B-INT8
[0;34m[INFO][0m Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/1] æµ‹è¯• M=65536
============================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æµ‹è¯•å‚æ•°                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ¨¡å‹:     Qwen2.5-7B-INT8                                 â”‚
â”‚ Backend:  cuBLASLt [INT32 output]                         â”‚
â”‚ é˜¶æ®µ:     prefill                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GEMM M ç»´åº¦ (ç²¾ç¡®æ§åˆ¶):
â”‚   ç›®æ ‡ M        = 65536
â”‚   M_prefill     = 65536 (= 64 x 1024)
â”‚   M_decode      = 64
â”‚   batched_tokens = 65536 (æ§åˆ¶ M çš„å…³é”®å‚æ•°)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ vLLM å‚æ•°:
â”‚   --input-len              = 1024
â”‚   --output-len             = 1
â”‚   --num-prompts            = 8192
â”‚   --max-num-seqs           = 64
â”‚   --max-model-len          = 1025
â”‚   --max-num-batched-tokens = 65536
â”‚   --no-enable-chunked-prefill
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¿­ä»£æ¬¡æ•°:
â”‚   N_prefill = 128
â”‚   N_decode  = 0
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[0;34m[INFO][0m å¼€å§‹æµ‹è¯•...

â”€â”€â”€ STDOUT â”€â”€â”€
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:48:21 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
[0;36m(EngineCore_DP0 pid=717483)[0;0m WARNING 01-26 01:48:38 [backends.py:609] Failed to read file <frozen os>
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     super().__init__(
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self.collective_rpc("determine_available_memory")
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     self.model_runner.profile_run()
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                                         ^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     outputs = self.model(
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]               ^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self.runnable(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     hidden_states = self.model(
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                     ^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self._call_with_optional_nvtx_range(
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return callable_fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     def forward(
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self.optimized_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     raise e
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self.runnable(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return range_entry.runnable(*args)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self._compiled_fn(*args)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return compiled_fn(full_args)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     all_outs = call_func_at_runtime_with_args(
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     out = normalize_as_list(f(args))
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                             ^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return compiled_fn(runtime_args)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self.current_callable(inputs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     out = model(new_inputs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]           ^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/tmp/torchinductor_root/5s/c5siom5mqr2n2rj7e6zg7iz275frdy7soybqietmela4oulbf4gi.py", line 1093, in call
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     buf17 = torch.ops.slidesparse.quant_only_int8.default(buf16, 'Qwen2.5-7B-INT8')
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return self._op(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 544, in _quant_only_int8_impl
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return fn(input)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]            ^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/quant_only_triton/build/A100_cc80_py312_cu129_x86_64/quant_only_tuned_Qwen2.5-7B.py", line 212, in quant_only_int8_triton
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     _quant_only_int8_kernel[(M,)](
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     self._init_handles()
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m ERROR 01-26 01:48:45 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered


â”€â”€â”€ STDERR â”€â”€â”€
[2026-01-26 01:48:21] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:48:21] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:48:21] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:21] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:21] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:21] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:21] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:21] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:21] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:48:21] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:48:21] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:48:21] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:48:21] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:48:21] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:48:28] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:48:28] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:48:28] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:28] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:28] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:28] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:28] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:28] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:48:28] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:48:28] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:48:28] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:48:28] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:48:28] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:48:28] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[0;36m(EngineCore_DP0 pid=717483)[0;0m [2026-01-26 01:48:29] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
[0;36m(EngineCore_DP0 pid=717483)[0;0m [2026-01-26 01:48:29] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[0;36m(EngineCore_DP0 pid=717483)[0;0m [2026-01-26 01:48:29] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
[0;36m(EngineCore_DP0 pid=717483)[0;0m [2026-01-26 01:48:29] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
[0;36m(EngineCore_DP0 pid=717483)[0;0m [2026-01-26 01:48:29] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
[0;36m(EngineCore_DP0 pid=717483)[0;0m 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=717483)[0;0m 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.86it/s]
[0;36m(EngineCore_DP0 pid=717483)[0;0m 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.80it/s]
[0;36m(EngineCore_DP0 pid=717483)[0;0m 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.81it/s]
[0;36m(EngineCore_DP0 pid=717483)[0;0m 
[0;36m(EngineCore_DP0 pid=717483)[0;0m [2026-01-26 01:48:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
[0;36m(EngineCore_DP0 pid=717483)[0;0m [2026-01-26 01:48:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
[0;36m(EngineCore_DP0 pid=717483)[0;0m [2026-01-26 01:48:45] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
[0;36m(EngineCore_DP0 pid=717483)[0;0m Process EngineCore_DP0:
[0;36m(EngineCore_DP0 pid=717483)[0;0m Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[0;36m(EngineCore_DP0 pid=717483)[0;0m     self.run()
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[0;36m(EngineCore_DP0 pid=717483)[0;0m     self._target(*self._args, **self._kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
[0;36m(EngineCore_DP0 pid=717483)[0;0m     raise e
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
[0;36m(EngineCore_DP0 pid=717483)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     super().__init__(
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[0;36m(EngineCore_DP0 pid=717483)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
[0;36m(EngineCore_DP0 pid=717483)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[0;36m(EngineCore_DP0 pid=717483)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self.collective_rpc("determine_available_memory")
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[0;36m(EngineCore_DP0 pid=717483)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
[0;36m(EngineCore_DP0 pid=717483)[0;0m     self.model_runner.profile_run()
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
[0;36m(EngineCore_DP0 pid=717483)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[0;36m(EngineCore_DP0 pid=717483)[0;0m                                         ^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
[0;36m(EngineCore_DP0 pid=717483)[0;0m     outputs = self.model(
[0;36m(EngineCore_DP0 pid=717483)[0;0m               ^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self.runnable(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
[0;36m(EngineCore_DP0 pid=717483)[0;0m     hidden_states = self.model(
[0;36m(EngineCore_DP0 pid=717483)[0;0m                     ^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self._call_with_optional_nvtx_range(
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return callable_fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
[0;36m(EngineCore_DP0 pid=717483)[0;0m     def forward(
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self.optimized_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self._wrapped_call(self, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     raise e
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "<eval_with_key>.58", line 325, in forward
[0;36m(EngineCore_DP0 pid=717483)[0;0m     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
[0;36m(EngineCore_DP0 pid=717483)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self.runnable(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return range_entry.runnable(*args)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self._compiled_fn(*args)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return compiled_fn(full_args)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
[0;36m(EngineCore_DP0 pid=717483)[0;0m     all_outs = call_func_at_runtime_with_args(
[0;36m(EngineCore_DP0 pid=717483)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
[0;36m(EngineCore_DP0 pid=717483)[0;0m     out = normalize_as_list(f(args))
[0;36m(EngineCore_DP0 pid=717483)[0;0m                             ^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return compiled_fn(runtime_args)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self.current_callable(inputs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
[0;36m(EngineCore_DP0 pid=717483)[0;0m     out = model(new_inputs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m           ^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/tmp/torchinductor_root/5s/c5siom5mqr2n2rj7e6zg7iz275frdy7soybqietmela4oulbf4gi.py", line 1093, in call
[0;36m(EngineCore_DP0 pid=717483)[0;0m     buf17 = torch.ops.slidesparse.quant_only_int8.default(buf16, 'Qwen2.5-7B-INT8')
[0;36m(EngineCore_DP0 pid=717483)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return self._op(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/slidesparse/core/kernels.py", line 544, in _quant_only_int8_impl
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return fn(input)
[0;36m(EngineCore_DP0 pid=717483)[0;0m            ^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/root/vllmbench/slidesparse/csrc/quant_only_triton/build/A100_cc80_py312_cu129_x86_64/quant_only_tuned_Qwen2.5-7B.py", line 212, in quant_only_int8_triton
[0;36m(EngineCore_DP0 pid=717483)[0;0m     _quant_only_int8_kernel[(M,)](
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
[0;36m(EngineCore_DP0 pid=717483)[0;0m     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=717483)[0;0m                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
[0;36m(EngineCore_DP0 pid=717483)[0;0m     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
[0;36m(EngineCore_DP0 pid=717483)[0;0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
[0;36m(EngineCore_DP0 pid=717483)[0;0m     self._init_handles()
[0;36m(EngineCore_DP0 pid=717483)[0;0m   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
[0;36m(EngineCore_DP0 pid=717483)[0;0m     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
[0;36m(EngineCore_DP0 pid=717483)[0;0m                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=717483)[0;0m RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 01:48:46.091147318 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[0;31m[ERROR][0m æµ‹è¯•å¤±è´¥: M=65536 (exit code: 1)


[0;35m------------------------------------------------------------[0m
[0;35m  ç”Ÿæˆ CSV: Qwen2.5-7B-INT8[0m
[0;35m------------------------------------------------------------[0m
[0;32m[SUCCESS][0m CSV ä¿å­˜åˆ°: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cublaslt/Qwen2.5-7B-INT8_prefill.csv

é¢„è§ˆ:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[0;34m[INFO][0m å®Œæˆ: 0 æˆåŠŸ, 1 å¤±è´¥


[0;36m============================================================[0m
[0;36m  Benchmark å®Œæˆ![0m
[0;36m============================================================[0m


æ€»è®¡: [0;32m0 æˆåŠŸ[0m, [0;31m1 å¤±è´¥[0m
============================================================

[0;34m[INFO][0m æ—¥å¿—å·²ä¿å­˜: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_014721.log


======================================================================
Test: qwen2.5-7b-int8 | cublaslt | prefill | M=[65536]
Attempt: 2
Time: 2026-01-26 01:49:01
Duration: 93.7s
Exit Code: 1
Command: python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-7b-int8 --stage prefill --backend cublaslt --M 65536 --gpu-mem 0.8 --gpu-id 0

STDOUT:

[0;36m============================================================[0m
[0;36m  SlideSparse vLLM Throughput Benchmark[0m
[0;36m============================================================[0m


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Hardware Information                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GPU:              NVIDIA A100 80GB PCIe                     â”‚â”‚
â”‚ GPU (short):      A100                                      â”‚
â”‚ Memory:           79.3 GB                                    â”‚
â”‚ CC:               cc80 (Ampere)                              â”‚â”‚
â”‚ SM Code:          sm_80                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CUDA Runtime:     12.9                                      â”‚
â”‚ CUDA Driver:      13.0                                      â”‚
â”‚ Driver:           580.95.05                                 â”‚
â”‚ PyTorch:          2.9.0+cu129                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Triton:           âœ“ supported                               â”‚â”‚
â”‚ FP8 Support:      âœ—                                         â”‚
â”‚ INT8 Support:     âœ“                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æµ‹è¯•é…ç½®:
  æ¨¡å‹:             ['qwen2.5-7b-int8']
  Backends:         ['cublaslt']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU å†…å­˜åˆ©ç”¨ç‡:   0.8

è¾“å‡ºç›®å½•ç»“æ„:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[0;34m[INFO][0m æ—¥å¿—æ–‡ä»¶: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_014906.log


[0;36m============================================================[0m
[0;36m  Qwen2.5-7B-INT8 | cuBLASLt | prefill[0m
[0;36m============================================================[0m

[0;34m[INFO][0m Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-7B-INT8
[0;34m[INFO][0m Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/1] æµ‹è¯• M=65536
============================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æµ‹è¯•å‚æ•°                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ¨¡å‹:     Qwen2.5-7B-INT8                                 â”‚
â”‚ Backend:  cuBLASLt [INT32 output]                         â”‚
â”‚ é˜¶æ®µ:     prefill                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ GEMM M ç»´åº¦ (ç²¾ç¡®æ§åˆ¶):
â”‚   ç›®æ ‡ M        = 65536
â”‚   M_prefill     = 65536 (= 64 x 1024)
â”‚   M_decode      = 64
â”‚   batched_tokens = 65536 (æ§åˆ¶ M çš„å…³é”®å‚æ•°)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ vLLM å‚æ•°:
â”‚   --input-len              = 1024
â”‚   --output-len             = 1
â”‚   --num-prompts            = 8192
â”‚   --max-num-seqs           = 64
â”‚   --max-model-len          = 1025
â”‚   --max-num-batched-tokens = 65536
â”‚   --no-enable-chunked-prefill
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¿­ä»£æ¬¡æ•°:
â”‚   N_prefill = 128
â”‚   N_decode  = 0
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[0;34m[INFO][0m å¼€å§‹æµ‹è¯•...

â”€â”€â”€ STDOUT â”€â”€â”€
When dataset path is not set, it will default to random dataset
WARNING 01-26 01:50:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
[0;36m(EngineCore_DP0 pid=719312)[0;0m WARNING 01-26 01:50:23 [backends.py:609] Failed to read file <frozen os>
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866] EngineCore failed to start.
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866] Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     super().__init__(
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     available_gpu_memory = self.model_executor.determine_available_memory()
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self.collective_rpc("determine_available_memory")
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     result = run_method(self.driver_worker, method, args, kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     self.model_runner.profile_run()
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     hidden_states, last_hidden_states = self._dummy_run(
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                                         ^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     outputs = self.model(
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]               ^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self.runnable(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     hidden_states = self.model(
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                     ^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self._call_with_optional_nvtx_range(
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return callable_fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     def forward(
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self.optimized_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self._wrapped_call(self, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     raise e
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "<eval_with_key>.58", line 325, in forward
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self.runnable(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return range_entry.runnable(*args)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self._compiled_fn(*args)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return compiled_fn(full_args)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     all_outs = call_func_at_runtime_with_args(
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     out = normalize_as_list(f(args))
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                             ^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return compiled_fn(runtime_args)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self.current_callable(inputs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     out = model(new_inputs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]           ^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/tmp/torchinductor_root/5s/c5siom5mqr2n2rj7e6zg7iz275frdy7soybqietmela4oulbf4gi.py", line 1093, in call
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     buf17 = torch.ops.slidesparse.quant_only_int8.default(buf16, 'Qwen2.5-7B-INT8')
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return self._op(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/slidesparse/core/kernels.py", line 544, in _quant_only_int8_impl
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return fn(input)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]            ^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/root/vllmbench/slidesparse/csrc/quant_only_triton/build/A100_cc80_py312_cu129_x86_64/quant_only_tuned_Qwen2.5-7B.py", line 212, in quant_only_int8_triton
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     _quant_only_int8_kernel[(M,)](
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     self._init_handles()
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866]                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m ERROR 01-26 01:50:31 [core.py:866] RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered


â”€â”€â”€ STDERR â”€â”€â”€
[2026-01-26 01:50:06] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:50:06] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:50:06] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:06] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:06] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:06] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:06] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:06] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:06] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:50:06] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:50:06] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:50:06] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:50:06] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:50:06] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 01:50:13] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 01:50:13] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:50:13] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:13] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:13] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:13] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:13] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:13] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B-INT8
[2026-01-26 01:50:13] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Qwen2.5-7B-INT8'
[2026-01-26 01:50:13] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 01:50:13] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 01:50:13] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 01:50:13] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 01:50:13] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[0;36m(EngineCore_DP0 pid=719312)[0;0m [2026-01-26 01:50:14] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
[0;36m(EngineCore_DP0 pid=719312)[0;0m [2026-01-26 01:50:14] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_A100_cc80_py312_cu129_x86_64.so
[0;36m(EngineCore_DP0 pid=719312)[0;0m [2026-01-26 01:50:14] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
[0;36m(EngineCore_DP0 pid=719312)[0;0m [2026-01-26 01:50:14] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Qwen2.5-7B-INT8
[0;36m(EngineCore_DP0 pid=719312)[0;0m [2026-01-26 01:50:14] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
[0;36m(EngineCore_DP0 pid=719312)[0;0m 
Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[0;36m(EngineCore_DP0 pid=719312)[0;0m 
Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.84it/s]
[0;36m(EngineCore_DP0 pid=719312)[0;0m 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.79it/s]
[0;36m(EngineCore_DP0 pid=719312)[0;0m 
Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.80it/s]
[0;36m(EngineCore_DP0 pid=719312)[0;0m 
[0;36m(EngineCore_DP0 pid=719312)[0;0m [2026-01-26 01:50:30] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=4608, K=3584), falling back to default heuristic
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
[0;36m(EngineCore_DP0 pid=719312)[0;0m [2026-01-26 01:50:30] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=3584, K=3584), falling back to default heuristic
[0;36m(EngineCore_DP0 pid=719312)[0;0m [2026-01-26 01:50:30] WARNING gemm_wrapper.py:352: cuBLASLt: M=65536 exceeds max searched M=32768 for (N=37888, K=3584), falling back to default heuristic
[0;36m(EngineCore_DP0 pid=719312)[0;0m Process EngineCore_DP0:
[0;36m(EngineCore_DP0 pid=719312)[0;0m Traceback (most recent call last):
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[0;36m(EngineCore_DP0 pid=719312)[0;0m     self.run()
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
[0;36m(EngineCore_DP0 pid=719312)[0;0m     self._target(*self._args, **self._kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/engine/core.py", line 870, in run_engine_core
[0;36m(EngineCore_DP0 pid=719312)[0;0m     raise e
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
[0;36m(EngineCore_DP0 pid=719312)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     super().__init__(
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/engine/core.py", line 109, in __init__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     num_gpu_blocks, num_cpu_blocks, kv_cache_config = self._initialize_kv_caches(
[0;36m(EngineCore_DP0 pid=719312)[0;0m                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/engine/core.py", line 240, in _initialize_kv_caches
[0;36m(EngineCore_DP0 pid=719312)[0;0m     available_gpu_memory = self.model_executor.determine_available_memory()
[0;36m(EngineCore_DP0 pid=719312)[0;0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/executor/abstract.py", line 126, in determine_available_memory
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self.collective_rpc("determine_available_memory")
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/executor/uniproc_executor.py", line 75, in collective_rpc
[0;36m(EngineCore_DP0 pid=719312)[0;0m     result = run_method(self.driver_worker, method, args, kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/serial_utils.py", line 461, in run_method
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/worker/gpu_worker.py", line 340, in determine_available_memory
[0;36m(EngineCore_DP0 pid=719312)[0;0m     self.model_runner.profile_run()
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4474, in profile_run
[0;36m(EngineCore_DP0 pid=719312)[0;0m     hidden_states, last_hidden_states = self._dummy_run(
[0;36m(EngineCore_DP0 pid=719312)[0;0m                                         ^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return func(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/v1/worker/gpu_model_runner.py", line 4198, in _dummy_run
[0;36m(EngineCore_DP0 pid=719312)[0;0m     outputs = self.model(
[0;36m(EngineCore_DP0 pid=719312)[0;0m               ^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self.runnable(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 583, in forward
[0;36m(EngineCore_DP0 pid=719312)[0;0m     hidden_states = self.model(
[0;36m(EngineCore_DP0 pid=719312)[0;0m                     ^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/compilation/decorators.py", line 526, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     output = TorchCompileWithNoGuardsWrapper.__call__(self, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/compilation/wrapper.py", line 218, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self._call_with_optional_nvtx_range(
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/compilation/wrapper.py", line 109, in _call_with_optional_nvtx_range
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return callable_fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 832, in compile_wrapper
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/model_executor/models/qwen2.py", line 418, in forward
[0;36m(EngineCore_DP0 pid=719312)[0;0m     def forward(
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/compilation/caching.py", line 54, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self.optimized_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 837, in call_wrapped
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self._wrapped_call(self, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 413, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     raise e
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py", line 400, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return super(self.cls, obj).__call__(*args, **kwargs)  # type: ignore[misc]
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self._call_impl(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1786, in _call_impl
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return forward_call(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "<eval_with_key>.58", line 325, in forward
[0;36m(EngineCore_DP0 pid=719312)[0;0m     submod_2 = self.submod_2(getitem_3, s72, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_, getitem_4, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_, l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_, l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_, l_positions_, l_self_modules_layers_modules_0_modules_self_attn_modules_rotary_emb_buffers_cos_sin_cache_);  getitem_3 = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_self_attn_modules_o_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_post_attention_layernorm_parameters_weight_ = getitem_4 = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_gate_up_proj_parameters_weight_scale_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_ = l_self_modules_layers_modules_0_modules_mlp_modules_down_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_input_layernorm_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_weight_scale_ = l_self_modules_layers_modules_1_modules_self_attn_modules_qkv_proj_parameters_bias_ = None
[0;36m(EngineCore_DP0 pid=719312)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/compilation/cuda_graph.py", line 220, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self.runnable(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/vllm/compilation/piecewise_backend.py", line 178, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return range_entry.runnable(*args)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/standalone_compile.py", line 63, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self._compiled_fn(*args)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py", line 1044, in _fn
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return fn(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/aot_autograd.py", line 1130, in forward
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return compiled_fn(full_args)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 353, in runtime_wrapper
[0;36m(EngineCore_DP0 pid=719312)[0;0m     all_outs = call_func_at_runtime_with_args(
[0;36m(EngineCore_DP0 pid=719312)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/utils.py", line 129, in call_func_at_runtime_with_args
[0;36m(EngineCore_DP0 pid=719312)[0;0m     out = normalize_as_list(f(args))
[0;36m(EngineCore_DP0 pid=719312)[0;0m                             ^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 526, in wrapper
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return compiled_fn(runtime_args)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/output_code.py", line 613, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self.current_callable(inputs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_inductor/utils.py", line 2962, in run
[0;36m(EngineCore_DP0 pid=719312)[0;0m     out = model(new_inputs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m           ^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/tmp/torchinductor_root/5s/c5siom5mqr2n2rj7e6zg7iz275frdy7soybqietmela4oulbf4gi.py", line 1093, in call
[0;36m(EngineCore_DP0 pid=719312)[0;0m     buf17 = torch.ops.slidesparse.quant_only_int8.default(buf16, 'Qwen2.5-7B-INT8')
[0;36m(EngineCore_DP0 pid=719312)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/torch/_ops.py", line 841, in __call__
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return self._op(*args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/slidesparse/core/kernels.py", line 544, in _quant_only_int8_impl
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return fn(input)
[0;36m(EngineCore_DP0 pid=719312)[0;0m            ^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/root/vllmbench/slidesparse/csrc/quant_only_triton/build/A100_cc80_py312_cu129_x86_64/quant_only_tuned_Qwen2.5-7B.py", line 212, in quant_only_int8_triton
[0;36m(EngineCore_DP0 pid=719312)[0;0m     _quant_only_int8_kernel[(M,)](
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 419, in <lambda>
[0;36m(EngineCore_DP0 pid=719312)[0;0m     return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
[0;36m(EngineCore_DP0 pid=719312)[0;0m                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/triton/runtime/jit.py", line 756, in run
[0;36m(EngineCore_DP0 pid=719312)[0;0m     launch_metadata = kernel.launch_metadata(grid, stream, *bound_args.values())
[0;36m(EngineCore_DP0 pid=719312)[0;0m                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 490, in launch_metadata
[0;36m(EngineCore_DP0 pid=719312)[0;0m     self._init_handles()
[0;36m(EngineCore_DP0 pid=719312)[0;0m   File "/usr/local/lib/python3.12/dist-packages/triton/compiler/compiler.py", line 473, in _init_handles
[0;36m(EngineCore_DP0 pid=719312)[0;0m     self.module, self.function, self.n_regs, self.n_spills, self.n_max_threads = driver.active.utils.load_binary(
[0;36m(EngineCore_DP0 pid=719312)[0;0m                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[0;36m(EngineCore_DP0 pid=719312)[0;0m RuntimeError: Triton Error [CUDA]: an illegal memory access was encountered
[rank0]:[W126 01:50:31.310335100 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/usr/local/bin/vllm", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/vllmbench/vllm/entrypoints/cli/main.py", line 73, in main
    args.dispatch_function(args)
  File "/root/vllmbench/vllm/entrypoints/cli/benchmark/throughput.py", line 21, in cmd
    main(args)
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 730, in main
    elapsed_time, request_outputs = run_vllm(
                                    ^^^^^^^^^
  File "/root/vllmbench/vllm/benchmarks/throughput.py", line 51, in run_vllm
    llm = LLM(**dataclasses.asdict(engine_args))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/entrypoints/llm.py", line 351, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 183, in from_engine_args
    return cls(
           ^^^^
  File "/root/vllmbench/vllm/v1/engine/llm_engine.py", line 109, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 93, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 648, in __init__
    super().__init__(
  File "/root/vllmbench/vllm/v1/engine/core_client.py", line 477, in __init__
    with launch_core_engines(vllm_config, executor_class, log_stats) as (
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 903, in launch_core_engines
    wait_for_engine_startup(
  File "/root/vllmbench/vllm/v1/engine/utils.py", line 960, in wait_for_engine_startup
    raise RuntimeError(
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}

[0;31m[ERROR][0m æµ‹è¯•å¤±è´¥: M=65536 (exit code: 1)


[0;35m------------------------------------------------------------[0m
[0;35m  ç”Ÿæˆ CSV: Qwen2.5-7B-INT8[0m
[0;35m------------------------------------------------------------[0m
[0;32m[SUCCESS][0m CSV ä¿å­˜åˆ°: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/A100_cc80_INT8_py312_cu129_x86_64/cublaslt/Qwen2.5-7B-INT8_prefill.csv

é¢„è§ˆ:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
65536,1024,64,8192,128,-1.0000,-1.0000,-1.0000

------------------------------------------------------------

[0;34m[INFO][0m å®Œæˆ: 0 æˆåŠŸ, 1 å¤±è´¥


[0;36m============================================================[0m
[0;36m  Benchmark å®Œæˆ![0m
[0;36m============================================================[0m


æ€»è®¡: [0;32m0 æˆåŠŸ[0m, [0;31m1 å¤±è´¥[0m
============================================================

[0;34m[INFO][0m æ—¥å¿—å·²ä¿å­˜: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_014906.log

