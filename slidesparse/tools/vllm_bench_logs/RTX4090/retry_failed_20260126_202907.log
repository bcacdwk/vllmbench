======================================================================
SlideSparse Retry Failed Tests Log
Started: 2026-01-26 20:29:07
======================================================================

Total tests to retry: 40
Max retries per test: 2
Initial util: 0.95, Max util: 0.98
GPU Memory: 24.6 GB

Model sizes (实测):
  qwen2.5-14b-int8 (dense): 16 GB
  qwen2.5-14b-fp8 (dense): 16 GB
  qwen2.5-14b-int8 (2_4): 16 GB
  qwen2.5-14b-int8 (2_6): 20 GB
  qwen2.5-14b-int8 (2_8): 22 GB
  qwen2.5-14b-int8 (2_10): 23 GB
  qwen2.5-14b-fp8 (2_4): 16 GB
  qwen2.5-14b-fp8 (2_6): 20 GB
  qwen2.5-14b-fp8 (2_8): 22 GB
  qwen2.5-14b-fp8 (2_10): 23 GB

[20:29:07] 日志文件: /root/vllmbench/slidesparse/tools/retry_failed_20260126_202907.log
[20:29:07] 状态文件: /root/vllmbench/slidesparse/tools/retry_failed_20260126_202907_status.json
[20:29:07] 
[20:29:07] [1/40] 开始测试...
[20:29:07] 
[20:29:07] ======================================================================
[20:29:07] 测试: qwen2.5-14b-int8 | cublaslt | prefill | M=32768
[20:29:07] 模型大小: 16 GB, 初始利用率: 0.95
[20:29:07] ======================================================================
[20:29:07] 
--- 尝试 1/2 (util=0.95) ---
[20:29:07]   清理 GPU 环境...
[20:29:20]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cublaslt --stage prefill --M 32768 --gpu-mem 0.95

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cublaslt']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_202927.log


============================================================
  Qwen2.5-14B-INT8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:30:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:30:06 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1035191) ERROR 01-26 20:30:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1035191) ERROR 01-26 20:30:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1035191) ERROR 01-26 20:30:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1035191) ERROR 01-26 20:30:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1035191) ERROR 01-26 20:30:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1035191) ERROR 01-26 20:30:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1035191) ERROR 01-26 20:30:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1035191) ERROR 01-26 20:30:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1035191) ERROR 01-26 20:30:15 [core.py:866]     self.model_executor = executor_cl
[20:30:22]   ✗ 失败: EngineCore failed, 耗时: 62.5s
[20:30:22]   提高利用率至 0.98，最后尝试
[20:30:22] 
--- 尝试 2/2 (util=0.98) ---
[20:30:22]   清理 GPU 环境...
[20:30:34]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cublaslt --stage prefill --M 32768 --gpu-mem 0.98

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cublaslt']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_203039.log


============================================================
  Qwen2.5-14B-INT8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:31:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:31:17 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1036700) ERROR 01-26 20:31:27 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1036700) ERROR 01-26 20:31:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1036700) ERROR 01-26 20:31:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1036700) ERROR 01-26 20:31:27 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1036700) ERROR 01-26 20:31:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1036700) ERROR 01-26 20:31:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1036700) ERROR 01-26 20:31:27 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1036700) ERROR 01-26 20:31:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1036700) ERROR 01-26 20:31:27 [core.py:866]     self.model_executor = executor_cl
[20:31:33]   ✗ 失败: EngineCore failed, 耗时: 59.4s
[20:31:33]   已达最大利用率，放弃
[20:31:33]   最终失败: qwen2.5-14b-int8 | cublaslt | prefill | M=32768
[20:31:33] 当前进度: 0 成功, 1 失败, 39 剩余
[20:31:33] 
[20:31:33] [2/40] 开始测试...
[20:31:33] 
[20:31:33] ======================================================================
[20:31:33] 测试: qwen2.5-14b-int8 | cublaslt | prefill | M=65536
[20:31:33] 模型大小: 16 GB, 初始利用率: 0.95
[20:31:33] ======================================================================
[20:31:33] 
--- 尝试 1/2 (util=0.95) ---
[20:31:33]   清理 GPU 环境...
[20:31:44]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cublaslt --stage prefill --M 65536 --gpu-mem 0.95

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cublaslt']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_203151.log


============================================================
  Qwen2.5-14B-INT8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:32:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:32:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1038381) ERROR 01-26 20:33:07 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1038381) ERROR 01-26 20:33:07 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1038381) ERROR 01-26 20:33:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1038381) ERROR 01-26 20:33:07 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1038381) ERROR 01-26 20:33:07 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1038381) ERROR 01-26 20:33:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1038381) ERROR 01-26 20:33:07 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1038381) ERROR 01-26 20:33:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1038381) ERROR 01-26 20:33:07 [core.py:866]     self.model_executor = executor_cl
[20:33:11]   ✗ 失败: EngineCore failed, 耗时: 87.0s
[20:33:11]   提高利用率至 0.98，最后尝试
[20:33:11] 
--- 尝试 2/2 (util=0.98) ---
[20:33:11]   清理 GPU 环境...
[20:33:24]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cublaslt --stage prefill --M 65536 --gpu-mem 0.98

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cublaslt']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_203330.log


============================================================
  Qwen2.5-14B-INT8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:34:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:34:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1040157) ERROR 01-26 20:34:44 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1040157) ERROR 01-26 20:34:44 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1040157) ERROR 01-26 20:34:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1040157) ERROR 01-26 20:34:44 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1040157) ERROR 01-26 20:34:44 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1040157) ERROR 01-26 20:34:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1040157) ERROR 01-26 20:34:44 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1040157) ERROR 01-26 20:34:44 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1040157) ERROR 01-26 20:34:44 [core.py:866]     self.model_executor = executor_cl
[20:34:52]   ✗ 失败: EngineCore failed, 耗时: 88.0s
[20:34:52]   已达最大利用率，放弃
[20:34:52]   最终失败: qwen2.5-14b-int8 | cublaslt | prefill | M=65536
[20:34:52] 当前进度: 0 成功, 2 失败, 38 剩余
[20:34:52] 
[20:34:52] [3/40] 开始测试...
[20:34:52] 
[20:34:52] ======================================================================
[20:34:52] 测试: qwen2.5-14b-int8 | cusparselt (2_4) | prefill | M=65536
[20:34:52] 模型大小: 16 GB, 初始利用率: 0.95
[20:34:52] ======================================================================
[20:34:52] 
--- 尝试 1/2 (util=0.95) ---
[20:34:52]   清理 GPU 环境...
[20:35:03]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.95 --sparsity 2_4

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_4']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_203509.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_4) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:36:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:36:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1041858) ERROR 01-26 20:36:24 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1041858) ERROR 01-26 20:36:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1041858) ERROR 01-26 20:36:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1041858) ERROR 01-26 20:36:24 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1041858) ERROR 01-26 20:36:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1041858) ERROR 01-26 20:36:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1041858) ERROR 01-26 20:36:24 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1041858) ERROR 01-26 20:36:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1041858) 
[20:36:30]   ✗ 失败: EngineCore failed, 耗时: 86.3s
[20:36:30]   提高利用率至 0.98，最后尝试
[20:36:30] 
--- 尝试 2/2 (util=0.98) ---
[20:36:30]   清理 GPU 环境...
[20:36:42]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.98 --sparsity 2_4

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_4']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_203648.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_4) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:37:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:37:54 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1043426) ERROR 01-26 20:38:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1043426) ERROR 01-26 20:38:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1043426) ERROR 01-26 20:38:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1043426) ERROR 01-26 20:38:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1043426) ERROR 01-26 20:38:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1043426) ERROR 01-26 20:38:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1043426) ERROR 01-26 20:38:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1043426) ERROR 01-26 20:38:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1043426) 
[20:38:09]   ✗ 失败: EngineCore failed, 耗时: 86.9s
[20:38:09]   已达最大利用率，放弃
[20:38:09]   最终失败: qwen2.5-14b-int8 | cusparselt (2_4) | prefill | M=65536
[20:38:09] 当前进度: 0 成功, 3 失败, 37 剩余
[20:38:09] 
[20:38:09] [4/40] 开始测试...
[20:38:09] 
[20:38:09] ======================================================================
[20:38:09] 测试: qwen2.5-14b-int8 | cusparselt (2_6) | prefill | M=32768
[20:38:09] 模型大小: 20 GB, 初始利用率: 0.95
[20:38:09] ======================================================================
[20:38:09] 
--- 尝试 1/2 (util=0.95) ---
[20:38:09]   清理 GPU 环境...
[20:38:21]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.95 --sparsity 2_6

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_6']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_203826.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:39:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:39:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1044592) ERROR 01-26 20:39:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1044592) ERROR 01-26 20:39:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1044592) ERROR 01-26 20:39:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1044592) ERROR 01-26 20:39:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1044592) ERROR 01-26 20:39:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1044592) ERROR 01-26 20:39:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1044592) ERROR 01-26 20:39:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1044592) ERROR 01-26 20:39:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1044592) 
[20:39:22]   ✗ 失败: EngineCore failed, 耗时: 60.1s
[20:39:22]   提高利用率至 0.98，最后尝试
[20:39:22] 
--- 尝试 2/2 (util=0.98) ---
[20:39:22]   清理 GPU 环境...
[20:39:32]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.98 --sparsity 2_6

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_6']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_203939.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:40:16 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:40:17 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1045804) ERROR 01-26 20:40:26 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1045804) ERROR 01-26 20:40:26 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1045804) ERROR 01-26 20:40:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1045804) ERROR 01-26 20:40:26 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1045804) ERROR 01-26 20:40:26 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1045804) ERROR 01-26 20:40:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1045804) ERROR 01-26 20:40:26 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1045804) ERROR 01-26 20:40:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1045804) 
[20:40:32]   ✗ 失败: EngineCore failed, 耗时: 60.1s
[20:40:32]   已达最大利用率，放弃
[20:40:32]   最终失败: qwen2.5-14b-int8 | cusparselt (2_6) | prefill | M=32768
[20:40:32] 当前进度: 0 成功, 4 失败, 36 剩余
[20:40:32] 
[20:40:32] [5/40] 开始测试...
[20:40:32] 
[20:40:32] ======================================================================
[20:40:32] 测试: qwen2.5-14b-int8 | cusparselt (2_6) | prefill | M=65536
[20:40:32] 模型大小: 20 GB, 初始利用率: 0.95
[20:40:32] ======================================================================
[20:40:32] 
--- 尝试 1/2 (util=0.95) ---
[20:40:32]   清理 GPU 环境...
[20:40:45]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.95 --sparsity 2_6

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_6']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_204051.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:41:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:41:58 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1047374) ERROR 01-26 20:42:06 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1047374) ERROR 01-26 20:42:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1047374) ERROR 01-26 20:42:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1047374) ERROR 01-26 20:42:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1047374) ERROR 01-26 20:42:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1047374) ERROR 01-26 20:42:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1047374) ERROR 01-26 20:42:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1047374) ERROR 01-26 20:42:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1047374) 
[20:42:12]   ✗ 失败: EngineCore failed, 耗时: 86.8s
[20:42:12]   提高利用率至 0.98，最后尝试
[20:42:12] 
--- 尝试 2/2 (util=0.98) ---
[20:42:12]   清理 GPU 环境...
[20:42:24]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.98 --sparsity 2_6

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_6']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_204229.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:43:35 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:43:36 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1048925) ERROR 01-26 20:43:45 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1048925) ERROR 01-26 20:43:45 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1048925) ERROR 01-26 20:43:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1048925) ERROR 01-26 20:43:45 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1048925) ERROR 01-26 20:43:45 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1048925) ERROR 01-26 20:43:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1048925) ERROR 01-26 20:43:45 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1048925) ERROR 01-26 20:43:45 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1048925) 
[20:43:51]   ✗ 失败: EngineCore failed, 耗时: 87.5s
[20:43:51]   已达最大利用率，放弃
[20:43:51]   最终失败: qwen2.5-14b-int8 | cusparselt (2_6) | prefill | M=65536
[20:43:51] 当前进度: 0 成功, 5 失败, 35 剩余
[20:43:51] 
[20:43:51] [6/40] 开始测试...
[20:43:51] 
[20:43:51] ======================================================================
[20:43:51] 测试: qwen2.5-14b-int8 | cusparselt (2_8) | prefill | M=16384
[20:43:51] 模型大小: 22 GB, 初始利用率: 0.95
[20:43:51] ======================================================================
[20:43:51] 
--- 尝试 1/2 (util=0.95) ---
[20:43:51]   清理 GPU 环境...
[20:44:02]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 16384 --gpu-mem 0.95 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [16384]
  M_decode:         [16384]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_204408.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:44:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:44:33 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1049897) ERROR 01-26 20:44:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1049897) ERROR 01-26 20:44:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1049897) ERROR 01-26 20:44:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1049897) ERROR 01-26 20:44:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1049897) ERROR 01-26 20:44:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1049897) ERROR 01-26 20:44:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1049897) ERROR 01-26 20:44:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1049897) ERROR 01-26 20:44:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1049897) 
[20:44:48]   ✗ 失败: EngineCore failed, 耗时: 46.3s
[20:44:48]   提高利用率至 0.98，最后尝试
[20:44:48] 
--- 尝试 2/2 (util=0.98) ---
[20:44:48]   清理 GPU 环境...
[20:45:00]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 16384 --gpu-mem 0.98 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [16384]
  M_decode:         [16384]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_204505.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:45:28 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:45:29 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1050887) ERROR 01-26 20:45:38 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1050887) ERROR 01-26 20:45:38 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1050887) ERROR 01-26 20:45:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1050887) ERROR 01-26 20:45:38 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1050887) ERROR 01-26 20:45:38 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1050887) ERROR 01-26 20:45:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1050887) ERROR 01-26 20:45:38 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1050887) ERROR 01-26 20:45:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1050887) 
[20:45:45]   ✗ 失败: EngineCore failed, 耗时: 44.3s
[20:45:45]   已达最大利用率，放弃
[20:45:45]   最终失败: qwen2.5-14b-int8 | cusparselt (2_8) | prefill | M=16384
[20:45:45] 当前进度: 0 成功, 6 失败, 34 剩余
[20:45:45] 
[20:45:45] [7/40] 开始测试...
[20:45:45] 
[20:45:45] ======================================================================
[20:45:45] 测试: qwen2.5-14b-int8 | cusparselt (2_8) | prefill | M=32768
[20:45:45] 模型大小: 22 GB, 初始利用率: 0.95
[20:45:45] ======================================================================
[20:45:45] 
--- 尝试 1/2 (util=0.95) ---
[20:45:45]   清理 GPU 环境...
[20:45:57]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.95 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_204603.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:46:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:46:40 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1052074) ERROR 01-26 20:46:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1052074) ERROR 01-26 20:46:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1052074) ERROR 01-26 20:46:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1052074) ERROR 01-26 20:46:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1052074) ERROR 01-26 20:46:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1052074) ERROR 01-26 20:46:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1052074) ERROR 01-26 20:46:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1052074) ERROR 01-26 20:46:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1052074) 
[20:46:57]   ✗ 失败: EngineCore failed, 耗时: 60.3s
[20:46:57]   提高利用率至 0.98，最后尝试
[20:46:57] 
--- 尝试 2/2 (util=0.98) ---
[20:46:57]   清理 GPU 环境...
[20:47:08]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.98 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_204714.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:47:51 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:47:52 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1053284) ERROR 01-26 20:48:04 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1053284) ERROR 01-26 20:48:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1053284) ERROR 01-26 20:48:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1053284) ERROR 01-26 20:48:04 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1053284) ERROR 01-26 20:48:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1053284) ERROR 01-26 20:48:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1053284) ERROR 01-26 20:48:04 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1053284) ERROR 01-26 20:48:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1053284) 
[20:48:10]   ✗ 失败: EngineCore failed, 耗时: 61.3s
[20:48:10]   已达最大利用率，放弃
[20:48:10]   最终失败: qwen2.5-14b-int8 | cusparselt (2_8) | prefill | M=32768
[20:48:10] 当前进度: 0 成功, 7 失败, 33 剩余
[20:48:10] 
[20:48:10] [8/40] 开始测试...
[20:48:10] 
[20:48:10] ======================================================================
[20:48:10] 测试: qwen2.5-14b-int8 | cusparselt (2_8) | prefill | M=65536
[20:48:10] 模型大小: 22 GB, 初始利用率: 0.95
[20:48:10] ======================================================================
[20:48:10] 
--- 尝试 1/2 (util=0.95) ---
[20:48:10]   清理 GPU 环境...
[20:48:21]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.95 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_204827.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:49:33 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:49:34 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1054879) ERROR 01-26 20:49:43 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1054879) ERROR 01-26 20:49:43 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1054879) ERROR 01-26 20:49:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1054879) ERROR 01-26 20:49:43 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1054879) ERROR 01-26 20:49:43 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1054879) ERROR 01-26 20:49:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1054879) ERROR 01-26 20:49:43 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1054879) ERROR 01-26 20:49:43 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1054879) 
[20:49:47]   ✗ 失败: EngineCore failed, 耗时: 86.5s
[20:49:47]   提高利用率至 0.98，最后尝试
[20:49:47] 
--- 尝试 2/2 (util=0.98) ---
[20:49:47]   清理 GPU 环境...
[20:50:00]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.98 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205007.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:51:12 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:51:13 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1056420) ERROR 01-26 20:51:21 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1056420) ERROR 01-26 20:51:21 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1056420) ERROR 01-26 20:51:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1056420) ERROR 01-26 20:51:21 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1056420) ERROR 01-26 20:51:21 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1056420) ERROR 01-26 20:51:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1056420) ERROR 01-26 20:51:21 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1056420) ERROR 01-26 20:51:21 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1056420) 
[20:51:27]   ✗ 失败: EngineCore failed, 耗时: 86.6s
[20:51:27]   已达最大利用率，放弃
[20:51:27]   最终失败: qwen2.5-14b-int8 | cusparselt (2_8) | prefill | M=65536
[20:51:27] 当前进度: 0 成功, 8 失败, 32 剩余
[20:51:27] 
[20:51:27] [9/40] 开始测试...
[20:51:27] 
[20:51:27] ======================================================================
[20:51:27] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=512
[20:51:27] 模型大小: 23 GB, 初始利用率: 0.95
[20:51:27] ======================================================================
[20:51:27] 
--- 尝试 1/2 (util=0.95) ---
[20:51:27]   清理 GPU 环境...
[20:51:39]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 512 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205145.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:51:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:51:54 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1057214) ERROR 01-26 20:52:03 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1057214) ERROR 01-26 20:52:03 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1057214) ERROR 01-26 20:52:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1057214) ERROR 01-26 20:52:03 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1057214) ERROR 01-26 20:52:03 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1057214) ERROR 01-26 20:52:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1057214) ERROR 01-26 20:52:03 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1057214) ERROR 01-26 20:52:03 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1057214) ERROR 01-26 20:52
[20:52:09]   ✗ 失败: EngineCore failed, 耗时: 30.2s
[20:52:09]   提高利用率至 0.98，最后尝试
[20:52:09] 
--- 尝试 2/2 (util=0.98) ---
[20:52:09]   清理 GPU 环境...
[20:52:20]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 512 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205226.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:52:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:52:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1058019) ERROR 01-26 20:52:46 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1058019) ERROR 01-26 20:52:46 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1058019) ERROR 01-26 20:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1058019) ERROR 01-26 20:52:46 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1058019) ERROR 01-26 20:52:46 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1058019) ERROR 01-26 20:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1058019) ERROR 01-26 20:52:46 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1058019) ERROR 01-26 20:52:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1058019) ERROR 01-26 20:52
[20:52:50]   ✗ 失败: EngineCore failed, 耗时: 30.1s
[20:52:50]   已达最大利用率，放弃
[20:52:50]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=512
[20:52:50] 当前进度: 0 成功, 9 失败, 31 剩余
[20:52:50] 
[20:52:50] [10/40] 开始测试...
[20:52:50] 
[20:52:50] ======================================================================
[20:52:50] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=1024
[20:52:50] 模型大小: 23 GB, 初始利用率: 0.95
[20:52:50] ======================================================================
[20:52:50] 
--- 尝试 1/2 (util=0.95) ---
[20:52:50]   清理 GPU 环境...
[20:53:03]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 1024 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [1024]
  M_decode:         [1024]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205309.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:53:19 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:53:20 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1058809) ERROR 01-26 20:53:29 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1058809) ERROR 01-26 20:53:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1058809) ERROR 01-26 20:53:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1058809) ERROR 01-26 20:53:29 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1058809) ERROR 01-26 20:53:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1058809) ERROR 01-26 20:53:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1058809) ERROR 01-26 20:53:29 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1058809) ERROR 01-26 20:53:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1058809) ERROR 0
[20:53:35]   ✗ 失败: EngineCore failed, 耗时: 31.5s
[20:53:35]   提高利用率至 0.98，最后尝试
[20:53:35] 
--- 尝试 2/2 (util=0.98) ---
[20:53:35]   清理 GPU 环境...
[20:53:47]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 1024 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [1024]
  M_decode:         [1024]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205353.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:54:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:54:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1059642) ERROR 01-26 20:54:13 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1059642) ERROR 01-26 20:54:13 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1059642) ERROR 01-26 20:54:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1059642) ERROR 01-26 20:54:13 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1059642) ERROR 01-26 20:54:13 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1059642) ERROR 01-26 20:54:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1059642) ERROR 01-26 20:54:13 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1059642) ERROR 01-26 20:54:13 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1059642) ERROR 0
[20:54:18]   ✗ 失败: EngineCore failed, 耗时: 31.3s
[20:54:18]   已达最大利用率，放弃
[20:54:18]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=1024
[20:54:18] 当前进度: 0 成功, 10 失败, 30 剩余
[20:54:18] 
[20:54:18] [11/40] 开始测试...
[20:54:18] 
[20:54:18] ======================================================================
[20:54:18] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=2048
[20:54:18] 模型大小: 23 GB, 初始利用率: 0.95
[20:54:18] ======================================================================
[20:54:18] 
--- 尝试 1/2 (util=0.95) ---
[20:54:18]   清理 GPU 环境...
[20:54:29]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 2048 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [2048]
  M_decode:         [2048]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205436.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:54:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:54:47 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1060429) ERROR 01-26 20:54:56 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1060429) ERROR 01-26 20:54:56 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1060429) ERROR 01-26 20:54:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1060429) ERROR 01-26 20:54:56 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1060429) ERROR 01-26 20:54:56 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1060429) ERROR 01-26 20:54:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1060429) ERROR 01-26 20:54:56 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1060429) ERROR 01-26 20:54:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1060429) ERROR 0
[20:55:03]   ✗ 失败: EngineCore failed, 耗时: 33.3s
[20:55:03]   提高利用率至 0.98，最后尝试
[20:55:03] 
--- 尝试 2/2 (util=0.98) ---
[20:55:03]   清理 GPU 环境...
[20:55:15]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 2048 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [2048]
  M_decode:         [2048]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205522.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:55:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:55:31 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1061275) ERROR 01-26 20:55:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1061275) ERROR 01-26 20:55:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1061275) ERROR 01-26 20:55:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1061275) ERROR 01-26 20:55:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1061275) ERROR 01-26 20:55:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1061275) ERROR 01-26 20:55:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1061275) ERROR 01-26 20:55:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1061275) ERROR 01-26 20:55:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1061275) ERROR 0
[20:55:48]   ✗ 失败: EngineCore failed, 耗时: 33.3s
[20:55:48]   已达最大利用率，放弃
[20:55:48]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=2048
[20:55:48] 当前进度: 0 成功, 11 失败, 29 剩余
[20:55:48] 
[20:55:48] [12/40] 开始测试...
[20:55:48] 
[20:55:48] ======================================================================
[20:55:48] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=4096
[20:55:48] 模型大小: 23 GB, 初始利用率: 0.95
[20:55:48] ======================================================================
[20:55:48] 
--- 尝试 1/2 (util=0.95) ---
[20:55:48]   清理 GPU 环境...
[20:55:59]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 4096 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [4096]
  M_decode:         [4096]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205606.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:56:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:56:19 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1062121) ERROR 01-26 20:56:26 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1062121) ERROR 01-26 20:56:26 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1062121) ERROR 01-26 20:56:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1062121) ERROR 01-26 20:56:26 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1062121) ERROR 01-26 20:56:26 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1062121) ERROR 01-26 20:56:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1062121) ERROR 01-26 20:56:26 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1062121) ERROR 01-26 20:56:26 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1062121) ERROR 0
[20:56:34]   ✗ 失败: EngineCore failed, 耗时: 34.5s
[20:56:34]   提高利用率至 0.98，最后尝试
[20:56:34] 
--- 尝试 2/2 (util=0.98) ---
[20:56:34]   清理 GPU 环境...
[20:56:45]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 4096 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [4096]
  M_decode:         [4096]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205651.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:57:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:57:03 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1062958) ERROR 01-26 20:57:12 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1062958) ERROR 01-26 20:57:12 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1062958) ERROR 01-26 20:57:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1062958) ERROR 01-26 20:57:12 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1062958) ERROR 01-26 20:57:12 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1062958) ERROR 01-26 20:57:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1062958) ERROR 01-26 20:57:12 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1062958) ERROR 01-26 20:57:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1062958) ERROR 0
[20:57:18]   ✗ 失败: EngineCore failed, 耗时: 32.8s
[20:57:18]   已达最大利用率，放弃
[20:57:18]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=4096
[20:57:18] 当前进度: 0 成功, 12 失败, 28 剩余
[20:57:18] 
[20:57:18] [13/40] 开始测试...
[20:57:18] 
[20:57:18] ======================================================================
[20:57:18] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=8192
[20:57:18] 模型大小: 23 GB, 初始利用率: 0.95
[20:57:18] ======================================================================
[20:57:18] 
--- 尝试 1/2 (util=0.95) ---
[20:57:18]   清理 GPU 环境...
[20:57:29]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 8192 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [8192]
  M_decode:         [8192]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205735.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:57:52 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:57:53 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1063828) ERROR 01-26 20:58:02 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1063828) ERROR 01-26 20:58:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1063828) ERROR 01-26 20:58:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1063828) ERROR 01-26 20:58:02 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1063828) ERROR 01-26 20:58:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1063828) ERROR 01-26 20:58:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1063828) ERROR 01-26 20:58:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1063828) ERROR 01-26 20:58:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1063828) ERROR 
[20:58:09]   ✗ 失败: EngineCore failed, 耗时: 39.7s
[20:58:09]   提高利用率至 0.98，最后尝试
[20:58:09] 
--- 尝试 2/2 (util=0.98) ---
[20:58:09]   清理 GPU 环境...
[20:58:21]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 8192 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [8192]
  M_decode:         [8192]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205827.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:58:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:58:43 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1064750) ERROR 01-26 20:58:55 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1064750) ERROR 01-26 20:58:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1064750) ERROR 01-26 20:58:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1064750) ERROR 01-26 20:58:55 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1064750) ERROR 01-26 20:58:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1064750) ERROR 01-26 20:58:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1064750) ERROR 01-26 20:58:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1064750) ERROR 01-26 20:58:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1064750) ERROR 
[20:59:01]   ✗ 失败: EngineCore failed, 耗时: 39.7s
[20:59:01]   已达最大利用率，放弃
[20:59:01]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=8192
[20:59:01] 当前进度: 0 成功, 13 失败, 27 剩余
[20:59:01] 
[20:59:01] [14/40] 开始测试...
[20:59:01] 
[20:59:01] ======================================================================
[20:59:01] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=16384
[20:59:01] 模型大小: 23 GB, 初始利用率: 0.95
[20:59:01] ======================================================================
[20:59:01] 
--- 尝试 1/2 (util=0.95) ---
[20:59:01]   清理 GPU 环境...
[20:59:12]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 16384 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [16384]
  M_decode:         [16384]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_205918.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 20:59:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 20:59:41 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1065748) ERROR 01-26 20:59:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1065748) ERROR 01-26 20:59:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1065748) ERROR 01-26 20:59:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1065748) ERROR 01-26 20:59:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1065748) ERROR 01-26 20:59:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1065748) ERROR 01-26 20:59:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1065748) ERROR 01-26 20:59:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1065748) ERROR 01-26 20:59:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1065748)[0
[20:59:57]   ✗ 失败: EngineCore failed, 耗时: 45.3s
[20:59:57]   提高利用率至 0.98，最后尝试
[20:59:57] 
--- 尝试 2/2 (util=0.98) ---
[20:59:57]   清理 GPU 环境...
[21:00:08]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 16384 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [16384]
  M_decode:         [16384]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_210015.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:00:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:00:39 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1066742) ERROR 01-26 21:00:48 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1066742) ERROR 01-26 21:00:48 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1066742) ERROR 01-26 21:00:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1066742) ERROR 01-26 21:00:48 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1066742) ERROR 01-26 21:00:48 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1066742) ERROR 01-26 21:00:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1066742) ERROR 01-26 21:00:48 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1066742) ERROR 01-26 21:00:48 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1066742)[0
[21:00:54]   ✗ 失败: EngineCore failed, 耗时: 46.5s
[21:00:54]   已达最大利用率，放弃
[21:00:54]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=16384
[21:00:54] 当前进度: 0 成功, 14 失败, 26 剩余
[21:00:54] 
[21:00:54] [15/40] 开始测试...
[21:00:54] 
[21:00:54] ======================================================================
[21:00:54] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=32768
[21:00:54] 模型大小: 23 GB, 初始利用率: 0.95
[21:00:54] ======================================================================
[21:00:54] 
--- 尝试 1/2 (util=0.95) ---
[21:00:54]   清理 GPU 环境...
[21:01:05]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_210112.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:01:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:01:50 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1067907) ERROR 01-26 21:02:01 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1067907) ERROR 01-26 21:02:01 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1067907) ERROR 01-26 21:02:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1067907) ERROR 01-26 21:02:01 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1067907) ERROR 01-26 21:02:01 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1067907) ERROR 01-26 21:02:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1067907) ERROR 01-26 21:02:01 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1067907) ERROR 01-26 21:02:01 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1067907)[0
[21:02:07]   ✗ 失败: EngineCore failed, 耗时: 61.9s
[21:02:07]   提高利用率至 0.98，最后尝试
[21:02:07] 
--- 尝试 2/2 (util=0.98) ---
[21:02:07]   清理 GPU 环境...
[21:02:18]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_210225.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:03:02 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:03:03 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1069116) ERROR 01-26 21:03:12 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1069116) ERROR 01-26 21:03:12 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1069116) ERROR 01-26 21:03:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1069116) ERROR 01-26 21:03:12 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1069116) ERROR 01-26 21:03:12 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1069116) ERROR 01-26 21:03:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1069116) ERROR 01-26 21:03:12 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1069116) ERROR 01-26 21:03:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1069116)[0
[21:03:18]   ✗ 失败: EngineCore failed, 耗时: 60.1s
[21:03:18]   已达最大利用率，放弃
[21:03:18]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=32768
[21:03:18] 当前进度: 0 成功, 15 失败, 25 剩余
[21:03:18] 
[21:03:18] [16/40] 开始测试...
[21:03:18] 
[21:03:18] ======================================================================
[21:03:18] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=65536
[21:03:18] 模型大小: 23 GB, 初始利用率: 0.95
[21:03:18] ======================================================================
[21:03:18] 
--- 尝试 1/2 (util=0.95) ---
[21:03:18]   清理 GPU 环境...
[21:03:31]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_210337.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:04:42 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:04:42 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1070713) ERROR 01-26 21:04:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1070713) ERROR 01-26 21:04:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1070713) ERROR 01-26 21:04:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1070713) ERROR 01-26 21:04:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1070713) ERROR 01-26 21:04:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1070713) ERROR 01-26 21:04:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1070713) ERROR 01-26 21:04:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1070713) ERROR 01-26 21:04:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1070713)[0
[21:04:58]   ✗ 失败: EngineCore failed, 耗时: 87.6s
[21:04:58]   提高利用率至 0.98，最后尝试
[21:04:58] 
--- 尝试 2/2 (util=0.98) ---
[21:04:58]   清理 GPU 环境...
[21:05:11]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_210517.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:06:23 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:06:24 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1072295) ERROR 01-26 21:06:33 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1072295) ERROR 01-26 21:06:33 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1072295) ERROR 01-26 21:06:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1072295) ERROR 01-26 21:06:33 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1072295) ERROR 01-26 21:06:33 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1072295) ERROR 01-26 21:06:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1072295) ERROR 01-26 21:06:33 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1072295) ERROR 01-26 21:06:33 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1072295)[0
[21:06:39]   ✗ 失败: EngineCore failed, 耗时: 88.7s
[21:06:39]   已达最大利用率，放弃
[21:06:39]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | prefill | M=65536
[21:06:39] 当前进度: 0 成功, 16 失败, 24 剩余
[21:06:39] 
[21:06:39] [17/40] 开始测试...
[21:06:39] 
[21:06:39] ======================================================================
[21:06:39] 测试: qwen2.5-14b-fp8 | cublaslt | prefill | M=32768
[21:06:39] 模型大小: 16 GB, 初始利用率: 0.95
[21:06:39] ======================================================================
[21:06:39] 
--- 尝试 1/2 (util=0.95) ---
[21:06:39]   清理 GPU 环境...
[21:06:51]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cublaslt --stage prefill --M 32768 --gpu-mem 0.95

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cublaslt']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_210658.log


============================================================
  Qwen2.5-14B-FP8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cublaslt

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:07:34 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:07:35 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1073486) ERROR 01-26 21:07:46 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1073486) ERROR 01-26 21:07:46 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1073486) ERROR 01-26 21:07:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1073486) ERROR 01-26 21:07:46 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1073486) ERROR 01-26 21:07:46 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1073486) ERROR 01-26 21:07:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1073486) ERROR 01-26 21:07:46 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1073486) ERROR 01-26 21:07:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1073486) ERROR 01-26 21:07:46 [core.py:866]     self.model_executor = executor_cl
[21:07:50]   ✗ 失败: EngineCore failed, 耗时: 59.6s
[21:07:50]   提高利用率至 0.98，最后尝试
[21:07:50] 
--- 尝试 2/2 (util=0.98) ---
[21:07:50]   清理 GPU 环境...
[21:08:03]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cublaslt --stage prefill --M 32768 --gpu-mem 0.98

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cublaslt']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_210810.log


============================================================
  Qwen2.5-14B-FP8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cublaslt

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:08:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:08:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1074679) ERROR 01-26 21:08:57 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1074679) ERROR 01-26 21:08:57 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1074679) ERROR 01-26 21:08:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1074679) ERROR 01-26 21:08:57 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1074679) ERROR 01-26 21:08:57 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1074679) ERROR 01-26 21:08:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1074679) ERROR 01-26 21:08:57 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1074679) ERROR 01-26 21:08:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1074679) ERROR 01-26 21:08:57 [core.py:866]     self.model_executor = executor_cl
[21:09:03]   ✗ 失败: EngineCore failed, 耗时: 60.1s
[21:09:03]   已达最大利用率，放弃
[21:09:03]   最终失败: qwen2.5-14b-fp8 | cublaslt | prefill | M=32768
[21:09:03] 当前进度: 0 成功, 17 失败, 23 剩余
[21:09:03] 
[21:09:03] [18/40] 开始测试...
[21:09:03] 
[21:09:03] ======================================================================
[21:09:03] 测试: qwen2.5-14b-fp8 | cublaslt | prefill | M=65536
[21:09:03] 模型大小: 16 GB, 初始利用率: 0.95
[21:09:03] ======================================================================
[21:09:03] 
--- 尝试 1/2 (util=0.95) ---
[21:09:03]   清理 GPU 环境...
[21:09:15]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cublaslt --stage prefill --M 65536 --gpu-mem 0.95

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cublaslt']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_210920.log


============================================================
  Qwen2.5-14B-FP8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cublaslt

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:10:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:10:27 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1076248) ERROR 01-26 21:10:36 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1076248) ERROR 01-26 21:10:36 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1076248) ERROR 01-26 21:10:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1076248) ERROR 01-26 21:10:36 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1076248) ERROR 01-26 21:10:36 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1076248) ERROR 01-26 21:10:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1076248) ERROR 01-26 21:10:36 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1076248) ERROR 01-26 21:10:36 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1076248) ERROR 01-26 21:10:36 [core.py:866]     self.model_executor = executor_cl
[21:10:42]   ✗ 失败: EngineCore failed, 耗时: 86.9s
[21:10:42]   提高利用率至 0.98，最后尝试
[21:10:42] 
--- 尝试 2/2 (util=0.98) ---
[21:10:42]   清理 GPU 环境...
[21:10:54]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cublaslt --stage prefill --M 65536 --gpu-mem 0.98

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cublaslt']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_211101.log


============================================================
  Qwen2.5-14B-FP8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Qwen2.5-14B-FP8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cublaslt

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuBLASLt                                        │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:12:07 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:12:08 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1077819) ERROR 01-26 21:12:19 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1077819) ERROR 01-26 21:12:19 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1077819) ERROR 01-26 21:12:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1077819) ERROR 01-26 21:12:19 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1077819) ERROR 01-26 21:12:19 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1077819) ERROR 01-26 21:12:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1077819) ERROR 01-26 21:12:19 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1077819) ERROR 01-26 21:12:19 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1077819) ERROR 01-26 21:12:19 [core.py:866]     self.model_executor = executor_cl
[21:12:25]   ✗ 失败: EngineCore failed, 耗时: 91.3s
[21:12:25]   已达最大利用率，放弃
[21:12:25]   最终失败: qwen2.5-14b-fp8 | cublaslt | prefill | M=65536
[21:12:25] 当前进度: 0 成功, 18 失败, 22 剩余
[21:12:25] 
[21:12:25] [19/40] 开始测试...
[21:12:25] 
[21:12:25] ======================================================================
[21:12:25] 测试: qwen2.5-14b-fp8 | cusparselt (2_4) | prefill | M=65536
[21:12:25] 模型大小: 16 GB, 初始利用率: 0.95
[21:12:25] ======================================================================
[21:12:25] 
--- 尝试 1/2 (util=0.95) ---
[21:12:25]   清理 GPU 环境...
[21:12:36]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.95 --sparsity 2_4

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_4']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_211243.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_4) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:13:49 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:13:50 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1079465) ERROR 01-26 21:13:59 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1079465) ERROR 01-26 21:13:59 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1079465) ERROR 01-26 21:13:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1079465) ERROR 01-26 21:13:59 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1079465) ERROR 01-26 21:13:59 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1079465) ERROR 01-26 21:13:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1079465) ERROR 01-26 21:13:59 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1079465) ERROR 01-26 21:13:59 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1079465) 
[21:14:06]   ✗ 失败: EngineCore failed, 耗时: 89.9s
[21:14:06]   提高利用率至 0.98，最后尝试
[21:14:06] 
--- 尝试 2/2 (util=0.98) ---
[21:14:06]   清理 GPU 环境...
[21:14:18]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.98 --sparsity 2_4

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_4']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_211425.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_4) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_4

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:4)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:15:32 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:15:33 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1081070) ERROR 01-26 21:15:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1081070) ERROR 01-26 21:15:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1081070) ERROR 01-26 21:15:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1081070) ERROR 01-26 21:15:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1081070) ERROR 01-26 21:15:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1081070) ERROR 01-26 21:15:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1081070) ERROR 01-26 21:15:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1081070) ERROR 01-26 21:15:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1081070) 
[21:15:48]   ✗ 失败: EngineCore failed, 耗时: 89.6s
[21:15:48]   已达最大利用率，放弃
[21:15:48]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_4) | prefill | M=65536
[21:15:48] 当前进度: 0 成功, 19 失败, 21 剩余
[21:15:48] 
[21:15:48] [20/40] 开始测试...
[21:15:48] 
[21:15:48] ======================================================================
[21:15:48] 测试: qwen2.5-14b-fp8 | cusparselt (2_6) | prefill | M=32768
[21:15:48] 模型大小: 20 GB, 初始利用率: 0.95
[21:15:48] ======================================================================
[21:15:48] 
--- 尝试 1/2 (util=0.95) ---
[21:15:48]   清理 GPU 环境...
[21:16:00]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.95 --sparsity 2_6

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_6']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_211607.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:16:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:16:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1082354) ERROR 01-26 21:16:55 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1082354) 
[21:17:02]   ✗ 失败: EngineCore failed, 耗时: 61.4s
[21:17:02]   提高利用率至 0.98，最后尝试
[21:17:02] 
--- 尝试 2/2 (util=0.98) ---
[21:17:02]   清理 GPU 环境...
[21:17:12]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.98 --sparsity 2_6

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_6']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_211719.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:17:56 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:17:57 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1083574) ERROR 01-26 21:18:07 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1083574) 
[21:18:11]   ✗ 失败: EngineCore failed, 耗时: 59.3s
[21:18:11]   已达最大利用率，放弃
[21:18:11]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_6) | prefill | M=32768
[21:18:12] 当前进度: 0 成功, 20 失败, 20 剩余
[21:18:12] 
[21:18:12] [21/40] 开始测试...
[21:18:12] 
[21:18:12] ======================================================================
[21:18:12] 测试: qwen2.5-14b-fp8 | cusparselt (2_6) | prefill | M=65536
[21:18:12] 模型大小: 20 GB, 初始利用率: 0.95
[21:18:12] ======================================================================
[21:18:12] 
--- 尝试 1/2 (util=0.95) ---
[21:18:12]   清理 GPU 环境...
[21:18:24]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.95 --sparsity 2_6

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_6']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_211831.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:19:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:19:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1085131) ERROR 01-26 21:19:46 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1085131) 
[21:19:52]   ✗ 失败: EngineCore failed, 耗时: 88.5s
[21:19:52]   提高利用率至 0.98，最后尝试
[21:19:52] 
--- 尝试 2/2 (util=0.98) ---
[21:19:52]   清理 GPU 环境...
[21:20:05]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.98 --sparsity 2_6

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_6']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_212011.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_6) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_6

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:6)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:21:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:21:18 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1086729) ERROR 01-26 21:21:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1086729) 
[21:21:33]   ✗ 失败: EngineCore failed, 耗时: 88.1s
[21:21:33]   已达最大利用率，放弃
[21:21:33]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_6) | prefill | M=65536
[21:21:33] 当前进度: 0 成功, 21 失败, 19 剩余
[21:21:33] 
[21:21:33] [22/40] 开始测试...
[21:21:33] 
[21:21:33] ======================================================================
[21:21:33] 测试: qwen2.5-14b-fp8 | cusparselt (2_8) | prefill | M=16384
[21:21:33] 模型大小: 22 GB, 初始利用率: 0.95
[21:21:33] ======================================================================
[21:21:33] 
--- 尝试 1/2 (util=0.95) ---
[21:21:33]   清理 GPU 环境...
[21:21:44]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 16384 --gpu-mem 0.95 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [16384]
  M_decode:         [16384]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_212152.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:22:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:22:15 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1087740) ERROR 01-26 21:22:25 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1087740) ERROR 01-26 21:22:25 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1087740) ERROR 01-26 21:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1087740) ERROR 01-26 21:22:25 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1087740) ERROR 01-26 21:22:25 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1087740) ERROR 01-26 21:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1087740) ERROR 01-26 21:22:25 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1087740) ERROR 01-26 21:22:25 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1087740) 
[21:22:32]   ✗ 失败: EngineCore failed, 耗时: 47.4s
[21:22:32]   提高利用率至 0.98，最后尝试
[21:22:32] 
--- 尝试 2/2 (util=0.98) ---
[21:22:32]   清理 GPU 环境...
[21:22:44]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 16384 --gpu-mem 0.98 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [16384]
  M_decode:         [16384]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_212251.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:23:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:23:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1088766) ERROR 01-26 21:23:24 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1088766) ERROR 01-26 21:23:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1088766) ERROR 01-26 21:23:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1088766) ERROR 01-26 21:23:24 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1088766) ERROR 01-26 21:23:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1088766) ERROR 01-26 21:23:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1088766) ERROR 01-26 21:23:24 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1088766) ERROR 01-26 21:23:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1088766) 
[21:23:30]   ✗ 失败: EngineCore failed, 耗时: 45.6s
[21:23:30]   已达最大利用率，放弃
[21:23:30]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_8) | prefill | M=16384
[21:23:30] 当前进度: 0 成功, 22 失败, 18 剩余
[21:23:30] 
[21:23:30] [23/40] 开始测试...
[21:23:30] 
[21:23:30] ======================================================================
[21:23:30] 测试: qwen2.5-14b-fp8 | cusparselt (2_8) | prefill | M=32768
[21:23:30] 模型大小: 22 GB, 初始利用率: 0.95
[21:23:30] ======================================================================
[21:23:30] 
--- 尝试 1/2 (util=0.95) ---
[21:23:30]   清理 GPU 环境...
[21:23:42]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.95 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_212348.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:24:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:24:26 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1089937) ERROR 01-26 21:24:37 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1089937) ERROR 01-26 21:24:37 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1089937) ERROR 01-26 21:24:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1089937) ERROR 01-26 21:24:37 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1089937) ERROR 01-26 21:24:37 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1089937) ERROR 01-26 21:24:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1089937) ERROR 01-26 21:24:37 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1089937) ERROR 01-26 21:24:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1089937) 
[21:24:43]   ✗ 失败: EngineCore failed, 耗时: 60.7s
[21:24:43]   提高利用率至 0.98，最后尝试
[21:24:43] 
--- 尝试 2/2 (util=0.98) ---
[21:24:43]   清理 GPU 环境...
[21:24:53]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.98 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_212501.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:25:38 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:25:40 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1091170) ERROR 01-26 21:25:49 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1091170) ERROR 01-26 21:25:49 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1091170) ERROR 01-26 21:25:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1091170) ERROR 01-26 21:25:49 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1091170) ERROR 01-26 21:25:49 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1091170) ERROR 01-26 21:25:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1091170) ERROR 01-26 21:25:49 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1091170) ERROR 01-26 21:25:49 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1091170) 
[21:25:53]   ✗ 失败: EngineCore failed, 耗时: 60.0s
[21:25:53]   已达最大利用率，放弃
[21:25:53]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_8) | prefill | M=32768
[21:25:53] 当前进度: 0 成功, 23 失败, 17 剩余
[21:25:53] 
[21:25:53] [24/40] 开始测试...
[21:25:53] 
[21:25:53] ======================================================================
[21:25:53] 测试: qwen2.5-14b-fp8 | cusparselt (2_8) | prefill | M=65536
[21:25:53] 模型大小: 22 GB, 初始利用率: 0.95
[21:25:53] ======================================================================
[21:25:53] 
--- 尝试 1/2 (util=0.95) ---
[21:25:53]   清理 GPU 环境...
[21:26:05]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.95 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_212613.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:27:20 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:27:21 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1092781) ERROR 01-26 21:27:32 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1092781) ERROR 01-26 21:27:32 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1092781) ERROR 01-26 21:27:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1092781) ERROR 01-26 21:27:32 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1092781) ERROR 01-26 21:27:32 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1092781) ERROR 01-26 21:27:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1092781) ERROR 01-26 21:27:32 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1092781) ERROR 01-26 21:27:32 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1092781) 
[21:27:38]   ✗ 失败: EngineCore failed, 耗时: 92.7s
[21:27:38]   提高利用率至 0.98，最后尝试
[21:27:38] 
--- 尝试 2/2 (util=0.98) ---
[21:27:38]   清理 GPU 环境...
[21:27:51]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.98 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_212758.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:29:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:29:04 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1094410) ERROR 01-26 21:29:15 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1094410) ERROR 01-26 21:29:15 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1094410) ERROR 01-26 21:29:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1094410) ERROR 01-26 21:29:15 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1094410) ERROR 01-26 21:29:15 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1094410) ERROR 01-26 21:29:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1094410) ERROR 01-26 21:29:15 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1094410) ERROR 01-26 21:29:15 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1094410) 
[21:29:22]   ✗ 失败: EngineCore failed, 耗时: 91.0s
[21:29:22]   已达最大利用率，放弃
[21:29:22]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_8) | prefill | M=65536
[21:29:22] 当前进度: 0 成功, 24 失败, 16 剩余
[21:29:22] 
[21:29:22] [25/40] 开始测试...
[21:29:22] 
[21:29:22] ======================================================================
[21:29:22] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=512
[21:29:22] 模型大小: 23 GB, 初始利用率: 0.95
[21:29:22] ======================================================================
[21:29:22] 
--- 尝试 1/2 (util=0.95) ---
[21:29:22]   清理 GPU 环境...
[21:29:32]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 512 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_212939.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:29:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:29:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1095226) ERROR 01-26 21:30:04 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1095226) ERROR 01-26 21:30:04 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1095226) ERROR 01-26 21:30:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1095226) ERROR 01-26 21:30:04 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1095226) ERROR 01-26 21:30:04 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1095226) ERROR 01-26 21:30:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1095226) ERROR 01-26 21:30:04 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1095226) ERROR 01-26 21:30:04 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1095226) ERROR 01-26 21:30
[21:30:15]   ✗ 失败: EngineCore failed, 耗时: 43.0s
[21:30:15]   提高利用率至 0.98，最后尝试
[21:30:15] 
--- 尝试 2/2 (util=0.98) ---
[21:30:15]   清理 GPU 环境...
[21:30:28]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 512 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213039.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 512 (= 1 x 512)
│   M_decode      = 1
│   batched_tokens = 513 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 512
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 513
│   --max-num-batched-tokens = 513
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:30:48 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:30:49 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1096218) ERROR 01-26 21:31:02 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1096218) ERROR 01-26 21:31:02 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1096218) ERROR 01-26 21:31:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1096218) ERROR 01-26 21:31:02 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1096218) ERROR 01-26 21:31:02 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1096218) ERROR 01-26 21:31:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1096218) ERROR 01-26 21:31:02 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1096218) ERROR 01-26 21:31:02 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1096218) ERROR 01-26 21:31
[21:31:09]   ✗ 失败: EngineCore failed, 耗时: 40.4s
[21:31:09]   已达最大利用率，放弃
[21:31:09]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=512
[21:31:09] 当前进度: 0 成功, 25 失败, 15 剩余
[21:31:09] 
[21:31:09] [26/40] 开始测试...
[21:31:09] 
[21:31:09] ======================================================================
[21:31:09] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=1024
[21:31:09] 模型大小: 23 GB, 初始利用率: 0.95
[21:31:09] ======================================================================
[21:31:09] 
--- 尝试 1/2 (util=0.95) ---
[21:31:09]   清理 GPU 环境...
[21:31:21]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 1024 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [1024]
  M_decode:         [1024]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213129.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:31:39 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:31:40 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1097113) ERROR 01-26 21:31:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1097113) ERROR 01-26 21:31:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1097113) ERROR 01-26 21:31:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1097113) ERROR 01-26 21:31:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1097113) ERROR 01-26 21:31:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1097113) ERROR 01-26 21:31:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1097113) ERROR 01-26 21:31:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1097113) ERROR 01-26 21:31:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1097113) ERROR 0
[21:31:57]   ✗ 失败: EngineCore failed, 耗时: 35.5s
[21:31:57]   提高利用率至 0.98，最后尝试
[21:31:57] 
--- 尝试 2/2 (util=0.98) ---
[21:31:57]   清理 GPU 环境...
[21:32:08]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 1024 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [1024]
  M_decode:         [1024]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213216.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=1024
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 1024
│   M_prefill     = 1024 (= 1 x 1024)
│   M_decode      = 1
│   batched_tokens = 1025 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 1025
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:32:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:32:27 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1097950) ERROR 01-26 21:32:37 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1097950) ERROR 01-26 21:32:37 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1097950) ERROR 01-26 21:32:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1097950) ERROR 01-26 21:32:37 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1097950) ERROR 01-26 21:32:37 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1097950) ERROR 01-26 21:32:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1097950) ERROR 01-26 21:32:37 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1097950) ERROR 01-26 21:32:37 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1097950) ERROR 0
[21:32:44]   ✗ 失败: EngineCore failed, 耗时: 35.6s
[21:32:44]   已达最大利用率，放弃
[21:32:44]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=1024
[21:32:44] 当前进度: 0 成功, 26 失败, 14 剩余
[21:32:44] 
[21:32:44] [27/40] 开始测试...
[21:32:44] 
[21:32:44] ======================================================================
[21:32:44] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=2048
[21:32:44] 模型大小: 23 GB, 初始利用率: 0.95
[21:32:44] ======================================================================
[21:32:44] 
--- 尝试 1/2 (util=0.95) ---
[21:32:44]   清理 GPU 环境...
[21:32:57]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 2048 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [2048]
  M_decode:         [2048]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213306.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:33:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:33:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1098822) ERROR 01-26 21:33:27 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1098822) ERROR 01-26 21:33:27 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1098822) ERROR 01-26 21:33:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1098822) ERROR 01-26 21:33:27 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1098822) ERROR 01-26 21:33:27 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1098822) ERROR 01-26 21:33:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1098822) ERROR 01-26 21:33:27 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1098822) ERROR 01-26 21:33:27 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1098822) ERROR 0
[21:33:33]   ✗ 失败: EngineCore failed, 耗时: 36.7s
[21:33:33]   提高利用率至 0.98，最后尝试
[21:33:33] 
--- 尝试 2/2 (util=0.98) ---
[21:33:33]   清理 GPU 环境...
[21:33:45]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 2048 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [2048]
  M_decode:         [2048]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213353.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=2048
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 2048
│   M_prefill     = 2048 (= 2 x 1024)
│   M_decode      = 2
│   batched_tokens = 2048 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 256
│   --max-num-seqs           = 2
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 2048
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:34:04 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:34:05 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1099707) ERROR 01-26 21:34:14 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1099707) ERROR 01-26 21:34:14 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1099707) ERROR 01-26 21:34:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1099707) ERROR 01-26 21:34:14 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1099707) ERROR 01-26 21:34:14 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1099707) ERROR 01-26 21:34:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1099707) ERROR 01-26 21:34:14 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1099707) ERROR 01-26 21:34:14 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1099707) ERROR 0
[21:34:21]   ✗ 失败: EngineCore failed, 耗时: 35.9s
[21:34:21]   已达最大利用率，放弃
[21:34:21]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=2048
[21:34:21] 当前进度: 0 成功, 27 失败, 13 剩余
[21:34:21] 
[21:34:21] [28/40] 开始测试...
[21:34:21] 
[21:34:21] ======================================================================
[21:34:21] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=4096
[21:34:21] 模型大小: 23 GB, 初始利用率: 0.95
[21:34:21] ======================================================================
[21:34:21] 
--- 尝试 1/2 (util=0.95) ---
[21:34:21]   清理 GPU 环境...
[21:34:34]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 4096 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [4096]
  M_decode:         [4096]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213440.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:34:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:34:54 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1100601) ERROR 01-26 21:35:05 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1100601) ERROR 01-26 21:35:05 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1100601) ERROR 01-26 21:35:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1100601) ERROR 01-26 21:35:05 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1100601) ERROR 01-26 21:35:05 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1100601) ERROR 01-26 21:35:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1100601) ERROR 01-26 21:35:05 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1100601) ERROR 01-26 21:35:05 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1100601) ERROR 0
[21:35:10]   ✗ 失败: EngineCore failed, 耗时: 36.7s
[21:35:10]   提高利用率至 0.98，最后尝试
[21:35:10] 
--- 尝试 2/2 (util=0.98) ---
[21:35:10]   清理 GPU 环境...
[21:35:22]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 4096 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [4096]
  M_decode:         [4096]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213529.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=4096
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 4096
│   M_prefill     = 4096 (= 4 x 1024)
│   M_decode      = 4
│   batched_tokens = 4096 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 512
│   --max-num-seqs           = 4
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 4096
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:35:40 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:35:41 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1101481) ERROR 01-26 21:35:52 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1101481) ERROR 01-26 21:35:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1101481) ERROR 01-26 21:35:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1101481) ERROR 01-26 21:35:52 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1101481) ERROR 01-26 21:35:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1101481) ERROR 01-26 21:35:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1101481) ERROR 01-26 21:35:52 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1101481) ERROR 01-26 21:35:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1101481) ERROR 0
[21:35:59]   ✗ 失败: EngineCore failed, 耗时: 37.2s
[21:35:59]   已达最大利用率，放弃
[21:35:59]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=4096
[21:35:59] 当前进度: 0 成功, 28 失败, 12 剩余
[21:35:59] 
[21:35:59] [29/40] 开始测试...
[21:35:59] 
[21:35:59] ======================================================================
[21:35:59] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=8192
[21:35:59] 模型大小: 23 GB, 初始利用率: 0.95
[21:35:59] ======================================================================
[21:35:59] 
--- 尝试 1/2 (util=0.95) ---
[21:35:59]   清理 GPU 环境...
[21:36:12]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 8192 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [8192]
  M_decode:         [8192]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213620.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:36:36 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:36:37 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1102411) ERROR 01-26 21:36:47 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1102411) ERROR 01-26 21:36:47 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1102411) ERROR 01-26 21:36:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1102411) ERROR 01-26 21:36:47 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1102411) ERROR 01-26 21:36:47 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1102411) ERROR 01-26 21:36:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1102411) ERROR 01-26 21:36:47 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1102411) ERROR 01-26 21:36:47 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1102411) ERROR 
[21:36:53]   ✗ 失败: EngineCore failed, 耗时: 41.4s
[21:36:53]   提高利用率至 0.98，最后尝试
[21:36:53] 
--- 尝试 2/2 (util=0.98) ---
[21:36:53]   清理 GPU 环境...
[21:37:06]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 8192 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [8192]
  M_decode:         [8192]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213714.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=8192
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 8192
│   M_prefill     = 8192 (= 8 x 1024)
│   M_decode      = 8
│   batched_tokens = 8192 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 1024
│   --max-num-seqs           = 8
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 8192
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:37:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:37:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1103362) ERROR 01-26 21:37:41 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1103362) ERROR 01-26 21:37:41 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1103362) ERROR 01-26 21:37:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1103362) ERROR 01-26 21:37:41 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1103362) ERROR 01-26 21:37:41 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1103362) ERROR 01-26 21:37:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1103362) ERROR 01-26 21:37:41 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1103362) ERROR 01-26 21:37:41 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1103362) ERROR 
[21:37:46]   ✗ 失败: EngineCore failed, 耗时: 40.3s
[21:37:46]   已达最大利用率，放弃
[21:37:46]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=8192
[21:37:46] 当前进度: 0 成功, 29 失败, 11 剩余
[21:37:46] 
[21:37:46] [30/40] 开始测试...
[21:37:46] 
[21:37:46] ======================================================================
[21:37:46] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=16384
[21:37:46] 模型大小: 23 GB, 初始利用率: 0.95
[21:37:46] ======================================================================
[21:37:46] 
--- 尝试 1/2 (util=0.95) ---
[21:37:46]   清理 GPU 环境...
[21:37:58]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 16384 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [16384]
  M_decode:         [16384]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213807.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:38:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:38:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1104382) ERROR 01-26 21:38:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1104382) ERROR 01-26 21:38:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1104382) ERROR 01-26 21:38:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1104382) ERROR 01-26 21:38:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1104382) ERROR 01-26 21:38:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1104382) ERROR 01-26 21:38:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1104382) ERROR 01-26 21:38:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1104382) ERROR 01-26 21:38:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1104382)[0
[21:38:47]   ✗ 失败: EngineCore failed, 耗时: 48.5s
[21:38:47]   提高利用率至 0.98，最后尝试
[21:38:47] 
--- 尝试 2/2 (util=0.98) ---
[21:38:47]   清理 GPU 环境...
[21:39:00]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 16384 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [16384]
  M_decode:         [16384]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_213908.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=16384
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16384
│   M_prefill     = 16384 (= 16 x 1024)
│   M_decode      = 16
│   batched_tokens = 16384 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 2048
│   --max-num-seqs           = 16
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 16384
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:39:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:39:31 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1105453) ERROR 01-26 21:39:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1105453) ERROR 01-26 21:39:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1105453) ERROR 01-26 21:39:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1105453) ERROR 01-26 21:39:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1105453) ERROR 01-26 21:39:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1105453) ERROR 01-26 21:39:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1105453) ERROR 01-26 21:39:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1105453) ERROR 01-26 21:39:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1105453)[0
[21:39:49]   ✗ 失败: EngineCore failed, 耗时: 48.8s
[21:39:49]   已达最大利用率，放弃
[21:39:49]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=16384
[21:39:49] 当前进度: 0 成功, 30 失败, 10 剩余
[21:39:49] 
[21:39:49] [31/40] 开始测试...
[21:39:49] 
[21:39:49] ======================================================================
[21:39:49] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=32768
[21:39:49] 模型大小: 23 GB, 初始利用率: 0.95
[21:39:49] ======================================================================
[21:39:49] 
--- 尝试 1/2 (util=0.95) ---
[21:39:49]   清理 GPU 环境...
[21:40:00]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_214008.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:40:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:40:47 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1106744) ERROR 01-26 21:40:56 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1106744) ERROR 01-26 21:40:56 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1106744) ERROR 01-26 21:40:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1106744) ERROR 01-26 21:40:56 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1106744) ERROR 01-26 21:40:56 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1106744) ERROR 01-26 21:40:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1106744) ERROR 01-26 21:40:56 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1106744) ERROR 01-26 21:40:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1106744)[0
[21:41:02]   ✗ 失败: EngineCore failed, 耗时: 62.5s
[21:41:02]   提高利用率至 0.98，最后尝试
[21:41:02] 
--- 尝试 2/2 (util=0.98) ---
[21:41:02]   清理 GPU 环境...
[21:41:15]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 32768 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [32768]
  M_decode:         [32768]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_214122.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=32768
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 32768
│   M_prefill     = 32768 (= 32 x 1024)
│   M_decode      = 32
│   batched_tokens = 32768 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 4096
│   --max-num-seqs           = 32
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 32768
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:42:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:42:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1108244) ERROR 01-26 21:42:12 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1108244) ERROR 01-26 21:42:12 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1108244) ERROR 01-26 21:42:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1108244) ERROR 01-26 21:42:12 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1108244) ERROR 01-26 21:42:12 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1108244) ERROR 01-26 21:42:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1108244) ERROR 01-26 21:42:12 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1108244) ERROR 01-26 21:42:12 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1108244)[0
[21:42:18]   ✗ 失败: EngineCore failed, 耗时: 63.5s
[21:42:18]   已达最大利用率，放弃
[21:42:18]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=32768
[21:42:18] 当前进度: 0 成功, 31 失败, 9 剩余
[21:42:18] 
[21:42:18] [32/40] 开始测试...
[21:42:18] 
[21:42:18] ======================================================================
[21:42:18] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=65536
[21:42:18] 模型大小: 23 GB, 初始利用率: 0.95
[21:42:18] ======================================================================
[21:42:18] 
--- 尝试 1/2 (util=0.95) ---
[21:42:18]   清理 GPU 环境...
[21:42:30]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_214238.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:43:44 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:43:45 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1109933) ERROR 01-26 21:43:56 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1109933) ERROR 01-26 21:43:56 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1109933) ERROR 01-26 21:43:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1109933) ERROR 01-26 21:43:56 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1109933) ERROR 01-26 21:43:56 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1109933) ERROR 01-26 21:43:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1109933) ERROR 01-26 21:43:56 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1109933) ERROR 01-26 21:43:56 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1109933)[0
[21:44:01]   ✗ 失败: EngineCore failed, 耗时: 91.6s
[21:44:01]   提高利用率至 0.98，最后尝试
[21:44:01] 
--- 尝试 2/2 (util=0.98) ---
[21:44:01]   清理 GPU 环境...
[21:44:13]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage prefill --M 65536 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['prefill']
  M_prefill:        [65536]
  M_decode:         [65536]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_214420.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=65536
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 65536
│   M_prefill     = 65536 (= 64 x 1024)
│   M_decode      = 64
│   batched_tokens = 65536 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 1024
│   --output-len             = 1
│   --num-prompts            = 8192
│   --max-num-seqs           = 64
│   --max-model-len          = 1025
│   --max-num-batched-tokens = 65536
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:45:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:45:27 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1111742) ERROR 01-26 21:45:38 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1111742) ERROR 01-26 21:45:38 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1111742) ERROR 01-26 21:45:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1111742) ERROR 01-26 21:45:38 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1111742) ERROR 01-26 21:45:38 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1111742) ERROR 01-26 21:45:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1111742) ERROR 01-26 21:45:38 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1111742) ERROR 01-26 21:45:38 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1111742)[0
[21:45:45]   ✗ 失败: EngineCore failed, 耗时: 91.3s
[21:45:45]   已达最大利用率，放弃
[21:45:45]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | prefill | M=65536
[21:45:45] 当前进度: 0 成功, 32 失败, 8 剩余
[21:45:45] 
[21:45:45] [33/40] 开始测试...
[21:45:45] 
[21:45:45] ======================================================================
[21:45:45] 测试: qwen2.5-14b-int8 | cusparselt (2_8) | decode | M=512
[21:45:45] 模型大小: 22 GB, 初始利用率: 0.95
[21:45:45] ======================================================================
[21:45:45] 
--- 尝试 1/2 (util=0.95) ---
[21:45:45]   清理 GPU 环境...
[21:45:57]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage decode --M 512 --gpu-mem 0.95 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['decode']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_214604.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_8) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:46:13 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:46:14 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1112628) ERROR 01-26 21:46:24 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1112628) ERROR 01-26 21:46:24 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1112628) ERROR 01-26 21:46:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1112628) ERROR 01-26 21:46:24 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1112628) ERROR 01-26 21:46:24 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1112628) ERROR 01-26 21:46:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1112628) ERROR 01-26 21:46:24 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1112628) ERROR 01-26 21:46:24 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1112628) ERROR 01-26 21:46
[21:46:30]   ✗ 失败: EngineCore failed, 耗时: 33.1s
[21:46:30]   提高利用率至 0.98，最后尝试
[21:46:30] 
--- 尝试 2/2 (util=0.98) ---
[21:46:30]   清理 GPU 环境...
[21:46:42]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage decode --M 512 --gpu-mem 0.98 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['decode']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_214650.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_8) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:47:00 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:47:01 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1113517) ERROR 01-26 21:47:10 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1113517) ERROR 01-26 21:47:10 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1113517) ERROR 01-26 21:47:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1113517) ERROR 01-26 21:47:10 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1113517) ERROR 01-26 21:47:10 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1113517) ERROR 01-26 21:47:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1113517) ERROR 01-26 21:47:10 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1113517) ERROR 01-26 21:47:10 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1113517) ERROR 01-26 21:47
[21:47:17]   ✗ 失败: EngineCore failed, 耗时: 35.6s
[21:47:17]   已达最大利用率，放弃
[21:47:17]   最终失败: qwen2.5-14b-int8 | cusparselt (2_8) | decode | M=512
[21:47:17] 当前进度: 0 成功, 33 失败, 7 剩余
[21:47:17] 
[21:47:17] [34/40] 开始测试...
[21:47:17] 
[21:47:17] ======================================================================
[21:47:17] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | decode | M=64
[21:47:17] 模型大小: 23 GB, 初始利用率: 0.95
[21:47:17] ======================================================================
[21:47:17] 
--- 尝试 1/2 (util=0.95) ---
[21:47:17]   清理 GPU 环境...
[21:47:29]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage decode --M 64 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [64]
  M_decode:         [64]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_214736.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=64
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 64
│   M_prefill     = 1024 (= 64 x 16)
│   M_decode      = 64
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 64
│   --max-num-seqs           = 64
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:47:46 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:47:47 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1114426) ERROR 01-26 21:47:57 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1114426) ERROR 01-26 21:47:57 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1114426) ERROR 01-26 21:47:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1114426) ERROR 01-26 21:47:57 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1114426) ERROR 01-26 21:47:57 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1114426) ERROR 01-26 21:47:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1114426) ERROR 01-26 21:47:57 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1114426) ERROR 01-26 21:47:57 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1114426) ERROR 01-26 21:47:57 
[21:48:03]   ✗ 失败: EngineCore failed, 耗时: 34.4s
[21:48:03]   提高利用率至 0.98，最后尝试
[21:48:03] 
--- 尝试 2/2 (util=0.98) ---
[21:48:03]   清理 GPU 环境...
[21:48:15]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage decode --M 64 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [64]
  M_decode:         [64]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_214822.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=64
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 64
│   M_prefill     = 1024 (= 64 x 16)
│   M_decode      = 64
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 64
│   --max-num-seqs           = 64
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:48:31 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:48:32 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1115293) ERROR 01-26 21:48:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1115293) ERROR 01-26 21:48:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1115293) ERROR 01-26 21:48:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1115293) ERROR 01-26 21:48:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1115293) ERROR 01-26 21:48:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1115293) ERROR 01-26 21:48:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1115293) ERROR 01-26 21:48:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1115293) ERROR 01-26 21:48:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1115293) ERROR 01-26 21:48:42 
[21:48:48]   ✗ 失败: EngineCore failed, 耗时: 33.1s
[21:48:48]   已达最大利用率，放弃
[21:48:48]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | decode | M=64
[21:48:48] 当前进度: 0 成功, 34 失败, 6 剩余
[21:48:48] 
[21:48:48] [35/40] 开始测试...
[21:48:48] 
[21:48:48] ======================================================================
[21:48:48] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | decode | M=256
[21:48:48] 模型大小: 23 GB, 初始利用率: 0.95
[21:48:48] ======================================================================
[21:48:48] 
--- 尝试 1/2 (util=0.95) ---
[21:48:48]   清理 GPU 环境...
[21:49:01]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage decode --M 256 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [256]
  M_decode:         [256]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_214907.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 4096 (= 256 x 16)
│   M_decode      = 256
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 256
│   --max-num-seqs           = 256
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:49:17 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:49:18 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1116206) ERROR 01-26 21:49:29 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1116206) ERROR 01-26 21:49:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1116206) ERROR 01-26 21:49:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1116206) ERROR 01-26 21:49:29 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1116206) ERROR 01-26 21:49:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1116206) ERROR 01-26 21:49:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1116206) ERROR 01-26 21:49:29 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1116206) ERROR 01-26 21:49:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1116206) ERROR 01-26 2
[21:49:36]   ✗ 失败: EngineCore failed, 耗时: 35.2s
[21:49:36]   提高利用率至 0.98，最后尝试
[21:49:36] 
--- 尝试 2/2 (util=0.98) ---
[21:49:36]   清理 GPU 环境...
[21:49:47]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage decode --M 256 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [256]
  M_decode:         [256]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_214956.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 4096 (= 256 x 16)
│   M_decode      = 256
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 256
│   --max-num-seqs           = 256
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:50:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:50:07 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1117089) ERROR 01-26 21:50:16 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1117089) ERROR 01-26 21:50:16 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1117089) ERROR 01-26 21:50:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1117089) ERROR 01-26 21:50:16 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1117089) ERROR 01-26 21:50:16 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1117089) ERROR 01-26 21:50:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1117089) ERROR 01-26 21:50:16 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1117089) ERROR 01-26 21:50:16 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1117089) ERROR 01-26 2
[21:50:23]   ✗ 失败: EngineCore failed, 耗时: 36.1s
[21:50:23]   已达最大利用率，放弃
[21:50:23]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | decode | M=256
[21:50:23] 当前进度: 0 成功, 35 失败, 5 剩余
[21:50:23] 
[21:50:23] [36/40] 开始测试...
[21:50:23] 
[21:50:23] ======================================================================
[21:50:23] 测试: qwen2.5-14b-int8 | cusparselt (2_10) | decode | M=512
[21:50:23] 模型大小: 23 GB, 初始利用率: 0.95
[21:50:23] ======================================================================
[21:50:23] 
--- 尝试 1/2 (util=0.95) ---
[21:50:23]   清理 GPU 环境...
[21:50:36]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage decode --M 512 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_215043.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:50:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:50:54 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1118026) ERROR 01-26 21:51:06 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1118026) ERROR 01-26 21:51:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1118026) ERROR 01-26 21:51:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1118026) ERROR 01-26 21:51:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1118026) ERROR 01-26 21:51:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1118026) ERROR 01-26 21:51:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1118026) ERROR 01-26 21:51:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1118026) ERROR 01-26 21:51:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1118026) ERROR 01-26 2
[21:51:11]   ✗ 失败: EngineCore failed, 耗时: 35.2s
[21:51:11]   提高利用率至 0.98，最后尝试
[21:51:11] 
--- 尝试 2/2 (util=0.98) ---
[21:51:11]   清理 GPU 环境...
[21:51:24]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-int8 --backend cusparselt --stage decode --M 512 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-int8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_215132.log


============================================================
  Qwen2.5-14B-INT8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_INT8_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-INT8                                │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:51:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:51:42 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1118921) ERROR 01-26 21:51:51 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1118921) ERROR 01-26 21:51:51 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1118921) ERROR 01-26 21:51:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1118921) ERROR 01-26 21:51:51 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1118921) ERROR 01-26 21:51:51 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1118921) ERROR 01-26 21:51:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1118921) ERROR 01-26 21:51:51 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1118921) ERROR 01-26 21:51:51 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1118921) ERROR 01-26 2
[21:51:57]   ✗ 失败: EngineCore failed, 耗时: 33.2s
[21:51:57]   已达最大利用率，放弃
[21:51:57]   最终失败: qwen2.5-14b-int8 | cusparselt (2_10) | decode | M=512
[21:51:57] 当前进度: 0 成功, 36 失败, 4 剩余
[21:51:57] 
[21:51:57] [37/40] 开始测试...
[21:51:57] 
[21:51:57] ======================================================================
[21:51:57] 测试: qwen2.5-14b-fp8 | cusparselt (2_8) | decode | M=512
[21:51:57] 模型大小: 22 GB, 初始利用率: 0.95
[21:51:57] ======================================================================
[21:51:57] 
--- 尝试 1/2 (util=0.95) ---
[21:51:57]   清理 GPU 环境...
[21:52:10]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage decode --M 512 --gpu-mem 0.95 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['decode']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_215217.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:52:26 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:52:27 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1119835) ERROR 01-26 21:52:39 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1119835) ERROR 01-26 21:52:39 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1119835) ERROR 01-26 21:52:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1119835) ERROR 01-26 21:52:39 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1119835) ERROR 01-26 21:52:39 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1119835) ERROR 01-26 21:52:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1119835) ERROR 01-26 21:52:39 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1119835) ERROR 01-26 21:52:39 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1119835) ERROR 01-26 21:52
[21:52:44]   ✗ 失败: EngineCore failed, 耗时: 34.5s
[21:52:44]   提高利用率至 0.98，最后尝试
[21:52:44] 
--- 尝试 2/2 (util=0.98) ---
[21:52:44]   清理 GPU 环境...
[21:52:58]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage decode --M 512 --gpu-mem 0.98 --sparsity 2_8

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_8']
  Stages:           ['decode']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_215307.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_8) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_8

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:8)                                │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:53:15 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:53:16 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1120783) ERROR 01-26 21:53:28 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1120783) ERROR 01-26 21:53:28 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1120783) ERROR 01-26 21:53:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1120783) ERROR 01-26 21:53:28 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1120783) ERROR 01-26 21:53:28 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1120783) ERROR 01-26 21:53:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1120783) ERROR 01-26 21:53:28 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1120783) ERROR 01-26 21:53:28 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1120783) ERROR 01-26 21:53
[21:53:36]   ✗ 失败: EngineCore failed, 耗时: 38.6s
[21:53:36]   已达最大利用率，放弃
[21:53:36]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_8) | decode | M=512
[21:53:36] 当前进度: 0 成功, 37 失败, 3 剩余
[21:53:36] 
[21:53:36] [38/40] 开始测试...
[21:53:36] 
[21:53:36] ======================================================================
[21:53:36] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | decode | M=64
[21:53:36] 模型大小: 23 GB, 初始利用率: 0.95
[21:53:36] ======================================================================
[21:53:36] 
--- 尝试 1/2 (util=0.95) ---
[21:53:36]   清理 GPU 环境...
[21:53:48]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage decode --M 64 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [64]
  M_decode:         [64]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_215356.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=64
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 64
│   M_prefill     = 1024 (= 64 x 16)
│   M_decode      = 64
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 64
│   --max-num-seqs           = 64
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:54:06 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:54:07 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1121693) ERROR 01-26 21:54:17 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1121693) ERROR 01-26 21:54:17 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1121693) ERROR 01-26 21:54:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1121693) ERROR 01-26 21:54:17 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1121693) ERROR 01-26 21:54:17 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1121693) ERROR 01-26 21:54:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1121693) ERROR 01-26 21:54:17 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1121693) ERROR 01-26 21:54:17 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1121693) ERROR 01-26 21:54:17 
[21:54:24]   ✗ 失败: EngineCore failed, 耗时: 36.0s
[21:54:24]   提高利用率至 0.98，最后尝试
[21:54:24] 
--- 尝试 2/2 (util=0.98) ---
[21:54:24]   清理 GPU 环境...
[21:54:37]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage decode --M 64 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [64]
  M_decode:         [64]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_215445.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=64
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 64
│   M_prefill     = 1024 (= 64 x 16)
│   M_decode      = 64
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 64
│   --max-num-seqs           = 64
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:54:53 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:54:54 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1122622) ERROR 01-26 21:55:06 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1122622) ERROR 01-26 21:55:06 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1122622) ERROR 01-26 21:55:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1122622) ERROR 01-26 21:55:06 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1122622) ERROR 01-26 21:55:06 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1122622) ERROR 01-26 21:55:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1122622) ERROR 01-26 21:55:06 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1122622) ERROR 01-26 21:55:06 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1122622) ERROR 01-26 21:55:06 
[21:55:13]   ✗ 失败: EngineCore failed, 耗时: 35.9s
[21:55:13]   已达最大利用率，放弃
[21:55:13]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | decode | M=64
[21:55:13] 当前进度: 0 成功, 38 失败, 2 剩余
[21:55:13] 
[21:55:13] [39/40] 开始测试...
[21:55:13] 
[21:55:13] ======================================================================
[21:55:13] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | decode | M=256
[21:55:13] 模型大小: 23 GB, 初始利用率: 0.95
[21:55:13] ======================================================================
[21:55:13] 
--- 尝试 1/2 (util=0.95) ---
[21:55:13]   清理 GPU 环境...
[21:55:24]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage decode --M 256 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [256]
  M_decode:         [256]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_215531.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 4096 (= 256 x 16)
│   M_decode      = 256
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 256
│   --max-num-seqs           = 256
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:55:41 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:55:42 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1123557) ERROR 01-26 21:55:52 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1123557) ERROR 01-26 21:55:52 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1123557) ERROR 01-26 21:55:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1123557) ERROR 01-26 21:55:52 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1123557) ERROR 01-26 21:55:52 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1123557) ERROR 01-26 21:55:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1123557) ERROR 01-26 21:55:52 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1123557) ERROR 01-26 21:55:52 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1123557) ERROR 01-26 2
[21:56:00]   ✗ 失败: EngineCore failed, 耗时: 36.0s
[21:56:00]   提高利用率至 0.98，最后尝试
[21:56:00] 
--- 尝试 2/2 (util=0.98) ---
[21:56:00]   清理 GPU 环境...
[21:56:13]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage decode --M 256 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [256]
  M_decode:         [256]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_215620.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 4096 (= 256 x 16)
│   M_decode      = 256
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 256
│   --max-num-seqs           = 256
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:56:29 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:56:30 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1124502) ERROR 01-26 21:56:42 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1124502) ERROR 01-26 21:56:42 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1124502) ERROR 01-26 21:56:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1124502) ERROR 01-26 21:56:42 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1124502) ERROR 01-26 21:56:42 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1124502) ERROR 01-26 21:56:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1124502) ERROR 01-26 21:56:42 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1124502) ERROR 01-26 21:56:42 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1124502) ERROR 01-26 2
[21:56:49]   ✗ 失败: EngineCore failed, 耗时: 35.7s
[21:56:49]   已达最大利用率，放弃
[21:56:49]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | decode | M=256
[21:56:49] 当前进度: 0 成功, 39 失败, 1 剩余
[21:56:49] 
[21:56:49] [40/40] 开始测试...
[21:56:49] 
[21:56:49] ======================================================================
[21:56:49] 测试: qwen2.5-14b-fp8 | cusparselt (2_10) | decode | M=512
[21:56:49] 模型大小: 23 GB, 初始利用率: 0.95
[21:56:49] ======================================================================
[21:56:49] 
--- 尝试 1/2 (util=0.95) ---
[21:56:49]   清理 GPU 环境...
[21:57:00]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage decode --M 512 --gpu-mem 0.95 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.95

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_215708.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:57:18 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:57:19 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1125416) ERROR 01-26 21:57:29 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1125416) ERROR 01-26 21:57:29 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1125416) ERROR 01-26 21:57:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1125416) ERROR 01-26 21:57:29 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1125416) ERROR 01-26 21:57:29 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1125416) ERROR 01-26 21:57:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1125416) ERROR 01-26 21:57:29 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1125416) ERROR 01-26 21:57:29 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1125416) ERROR 01-26 2
[21:57:36]   ✗ 失败: EngineCore failed, 耗时: 35.7s
[21:57:36]   提高利用率至 0.98，最后尝试
[21:57:36] 
--- 尝试 2/2 (util=0.98) ---
[21:57:36]   清理 GPU 环境...
[21:57:49]   命令: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model qwen2.5-14b-fp8 --backend cusparselt --stage decode --M 512 --gpu-mem 0.98 --sparsity 2_10

--- STDOUT ---

============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA GeForce RTX 4090                   ││
│ GPU (short):      RTX4090                                   │
│ Memory:           24.0 GB                                    │
│ CC:               cc89 (Ampere)                              ││
│ SM Code:          sm_89                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           581.80                                    │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['qwen2.5-14b-fp8']
  Backends:         ['cusparselt']
  Sparsities:       ['2_10']
  Stages:           ['decode']
  M_prefill:        [512]
  M_decode:         [512]
  GPU 内存利用率:   0.98

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_215756.log


============================================================
  Qwen2.5-14B-FP8 | cuSPARSELt (2_10) | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/RTX4090_cc89_FP8E4M3_py312_cu129_x86_64/cusparselt/2_10

============================================================
[1/1] 测试 M=512
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Qwen2.5-14B-FP8                                 │
│ Backend:  cuSPARSELt (2:10)                               │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 512
│   M_prefill     = 8192 (= 512 x 16)
│   M_decode      = 512
│   batched_tokens = 512 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 512
│   --max-num-seqs           = 512
│   --max-model-len          = 272
│   --max-num-batched-tokens = 512
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 21:58:05 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
WARNING 01-26 21:58:06 [interface.py:465] Using 'pin_memory=False' as WSL is detected. This may slow down the performance.
(EngineCore_DP0 pid=1126364) ERROR 01-26 21:58:18 [core.py:866] EngineCore failed to start.
(EngineCore_DP0 pid=1126364) ERROR 01-26 21:58:18 [core.py:866] Traceback (most recent call last):
(EngineCore_DP0 pid=1126364) ERROR 01-26 21:58:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 857, in run_engine_core
(EngineCore_DP0 pid=1126364) ERROR 01-26 21:58:18 [core.py:866]     engine_core = EngineCoreProc(*args, **kwargs)
(EngineCore_DP0 pid=1126364) ERROR 01-26 21:58:18 [core.py:866]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(EngineCore_DP0 pid=1126364) ERROR 01-26 21:58:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 637, in __init__
(EngineCore_DP0 pid=1126364) ERROR 01-26 21:58:18 [core.py:866]     super().__init__(
(EngineCore_DP0 pid=1126364) ERROR 01-26 21:58:18 [core.py:866]   File "/root/vllmbench/vllm/v1/engine/core.py", line 102, in __init__
(EngineCore_DP0 pid=1126364) ERROR 01-26 2
[21:58:23]   ✗ 失败: EngineCore failed, 耗时: 34.9s
[21:58:23]   已达最大利用率，放弃
[21:58:23]   最终失败: qwen2.5-14b-fp8 | cusparselt (2_10) | decode | M=512
[21:58:23] 当前进度: 0 成功, 40 失败, 0 剩余

======================================================================
FINAL SUMMARY
======================================================================
Total: 40
Success: 0
Failed: 40
Skipped: 0
Completed: 2026-01-26 21:58:37
