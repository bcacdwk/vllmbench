
==============================================
SlideSparse vLLM Accuracy Quick Benchmark Log
==============================================
Start Time: 2026-01-12 22:11:32

Hardware Information:
  GPU: RTX5080
  CC: cc120
  CUDA: cu129
  PyTorch: 2.9.0+cu129

Test Configuration:
  Prompt Input File:  /root/vllmbench/slidesparse/tools/accuracy_quickbench_prompts.jsonl
  Max Output Tokens:  64
  Max Model Length:   512
  Temperature:        0.0
  GPU Memory Util:    0.8
  vLLM Log Level:     WARNING
==============================================

========== Llama3.2-1B-FP8 ==========
Time: 2026-01-12 22:11:32
Model: /root/vllmbench/checkpoints/Llama3.2-1B-FP8
Output: /root/vllmbench/slidesparse/tools/accuracy_quickbench_results/RTX5080_cc120_py312_cu129_x86_64/Llama3.2-1B-FP8.json
Command: vllm run-batch --model /root/vllmbench/checkpoints/Llama3.2-1B-FP8 --served-model-name model --input-file /root/vllmbench/slidesparse/tools/accuracy_quickbench_prompts.jsonl --output-file /root/vllmbench/slidesparse/tools/accuracy_quickbench_results/RTX5080_cc120_py312_cu129_x86_64/Llama3.2-1B-FP8.json --max-model-len 512 --gpu-memory-utilization 0.8 --override-generation-config {"max_new_tokens": 64, "temperature": 0.0} --disable-log-stats --tensor-parallel-size 2

STDOUT:
(EngineCore_DP0 pid=467462) WARNING 01-12 22:11:39 [multiproc_executor.py:882] Reducing Torch parallelism from 24 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
WARNING 01-12 22:11:43 [symm_mem.py:67] SymmMemCommunicator: Device capability 12.0 not supported, communicator is not available.
WARNING 01-12 22:11:43 [symm_mem.py:67] SymmMemCommunicator: Device capability 12.0 not supported, communicator is not available.
WARNING 01-12 22:11:43 [custom_all_reduce.py:165] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-12 22:11:43 [custom_all_reduce.py:165] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-12 22:11:51 [model.py:1487] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.

STDERR:
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:78: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:78: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:78: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:78: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
(Worker_TP0 pid=467542) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(Worker_TP0 pid=467542) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.62it/s]
(Worker_TP0 pid=467542) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.61it/s]
(Worker_TP0 pid=467542) 
(Worker_TP1 pid=467543) 2026-01-12 22:11:50,066 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(Worker_TP0 pid=467542) 2026-01-12 22:11:50,066 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(Worker_TP0 pid=467542) 2026-01-12 22:11:50,070 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(Worker_TP1 pid=467543) 2026-01-12 22:11:50,070 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(Worker_TP0 pid=467542) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  17%|█▋        | 6/35 [00:00<00:00, 54.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 12/35 [00:00<00:00, 57.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▍    | 19/35 [00:00<00:00, 62.13it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  77%|███████▋  | 27/35 [00:00<00:00, 68.54it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:00<00:00, 72.55it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:00<00:00, 67.85it/s]
(Worker_TP0 pid=467542) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  7.56it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:00<00:00, 48.90it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 59.31it/s]

Running batch:   0% Completed | 0/16 [00:00<?, ?req/s]

Running batch: 100% Completed | 16/16 [00:00<00:00, 25.41req/s]


