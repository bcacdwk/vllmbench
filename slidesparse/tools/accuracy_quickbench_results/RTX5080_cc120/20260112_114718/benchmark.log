
==============================================
SlideSparse vLLM Accuracy Quick Benchmark Log
==============================================
Start Time: 2026-01-12 11:47:18

Hardware Information:
  GPU: RTX5080
  CC: cc120
  CUDA: cu129
  PyTorch: 2.9.0+cu129

Test Configuration:
  Prompt Input File:  /root/vllmbench/slidesparse/tools/accuracy_quickbench_prompts.jsonl
  Max Output Tokens:  64
  Max Model Length:   512
  Temperature:        0.0
  GPU Memory Util:    0.8
  vLLM Log Level:     WARNING
==============================================

========== Qwen2.5-0.5B-INT8 ==========
Time: 2026-01-12 11:47:18
Model: /root/vllmbench/checkpoints/Qwen2.5-0.5B-INT8
Output: /root/vllmbench/slidesparse/tools/accuracy_quickbench_results/RTX5080_cc120/20260112_114718/Qwen2.5-0.5B-INT8.json
Command: vllm run-batch --model /root/vllmbench/checkpoints/Qwen2.5-0.5B-INT8 --served-model-name model --input-file /root/vllmbench/slidesparse/tools/accuracy_quickbench_prompts.jsonl --output-file /root/vllmbench/slidesparse/tools/accuracy_quickbench_results/RTX5080_cc120/20260112_114718/Qwen2.5-0.5B-INT8.json --max-model-len 512 --gpu-memory-utilization 0.8 --override-generation-config {"max_new_tokens": 64, "temperature": 0.0} --disable-log-stats --tensor-parallel-size 2

