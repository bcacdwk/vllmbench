
==============================================
SlideSparse vLLM Accuracy Quick Benchmark Log
==============================================
Start Time: 2026-01-12 22:35:07

Hardware Information:
  GPU: RTX5080
  CC: cc120
  CUDA: cu129
  PyTorch: 2.9.0+cu129

Test Configuration:
  Prompt Input File:  /root/vllmbench/slidesparse/tools/accuracy_quickbench_prompts.jsonl
  Max Output Tokens:  64
  Max Model Length:   512
  Temperature:        0.0
  GPU Memory Util:    0.8
  vLLM Log Level:     WARNING
==============================================

========== Llama3.2-1B-FP8 ==========
Time: 2026-01-12 22:35:07
Model: /root/vllmbench/checkpoints/Llama3.2-1B-FP8
Output: /root/vllmbench/slidesparse/tools/accuracy_quickbench_results/RTX5080_cc120_py312_cu129_x86_64/Llama3.2-1B-FP8.json
Command: vllm run-batch --model /root/vllmbench/checkpoints/Llama3.2-1B-FP8 --served-model-name model --input-file /root/vllmbench/slidesparse/tools/accuracy_quickbench_prompts.jsonl --output-file /root/vllmbench/slidesparse/tools/accuracy_quickbench_results/RTX5080_cc120_py312_cu129_x86_64/Llama3.2-1B-FP8.json --max-model-len 512 --gpu-memory-utilization 0.8 --override-generation-config {"max_new_tokens": 64, "temperature": 0.0} --disable-log-stats --tensor-parallel-size 2

STDOUT:
(EngineCore_DP0 pid=485291) WARNING 01-12 22:35:14 [multiproc_executor.py:882] Reducing Torch parallelism from 24 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
WARNING 01-12 22:35:18 [symm_mem.py:67] SymmMemCommunicator: Device capability 12.0 not supported, communicator is not available.
WARNING 01-12 22:35:18 [symm_mem.py:67] SymmMemCommunicator: Device capability 12.0 not supported, communicator is not available.
WARNING 01-12 22:35:18 [custom_all_reduce.py:165] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-12 22:35:18 [custom_all_reduce.py:165] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.
WARNING 01-12 22:35:27 [model.py:1487] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.

STDERR:
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:78: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:78: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:78: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
/root/vllmbench/vllm/model_executor/layers/quantization/slidesparse.py:78: UserWarning: Failed to import slidesparse modules: No module named 'slidesparse'. SlideSparse features will be disabled.
  warnings.warn(
(Worker_TP0 pid=485381) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(Worker_TP0 pid=485381) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.58it/s]
(Worker_TP0 pid=485381) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.57it/s]
(Worker_TP0 pid=485381) 
(Worker_TP1 pid=485382) 2026-01-12 22:35:25,422 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(Worker_TP0 pid=485381) 2026-01-12 22:35:25,422 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(Worker_TP1 pid=485382) 2026-01-12 22:35:25,426 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(Worker_TP0 pid=485381) 2026-01-12 22:35:25,427 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(Worker_TP0 pid=485381) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 5/35 [00:00<00:00, 48.84it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:00<00:00, 52.97it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████▏    | 18/35 [00:00<00:00, 57.51it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  74%|███████▍  | 26/35 [00:00<00:00, 63.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:00<00:00, 67.17it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:00<00:00, 62.94it/s]
(Worker_TP0 pid=485381) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):   5%|▌         | 1/19 [00:00<00:02,  7.34it/s]
Capturing CUDA graphs (decode, FULL):  47%|████▋     | 9/19 [00:00<00:00, 44.33it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 67.55it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 56.20it/s]

Running batch:   0% Completed | 0/16 [00:00<?, ?req/s]

Running batch: 100% Completed | 16/16 [00:00<00:00, 24.76req/s]


