======================================================================
SlideSparse Prepare Benchmark Log
Started: 2026-01-25 22:18:52
======================================================================

Hardware:
  GPU: NVIDIA H100 PCIe (cc90)
  Python: py312
  CUDA: cu129
  Arch: x86_64

[INFO] 日志文件: /root/vllmbench/slidesparse/tools/prepare_bench_20260125_221852.log
[INFO] 跳过 Task 1: 模型下载

======================================================================
TASK 2: 模型转换 (SlideSparse)
Started: 2026-01-25 22:18:52
======================================================================

[INFO] 跳过已存在: llama3.2-1b-int8 2_4
[INFO] 跳过已存在: llama3.2-1b-int8 2_6
[INFO] 跳过已存在: llama3.2-1b-int8 2_8
[INFO] 跳过已存在: llama3.2-1b-int8 2_10
[INFO] 跳过已存在: llama3.2-1b-fp8 2_4
[INFO] 跳过已存在: llama3.2-1b-fp8 2_6
[INFO] 跳过已存在: llama3.2-1b-fp8 2_8
[INFO] 跳过已存在: llama3.2-1b-fp8 2_10
[INFO] 跳过已存在: llama3.2-3b-int8 2_4
[INFO] 跳过已存在: llama3.2-3b-int8 2_6
[INFO] 跳过已存在: llama3.2-3b-int8 2_8
[INFO] 跳过已存在: llama3.2-3b-int8 2_10
[INFO] 跳过已存在: llama3.2-3b-fp8 2_4
[INFO] 跳过已存在: llama3.2-3b-fp8 2_6
[INFO] 跳过已存在: llama3.2-3b-fp8 2_8
[INFO] 跳过已存在: llama3.2-3b-fp8 2_10

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 100.13s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_4 转换完成 (106.2s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 117.04s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_6 转换完成 (123.4s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 118.76s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_8 转换完成 (125.4s)

------------------------------------------------------------
  转换: qwen2.5-7b-int8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-int8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 129.66s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-INT8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-7b-int8 2_10 转换完成 (136.2s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 18944] -> [3584, 18944]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [18944, 3584] -> [18944, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [3584, 3584] -> [3584, 3584]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [512, 3584] -> [512, 3584]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 100.63s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_4 转换完成 (107.0s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 18944] -> [3584, 25280]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [18944, 3584] -> [18944, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [3584, 3584] -> [3584, 4800]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [512, 3584] -> [512, 4800]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 115.64s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_6 转换完成 (122.2s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 18944] -> [3584, 28416]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [18944, 3584] -> [18944, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [3584, 3584] -> [3584, 5376]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [512, 3584] -> [512, 5376]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 109.83s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_8 转换完成 (116.1s)

------------------------------------------------------------
  转换: qwen2.5-7b-fp8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-7b-fp8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-7B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00002.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10/model-00001-of-00002.safetensors

[INFO] Processing file: model-00002-of-00002.safetensors
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[3584, 18944], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 18944] -> [3584, 30336]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[18944, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [18944, 3584] -> [18944, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[3584, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [3584, 3584] -> [3584, 5760]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[512, 3584], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [512, 3584] -> [512, 5760]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10/model-00002-of-00002.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 196 layers
[INFO] Skipped: 339 layers
[INFO] Time: 134.63s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-7B-FP8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-7b-fp8 2_10 转换完成 (140.9s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 197.11s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_4 转换完成 (203.1s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 234.22s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_6 转换完成 (240.5s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 229.24s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_8 转换完成 (235.8s)

------------------------------------------------------------
  转换: qwen2.5-14b-int8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-int8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-INT8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, README.md...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=int8
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 248.80s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-INT8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-14b-int8 2_10 转换完成 (255.2s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_4
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 4
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=4, N=2, expand=1.000)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, tokenizer.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 13824] -> [5120, 13824]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [13824, 5120] -> [13824, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [5120, 5120] -> [5120, 5120]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:4, mode=magnitude)
[INFO]     2:4 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.000)
[INFO]     Shape: [1024, 5120] -> [1024, 5120]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 152.10s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_4/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_4 转换完成 (158.4s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_6
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 6
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=6, N=3, expand=1.333)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, tokenizer.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 13824] -> [5120, 18432]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [13824, 5120] -> [13824, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [5120, 5120] -> [5120, 6848]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:6, mode=magnitude)
[INFO]     2:6 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.333)
[INFO]     Shape: [1024, 5120] -> [1024, 6848]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 185.81s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_6/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_6 转换完成 (192.1s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 8
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=8, N=4, expand=1.500)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, tokenizer.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 13824] -> [5120, 20736]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [13824, 5120] -> [13824, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [5120, 5120] -> [5120, 7680]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:8, mode=magnitude)
[INFO]     2:8 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.500)
[INFO]     Shape: [1024, 5120] -> [1024, 7680]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 165.28s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_8/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_8 转换完成 (171.9s)

------------------------------------------------------------
  转换: qwen2.5-14b-fp8 -> SlideSparse-2_10
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/weight_convert_entry.py --model qwen2.5-14b-fp8 --Z 2 --L 10
[INFO] 工作目录: /root/vllmbench/slidesparse/weight_convert

======================================================================
Processing: Qwen2.5-14B-FP8
======================================================================
[INFO] Config: SlideSparseConfig(Z=2, L=10, N=5, expand=1.600)
[INFO] Mode: magnitude
[INFO] Output: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10

[INFO] Copying non-weight files...
[INFO]   Copied: added_tokens.json, config.json, .gitattributes, model.safetensors.index.json, tokenizer.json...

[INFO] Processing file: model-00001-of-00004.safetensors
[INFO] 
Layer: model.layers.0.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.0.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.1.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.10.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.11.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.2.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.3.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.4.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.5.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.6.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.7.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.8.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.9.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00001-of-00004.safetensors

[INFO] Processing file: model-00002-of-00004.safetensors
[INFO] 
Layer: model.layers.12.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.12.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.13.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.14.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.15.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.16.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.17.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.18.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.19.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.20.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.21.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.22.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.23.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.24.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.25.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.26.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.27.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.28.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.29.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00002-of-00004.safetensors

[INFO] Processing file: model-00003-of-00004.safetensors
[INFO] 
Layer: model.layers.30.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.30.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.31.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.32.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.33.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.34.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.35.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.36.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.37.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.38.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.39.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.40.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.41.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.42.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.43.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.44.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.45.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.46.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.down_proj.weight
[INFO]   Input: shape=[5120, 13824], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 13824] -> [5120, 22144]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.gate_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.mlp.up_proj.weight
[INFO]   Input: shape=[13824, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [13824, 5120] -> [13824, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.k_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.o_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.q_proj.weight
[INFO]   Input: shape=[5120, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [5120, 5120] -> [5120, 8192]
[INFO]     2:4 validation: ✓
[INFO] 
Layer: model.layers.47.self_attn.v_proj.weight
[INFO]   Input: shape=[1024, 5120], dtype=fp8_e4m3
[INFO]   Stage 1: Pruning (2:10, mode=magnitude)
[INFO]     2:10 validation: ✓
[INFO]   Stage 2: Sliding (expand_ratio=1.600)
[INFO]     Shape: [1024, 5120] -> [1024, 8192]
[INFO]     2:4 validation: ✓

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00003-of-00004.safetensors

[INFO] Processing file: model-00004-of-00004.safetensors

[INFO] Saving: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/model-00004-of-00004.safetensors

======================================================================
Summary
======================================================================
[✓] Processed: 336 layers
[INFO] Skipped: 579 layers
[INFO] Time: 180.39s
[INFO] Report: /root/vllmbench/checkpoints_slidesparse/Qwen2.5-14B-FP8-SlideSparse-2_10/conversion_report.json
[SUCCESS] qwen2.5-14b-fp8 2_10 转换完成 (186.4s)

[INFO] 转换统计: 成功 16, 跳过 16, 失败 0

----------------------------------------------------------------------
TASK 2: 模型转换 (SlideSparse) - SUCCESS
Duration: 2620.7 seconds (43.7 minutes)
----------------------------------------------------------------------


======================================================================
TASK 3: 离线粗调优 (cuBLAS + quant_only)
Started: 2026-01-25 23:02:32
======================================================================

[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/offline_autotune_algsearch.py --model Llama3.2-1B,Llama3.2-3B,Qwen2.5-7B,Qwen2.5-14B --dtype all --m_list 256,1024,4096,16384,32768 --Lmax 10 --warmup 10 --repeat 50 --kernels 1,0,0,0,1


============================================================
  SlideSparse 统一离线调优
============================================================

  GPU:           NVIDIA H100 PCIe (cc90)
  Python:        py312
  CUDA:          cu129
  Arch:          x86_64

  数据类型:      ['int8', 'fp8']
  输出类型:      bf16
  高精度累加:    否
  模型 (base):   ['Llama3.2-1B', 'Llama3.2-3B', 'Qwen2.5-7B', 'Qwen2.5-14B']
  Lmax:          10
  M-quick:       否
  M 列表:        [256, 1024, 4096, 16384, 32768]
  Warmup/Repeat: 10/50

  Kernel 调优:
    ✓ cuBLASLt GEMM
    ✗ cuSPARSELt GEMM
    ✗ Triton Dequant + Bias
    ✗ Triton Quant + Slide
    ✓ Triton Quant Only

============================================================
  Step 0: 编译 CUDA 扩展
============================================================


------------------------------------------------------------
  编译 cublaslt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cublaslt_gemm/build_cublaslt.py build --force
[SUCCESS] cublaslt 编译成功

------------------------------------------------------------
  编译 cusparselt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cusparselt_gemm/build_cusparselt.py build --force
[SUCCESS] cusparselt 编译成功

------------------------------------------------------------
  编译 compress
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/build_compress.py build --force
[SUCCESS] compress 编译成功

============================================================
  Step 1: cuBLASLt GEMM
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Llama3.2-1B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-1B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Llama3.2-3B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-3B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Qwen2.5-7B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-7B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Qwen2.5-7B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Qwen2.5-7B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Qwen2.5-14B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-14B-INT8)
[INFO] dtype=int8, outdtype=int32
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype int8 --outdtype int32 --model Qwen2.5-14B-INT8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuBLASLt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Qwen2.5-14B-FP8 --warmup 10 --repeat 50 --compile --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] cuBLASLt GEMM (fp8) 完成

============================================================
  Step 2: cuSPARSELt GEMM [跳过]
============================================================


============================================================
  Step 3: Triton Dequant + Bias [跳过]
============================================================


============================================================
  Step 4: Triton Quant + Slide [跳过]
============================================================


============================================================
  Step 5: Triton Quant Only
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Llama3.2-1B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Llama3.2-3B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

------------------------------------------------------------
  模型: Qwen2.5-7B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-7B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Qwen2.5-7B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

------------------------------------------------------------
  模型: Qwen2.5-14B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-14B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/quant_only_triton/autotune_autogen_quant_only.py --model Qwen2.5-14B-INT8 --warmup 10 --repeat 50 --Lmax 10 --m_list 256,1024,4096,16384,32768
[SUCCESS] Triton Quant Only 完成

============================================================
  调优总结
============================================================

  cuBLASLt GEMM: [全部成功] (8/8)
  cuSPARSELt GEMM: [跳过]
  Triton Dequant + Bias: [跳过]
  Triton Quant + Slide: [跳过]
  Triton Quant Only: [全部成功] (4/4)

总计: 成功 12, 失败 0, 跳过 3

----------------------------------------------------------------------
TASK 3: 离线粗调优 (cuBLAS + quant_only) - SUCCESS
Duration: 914.7 seconds (15.2 minutes)
----------------------------------------------------------------------


======================================================================
TASK 4: 离线细调优 (cuSPARSE + Triton)
Started: 2026-01-25 23:17:47
======================================================================

[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/offline_autotune_algsearch.py --model Llama3.2-1B,Llama3.2-3B,Qwen2.5-7B,Qwen2.5-14B --dtype all --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536 --Lmax 10 --warmup 25 --repeat 100 --kernels 0,1,1,1,0


============================================================
  SlideSparse 统一离线调优
============================================================

  GPU:           NVIDIA H100 PCIe (cc90)
  Python:        py312
  CUDA:          cu129
  Arch:          x86_64

  数据类型:      ['int8', 'fp8']
  输出类型:      bf16
  高精度累加:    否
  模型 (base):   ['Llama3.2-1B', 'Llama3.2-3B', 'Qwen2.5-7B', 'Qwen2.5-14B']
  Lmax:          10
  M-quick:       否
  M 列表:        [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]
  Warmup/Repeat: 25/100

  Kernel 调优:
    ✗ cuBLASLt GEMM
    ✓ cuSPARSELt GEMM
    ✓ Triton Dequant + Bias
    ✓ Triton Quant + Slide
    ✗ Triton Quant Only

============================================================
  Step 0: 编译 CUDA 扩展
============================================================


------------------------------------------------------------
  编译 cublaslt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cublaslt_gemm/build_cublaslt.py build --force
[SUCCESS] cublaslt 编译成功

------------------------------------------------------------
  编译 cusparselt
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/cusparselt_gemm/build_cusparselt.py build --force
[SUCCESS] cusparselt 编译成功

------------------------------------------------------------
  编译 compress
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/weight_convert/build_compress.py build --force
[SUCCESS] compress 编译成功

============================================================
  Step 1: cuBLASLt GEMM [跳过]
============================================================


============================================================
  Step 2: cuSPARSELt GEMM
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] dtype=int8, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype int8 --outdtype bf16 --model Llama3.2-1B-INT8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-1B-FP8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] dtype=int8, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype int8 --outdtype bf16 --model Llama3.2-3B-INT8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (int8) 完成
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Llama3.2-3B-FP8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Qwen2.5-7B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-7B-INT8)
[INFO] dtype=int8, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype int8 --outdtype bf16 --model Qwen2.5-7B-INT8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuSPARSELt GEMM (int8) 失败:
[cusparselt] 超时（超过 1 小时）
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Qwen2.5-7B-FP8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] cuSPARSELt GEMM (fp8) 完成

------------------------------------------------------------
  模型: Qwen2.5-14B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-14B-INT8)
[INFO] dtype=int8, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype int8 --outdtype bf16 --model Qwen2.5-14B-INT8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuSPARSELt GEMM (int8) 失败:
[cusparselt] 超时（超过 1 小时）
[INFO] dtype=fp8e4m3, outdtype=bf16
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/search/cuSPARSELt_AlgSearch/alg_search.py --dtype fp8e4m3 --outdtype bf16 --model Qwen2.5-14B-FP8 --warmup 25 --repeat 100 --compile --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[ERROR] cuSPARSELt GEMM (fp8) 失败:
[cusparselt] 超时（超过 1 小时）

============================================================
  Step 3: Triton Dequant + Bias
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/autotune_autogen_dequant_bias.py --model Llama3.2-1B-INT8 --warmup 25 --repeat 100 --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] Triton Dequant + Bias 完成

------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/autotune_autogen_dequant_bias.py --model Llama3.2-3B-INT8 --warmup 25 --repeat 100 --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] Triton Dequant + Bias 完成

------------------------------------------------------------
  模型: Qwen2.5-7B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-7B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/autotune_autogen_dequant_bias.py --model Qwen2.5-7B-INT8 --warmup 25 --repeat 100 --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] Triton Dequant + Bias 完成

------------------------------------------------------------
  模型: Qwen2.5-14B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-14B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/fused_dequant_bias_triton/autotune_autogen_dequant_bias.py --model Qwen2.5-14B-INT8 --warmup 25 --repeat 100 --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] Triton Dequant + Bias 完成

============================================================
  Step 4: Triton Quant + Slide
============================================================


------------------------------------------------------------
  模型: Llama3.2-1B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-1B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/autotune_autogen_quant_slide.py --model Llama3.2-1B-INT8 --warmup 25 --repeat 100 --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] Triton Quant + Slide 完成

------------------------------------------------------------
  模型: Llama3.2-3B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Llama3.2-3B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/autotune_autogen_quant_slide.py --model Llama3.2-3B-INT8 --warmup 25 --repeat 100 --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] Triton Quant + Slide 完成

------------------------------------------------------------
  模型: Qwen2.5-7B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-7B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/autotune_autogen_quant_slide.py --model Qwen2.5-7B-INT8 --warmup 25 --repeat 100 --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] Triton Quant + Slide 完成

------------------------------------------------------------
  模型: Qwen2.5-14B
------------------------------------------------------------
[INFO] NK 组合数: 16 (from Qwen2.5-14B-INT8)
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/csrc/fused_quant_slide_triton/autotune_autogen_quant_slide.py --model Qwen2.5-14B-INT8 --warmup 25 --repeat 100 --Lmax 10 --m_list 64,128,256,512,1024,2048,4096,8192,16384,32768,65536
[SUCCESS] Triton Quant + Slide 完成

============================================================
  Step 5: Triton Quant Only [跳过]
============================================================


============================================================
  调优总结
============================================================

  cuBLASLt GEMM: [跳过]
  cuSPARSELt GEMM: [部分成功] (5/8)
  Triton Dequant + Bias: [全部成功] (4/4)
  Triton Quant + Slide: [全部成功] (4/4)
  Triton Quant Only: [跳过]

总计: 成功 13, 失败 3, 跳过 2

----------------------------------------------------------------------
TASK 4: 离线细调优 (cuSPARSE + Triton) - FAILED
Duration: 20364.7 seconds (339.4 minutes)
----------------------------------------------------------------------


======================================================================
TASK 5: 简单端到端 Benchmark
Started: 2026-01-26 04:57:12
======================================================================


------------------------------------------------------------
  Benchmark: llama3.2-1b-int8
------------------------------------------------------------
[INFO] 执行: /usr/bin/python3 /root/vllmbench/slidesparse/tools/throughput_benchmark.py --model llama3.2-1b-int8 --backend all --stage all --sparsity 2_4,2_6,2_10 --M quick


============================================================
  SlideSparse vLLM Throughput Benchmark
============================================================


┌─────────────────────────────────────────────────────────────┐
│                    Hardware Information                      │
├─────────────────────────────────────────────────────────────┤
│ GPU:              NVIDIA H100 PCIe                          ││
│ GPU (short):      H100                                      │
│ Memory:           79.2 GB                                    │
│ CC:               cc90 (Hopper)                              ││
│ SM Code:          sm_90                                     │
├─────────────────────────────────────────────────────────────┤
│ CUDA Runtime:     12.9                                      │
│ CUDA Driver:      13.0                                      │
│ Driver:           580.105.08                                │
│ PyTorch:          2.9.0+cu129                               │
├─────────────────────────────────────────────────────────────┤
│ Triton:           ✓ supported                               ││
│ FP8 Support:      ✓                                         │
│ INT8 Support:     ✓                                         │
└─────────────────────────────────────────────────────────────┘

测试配置:
  模型:             ['llama3.2-1b-int8']
  Backends:         ['cutlass', 'cublaslt', 'cusparselt']
  Sparsities:       ['2_4', '2_6', '2_10']
  Stages:           ['prefill', 'decode']
  M_prefill:        [16, 128, 256]
  M_decode:         [16, 128, 256]
  GPU 内存利用率:   0.8

输出目录结构:
  throughput_benchmark_results/{stage}/{hw_folder}/{backend}/[{sparsity}/]
============================================================
[INFO] 日志文件: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/logs/benchmark_20260126_045718.log


============================================================
  Llama3.2-1B-INT8 | CUTLASS | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Llama3.2-1B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cutlass

============================================================
[1/3] 测试 M=16
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Llama3.2-1B-INT8                                │
│ Backend:  CUTLASS (SlideSparse fallback)                  │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16
│   M_prefill     = 16 (= 1 x 16)
│   M_decode      = 1
│   batched_tokens = 17 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 17
│   --max-num-batched-tokens = 17
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:57:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
Throughput: 190.61 requests/s, 3240.34 total tokens/s, 190.61 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128


─── STDERR ───
[2026-01-26 04:57:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:57:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:57:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:57:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:57:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:57:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:25] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:57:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:57:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:57:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:57:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:57:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:57:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:57:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:57:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:57:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:57:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:57:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:32] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:57:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:57:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:57:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:57:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:57:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=833407) [2026-01-26 04:57:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (CUTLASS)
(EngineCore_DP0 pid=833407) [2026-01-26 04:57:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=CUTLASS)
(EngineCore_DP0 pid=833407) [2026-01-26 04:57:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=CUTLASS, symmetric=True
(EngineCore_DP0 pid=833407) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=833407) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.62it/s]
(EngineCore_DP0 pid=833407) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.61it/s]
(EngineCore_DP0 pid=833407) 
(EngineCore_DP0 pid=833407) 2026-01-26 04:57:43,849 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=833407) 2026-01-26 04:57:43,870 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=833407) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  3.26it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  6.03it/s]
(EngineCore_DP0 pid=833407) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 35.07it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2447.35it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:00, 208.94it/s, est. speed input: 3344.18 toks/s, output: 208.96 toks/s]
Processed prompts:  33%|███▎      | 42/128 [00:00<00:00, 208.16it/s, est. speed input: 3333.08 toks/s, output: 208.29 toks/s]
Processed prompts:  49%|████▉     | 63/128 [00:00<00:00, 207.83it/s, est. speed input: 3328.21 toks/s, output: 208.00 toks/s]
Processed prompts:  66%|██████▌   | 84/128 [00:00<00:00, 207.55it/s, est. speed input: 3324.75 toks/s, output: 207.78 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:00<00:00, 207.21it/s, est. speed input: 3320.96 toks/s, output: 207.55 toks/s]
Processed prompts:  98%|█████████▊| 126/128 [00:00<00:00, 207.01it/s, est. speed input: 3318.42 toks/s, output: 207.39 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:00<00:00, 207.01it/s, est. speed input: 3318.12 toks/s, output: 207.37 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:00<00:00, 207.30it/s, est. speed input: 3318.12 toks/s, output: 207.37 toks/s]
[rank0]:[W126 04:57:46.448247965 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 29.9s

测试结果:
  Requests/s:   190.61
  Tokens/s:     3240.34
  Total Reqs:   128
  Elapsed:      0.67s

  [Prefill 分析]
  Total Prefill Tokens: 2048
  Prefill Tokens/s:     3049.73

============================================================
[2/3] 测试 M=128
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Llama3.2-1B-INT8                                │
│ Backend:  CUTLASS (SlideSparse fallback)                  │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 128
│   M_prefill     = 128 (= 1 x 128)
│   M_decode      = 1
│   batched_tokens = 129 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 128
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 129
│   --max-num-batched-tokens = 129
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:57:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
Throughput: 178.25 requests/s, 22994.45 total tokens/s, 178.25 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128


─── STDERR ───
[2026-01-26 04:57:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:57:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:57:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:57:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:57:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:57:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:57:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:57:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:57:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:57:55] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:57:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:57:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:57:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:57:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:57:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:58:01] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:58:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:58:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:58:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:58:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:58:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:02] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:58:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:58:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:58:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:58:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:58:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=834367) [2026-01-26 04:58:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (CUTLASS)
(EngineCore_DP0 pid=834367) [2026-01-26 04:58:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=CUTLASS)
(EngineCore_DP0 pid=834367) [2026-01-26 04:58:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=CUTLASS, symmetric=True
(EngineCore_DP0 pid=834367) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=834367) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.55it/s]
(EngineCore_DP0 pid=834367) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.55it/s]
(EngineCore_DP0 pid=834367) 
(EngineCore_DP0 pid=834367) 2026-01-26 04:58:14,011 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=834367) 2026-01-26 04:58:14,016 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=834367) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 97.87it/s]
(EngineCore_DP0 pid=834367) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 67.14it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1684.92it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  14%|█▍        | 18/128 [00:00<00:00, 169.24it/s, est. speed input: 21671.37 toks/s, output: 169.26 toks/s]
Processed prompts:  30%|███       | 39/128 [00:00<00:00, 188.19it/s, est. speed input: 23725.18 toks/s, output: 185.32 toks/s]
Processed prompts:  47%|████▋     | 60/128 [00:00<00:00, 196.69it/s, est. speed input: 24632.36 toks/s, output: 192.42 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:00<00:00, 200.67it/s, est. speed input: 25086.35 toks/s, output: 195.97 toks/s]
Processed prompts:  80%|███████▉  | 102/128 [00:00<00:00, 202.77it/s, est. speed input: 25353.12 toks/s, output: 198.06 toks/s]
Processed prompts:  96%|█████████▌| 123/128 [00:00<00:00, 204.07it/s, est. speed input: 25532.91 toks/s, output: 199.47 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:00<00:00, 204.07it/s, est. speed input: 25574.84 toks/s, output: 199.79 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:00<00:00, 199.72it/s, est. speed input: 25574.84 toks/s, output: 199.79 toks/s]
[rank0]:[W126 04:58:16.312067336 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 30.0s

测试结果:
  Requests/s:   178.25
  Tokens/s:     22994.45
  Total Reqs:   128
  Elapsed:      0.72s

  [Prefill 分析]
  Total Prefill Tokens: 16384
  Prefill Tokens/s:     22816.20

============================================================
[3/3] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Llama3.2-1B-INT8                                │
│ Backend:  CUTLASS (SlideSparse fallback)                  │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 256 (= 1 x 256)
│   M_decode      = 1
│   batched_tokens = 257 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 256
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 257
│   --max-num-batched-tokens = 257
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:58:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
Throughput: 170.75 requests/s, 43881.85 total tokens/s, 170.75 output tokens/s
Total num prompt tokens:  32768
Total num output tokens:  128


─── STDERR ───
[2026-01-26 04:58:24] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:58:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:58:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:58:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:58:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:58:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:25] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:58:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:58:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:58:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:58:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:58:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:58:31] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:58:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:58:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:58:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:32] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:58:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:32] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:58:32] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:32] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:32] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:32] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:32] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:32] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:58:32] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:58:32] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:58:32] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:58:32] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:58:32] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=835281) [2026-01-26 04:58:33] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (CUTLASS)
(EngineCore_DP0 pid=835281) [2026-01-26 04:58:33] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=CUTLASS)
(EngineCore_DP0 pid=835281) [2026-01-26 04:58:33] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=CUTLASS, symmetric=True
(EngineCore_DP0 pid=835281) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=835281) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.29it/s]
(EngineCore_DP0 pid=835281) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.29it/s]
(EngineCore_DP0 pid=835281) 
(EngineCore_DP0 pid=835281) 2026-01-26 04:58:43,816 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=835281) 2026-01-26 04:58:43,821 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=835281) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00, 96.53it/s]
(EngineCore_DP0 pid=835281) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 69.25it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests:  90%|████████▉ | 115/128 [00:00<00:00, 1145.21it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1180.85it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:  15%|█▍        | 19/128 [00:00<00:00, 183.00it/s, est. speed input: 46863.41 toks/s, output: 183.01 toks/s]
Processed prompts:  31%|███▏      | 40/128 [00:00<00:00, 195.70it/s, est. speed input: 49618.21 toks/s, output: 193.79 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:00<00:00, 199.97it/s, est. speed input: 50573.39 toks/s, output: 197.53 toks/s]
Processed prompts:  64%|██████▍   | 82/128 [00:00<00:00, 201.89it/s, est. speed input: 51038.18 toks/s, output: 199.35 toks/s]
Processed prompts:  80%|████████  | 103/128 [00:00<00:00, 201.84it/s, est. speed input: 51162.35 toks/s, output: 199.84 toks/s]
Processed prompts:  97%|█████████▋| 124/128 [00:00<00:00, 201.56it/s, est. speed input: 51212.75 toks/s, output: 200.04 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:00<00:00, 201.56it/s, est. speed input: 51223.98 toks/s, output: 200.08 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:00<00:00, 200.02it/s, est. speed input: 51223.98 toks/s, output: 200.08 toks/s]
[rank0]:[W126 04:58:46.236721205 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 30.3s

测试结果:
  Requests/s:   170.75
  Tokens/s:     43881.85
  Total Reqs:   128
  Elapsed:      0.75s

  [Prefill 分析]
  Total Prefill Tokens: 32768
  Prefill Tokens/s:     43711.10


------------------------------------------------------------
  生成 CSV: Llama3.2-1B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cutlass/Llama3.2-1B-INT8_prefill.csv

预览:
------------------------------------------------------------
M_prefill,prompt_len,max_num_seqs,num_prompts,N_prefill,requests_per_s,tokens_per_s,elapsed_time_s
16,16,1,128,128,190.6084,3240.3431,0.6715
128,128,1,128,128,178.2516,22994.4508,0.7181
256,256,1,128,128,170.7465,43881.8506,0.7496

------------------------------------------------------------

[INFO] 完成: 3 成功, 0 失败

============================================================
  Llama3.2-1B-INT8 | CUTLASS | decode
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Llama3.2-1B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_INT8_py312_cu129_x86_64/cutlass

============================================================
[1/3] 测试 M=16
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Llama3.2-1B-INT8                                │
│ Backend:  CUTLASS (SlideSparse fallback)                  │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16
│   M_prefill     = 256 (= 16 x 16)
│   M_decode      = 16
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 16
│   --max-num-seqs           = 16
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:58:55 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
Throughput: 18.10 requests/s, 4923.30 total tokens/s, 4633.69 output tokens/s
Total num prompt tokens:  256
Total num output tokens:  4096


─── STDERR ───
[2026-01-26 04:58:54] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:58:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:58:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:58:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:55] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:58:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:55] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:58:55] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:55] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:55] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:58:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:58:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:58:55] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:55] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:58:55] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:58:55] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:58:55] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:58:55] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:58:55] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:58:55] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:59:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:59:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:59:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:59:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:02] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:59:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:02] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:59:02] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:02] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:02] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:02] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:02] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:02] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:59:02] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:59:02] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:59:02] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:59:02] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:59:02] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=836205) [2026-01-26 04:59:04] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (CUTLASS)
(EngineCore_DP0 pid=836205) [2026-01-26 04:59:04] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=CUTLASS)
(EngineCore_DP0 pid=836205) [2026-01-26 04:59:04] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=CUTLASS, symmetric=True
(EngineCore_DP0 pid=836205) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=836205) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.56it/s]
(EngineCore_DP0 pid=836205) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.56it/s]
(EngineCore_DP0 pid=836205) 
(EngineCore_DP0 pid=836205) 2026-01-26 04:59:14,052 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=836205) 2026-01-26 04:59:14,067 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=836205) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/7 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  14%|█▍        | 1/7 [00:00<00:01,  3.25it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 20.98it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 7/7 [00:00<00:00, 17.00it/s]
(EngineCore_DP0 pid=836205) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/5 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 5/5 [00:00<00:00, 96.07it/s]

Adding requests:   0%|          | 0/16 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 16/16 [00:00<00:00, 3645.24it/s]

Processed prompts:   0%|          | 0/16 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   6%|▋         | 1/16 [00:00<00:13,  1.14it/s, est. speed input: 18.27 toks/s, output: 292.37 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:00<00:00,  1.14it/s, est. speed input: 291.38 toks/s, output: 4662.07 toks/s]
Processed prompts: 100%|██████████| 16/16 [00:00<00:00, 18.21it/s, est. speed input: 291.38 toks/s, output: 4662.07 toks/s]
[rank0]:[W126 04:59:16.983229027 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 30.7s

测试结果:
  Requests/s:   18.10
  Tokens/s:     4923.30
  Total Reqs:   16
  Elapsed:      0.88s

  [Decode 分析]
  Total Decode Tokens:  4096
  Decode Tokens/s:      4633.69

============================================================
[2/3] 测试 M=128
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Llama3.2-1B-INT8                                │
│ Backend:  CUTLASS (SlideSparse fallback)                  │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 128
│   M_prefill     = 2048 (= 128 x 16)
│   M_decode      = 128
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 128
│   --max-num-seqs           = 128
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:59:25 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
Throughput: 94.63 requests/s, 25740.36 total tokens/s, 24226.22 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  32768


─── STDERR ───
[2026-01-26 04:59:25] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:59:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:59:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:59:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:25] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:59:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:25] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:59:25] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:25] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:25] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:25] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:25] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:25] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:59:25] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:59:25] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:59:25] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:59:25] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:59:25] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 04:59:32] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:59:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:59:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:59:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:33] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:59:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:33] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:59:33] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:33] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:33] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:33] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:33] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:33] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:59:33] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:59:33] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:59:33] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:59:33] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:59:33] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=837161) [2026-01-26 04:59:35] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (CUTLASS)
(EngineCore_DP0 pid=837161) [2026-01-26 04:59:35] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=CUTLASS)
(EngineCore_DP0 pid=837161) [2026-01-26 04:59:35] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=CUTLASS, symmetric=True
(EngineCore_DP0 pid=837161) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=837161) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.56it/s]
(EngineCore_DP0 pid=837161) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.55it/s]
(EngineCore_DP0 pid=837161) 
(EngineCore_DP0 pid=837161) 2026-01-26 04:59:44,209 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=837161) 2026-01-26 04:59:44,214 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=837161) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▊         | 3/35 [00:00<00:01, 28.16it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 11/35 [00:00<00:00, 41.66it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 15/35 [00:00<00:01, 13.49it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 22/35 [00:01<00:00, 21.82it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  83%|████████▎ | 29/35 [00:01<00:00, 26.22it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 34/35 [00:01<00:00, 27.77it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 35/35 [00:01<00:00, 25.13it/s]
(EngineCore_DP0 pid=837161) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/19 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▋       | 5/19 [00:00<00:00, 35.34it/s]
Capturing CUDA graphs (decode, FULL):  53%|█████▎    | 10/19 [00:00<00:00, 40.78it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 19/19 [00:00<00:00, 56.50it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2587.65it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:01<02:40,  1.26s/it, est. speed input: 12.70 toks/s, output: 203.17 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00,  1.26s/it, est. speed input: 1574.09 toks/s, output: 25185.20 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:01<00:00, 98.36it/s, est. speed input: 1574.09 toks/s, output: 25185.20 toks/s]
[rank0]:[W126 04:59:48.836051412 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 31.5s

测试结果:
  Requests/s:   94.63
  Tokens/s:     25740.36
  Total Reqs:   128
  Elapsed:      1.35s

  [Decode 分析]
  Total Decode Tokens:  32768
  Decode Tokens/s:      24226.22

============================================================
[3/3] 测试 M=256
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Llama3.2-1B-INT8                                │
│ Backend:  CUTLASS (SlideSparse fallback)                  │
│ 阶段:     decode                                          │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 256
│   M_prefill     = 4096 (= 256 x 16)
│   M_decode      = 256
│   batched_tokens = 272 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 256
│   --num-prompts            = 256
│   --max-num-seqs           = 256
│   --max-model-len          = 272
│   --max-num-batched-tokens = 272
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 1
│   N_decode  = 256
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 04:59:57 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
Throughput: 117.11 requests/s, 31853.57 total tokens/s, 29979.83 output tokens/s
Total num prompt tokens:  4096
Total num output tokens:  65536


─── STDERR ───
[2026-01-26 04:59:56] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 04:59:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 04:59:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 04:59:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:57] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 04:59:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:57] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 04:59:57] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:57] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:57] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 04:59:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 04:59:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 04:59:57] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:57] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 04:59:57] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 04:59:57] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 04:59:57] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 04:59:57] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 04:59:57] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 04:59:57] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 05:00:03] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 05:00:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-7B
[2026-01-26 05:00:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-7B
[2026-01-26 05:00:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-3B
[2026-01-26 05:00:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-3B
[2026-01-26 05:00:04] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B
[2026-01-26 05:00:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B
[2026-01-26 05:00:04] INFO kernels.py:109: Loaded tuned kernel for model: Qwen2.5-14B
[2026-01-26 05:00:04] INFO kernels.py:155: Dequant+bias kernel loaded for model: Qwen2.5-14B
[2026-01-26 05:00:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 05:00:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-7B
[2026-01-26 05:00:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 05:00:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Qwen2.5-14B
[2026-01-26 05:00:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 05:00:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-3B
[2026-01-26 05:00:04] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 05:00:04] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B
[2026-01-26 05:00:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 05:00:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-14B
[2026-01-26 05:00:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 05:00:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Qwen2.5-7B
[2026-01-26 05:00:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 05:00:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-3B
[2026-01-26 05:00:04] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 05:00:04] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B
[2026-01-26 05:00:04] INFO kernels.py:719: Preloaded 20 Triton kernels from H100_cc90_py312_cu129_x86_64
[2026-01-26 05:00:04] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=8, cuSPARSELt=5 models
[2026-01-26 05:00:04] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 05:00:04] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 05:00:04] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 05:00:04] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=838124) [2026-01-26 05:00:06] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (CUTLASS)
(EngineCore_DP0 pid=838124) [2026-01-26 05:00:06] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=CUTLASS)
(EngineCore_DP0 pid=838124) [2026-01-26 05:00:06] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=CUTLASS, symmetric=True
(EngineCore_DP0 pid=838124) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=838124) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.51it/s]
(EngineCore_DP0 pid=838124) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.50it/s]
(EngineCore_DP0 pid=838124) 
(EngineCore_DP0 pid=838124) 2026-01-26 05:00:15,631 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=838124) 2026-01-26 05:00:15,653 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=838124) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/36 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 1/36 [00:00<00:12,  2.92it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 8/36 [00:00<00:01, 21.85it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 18/36 [00:00<00:00, 42.64it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|███████▊  | 28/36 [00:00<00:00, 57.94it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:00<00:00, 47.50it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 36/36 [00:00<00:00, 40.04it/s]
(EngineCore_DP0 pid=838124) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL):  26%|██▌       | 9/35 [00:00<00:00, 89.05it/s]
Capturing CUDA graphs (decode, FULL):  51%|█████▏    | 18/35 [00:00<00:00, 39.80it/s]
Capturing CUDA graphs (decode, FULL):  69%|██████▊   | 24/35 [00:00<00:00, 23.63it/s]
Capturing CUDA graphs (decode, FULL):  80%|████████  | 28/35 [00:01<00:00, 18.31it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 27.19it/s]

Adding requests:   0%|          | 0/256 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 256/256 [00:00<00:00, 2636.10it/s]

Processed prompts:   0%|          | 0/256 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   0%|          | 1/256 [00:01<08:00,  1.88s/it, est. speed input: 8.50 toks/s, output: 135.95 toks/s]
Processed prompts:  67%|██████▋   | 172/256 [00:01<00:00, 120.89it/s, est. speed input: 1386.25 toks/s, output: 22179.69 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 120.89it/s, est. speed input: 1962.99 toks/s, output: 31407.57 toks/s]
Processed prompts: 100%|██████████| 256/256 [00:02<00:00, 122.67it/s, est. speed input: 1962.99 toks/s, output: 31407.57 toks/s]
[rank0]:[W126 05:00:21.621874578 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 32.6s

测试结果:
  Requests/s:   117.11
  Tokens/s:     31853.57
  Total Reqs:   256
  Elapsed:      2.19s

  [Decode 分析]
  Total Decode Tokens:  65536
  Decode Tokens/s:      29979.83


------------------------------------------------------------
  生成 CSV: Llama3.2-1B-INT8
------------------------------------------------------------
[SUCCESS] CSV 保存到: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/decode/H100_cc90_INT8_py312_cu129_x86_64/cutlass/Llama3.2-1B-INT8_decode.csv

预览:
------------------------------------------------------------
M_decode,prompt_len,max_num_seqs,num_prompts,N_decode,output_len,requests_per_s,tokens_per_s,elapsed_time_s
16,16,16,16,256,256,18.1004,4923.3009,0.8840
128,16,128,128,256,256,94.6337,25740.3561,1.3526
256,16,256,256,256,256,117.1087,31853.5715,2.1860

------------------------------------------------------------

[INFO] 完成: 3 成功, 0 失败

============================================================
  Llama3.2-1B-INT8 | cuBLASLt | prefill
============================================================

[INFO] Checkpoint: /root/vllmbench/checkpoints/Llama3.2-1B-INT8
[INFO] Output: /root/vllmbench/slidesparse/tools/throughput_benchmark_results/prefill/H100_cc90_INT8_py312_cu129_x86_64/cublaslt

============================================================
[1/3] 测试 M=16
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Llama3.2-1B-INT8                                │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 16
│   M_prefill     = 16 (= 1 x 16)
│   M_decode      = 1
│   batched_tokens = 17 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 16
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 17
│   --max-num-batched-tokens = 17
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 05:00:30 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=839358) WARNING 01-26 05:00:43 [backends.py:609] Failed to read file <frozen os>
Throughput: 33.83 requests/s, 575.11 total tokens/s, 33.83 output tokens/s
Total num prompt tokens:  2048
Total num output tokens:  128


─── STDERR ───
[2026-01-26 05:00:29] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 05:00:30] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 05:00:30] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 05:00:30] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:00:30] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:00:30] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:00:30] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:00:30] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:00:30] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 05:00:30] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 05:00:30] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 05:00:30] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 05:00:30] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 05:00:30] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 05:00:36] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 05:00:37] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 05:00:37] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 05:00:37] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:00:37] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:00:37] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:00:37] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:00:37] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:00:37] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 05:00:37] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 05:00:37] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 05:00:37] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 05:00:37] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 05:00:37] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=839358) [2026-01-26 05:00:39] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=839358) [2026-01-26 05:00:39] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=839358) [2026-01-26 05:00:39] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=839358) [2026-01-26 05:00:39] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=839358) [2026-01-26 05:00:39] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=839358) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=839358) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.28it/s]
(EngineCore_DP0 pid=839358) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.28it/s]
(EngineCore_DP0 pid=839358) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=839358) 2026-01-26 05:00:48,364 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=839358) 2026-01-26 05:00:48,398 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=839358) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  2.61it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  2.12it/s]
(EngineCore_DP0 pid=839358) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 2838.90it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:59,  2.15it/s, est. speed input: 34.42 toks/s, output: 2.15 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:11, 11.02it/s, est. speed input: 141.35 toks/s, output: 8.83 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:06, 18.04it/s, est. speed input: 214.42 toks/s, output: 13.40 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:04, 23.59it/s, est. speed input: 268.57 toks/s, output: 16.79 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:04, 27.74it/s, est. speed input: 309.70 toks/s, output: 19.36 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 30.83it/s, est. speed input: 342.25 toks/s, output: 21.39 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:01<00:03, 33.13it/s, est. speed input: 368.74 toks/s, output: 23.05 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:01<00:02, 34.72it/s, est. speed input: 390.41 toks/s, output: 24.40 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 35.87it/s, est. speed input: 408.66 toks/s, output: 25.54 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 36.66it/s, est. speed input: 424.13 toks/s, output: 26.51 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 37.26it/s, est. speed input: 437.55 toks/s, output: 27.35 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 37.69it/s, est. speed input: 449.28 toks/s, output: 28.08 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 37.96it/s, est. speed input: 459.49 toks/s, output: 28.72 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:01, 38.15it/s, est. speed input: 468.55 toks/s, output: 29.28 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 38.30it/s, est. speed input: 476.64 toks/s, output: 29.79 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:02<00:01, 38.41it/s, est. speed input: 483.94 toks/s, output: 30.25 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:02<00:01, 38.49it/s, est. speed input: 490.52 toks/s, output: 30.66 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 38.54it/s, est. speed input: 496.48 toks/s, output: 31.03 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 38.56it/s, est. speed input: 501.88 toks/s, output: 31.37 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 38.61it/s, est. speed input: 506.87 toks/s, output: 31.68 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 38.61it/s, est. speed input: 511.42 toks/s, output: 31.96 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 38.84it/s, est. speed input: 515.99 toks/s, output: 32.25 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:00, 39.05it/s, est. speed input: 520.31 toks/s, output: 32.52 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 39.08it/s, est. speed input: 524.13 toks/s, output: 32.76 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 39.03it/s, est. speed input: 527.58 toks/s, output: 32.97 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:03<00:00, 39.16it/s, est. speed input: 531.02 toks/s, output: 33.19 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:03<00:00, 39.10it/s, est. speed input: 534.04 toks/s, output: 33.38 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 38.95it/s, est. speed input: 536.71 toks/s, output: 33.54 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 38.88it/s, est. speed input: 539.25 toks/s, output: 33.70 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 38.80it/s, est. speed input: 541.62 toks/s, output: 33.85 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 38.71it/s, est. speed input: 543.79 toks/s, output: 33.99 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 39.02it/s, est. speed input: 546.32 toks/s, output: 34.14 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 39.02it/s, est. speed input: 548.05 toks/s, output: 34.25 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 34.25it/s, est. speed input: 548.05 toks/s, output: 34.25 toks/s]
[rank0]:[W126 05:00:54.803734894 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

[SUCCESS] 测试完成! 耗时: 33.2s

测试结果:
  Requests/s:   33.83
  Tokens/s:     575.11
  Total Reqs:   128
  Elapsed:      3.78s

  [Prefill 分析]
  Total Prefill Tokens: 2048
  Prefill Tokens/s:     541.28

============================================================
[2/3] 测试 M=128
============================================================

┌─────────────────────────────────────────────────────────────┐
│                    测试参数                                  │
├─────────────────────────────────────────────────────────────┤
│ 模型:     Llama3.2-1B-INT8                                │
│ Backend:  cuBLASLt [INT32 output]                         │
│ 阶段:     prefill                                         │
├─────────────────────────────────────────────────────────────┤
│ GEMM M 维度 (精确控制):
│   目标 M        = 128
│   M_prefill     = 128 (= 1 x 128)
│   M_decode      = 1
│   batched_tokens = 129 (控制 M 的关键参数)
├─────────────────────────────────────────────────────────────┤
│ vLLM 参数:
│   --input-len              = 128
│   --output-len             = 1
│   --num-prompts            = 128
│   --max-num-seqs           = 1
│   --max-model-len          = 129
│   --max-num-batched-tokens = 129
│   --no-enable-chunked-prefill
├─────────────────────────────────────────────────────────────┤
│ 迭代次数:
│   N_prefill = 128
│   N_decode  = 0
└─────────────────────────────────────────────────────────────┘

[INFO] 开始测试...

─── STDOUT ───
When dataset path is not set, it will default to random dataset
WARNING 01-26 05:01:03 [arg_utils.py:1869] This model does not officially support disabling chunked prefill. Disabling this manually may cause the engine to crash or produce incorrect outputs.
(EngineCore_DP0 pid=840480) WARNING 01-26 05:01:16 [backends.py:609] Failed to read file <frozen os>
Throughput: 35.28 requests/s, 4550.73 total tokens/s, 35.28 output tokens/s
Total num prompt tokens:  16384
Total num output tokens:  128


─── STDERR ───
[2026-01-26 05:01:02] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 05:01:03] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 05:01:03] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 05:01:03] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:01:03] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:01:03] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:01:03] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:01:03] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:01:03] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 05:01:03] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 05:01:03] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 05:01:03] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 05:01:03] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 05:01:03] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
[2026-01-26 05:01:10] INFO kernels.py:578: Triton kernel custom ops registered
[2026-01-26 05:01:11] INFO kernels.py:627: Optimization enabled: Only preloading kernels for model 'Llama3.2-1B-INT8'
[2026-01-26 05:01:11] INFO kernels.py:109: Loaded tuned kernel for model: Llama3.2-1B-INT8
[2026-01-26 05:01:11] INFO kernels.py:155: Dequant+bias kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:01:11] INFO kernels.py:224: FP8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:01:11] INFO kernels.py:348: INT8 quant kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:01:11] INFO kernels.py:284: FP8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:01:11] INFO kernels.py:408: INT8 quant+slide kernel loaded for model: Llama3.2-1B-INT8
[2026-01-26 05:01:11] INFO gemm_wrapper.py:157: Optimization enabled: Only loading GEMM configs for model 'Llama3.2-1B-INT8'
[2026-01-26 05:01:11] INFO gemm_wrapper.py:172: Loaded algorithm configs: cuBLASLt=1, cuSPARSELt=1 models
[2026-01-26 05:01:11] INFO gemm_wrapper.py:944: cuBLASLt FP8 custom op registered: slidesparse::cublaslt_fp8_mm
[2026-01-26 05:01:11] INFO gemm_wrapper.py:1009: cuSPARSELt FP8 custom op registered: slidesparse::cusparselt_fp8_mm
[2026-01-26 05:01:11] INFO gemm_wrapper.py:1075: cuBLASLt INT8 custom op registered: slidesparse::cublaslt_int8_mm
[2026-01-26 05:01:11] INFO gemm_wrapper.py:1141: cuSPARSELt INT8 custom op registered: slidesparse::cusparselt_int8_mm
(EngineCore_DP0 pid=840480) [2026-01-26 05:01:12] INFO SlideSparseLinearMethod_INT8.py:805: Wrapping CompressedTensorsW8A8Int8 with SlideSparse (cuBLASLt)
(EngineCore_DP0 pid=840480) [2026-01-26 05:01:12] INFO gemm_wrapper.py:870: cublaslt GEMM extension loaded: cublaslt_gemm_H100_cc90_py312_cu129_x86_64.so
(EngineCore_DP0 pid=840480) [2026-01-26 05:01:12] INFO SlideSparseLinearMethod_INT8.py:452: SlideSparseInt8LinearOp initialized (kernel=cuBLASLt)
(EngineCore_DP0 pid=840480) [2026-01-26 05:01:12] INFO SlideSparseLinearMethod_INT8.py:621: Preloaded INT8 Triton kernels for model: Llama3.2-1B-INT8
(EngineCore_DP0 pid=840480) [2026-01-26 05:01:12] INFO SlideSparseLinearMethod_INT8.py:625: SlideSparseInt8LinearMethod initialized, kernel=cuBLASLt, symmetric=True
(EngineCore_DP0 pid=840480) 
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
(EngineCore_DP0 pid=840480) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.58it/s]
(EngineCore_DP0 pid=840480) 
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  5.57it/s]
(EngineCore_DP0 pid=840480) 
[cuBLASLt] INFO: INT8 GEMM only supports INT32 output. inner_dtype parameter is ignored, always using int32.
(EngineCore_DP0 pid=840480) 2026-01-26 05:01:21,418 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
(EngineCore_DP0 pid=840480) 2026-01-26 05:01:21,462 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
(EngineCore_DP0 pid=840480) 
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/2 [00:00<?, ?it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  50%|█████     | 1/2 [00:00<00:00,  6.46it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 2/2 [00:00<00:00,  8.93it/s]
(EngineCore_DP0 pid=840480) 
Capturing CUDA graphs (decode, FULL):   0%|          | 0/1 [00:00<?, ?it/s]
Capturing CUDA graphs (decode, FULL): 100%|██████████| 1/1 [00:00<00:00, 14.74it/s]

Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]
Adding requests: 100%|██████████| 128/128 [00:00<00:00, 1392.09it/s]

Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]
Processed prompts:   1%|          | 1/128 [00:00<00:32,  3.96it/s, est. speed input: 506.65 toks/s, output: 3.96 toks/s]
Processed prompts:   4%|▍         | 5/128 [00:00<00:07, 16.18it/s, est. speed input: 1747.61 toks/s, output: 13.65 toks/s]
Processed prompts:   7%|▋         | 9/128 [00:00<00:04, 23.89it/s, est. speed input: 2461.35 toks/s, output: 19.23 toks/s]
Processed prompts:  10%|█         | 13/128 [00:00<00:03, 28.92it/s, est. speed input: 2923.59 toks/s, output: 22.84 toks/s]
Processed prompts:  13%|█▎        | 17/128 [00:00<00:03, 32.30it/s, est. speed input: 3248.21 toks/s, output: 25.37 toks/s]
Processed prompts:  16%|█▋        | 21/128 [00:00<00:03, 34.58it/s, est. speed input: 3487.40 toks/s, output: 27.24 toks/s]
Processed prompts:  20%|█▉        | 25/128 [00:00<00:02, 35.92it/s, est. speed input: 3662.77 toks/s, output: 28.61 toks/s]
Processed prompts:  23%|██▎       | 29/128 [00:00<00:02, 36.83it/s, est. speed input: 3801.03 toks/s, output: 29.69 toks/s]
Processed prompts:  26%|██▌       | 33/128 [00:01<00:02, 37.44it/s, est. speed input: 3912.54 toks/s, output: 30.57 toks/s]
Processed prompts:  29%|██▉       | 37/128 [00:01<00:02, 37.81it/s, est. speed input: 4003.04 toks/s, output: 31.27 toks/s]
Processed prompts:  32%|███▏      | 41/128 [00:01<00:02, 38.11it/s, est. speed input: 4080.29 toks/s, output: 31.88 toks/s]
Processed prompts:  35%|███▌      | 45/128 [00:01<00:02, 38.25it/s, est. speed input: 4144.25 toks/s, output: 32.38 toks/s]
Processed prompts:  38%|███▊      | 49/128 [00:01<00:02, 38.37it/s, est. speed input: 4199.95 toks/s, output: 32.81 toks/s]
Processed prompts:  41%|████▏     | 53/128 [00:01<00:01, 38.45it/s, est. speed input: 4248.19 toks/s, output: 33.19 toks/s]
Processed prompts:  45%|████▍     | 57/128 [00:01<00:01, 38.51it/s, est. speed input: 4290.86 toks/s, output: 33.52 toks/s]
Processed prompts:  48%|████▊     | 61/128 [00:01<00:01, 38.51it/s, est. speed input: 4327.54 toks/s, output: 33.81 toks/s]
Processed prompts:  51%|█████     | 65/128 [00:01<00:01, 38.50it/s, est. speed input: 4360.12 toks/s, output: 34.06 toks/s]
Processed prompts:  54%|█████▍    | 69/128 [00:02<00:01, 38.51it/s, est. speed input: 4389.64 toks/s, output: 34.29 toks/s]
Processed prompts:  57%|█████▋    | 73/128 [00:02<00:01, 38.55it/s, est. speed input: 4416.90 toks/s, output: 34.51 toks/s]
Processed prompts:  60%|██████    | 77/128 [00:02<00:01, 38.54it/s, est. speed input: 4440.86 toks/s, output: 34.69 toks/s]
Processed prompts:  63%|██████▎   | 81/128 [00:02<00:01, 38.53it/s, est. speed input: 4462.78 toks/s, output: 34.86 toks/s]
Processed prompts:  66%|██████▋   | 85/128 [00:02<00:01, 38.51it/s, est. speed input: 4482.50 toks/s, output: 35.02 toks/s]
Processed prompts:  70%|██████▉   | 89/128 [00:02<00:01, 38.53it/s, est. speed input: 4501.16 toks/s, output: 35.16 toks/s]
Processed prompts:  73%|███████▎  | 93/128 [00:02<00:00, 38.58it/s, est. speed input: 4518.81 toks/s, output: 35.30 toks/s]
Processed prompts:  76%|███████▌  | 97/128 [00:02<00:00, 38.60it/s, est. speed input: 4534.97 toks/s, output: 35.43 toks/s]
Processed prompts:  79%|███████▉  | 101/128 [00:02<00:00, 38.59it/s, est. speed input: 4549.64 toks/s, output: 35.54 toks/s]
Processed prompts:  82%|████████▏ | 105/128 [00:02<00:00, 38.57it/s, est. speed input: 4563.11 toks/s, output: 35.65 toks/s]
Processed prompts:  85%|████████▌ | 109/128 [00:03<00:00, 38.79it/s, est. speed input: 4578.78 toks/s, output: 35.77 toks/s]
Processed prompts:  88%|████████▊ | 113/128 [00:03<00:00, 39.03it/s, est. speed input: 4594.54 toks/s, output: 35.89 toks/s]
Processed prompts:  91%|█████████▏| 117/128 [00:03<00:00, 39.17it/s, est. speed input: 4608.91 toks/s, output: 36.01 toks/s]
Processed prompts:  95%|█████████▍| 121/128 [00:03<00:00, 39.06it/s, est. speed input: 4619.91 toks/s, output: 36.09 toks/s]
Processed prompts:  98%|█████████▊| 125/128 [00:03<00:00, 38.87it/s, est. speed input: 4628.92 toks/s, output: 36.16 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 38.87it/s, est. speed input: 4635.40 toks/s, output: 36.21 toks/s]
Processed prompts: 100%|██████████| 128/128 [00:03<00:00, 36.21it/s, est. speed input: 4635.40 toks/s, output: 36.21 toks/s]
[rank0]:[W126 05:01:26.943670824 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())

======================================================================
收到中断信号 (signal 2)
======================================================================
[INFO] 状态已保存: /root/vllmbench/slidesparse/tools/prepare_bench_20260125_221852_status.json
